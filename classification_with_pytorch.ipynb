{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMaqJyU8BuGt5qA2OgeOVdi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeDKYLmYCNk7"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_circles\n",
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = 1000\n",
        "\n",
        "X,y = make_circles(n_samples, noise=0.03,random_state=42)\n"
      ],
      "metadata": {
        "id": "Q8KofSA3Clde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "g5gy77PWDLbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "circles = pd.DataFrame({\"X1\": X[:,0], 'X2':X[:,1], 'label': y })\n",
        "circles.head()"
      ],
      "metadata": {
        "id": "cIiXu8KlDnNS",
        "outputId": "279629e3-d8ec-45b9-becb-1dbe2725fa86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         X1        X2  label\n",
              "0  0.754246  0.231481      1\n",
              "1 -0.756159  0.153259      1\n",
              "2 -0.815392  0.173282      1\n",
              "3 -0.393731  0.692883      1\n",
              "4  0.442208 -0.896723      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe2b890e-8942-42b6-8af6-1ef02cdfbf75\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.754246</td>\n",
              "      <td>0.231481</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.756159</td>\n",
              "      <td>0.153259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.815392</td>\n",
              "      <td>0.173282</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.393731</td>\n",
              "      <td>0.692883</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.442208</td>\n",
              "      <td>-0.896723</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe2b890e-8942-42b6-8af6-1ef02cdfbf75')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fe2b890e-8942-42b6-8af6-1ef02cdfbf75 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fe2b890e-8942-42b6-8af6-1ef02cdfbf75');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-492ad2da-80d6-4937-9f21-cf4cc98c98b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-492ad2da-80d6-4937-9f21-cf4cc98c98b2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-492ad2da-80d6-4937-9f21-cf4cc98c98b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "circles",
              "summary": "{\n  \"name\": \"circles\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"X1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6398365674574613,\n        \"min\": -1.0595024599098635,\n        \"max\": 1.0337117525463373,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          -0.3751930206933384,\n          0.015380346701456493,\n          -0.7027835978832848\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6411559581015384,\n        \"min\": -1.0677683182718436,\n        \"max\": 1.0360036756154805,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          0.6826597225888621,\n          0.9600260220697324,\n          -0.3147169925147762\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the number of each value that we have\n",
        "circles.label.value_counts()"
      ],
      "metadata": {
        "id": "JFgqvjSYESpR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "90a1de78-fcba-40dd-de41-8e13523c0b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "1    500\n",
              "0    500\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BcdeaQ7uFAHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***visualize with a plot***"
      ],
      "metadata": {
        "id": "oxKiLXSYFb4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X[:,0],X[:,1], c=y, cmap=plt.cm.RdBu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "iWukiyttFfmN",
        "outputId": "86a4061e-504f-4ed1-9015-0e66ece0b6fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7aca45e8a050>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGdCAYAAADaPpOnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOyddXgUVxeH35nZeEiQQHB3d3d3d4o7heItfKWFUgot3hZ3d/fi7u7ukBAIkBDP7sz3R0hKSNaSTZDe93ko3Zk7954Nm53fnHtE0jRNQyAQCAQCgeALQf7UBggEAoFAIBBYgxAvAoFAIBAIviiEeBEIBAKBQPBFIcSLQCAQCASCLwohXgQCgUAgEHxRCPEiEAgEAoHgi0KIF4FAIBAIBF8UQrwIBAKBQCD4otB9agNsjaqqPH/+nCRJkiBJ0qc2RyAQCAQCgQVomsa7d+9ImzYtsmzat/LViZfnz5+TIUOGT22GQCAQCASCOPDkyRPSp09vcsxXJ16SJEkCRLx5Nze3T2yNQCAQCAQCS/D39ydDhgxR93FTfHXiJXKryM3NTYgXgUAgEAi+MCwJ+RABuwKBQCAQCL4ohHgRCAQCgUDwRSHEi0AgEAgEgi8KIV4EAoFAIBB8UQjxIhAIBAKB4ItCiBeBQCAQCARfFEK8CAQCgUAg+KIQ4kUgEAgEAsEXxVdXpE4gEAgiCQ8J4enlm2iqStr8uXB0dbHoOj9vH24fOIFqUMlcshCeObMmsKUCgcAahHgRCARfHYbwcLaP/ov9fy8ixO8dAPbOTpTv0YbGY7/H3skx1utCA4NY+e1PnF62EdWgRh3PXb08HRdNJFm61BbbEPj6LYdmLuP4gjW88/ElaTpPyndvQ4UebXBM4hq/NygQ/MeRNE3TPrURtsTf3x93d3f8/PxEewCBIBEJeuvH60fPkBQFj6wZcXB2stncoYFBnFi8nmPzV+Pn5UOy9Gko360Vpdo3jSFEVFVlbos+XNj4D3z09SbJMtkrlKD/7qXo7O2jX2cwMLV6O+4cOY32gXABkHUKydKn4X/nt+OSzN2svW+eejGhfHPePPFCU/+dS5IlPHNlY8jhNbh6JLf2xyAQfNVYc/8W4kUgEMQLPy8fNvwwjjMrtqAaDFHHU2bLRM0feqGzt+PS5t08PncN2U6hYP1qVPq2A545slg0/7uXvkyq1Arvm/ciDmgakiShoZGhcD4G7l+Bc9J/BcWVHQeYXq+zyTk7LJxA2U4toh27vG0fMxp0NXqNJMs0+m0ItYf1MWvz5KptuHvkNKreEOOcrCgUaVab7qunm51HIPgvIcSLEC8CgVkMej0v7z0CTSNltkwodnZWz+H/4iXjSjTkzVPvGF4OY8iKgiTL9Nwwi4L1q5kdP6NRN65uPxBNGH04V9EW9ei28q+oYzMbd+fKtv2xjocIEZK5ZCF+OLGR8NBQXj9+jp2jA2sHjubSpj1GrwNwSZGMRr8NIX+dyiTPmC7WMd437zIqT3WT70mSZcY9OUHStJ4mxwGEBYeg6vU4uLpY1LBOIPhSseb+LWJeBIL/GAa9nj0TZrNv6gLe+fgCkCRVCqoN6EKNoT1RdJZ/LWwbNZW3z15YLFwgYnsGVWVO89789uAo7mlSGR376uETLm/dZ3R+1WDg/Npt+E0eETXPy3uPTAoQTVV5ee8R64eO5cicFYT4BwCgc3QweR1AoO8bVvQegQQUb92Ab+b+joOLc7QxD05dNDlHpA2Pz10xKV4ub93LP3/M4t6xs0CEJ6vqgC6U794axc4OWRbJooL/LuLTLxD8h1BVlQXt+rPpx4lRwgXgnY8vm36cyLzW/QgPCzM7j7/PKw7NXMbReaujxXRYjKZhCNdzdO5Kk8NuHzhpVhipBpUHpy4A8OzKTQJevTG7fMi7QPZNmRclXAD0IaEWGA5oGpqmcXbNNmY16cnHzmtZUSyaRtYZH7d74hxmNOzG/ZPno469vPeI1f1G0s8xF9/aZWdavc7cOnjCMpsFgq+MBBUvhw8fpkGDBqRNmxZJkti0aZPZaw4ePEjRokVxcHAge/bsLFq0KCFNFAi+Cgzh4Vz75xAnl27g1oHjRj0IV7bt49ya7bELAk3jwvqd9HPIyY9ZK7Bn0lzCQ0KACA/HtX8Osf+vhfxZuwPD0pZiZZ8RqHp9nG3WVJXbh04ZPR8SEMiOX/8yej4aksTZNdv4rUjdaKLM2Fh9aFi0bKK4oBlUbuw5wtWdB6Idz1mlDJIZr4idowPZyhaL9Zz3rXts+H5c1Bqxrq2qXP/nMFOqtuXovFVxsF4g+LJJ0G2jwMBAChUqRJcuXWjatKnZ8Q8ePKBevXr06tWL5cuXs2/fPrp160aaNGmoVatWQpoqEHyxnFyynnVDxhLw8t+btluaVLT6cyTFWtSLNnb3+NkWzen74Akbvh/LxU3/UOuH3qzo/SNvn3rb1G7AZAzH1p8n4/vomfk5ZJmTyzZycf0us14aWaegqVrcvEVGmNGgG6U7NKXRb0NJmtaTZOlSU6JNQ86s3GJ0naxli+HkHvue/pHZK5AVOdZg3w+JFKjLe/6PvDUrGI3BEQi+RhItYFeSJDZu3Ejjxo2Njvnhhx/Yvn07V69ejTrWunVr3r59y65duyxaRwTsCv5LHF+0liWdhxo9n6dmBTounEjStJ68eviEEVkrWhWfIskSmgYSxNgeiS+SLNNozGBqD/82xrmw4BCGpipKaECQTdfMUDQ/T85fNT/QSmSdQpJUHvTdsRCva3cIfP2WdYN+xRBu3DPVf88y8lQvH+P45KptuH3A8u0gWVGoPbwPDX8dHCfbBYLPhS82YPfEiRNUrx49Sr9WrVoMGDDA6DWhoaGEhv67V+3v759Q5gkEn4ygt36cW7uDt8+8cfP0oFiLejgkcWH94N9MXndj9xF+yVeDqgO68ODkeauEC4CmRoxPiCccSZZw8UiOITw8RqaT78OnNhcuOnt7yndvzZrvRpkUFXFB1Rvw8/LhtyL1LPoZy4rC7vGzYxUv9s5OEaJRteynrhoMPDp3xWqbBYIvmc9KvHh7e+PpGT363tPTE39/f4KDg3Fyiln0aty4cfzyyy+JZaJAkOjsmzqfjcPHow8NQ9EpqHoDa/r/QtHmdQl8/dbs9cFv/dk+amqC22ktqt7A8h7DWTNgNF2WTqFI09pR53QO9iaujBv6sDBW9vkJ0ECSrBZyZrEy4+rGniPow8PRfSTcijSpxdXt+61aOviteGgT/Lf44rONhg8fjp+fX9SfJ0+efGqTBAKbcWTuStYO/DUiE+Z9ho72/u8zK7d8avNiIkmkL5yXNPlyRNRzkSSTWTUA4UHBzG7Wixv7jkYd88iSgZTZM0eIDFuiaRFupM+kvNWqvj/H2I4r0aYhSdOnsThrCeD+yQvcfZ9SLRD8F/isxEvq1Kl58eJFtGMvXrzAzc0tVq8LgIODA25ubtH+CARfGs+u3OTqzgM8Ons56mZm0OvZ8tOkT2yZ5cg6hdIdmjLiwg5GXt3DeO8ztPr7F2r90JtSHcwH7Ed4RSKQJIk6P36bKCJD1ikRQT3/Lh5lAxIkTedJwYbVkWTbF4g7OmclU6q25fm121HH7J2dGLh/BckyprV8Ik1j22foXRMIEorPatuoTJky7NixI9qxPXv2UKZMmU9kkUCQsNw9eoZV/Uby9OL1qGOpcmSm+aQROLq58u7Fq09oneXIioJzUnca/DIw6pirR3Iqf9sBgNEFapqdw+f2A9489SJZ+jQAlOnYnDePn7N15BRkRUFVVYuycCxFkmUKNKjGg5MXePfiFZIsR2QHvRdMzsndafDLIMp0ao6DizMPTl/kj1KNbbL2h9w+eIKxxerz7bYFUTEwnjmyMPrWfhZ1HGyxh+3m3qMEvn6LS/KkNrdRIPjcSFDxEhAQwN27d6NeP3jwgIsXL5I8eXIyZszI8OHDefbsGUuWLAGgV69eTJs2je+//54uXbqwf/9+1qxZw/bt2xPSTIEgwQgPDeXU0o0cmbMC34dPcfVITplOzSnfvQ3Pr95iarV2MWqy+Nx9xIxG3chRsdQnsto6JEkiX53KtPprFCkypY91jJ/XS4vmCvR9EyVeJEmi3s/9Kd6mIcfmrcLnzkMc3Vyxd3bi8Mxl8bZbVhSeX7lF4Puidh+nNQe98eflvUdRFXSzlCxMqfZNOb18k01TrSEiHmd6vc7krlEB56RuFG1Rl7w1K3Bj7zGr5gn2fxdv8fLo3BX2TV3A9V2HUFUDOcqXpOqAzuSqUjZe8woEtiRBU6UPHjxIlSpVYhzv2LEjixYtolOnTjx8+JCDBw9Gu2bgwIFcv36d9OnT89NPP9GpUyeL1xSp0oLPhZCAQP6s8Q0PTl6Ilj0iyTLJ0qfGztkZn9v3bX4jTAySZkhD+W6tyVGxJKlyZCFZutRR517cvs/b5y9wT52S1LmzA/BTjsq8vPvQ7LwTX13ANUWyWM+Fh4RwatkmDs9cxuMLV+OfAiVhdg47J0fGe5/ByS1JhA2hoSzv8T9OLlmPrMhIsoIhPDyehkRHVhRUgwHPXNl4ceuexdfZOTow6fWlGF22IzHo9VzZto/ru4+gGQxkLlWEEq0bYP9B9+/ji9aytMv3SB94uOT3QeINxwyh7o994/fmBAITiMaMQrwIPjFhwSGs6vszJxavi7VKqqTIRqunJhaSLGPv7GhRSrKsKJTr2ooizWrjlNSNTMULxuitc+/4OdYOHM3D05eijmUonJfmk0fw5MJ11g0eY3KNNPlzMvLK7ljPBfu/Y2r1djw6c9mqNOKoraDYzikKmpleRgAD9i4nd7Vy0Y753H3I+XU7CPZ7R8psmbix5yjn1263aS0caz8jGYrm48dzsXupfe4+5O/aHXl57xGyToemaWgGA4q9HSXbNqLuT9+hGgyMyl3NpJgeeGAluSpH38YP9n/HqWWbuLp9P/rQMDKVKEiFHm3xyJLBYtsFAhDiRYgXwSfj0pY9/PPHLO4fP/epTTGLrNOhGvQWeTDsnZ0YdWOv0Squdw6fYmr1b1ANhmg3P0mWkSTovm4my7sPJ+DV69gXkCSGndpE5hKFYj29uPMQTi3daLZx4sc4ubsRGhAY63VFW9Tl/NodsVwVne92LyVvjQomxxj0erb+PJn9fy0kLDDYKhttSb2RA2gwakC0YyEBgYzKUx1/Lx/jPz8JMhbNz5OL140KJlmnULBBdXpt+LdK89NL15la/RsCfN/3k9I0ZEVB0zS+mTOOcl1b2eJtCf4jWHP//qyyjQSCT0nQWz92jPmb4RnL0sc+O9+nKcGmHyfg/8KyeI3dE2Yzs1F3Hpy8kMCWmke2Mx/OphoM2DnGvsUQbS6djr47FhoVLpqmsaLPTzGEC0TEkWiqxtoBoxl2dgse2TLGuN7B1YXv/lliVLgEvHrNqWWbrBYuKTKnZ9jZLeSvWzlaG4IUmdPTafEkirduaHYOxU5HxqL5zY/T6Wg89nvGe5+l385F1B7eB2zQ9dlcj6SP2f7LVHb8Ni3asTMrNvP2mZfpn58Gj89dNenpUfUG7h49E/U6NDCIP2u2J+iN3/sU9AgVHPk5WNp9WLTxAoEt+ayyjQSCT4W/zysmlGvOq/uPo27A/t4v2f3HLI4vWMPQY+tJmfXfG6+maXjfvEewnz8eWTIQ9Mbv32Z6nyCGJXKLQdbpSJktIz53Hpq9xs7RgVLfNOb4wrUmM3g6L5tCzkqljZ5/fP4qXh+k+n6Mpmm8fvSM1w+f8uudQ9w/eYGzq7YQFhRCvtqVKNK0tskeR4/OXo5TA8gmv/+AZ/bM9Nkyn7fPX/Dy7kMckriQvlBeZFlmao1vzM5RrHVDozE4seHo6kK+2pXJV7sy/t6vOLl0fbyyoyRZImW2LPjceWBxYb0tIyaSpVThqMylC+t3IiGh2aBO8oe1Z06v2My7l75GPXeyIrNn4hyyly8R73UFgo8R4kUgAFb2HoHvwycxhIdqMBDw6jUL2w/g+2MbADi/fidbRkzE+2ZEMKUky3hkSR8VaJnYNJ80AiRwcktCrmrl+DlHJfMCSpLotHgSmYoX5OzqbYQFBsXosiwrChmL5adY87omp/J9+NQiO18/eoYkSWQrU5RsZYpadE2krRYNex/f4ujmSsupP1O8VYOoc0nTepI07b/Vu18/ec7NvUdjmyYauavEvUxDtUFdObVsI5KkxjkWRtUbqD+qP/bOTqzq+zNvn70we42kyOybOj9KvIQGBtksFscj679xLNd3HUKSJKNzq3oD13Ydssm6AsHHCPEi+M/z5pk3FzftNnrDV/UG7h8/z6Nzlzk8cznH5q+Odl5TVV7ee2zVmrKikMTTA3/vl3H21EiyjGfOLFQb2DXKc/H68TPzT/qSROEmtaI6Tg/cv5I5zXvj+/BpRNdlTUMzqOSuVpauK/82W+nVJUVSi+x1scKD8SFZShVG52CPPjTM5LiaQ3uQvlAeCjWuZTTjJpLXj5+bXVdWFN75xL3OTrr8ueizZS5zmvchNCg4IsBZklD1ehzdkpC+UB7e+bzC5/aDWAWAJMu4pEhK0eZ10dnbE+j7lqXdfjC7rmZQuXv43+2a9IXy8uDURZvUx3l87ipPL10nfaG8GPR6s4HTqt6ApmkmPWsCQVwQ4kXwn+fpxesWCYjJldsQGhBokzXT5M2BZ66sXNz4T5yc+ZIsI8kybWf9Fu3G4Jw8aVRqqzFkWY4Wx5GpWAF+vXeYG7sP8+jsFRR7O/LXrUK6/LkssiV7+RK4p0mFn5eP0THOydzJXb2c0fOmcE7qTtkuLTkye0Ws/06yopC/flWa/D7M4jldPcwLKVVV4yy4IslXuzK/Pz/FqWWbeHTmEoqdHflqV6Jgg2oodnaEBQUzpXo7Hp66EE0IyDoFRaej57qZ6Owj+jyVaNOQ9UPHRsSYmOMDrVChZ1sOzVgar/cRiT4sjCnV2vHLrf1kLFaAK1v3GfW8SLJMxmL5hXARJAgiYFfwn0extzM/CGwmXGoN682wM5vJWbk0ahy9LplKFGTQgZUxYlEcXV0o2ryuyX5CmqpSun2TaMdkWSZf7crUHdGPWt/3sli4QESwapM/TAuHRr8Nwc7BweI5P6b5pBHkrBLxXmUl4msrMpg1XaHcdFwwwar5PHNmJX2hPCZL/it2umjNIuOKk1sSKvdpT8eFE/lmzjiKNK0d1UXb3tmJgftW0GzCjxFbMpKEvYszpTs048cL26MVKrR3dqL35rkoZoKxZZ1Cnhr/dqtOXzAPlft2iPf7AECDoDdv2fLTJA5NX2JyO0pTVar27wJAWFAwFzbu4sjclVzfc+STbK8Kvi5EqrTgP09IQCDfexYnLChxUlwr9mpHjkqlyFauOL/krUGYhTEJOns7eqybSaqcWUidK5vRcd637jGuREPCg0JivUnUGNKDZhP+F6/3EBtH561i3eAxhPgHRAUQ27s403jsUKp+1zne8xv0ei5v2cvReat4/egZbqlTUrZzC4q2qBsnYXRt10Gm1e0c4fmK5edf96fvaDh6ULzttgZLtlgenr3M+DJNTQYxDzm6juzlike9nlSpJXcOn7aZnUhSRLyLCfFdvnsb2s76jQN/LWTryCmE+AdEnUuaPjXtZo2lQL2qtrNJ8MUj6rwI8SKwgLfPX3Bw+hK8b9zF68ZdXty0vJqpLbBzdKBI8zqcW7MdTVXNxiQ0+m0odf73rUVzP718gyVdvufxuStRxxySuFDrh97U+d+3CebKDwsO4fKWPbx99gK31Ckp1KhGVHn9z5ELG3axrMdwAn3fRAkuxd4OpVJFbmTMiYuzAw0rF6VVnVK4OMXdc2Rrbu47xvQGXdGHhUWlN8s6BdWg0nraaCr3aR819sWdB4zMGbPSeULSaOxQag/rw74p82MtThjR9FLiu3+WRAUWCwRCvAjxIjDDmoGj2T91gckxkdlDOgcH9KGhZueUZBnZTochLNyqbshlu7bEzsGB8+t2EhoQiCFcH63kvL2zE/V+/o6a3/eyWnQ8vXQdrxt3cXB1IXfVstFKwQsi0IeFcWX7fnwfPOXYzadMPHkPvb0DBoMalU2TLlUy/pkzlJyZUpufMJF488ybo3NWcGX7AQxh4WSvUIKKvb+JseV3ZccBptcz7/lySOJK6LsAs+PMIet0VO7bgYajBzHUszjhwSGxjpNkiXQF8zDigvlCgYL/BkK8CPHyn0M1RGQ1KDrj8QBhwSGcWraRbb9Mxc+ClNNUOTLTevqv7P9rYUSTOjOeEUmRaTHlZzYMHYuqN1i8ry8pMuMen4hK5TXo9VzffSSikWOKpOSvVxVHVxeL5hLEnZ1HLtPou6mxnlMUmXSpknFj8zjsLCgA+Dlx99hZJpZvbnZcjcHd2TtlfrzrFMmKQslvGpOnenkWth9odvzI63tJkyd7vNYUfB1Yc//+sn4LBYKPuPbPIfZMnMOt/cfRVI30hfJQoVc70uTJjiRJZCiSD8ckrgT4vmFKlTY8u3LT4rl97jwkWfo0VO7Tnqvb9psc6+jmSuelUyjUsAbZyhZj848TuP7PYcsW0uDsqq1UH9QNiAiALVA3cd38Api4aAeKLGOI5eZtMKg89vJl88ELNK/xZRVdy1KqsNlsMDtHB+r+1I88NSuwbshYnlvxexITjZRZM/LOx9ei/kxvnnrx9NJ1ru06hCFcT+aShSjdoRkuydzjYYPga0eIF0GiE+z/jpNLNnB21VaC/fxJmy8nFXq2JWflMlZti+z/ayFr+v8S0UvlfZrp00s3WNl7RNQYOydHKvRow8v7j/G6fscqO2Wdwskl62k89nuTfXAylyrM4EOro4JGPXNmwT1NKrMpy1HrxLOeiCD+hIaFc+S88SrBADpFZvexK1+ceFF0OhqMHsSy7sYzwmoM7YmTuxt5a1bkp0sV8LpxlxOL1nJx426LuoF/iKZplO7UnOML1ljUWHJxp8H4PfeJ+D1G4+zKLWz633i6r55OwfrVrFpb8N9BiBdBovLy3iMmVWrF2+fvt23el9k/u3obFXq0pc3MMTG6FceG9827rBkwGsDk9kx4cAj7/1pkVQxKJKregO/DpwS9ecsNY9VYpYg6MW+eeJEqe2bCQ0Mjuh+fu2JxR2BVrydZhrRW2yewHQYL/q00INwGhd4+BeW7tSbEP4CNw/9ADde/b8oZ8V6qD+pG/Q+aOUqSRNq8OWg2/n80G/8/Qt4FcHLJBlb1/dmitRqMHsyusTM4Mnu56YGyhKLT8e6FLxD99zg8OJRZTXrSft7vXN99hMfnrmDv7ESRZnUo3701bqk8LLLl7tEzHJy2mHvHz6PY6SjYoBqV+3YkVfbMFl0v+HwRMS+CRENVVUbnq4HP3YdGPRKtp42m8rfma1KsGTiag9MW26RqqCmSpvMkNDCY4Lf+RsfIOoVKfdrT6s9RHFuwhqVdv7dqDcXejvFeZ3BJnjSe1griiqZp5G/yP+4+fmFU50oSTPm+HX1af7negMDXbzmzcgtvnjwnSSoPirduEK1tgjHuHDnNpIotzY5rNHYojklcWd1vpOmBkoQkSyYFviRLaKoW3YMpSTi5J2HA3uVkKlbA5BI7xvzNlp8mRbte1ilIskyvjXPE1uxniAjYFeLls+T67sP8Vcu0MEmeKR1j7h8x632ZWLEFd498Ph1r3dN68sezU/xRpgkPT1+yKuix2cQfqTG4u03tCQ4J441/IMncXHBytLfp3KZ4+PwVCzYe5trdZzg72tOoalEaVS7yRQS5zl5zgO/GLY214rEkSTg52PFo92Tck3y+qd8JhaZpjMxVhZf3Hsf62ZYUmaxlizH44Gp+zFKeN+baL8gSmGktYAqdowPt5/5Omrw5yFAkX4zt5mv/HOLv2h1jv1iS0DnYM/bhUdw8U8bZBoHtEQG7gs+SWwdORLirTRTXev3oGWdXbeHipt08u3wTR7ckFG9Vn7JdWkYL4LNzdLC4y25iEJkO+ubJc4uFi3uaVDQYPYjy3VrbzI47j14wZs5m1u4+g15vwE6n0LJWSUb0bES2DKlstk5sTF+5l0ETViJLEgZVRZFlVu86RY5MnvwzeyjpPZPHeW5N0zh//SEXbz3G3k5HjTL5Se1h24DObs0qcejcTdbtPoMsS6jvb646RUaWJVZN6IOrsyPbD1/k7LWH6BSZWuUKUDxfFpva8TkiSRIdF01iSrW2qOH6aFs8sqJg7+JEu5m/8frRM/PCBeIlXAD0IaFRmUypc2ej5V+jyFujQtT5fVPmG2+UqmkYwsI5Om81dX/sGy87BJ8O4XkRJBobfhjH3inzUcONi5dIPnT1SrKEq0dyBh1cHZVSeXD6Elb1G/lZiBdZUcheoQSDDqzit2L1eXLhmnG7JIm0+XLSduYYspQuYjK121ou335C1S7jCAoJQ/+BO16nyLg4O3Bo4f/Imy1dvNcJD9dz+/ELVFUjZyZPHOzt2H74Ik36/xXreJ0ikzNzas6vGW1RPNPH3HzgRYf/zebizX+bXyqyTIeG5RjbvwW7jl3hqfdrUiZLQpPqxUjmFve0clVVWbHjJDNX7+fqnSc4OtjRpFox+rWrSWhoOC0GT+OJ92t07xtYGgwqZQvnYPXEPnim+PqzYx5fuMrWn6dwdft+NE1DVhSKNq9Dg9GDePPUmy0/TeL+8XOJalNkwbtvt80nf52IraDvXPKYrZidp2YF+v9jm55PAtsgto2EePksubRlDzMbxW17RFYUkmVMy693DiIrCsH+7xiRtQKBvm8tniNp+tS8feodtZduS3qsm0nRZnU4MG0xq78bZVJUdVw0kTIdzdfdsJZSbX/h8q0nsab6KopMiXxZOLz4xzjPbzCoTF6yiz+X/YPP63cAJE3iTK9WVTlw6jpnrj2I8lbExtZpA6lVznScwsc88X5NidYj8QsIjhFUK0m89/Jo6JSIFGd7nY7/9WjAsK71bVpF+NHzVxRr+TOBwWExfr6KIpMnS1pOrfj5i9geswWBr98S4PsGt1QpcHJ348TidSzuPBRZlj9J3yJJkkiRJQO/3j2EJEl855qHsEDT4iVvrYp8t2tJIlkosARr7t+iMaMg0ShQryrJM6ZFVow3DTSGajDg++AJV7b/W2/FztHRomslWSJVziyMuLiTDgvGk7VsMTyyZiBHpVJkLJo/TvZ8SJlOzaMa+JXp1BzPnFlinVNWFNIXykvxVvXjtV5sXLj5iAs3HsUqXCBCeJy8fI+CzX6k5eBp7DhyyaqmkJqm0W3kfEb8tS5KuAC8fRfE+PnbOXXlvknhYqdT2HnksuVviAgvyIA/lvPaLzDWbCBNA8P7NfUGFU2D0HA9I6dvZOKinVatZY6/V+whMCSmcIGIn+3Vu0/ZfPCCTdf8nHFJnhTPHFlwcnfD3+dVRBq2pn2yhouapvHq/mPuHT+Hqqo4m6kRI8kSuaqWTSTrBAmBEC+CRENWFPpsnY+TexIk5d+PnmSheFDsdNw6cAKA4wvX8vaZt0XX6RzsGbBnObcPnuTqjgPo7O3JW7MiLSb/xMD9K8hSukiUfYDJjswf4ujmyjdzf6f9/PFRT/mOri4MPrwmWldfACSJ/PWrMnD/CotFlzXcuG9BnAFw874XWw9dpPF3f9K4/5+EhoWbvUbTNP5esYfl20/EGsyqWuC81YDQcPNrRRIerqfN0BlsjaMgGDt3KwFBsZelhwiPTscf55C9zlAy1hhIvT6T2HnkslFBt2LHSZPp1Iossfaf0wQGh7Jgw2G6j1pAr9GLWL3rFGEWbJN+yZxYuBbVwrIACc3lLXs4uWQ9b5+a/m7QOTpQrov57CnB58t/w8cp+GxIXzAPP1/bzeFZyzmzYgsh7wJInSc7xVs1YEUvCzodv79RHp+/xuI1FTs7ZjTsxtNL16Mqft45fIrDs5ZT5bvODDq4iuv/HOb08k28e/malFkzUKZLS7b/MpXru4/ESOeUFBmdvT0/nNwUa1lzt1Qe9Nu5mBd3HnDv6BmQJHJWKo1HlgwW22wt1jQNjLwJ7z52lR//WsfEIW2Mjn3tF0DzQdM4aqaAmzn0egNFcmeK9Zz3Kz/+Wr6bxVuO4vs2gORuLiR3d+X2I8vEaWwEBoey8+hlWtQsGePcLzM38tucrTFs2HPiGnUrFGTNpL7Yf7T98y7A9BaEQdV4+OwVWWoN5u27IHTvxfmCjYdJlyoZW6cPJH/29HF+P58zz67citjD+wzY/9ciUmXPZHZruFT7prh6xD2AXPDpETEvgs8CVVUZkbUCrx89MzkuMrZkYLKCJmuvRCJJEnbOTuhDQo26tFv9/QtV+sZMqwwNDGJ+2/5c3rIncjLQNJJlSEP31dPIWqaY+TeWSLwLDCZD9YEEhYRZdZ2jgx1P907FzTVmw0ZN06ja5XdOXrlnURE3Y0iShLOjPY/3TCaJS/R17j/1oXKncbx8887olldc6dG8Mj/1ahQtkHb+hkP0/nWxyesGdazN7wP+fSr3DwimVNtfuP/EJ1bPE0QEEEtShBcqtu0zezuF5b/3olHVz+czYyuW9RjO8YVrTWYRJhqWZCBKEkWb16XHmumJY5PAYkTMi+CLQ5bliN4+Rp7gZEUhafo0FGpU4/1ryz66mqYRFhhkci9+9/hZsZ6/uGk313YeiLIpyjJJwjVlCovWtxVh4XrOX3/Imav3Y90OSeLixMAOta2eNyQ0nFNX7sV67tiFOxy7eCdewkWnyCiyzPI/ekUTLgFBIcxbf5By7cfw4rWfzYULwJx1B8lcazBdfpqH//uA35+nbzB73azV+wkICuHG/ee0GToDz0r9uGdCuAAYVBW9QTUa9xMWbqDF4OmMmrERiPhcbjlwgdo9J+BZqR8Zqw+k39il3HzgFZe3+kkp1KiGSeEi6yKC7SP/PyGxJJtNkiWUBLZDkPCIbSPBZ0Plvh15eOYSp5dtilajQZJlHN1c6bttflRqsWMSV4syjZKmT4O/l49J8fLmiRcvbj+ItgV07/g5FrUfyIeOycj/93v+gqnV2/HLrf1R/YwSCoNB5Y8F2/lr+W5e+wUC4OxoT82y+Unu5kJIuJ5cmVNTp3xBjl+I29aOMXGycd9ZdIqCPo5BmI72dtSpUIDsGVNz6vI9Hnv50qJmSe49eUGDvlN54x8Yp3mtwWBQWbnjJLceevHHwFa8/CDY2BhBIWHM33CIUTM2ERIWblNhNXbuVkoXzMa2QxeZs+5gtEaQ8zccYuGmw6yf8p1FWVl3H7/g7mMfbtx/xolLd3ni/Zq0qZLSvkE56lcsjC6RbtD5alciXYHceN24E7PitRSxfdN1+Z/ow8I5PGsZXtfu4OjuSonWDUmSKgWHZy7jzuHTNrPH0S0Joe8CMLapoBlU8tWuZLP1BJ8GsW0kSFSC/d+hDw3DJUWyWJ+SfO49YsPQsdzcf5zwoBAc3V0p07E5NYf2iKqGaUmlXogoAlemcwt2j59t1qU94tJO0hfME/V6VpMeXN62z2T7ga4r/qREm0Zm7YgrmqbR6ce5rNp10qgnXJYkNDQ0LeL/LQme/RCdIvNw92RSJY/5u9Jr9CKWbDkarWaMpaRK7kaf1tX4bc4WDAYVRZHRG1QUWUJRZML1BpPZSQnB4I61mbR4V6KuGRuZ0qbg0XPfWM9JkoSjgx0Pdk0kubtrrGOu3HnKgN+XxdpIMlIMlS+aky1/D8DV2fbB4bHh5+XDX7U78uzyDWSdDtDQDCqKvR2dFk+ieKsGJq9f0XsER+etTPB2H7KikCRVCsbcP5wggfOC+CEq7Ao+Oy5v28eucdO5f/w8AG6pU1K5b0dqDOke5b04s2pLRNVM7d8mbUFv/Dg4fQm5q5WNKkC17ZepFq3ZZuYYFDs7VL3pvW0HV+dojdo0TePK9v0mv0glReby1n3xEi9nrt5n/obD3HnkTXJ3V1rWLknjKkWjaoUcPHOTlTtPmpzjQ7FirXBRZJmWtUpFEy5BwaHIsoyjgx15sqaNs8AwqGrUFgkQ9bPUG7Q4iaH4IssSh87eSvR1Y8OYcIGIz15wSBhLtx6n/zc1o46rqsoT79fcfuRNq8HTCQ6NPXMr0otz7MJtWg+dwdZpA21a78YY7mlS8eOF7dzYc4RLm/cQHhxC+kJ5KN2hmUU9u2oM6c6pZRsICw6JESAvKwrIUsQDSHz0rgSuHsnov2eZEC5fAUK8CBKcA9MWs7rfSKQPPC3+3i/Z+vMkbu47Rr+di/C5/YCF3wyIkXKpGVT0ahizmvRk9O0D6BzsowSQKbJXKEHhRjVRDQaSZ0rH26desaZzSopM+e5tsHf+Nx5DU1UMZtJbNVVDH2pdcGwkqqrS//flzF57AN17j4QsS2w+cJ4COdKza9YQUiZ3Y/6GQ1HnbUnkvSxf9rRMHdYOVVVZuOkIkxfv4s7jiG7fZQplo0fzKuh0itWpvrIs8S7QeJryp0BVNV69eUeNMvnZc+LqpzbHLMu3R4gXTdOYtWY/k5f8w6Pnryy+XtNg9/Gr1Oo1gU1T++NsRTZaXJFlmXy1KpGvlvVbMimzZWLAvhXMbtqLt8+8I7w37+vGZK9Qgjo/9mV2s16EBQbHqZaMS4pkNBozmJLtGuOYJHaPluDLQogXQYLy+vEz1vT/BSBGzx9N1bhz8CSHZy7D6/pd4+mWmoZBr+fw7BUoFlQwlRWFzCULR/1/rw2zmVy1TUTg7gfdaSUgc4lCNPx1cIzr0+TLgff1u0b3zSVJIkORfGZtiY1pK/cye+0BgChhEunhuH7/Oa2/n8G+ecO498THZsIlvWcynB0d8HntT4bUyenWrBIdG5bHydGe2j0ncuDMjWjjT16+x4lL92hWozjr95y1eB2JiJicgKBQm9htKyRJIk3KpPw5rB1lv/mVt++CPrVJJrl48zHLtx3n+KW7zF13MM7zHDx9k/p9p5AnS1rC9HoypfUgc1oP3FycqFAsZ7xaKdiaLCUL89vDo1zdcYBHZ6+gs7cjf90qZCyaH4CfLu/iwN+LObNiM0F+73B0dcElRVJUg4GXdx+aTI0O9H3DrQMncE6RjNQ5s5CuYB6LPVKapnHv2FmOL1zLm6deuKdOSclvmpC7Wrk4tbsQ2AYR8yJIULaOnMzO36Ybf1qSJDyyZsAQFs6bJ6YzLdIVyoPPrfuEh5i5MUrQbvY4KnT/t36J76On7Ju6gNPLNxHiH0CKLBmo2KsdFXu2jdWFfGTOCpb3NF53RtYpjHt8Avc01jU71OsNZK0zBO9XfibHnVo5kp/+Xs/ek9fiHRuiKDKNqhRl1YQ+Mc71Gr2IBRsPm7zezcUJfzOl1iNJ4+FOr1bVGGlBVo81ONjpCNPr49XKas7IznRqXIEHz14y4q91rN97NtHjbqwhVQo3fHzNlwOwBEWWUVU12q6Lg52Ors0q8cfAljjY29lknU/B6u9GcXjWMrPe0g/xzJWVZhN/pGD9aibHGcLDWdhhEGdXbY3qtxb5d95aFem1cQ72TmILylaIVGnBZ8Pzq7dNd1nWNF7de4zBgkC9wFdvCLdgq8bO0ZESraMHCKbIlJ6WU35mos95poXc5pcb+6jWv4vRve9yXVtRpFkdgGhPaLJOQZIkOiyYYLVwgYjmieaEiyLL7Dl+lTZ1y9jk5mowqHRqVD7G8Wc+b8wKF8Bi4QLwx8BWVC+d1yr7TJHc3YXJQ9vgf2o293dNivM8Lk4OZEyTAlVVyZIuJcv/6M2rI9NJlsTZZrbaGh9ffxTZNvEqho+EC0S0Upi1ej9tvp9p1MP4JeCRLaPVW0k+tx8wo2E3zq833UZi84iJnF29Dfg3bivy7xt7jrKq789xsFhgC4R4ESQYqsGAztEhWiuA2FDs7MhRsaTJGhCyTsE9nadF9Rnq/dQv3vvasqLQffU02s0eS+q82aNsKFC3KoMPr6F0+6ZWzzlz9T6qd/vD7DhJithOal6jOHmzpUOxsKaNsblqlStAzbL5Y5z7fd62OM9rjE0HzlE8XxbyZE2LbOTGG6kFlQ9c7pFjB7avxemVI1kxvjfbZwzi8Z4p9G1bA0mS8EjqipODfZzsCgwOpXavieSs/wNbDkS0HHB1dqRb88rR7PjcMCSwZ0jVNLYdusihszcTdJ2EpFS7xlb3J9M0DTSNlX1GYDDStiLkXQAHpy0xWvROU1VOLlmPn7eP1TYL4s/n+1sr+GK5f+IcMxt1p69DTs6s2Gw6/VGSyFGpJFX6dTI5TlNV8tYob9ETVqk4CIvYkBWFCj3aMvLqHmbo7zE97C69N88le/kSVs81bcUe+v++nIBg87EgeoNKifxZcLC3Y/ecoZQvkjMu5kegwaQhbaLtzZ+99oASrUdFxd3YEv+AECRJYvbPnbDX6WIIA0WWcbC34/eBLSlTKFuUkCmWNwvL/+jF7wNbUjh3JprXKEGNMvmjlel3sLejXqVC8bLvibcvLQb/HSVgBnxTk9Qp3aPK+X+IJEmkS5UsXut9CegUmcWbj35qM+KEITycbb/8GeeGkO98fLn2T+zex3vHzxEWZNrrqOoN3Nx3PE5rC+KHEC8CmxASEMihmUsZmbsq48s249KWPZZ9oWgaN/ceY9e46TQa+z0QvQpn5DZN+3l/UKVfp2gZSx8jyTI5KpYkWfo08X4/HyMrikUBfqqqcubqff45diWqWmpgcCg/TbMsBkSRZbKkT0m1UhFbL6mSu7F7zlBSe5jukmvUbllm2fZ/v1wv3npMta6/c/n24zjNZwpFkcmTNeJnX7pQdg4uHE6Vkv/WzpEkqFY6L4cX/8igDrXZv2A4QWfmEXx2HseWjqBFzZImf8bPfd6w98S1eNkY+RA9aMIKVFUlZXI3Di/6kSolo291OTnYM6hjbb5rWyPOa8Vnx0dRZHJmSp0oLYP0BpVnL94k/EIJwLIewzk0fYnJYF2TSJLRliQGC5qWRoyLW9ahIH6IbCNBvHn9+BmTKrfG98GTOM9xbechnNzdGHJkLfv/WsjtgyeRJIm8tSpRtX9nMhWLqDhac2hPdo2bEeN6SZaQZDlKAH0Klm07xpCJq6Iq4QJkTJOCDg3KEWiBxyUCjYW/dovmKRk5Y6PZOBljGFSVK7f//XcZ8dc6QsLC4xX4anQtg0rnxhWiXhfNm5kdMwfj/cqPF75+eKZwjyHCrNkSm7lmv01SsDUNHnv5cvziXcoXzUmG1MnZPmMQ95/6cOnWExzsdVQompMkLk5cu/uUH6Za0QRUkTEYVCRA1d4LGElCVTXk90pE1bT3wib2ooKKIuPi5MDisd1pPvBvnr/0S9CYFJ0ik9bTuIdJVVU27D3H7/O38djLF0cHO7KkS8kbvwC8fP1JmdSVjo0q0KNFZZK5ufDytT+LNh/l4JmbgEaFYrno3LhCtB5TtsD75l1OLFoXv0k0DVePf9+776On+D1/QRLPlGQokg9Jksz+7DMVLxg/GwRxQogXQZwJDwkhwPctMxp1582T5/GaS1NVzqzcQqPfhtBjTUxxEknDMUPQOdjzz+8zI7KOJEAD97Sp6bBgPNnLFY+XHXFl5ur99P99WYzjj718GTNni0VfghBxY12y5ShlC+cAIhoX/jE/7rEpshxRsRXgha8fe45fjVedL3P8PH0jqyf0iSq0B5DaI6ZoiQsrt580WapfkkCnKIRbWKX1+cu30V5nTZ+KrOmjB2HbWZCaH4lnCncurP2F0u1G8+zFGwyqhqoR5e6RJAlXZwcGdazN9XvPkWWJjKmTc+zCHY5euANE/Hs1rFyEX/s1Q0Ii4nLL/8Ui6wJZUx9Ib1Dp0KBcrOfCwvVU6/YHpy5/0P/qHdHEtN+7IEbO2MDc9QcZ068ZvUYvIiQ0PEqY7Tt5nbFzt7J2Ul+L2h5YyukVW6Iyf+KKvYszBepX49HZy6wb/Bt3Dp+KOpe5VGGylS/O/ePnY/UiyzqFLKUKk65A7jivL4g7QrwIrOb142ds++VPTi/fFOdCbbEhAVe3H6Dyt8ZL/8uyTP2RA6g2oAtXth8g2M+flNkyRdRcsDJoz1YEh4QxeMIKk2MsvQGpmsaybccZN6AlydxcWLLlGLIsx7k5oqpqNKhcBIi44dhCuHimcOOFkRTe7YcvMXr2Zn7t28wGK0XHz0zWk6ZBwZwZGNyxNm1/mGV2vjQWCKqMqVPg6uxgUd2apeN6sPXgRR57vY71vEFVCQgKJTA4jKXjekY799znDb5+gaRNmZQUSV0JDQsnX+P/WZUqLUkSO2YOpmiezDg72jNrzX4GTViJLEtGs9ZkSSJfjvScu/6Qpy/e0KhKEdw/yMDqN3ZpdOFiBFXVePbiNZ1+nBtDcKmaRmiYnuYD/+bShjExBGJcCXj1Ot7VgxuOHsSzKzeZXLk1ho9aiDw6cxkkcPP0wN/7VbSsSVlRcPVITuelU+O1viDuiJgXgVW8vPeIscUacHLJepsKF4iIWQkLtmxbwMndjZJtG1Gpd3vy1qz4yYQLEOf+P8YICzdw+f1Wz6Pnr4jr17NOkcmU1oNm1SO8UbH1L7KW3q2qGhUuEHHTmrl6P8Ehto8DyJExldEMJoh4v7mzpKFJteKkSZnU5FzpPZNTrkgOs2s6OtjRpUnFqC0fY3RvXpnKJfKwZvdpkzdUg6qycseJGMfTpkpGgRzpSZE0Iktuw75zPPbyNfm5ivA0yciShL2djgW/dqNyiTy4uTqh0yn0bVuDTX/1p2yh7LFf//4/V24/4adp6+k2cj4Zagxk0uKdaJpGQFAIS7ceM/m+o783DVXTYhXqmqahV1Vmr7FdkHiKTOlirZptkvf/NvbOTjSb+CPVBnZlRe8RGML1MdoSaKqKpmpIskz9UQNIliENsk7BLXVKav7QixEXd+CRJYOt3o7ASoTnRRCFajBwdccBLmzYReAbf8ICg3jz+DlBfv54ZE5PhZ5tOb1iM0Fv/OIc3W9u/fQFPx8XbEhoOCt2nGDD3rO88PUjYxoPmlQrRvMaJaK2YgBOX71v87Ujs18ib2bWXqs3qGRMk4IdMwdHFSBLkzIphXJl5NIt64N1a5TJx4D2taK2O0zVn/EPCObKnSeULJDN6nVM0bNFFbqPWmj0vN6g0q1ZJRRFZtLQNrT9fqbRsROHtLa4OupPPRux/9QNrt97FmuMSufGFZj2v/YAvPUPMutlsyRuZ8fhS9E6TseORJu6pcmfPT0dGpaP9bNSt0Ih7HQKzQb8RUhYdM+CBlGBrpH/niGh4QyfuhZ7Ox0FcqS3qSg3GFS2Hb7IH4Na2WS+Uu2bsvnHCUa9iZIs45kzC+kL5yVltowA3D54kmC/d3jmykbKbBl5fP4qTy9eN76IpvH2qTdpC+Ri3OOYolPw6RDiRQCAn7cPf9WK6AorKXKMp5CAl748OHUxwdaXZJlkGdKQu3rMYmqfgp1HLtP2h5nRAm0v3XrC1oMX+GHyarbNGESR3JkATHoi4kISF0eK5skMQOs6pflr+R6Lr5VliXb1y1KnfEEaVi6C7qO6ONN/7ED5DmMsmkuRZXSKzO4531OmcMTT+7W7sWdmfExCxJe2rVuGlTtOcvDMzVhFRNemlaJihZrXKIH2h8aQiavw+iC2JW2qpEwa0pam1S2PjXJP4syhRcOZtHgXc9Ye4NXbAGRJolyRHIzt34JSBf8VabmzpOHSrcdGb/qyLJEzc2qza4aG6c022tQ0jTkju5gMej577QENvp1iddPOX2Zuom+b6lZdYwnh4bZ76Ema1pP6vwxiy4iJMc7JioJLiqR8t3spydKnYfV3ozg4bXFUjIzXjbtcWL8zStSYY93AXynSuJbNbBfEH9EeQICmaYwr0ZCnl64neEt6Yyj2dvTdvoA81SuYH5zAnLx0l0qdx5q8ASdzc+HaprE89XlDydajbLa2JEkM7librOlTsmn/eQKCQnju85bHXr5mb0CyLFEkdyZOLDdd9XPGqn0M+GO5WVsql8jNuP4tKJYvS9Sxs9ceUPabX01e5+LkwNN9U3FJgGaAoWHhjJmzhdlrDkT1J0qbKimDOtSmb5vqMbwpBoPKobM38XrlR9qUSalYLFe8iv5pmsa7wBCcHOxiDeY9fvEOlTuPMznHvF+60qFh7AGykYydu5XRszYZ9XBJkkSerGm4uM60EK3fZxK745lebit0ikzzmiVYMvbfeJ97T3xYsPEwtx95k8TZkabVi1OnfEGL/400TePo3JVs++VP/J5HNBWVJIn89arS6u9ReGTOwL6p81k7MPbPrCTLpiuAf0D28iUo26UlSVKlIEORfCRN62nRdQLLseb+LcSLgJv7jzO1WlubzinJEpqqYe/iRJgV5eWzlS9B3R+/JV/tyja1x1JUVSVrnSE893lrcpwkSYzp14wzV+6z9dAFm1VCrV2uAFfuPIlY/32GkiJLFs8/f3RX2hvJHPmQc9ceMGjCCk5cigjGtNMptK1bmq7NKqNTZFJ7uJPeM3ms15b95lcu3nwUq3dBliW+a1uD8YNbW2RvXAkNC+fuEx90ikz2DJ7xEiS2RNM0+v++nFlr9sc4J0sSNcrmZ+PU72J4xD7G6+VbstUdit7Ew8SMER3o1qyy0fP+AcF4VPjWYtvjiyzFnvr9IYcX/Y/S72Nwxi/Yzk/T1kcFpEemmRfKlZHtMwZZFaOlGgw8OneF0IAgPHNmiar1ZNDrGZ6hDP7eL+P+xmJBkmWKNKtNm+m/kiRliqjjYcEhvLh1D1lRSJ07G4rdl9sz6lMgxIsQL1axZuBoDk5bgqq3vLGZKZJ4epA6V1Yq9mpHzsqlGZa+jMVPN5FbVu3mRG+smFjMXL2P/r+b90oAONjrCA2zzc8MwM3VieRuzjx98cbotkPJAlk5feV+tLgT6X26eLOaJVg2rqdVnW7fvgvijX8gqZK7WewpefT8FVW7/s6zF2+iblaR9lQpmYfNfw2IFhP0X0PTNGat2c/ERTt54h2ReZTC3ZU+barxQ5d60aoGm2L59hN0+WkeiixFfR4iU+6bVivG8j96mxRtT7xfk63OkPi/IQtJldyN7s0q8dvcrVFCBP6tffNr32b80LUeAKt3naL98NmxzqMoMiXyZeHQov/FO5vo6eUbjClUx/Sg978/1iLJEs5J3akzoi/FWzfkwJ8LODRzGSH+AQAkSZWC6oO7U2NID9F92kKEeBHixSpW9BnBsXmrrOrKGiuSRLUBXWgx+adoh1d/N4oDfy+yaipZpzDuyQncU9smrdJS8jYaxt3Hn2evElmWKJQrI7/0acLERTs5fO4WADkyefJd25pRwaqJwdt3QSzceJhl247z6m0A2dKnpGuzyrSsWcKq2ihfM6qq8uDZKwyqSpa0HnH6uRy/eIfJi3ex48gl9AaVvNnS0rdNdTo3rmj23zokNByPCt8SFt/fawuRJYmqpfIyqGNtpq/cy4HTN9A0qFg8F9+1q0GNMhH9tTRNo0iLn7hx38tkcPOHXpq48ujsZcaVaGjabkWJfwJCpMj6+P1IEqU7NKXjwonxFmL/BYR4EeLFKo7MWcHyXv+L09PHh5Tu2Iz28/5A0UX/kjaEh7Os5/84sXBtVOl/c7E1kizTaMxgag9PPLd3cEgY7mV6Jdp6sWE+wwReHp6GexJnQsPCMRhUnBztxRfjV46maaiqZrU4/XbMEuauP5gwRhlh/ZR+UbWFYuOZzxuy1Bpscg6dIjO4U5141wsKeRfAUM/ihJspwZCzShluH0i4bKKB+1eQq0rZBJv/a8Ga+7fwZQko1rIe9k7O5geaQJJl2s/9PYZwgYiu0R0XTGDUjb3UHv4tZTpa8IUkSXhdvxsvm6zFVA2RhEaSIrKMLCnqErmF4GBvh7OTgxAu/wEkSYqTV21Ez4akTJYkASyKHUWWWbgxZqPDc9ce8Pv8bfw2Zwv7TpoPIJYkiTAbbMk6JnGlXNdWRjvby4pCymyZ6L15Ls7JbNu+IGoNncLRuasSZO7/MsK/+x8mLDiEPRNmc3D6EsKCguI8j6xTKNykltngtNS5s9Nw9CAM4eEcX7jOZByMJEnYOzvG2aa44GBvR96sabh+3ytR14UIb3OjKkVZts14h1pJgoxpPEju7pKIlgm+ZNKkTMqplSP5dswSdh69nODrGVSVR16+Ua9f+PrRasgMjl+8gyLLSFKE+DYX3BuuN1A4Tyab2NR47FDunzjHk/PXIpzLkXFaioJDEhd6rp+JUxJXem+ey+TKrS2Oz7MUVW/gxS3b14L6ryPEy3+U8JAQ/qz5DfePn4/+y/pB8Jpib2e2s6okSUiSRO1hfUyO8751jwN/LeLChl3oQ0NxTuZO0Bs/o18Uql5P4aa1rXlLNsEvIP6N/6whsqDcgG9qMrJ3Y7Yduoh/YHDsKbIafNeuhvC0CKwivWdyNv89gJev/bn1wAtNkiiZLzMrd52ih4mif3FBliVSeyQFIjLCavaYwO1H3gDRtkNN7VDLskTSJM40rVbMJjY5JnFlyOG1HJ61nEMzl/H60TMc3Vwp1b4J1QZ0IUWm9ADkqFCSPlvmsbD9QILexK0RamxIsoxLiqQ2m08QgRAv/1H2/7mQ+8fPxWwl/8FLUwG8ip0OQ7ge52TudF35FxmL5jc69vruw8xo2A3VYPg31kWWwYhwkXUK6QrkJk+NxK35cunWY575vIn3PA72OsLC9UbrxMiShEeyJGTLkIo8WdPQrVllir+vpbJucj8a9J1CmF4fla0RmcnTpFox+rSqFm/7BP9NUiZ3I+UH6cedGlVg7JytPHz+ymZrqKoWVcNm/d6z3Lgfe8NWY6GWOkVGkWVWTegTVRnaFtg7O1F9UDeqD+pmclyBelX5w+s0+/9cyNafJqEPD493LKCmqji4OvPs6i3S5sspHj5shBAvXzlvnnpxcdNuQt8FkCpnVgo2qIZiZ8eBaYtjCpePMeHWzV29PKXbN6Fw09rYORhPsQ3282d2014YwsOjr/eRcJHtdKBFeFwyFM7Ht9sXJHp64bz1h2wyT5cmFWOt8xGJqmnM/KljrEGNFYvn4uzqX5i+ci/r9pwhODSMvNnS0btVVVrVKvXZ1DMRfB3YUiAoskzh3BmRgCb9/+TIudsWXZfC3RVfvwAc7e1oWaskAzrUIn/29Dazy1rsHByo9X0vCjepxa6x0zm1fBNqPDO2Lm7czcWNu0mRJQONxw6lRGvTGVAC84hso68UQ3g4q74bxdE5K4GI5mKq3oBLimR8M2css5v1jtf8bqlTMt7rjNlxB/5exOr+vxgXQhK4p/GkYINq2Dk5UqhRDXJWKm3y6eSNfyArd5zk5oPnuDg70rx68WhVYONKpU5jOXEpfkHC/drW4Ne+TanY6Teu3Xseoxu0LEtUKZmHbdMGCSEi+OR8P2kVf6/cG+eu5ZFIkkSDSoV57OXLRSt7Z0mSxMnlP3P7kReLNx/jmc8b0qVKRsdG5WlardgnT73Xh4UR8i6QW/tPMLel6e1xS2k+eQTVB5r2Av0XEanSQrywpOv3nFi4Nnb3rCyBDSrCjnlwBI/Mpruqzm/Xn7Ort8bolfQxf4fcMunBiWTp1mN8O2YJoeF6dIoc0a3WoFKjTD5Wju+Dm6uTVe/hQ+p/O5ndx6/G6VoXJ3smDWlDl6aVgAiB1f/3Zaz950zUXr+DnY7OTSryx8CWODnax9lOgcBW3HviQ8GmP6I3GKzuR+Xm4kj5YrloUKkw1Uvno+WQ6Vy48ShOdkSG2kVukUb+XaZQNrZNH0QSl7j/XtuKF7fvMzJXVZvMJSsKYx8fFy0GPkKkSv/HeXnvEccXrDFeAErVkHU6pHhuywS+Mh8fIisKkgX5v5ZsEe05cZVuP88nJCwcTdMI1xui0ob3n7phsotwbBgMarSfUdNqljfrkyWJxtWKMvWHdqyd3Bfvg39HCReI6H20ZGxPHvwziY1/fsfmvwbweO8U/hr+jRAugs+GbBlSsXrit9jpdChWlAoY+10LvA78xeIx3fELCKZ8h9/iLFzg37AS9aMu16ev3Oe7ccviPK8t8cyZleQZ09pkLk3TOLFonU3m+q8ixMtXyNnV25DNbEmoen28UwKTpjffHTdPjfImq1dKikKOiqUs6gHy25wtSEa+YA2qyu4TV81+gYaGhTPi73VkqD4Ap+LdcCvVk/bDZ3Px1mNa1SlFes/kFm3naMD4Qa3p07oajaoUNRo7kNrDnXoVC1OnQkGSuYkUZ8HnR/1Khbm59Xd+6Fqf0gWzoTPz+Vdkmbb1SuPz5h0l2ozif1PX8sLXdtk5H2JQNVbtOoX3q4SZ31qylrVNBpQky7y8+9Cqa/RhYRjCTWd//pcQ4uUrJOiNn8VeFcUhbl6AfHUrW1S6v1iLurilTomsxN6ITjMYqDG0h9l5Xr15x/GLd4122QVQZInZ6w4YbWZ38cZD0lcbwPgFO3jh6w9AaLietf+cptw3v3Lk3C32zP2eLOlSArHXi4ssZDd+UCsyp/Uwa7dA8CWQ3jM5o/o04fDiH/ntu+ZGx8myRPsGZUmbKhldRszjqfdrs80Y44vBoHLswp0EXcNS0hfKY/QByloc3c0XD9Q0jVPLN/Fb0Xr0dcjJt/Y5GF+uGRc27rKJDV8yItvoK8QjawaL+hTJOoVS7RpzfMEaq+a3d3Wm2YQfLRpr5+hI/91LmVKtHQGvIprUoWnIOgVVb6DJH8MoWN98+m9gcKjZMQZVY8GGw2zce46cmTzJkj4lmdJ44B8YzModJ3n7LvZCfKqmoeoNtBs2i8d7pnBlw2/sOnaZXUevcO7aQ2499OJdUET9lyJ5MjGsa30aVSlq0fsXCL40BrSvhfcrP6Ys/ScqrkySIppD1qtYmL+Gt+fG/eccOHMj0WzS4puvbCOKtajHpuHj4z2PqtdTvFV9k2M0TWNN/1848PeiaA+jD05eYHbTXtQfNYD6IwfE25YvFRGw+xUS9NaPoalLYAgNMzlOsdORp0YFru44YPHcafLmoOuqv0lfILdVNgX7+XNi8XoubtpNeFAwGYsVoGLvb0iXP5dF14eGhZOmSn8CghK2iNzsnzvRuUnFaMcMBpUXvn442NuRIqlrgq4vEHwu3H7kzaJNR3js5UvKZEloW68MJfJnBWDhxsP0HL0oUeyQJIm7OyaQIXXyRFnPHIu7DOXk4nXmS00YQVJk8lSvQL+di0xmVV7bdZC/63QyOdew05vJXKJQnOz4HLHm/i08L18hzkndaT7pR1b3HWlynEGvJ3lmy+spSLKM1/U7nFqygfQT/meVTU7ublT9rjNVv+ts1XWRONjb0aVJBaav3Ge2cWFckWWJCzcf8bGFr96+Y+aa/SzadBRfvwDSeLjTrVklereqRtIk8esJJRB8ruTMlJqx/VvEei6x0vwVRaZhpcIxhEvkA4W9nQ6PROzdBNBu1m8oOoVj81ab7IodjfeVyDVVpWCD6nReOsVssbqD05dEeahjQ9YpHJqxlMwLvx7xYg0i5uUrpcq3HSnYsLrxAZKEnaMjfl4+Fs8ZGeC7Z+Icbuw9Gl8TrWZEz0bkyOSJkkDF6zQNHD4KHH7w7CUlWo9i4sKdvPD1Q6838MT7Nb/M3ESZdqMTLFBRIPicqVQ8NwlZKFaSIv7kzpKGGT91ijoeFq7nj/nbyVxrMJlrDSZt1f6UaD2KtbtPJ5wxH6Gzt+ebOb/z28OjpMmbA3M/COfkSak7oh+NfhvCyOt76b1xDo6u5oP3H5+/alS4QETPpEdnE75f1eeKEC9fMV2WTX0fYBb9n1lWFCQJwoNDuLJ1r9XzyjqFg9MW28pMi0maxJnDi3/ku3Y1Ijow2xhN06hXKfpTTMcf5/DqzbsY3h5V1Xj4/BXfjV1qczsEgs+dTGk9aFy1mMUemA87tn94r1dkKSq7SafIZEyTAs8UbhTOlYm/hrXn2JIRUVu14eF6GvWbys/TN0R7aLh86zHtfpjF7/O32eCdWU7yjOmo82Nfk5XIZUWhUu9vaDh6ELWH9SFJyuTsmTSXhe0HsrTbD1zcvBuDPvb4RDtH899xdk6fvv7Np0JsG33FOCZxZciRteweP5tDM5cR6PsGJImsZYty90hEdVxTyt4Yn1rxZ8uQiqbVirFq1ylCw+JXtvtD8mZNS6Xi/8byXLnzlJOX7hkdbzCobD54IaoiqEDwX2L2yM489X7NmWsPUGQJg6qhKDIGg0rW9ClpWaskFYvnJjxcz+Qluzh09hYAuTKnoV/bGuTLlo5N+88REBxK7ixp+KZ+WZK7x4wpCwkNZ/qqvYxfsJ03/jGD7iOlw8/TNtCoSlHyZLVNLRZLKNKsNmnH5cL75t0Y36WyouCU1I3K33YA4OzqrSzsMAhVrwdJRgKOzV+NW5pUfLt1PpmKFYh4P5rGrQMn0JmpByXJMkWa1kqQ9/UlIMTLV0jAq9ccnbuS06u2EvjyNUk8PSjfow3le7TB3TMl6wb9yv0T5+MkXCLRWVAN19bMXnOAIRNXEhrPPiOx4ehgx85ZQ6LtQ5+79sDsdaqqcfHmIyFeBP85kiZx5uDC4Ww6cJ4lW47h/cqPTGlS0LlJBWqXKxjNK1OnQiHCwvWoqoajw79bs2WL5DC5RkhoOPX6TOLohTsWxZc0+m4qebKkJb1nMorkyUS2DJ5UKJoTnS72Ug3xxc7BgQH7ljO35bfcOXQKSZGRkFANBlJmz0TPDbNxT5OKe8fPMb9t/w9qaxmiRJe/lw/jijegfPfWNJv0I4s7DuHixn+MlpeAiKBfJzdXyndrHe145M/ov9D8UYiXr4xnV28xpUobAnzfRLkz/bx8eHrxOnvGz6buT/24dfBkvISLrCgUaVrbViZbxKqdJ+k3LuG2aHbOHEyalEmjHbO0p4r9J+69IhB8KuzsdLSoWZIWNUuaHRuX35PJS3ZxzELhAvDw2SsePoveJTtpEmf6tK7GTz0bJUigsVsqDwYfXM3jC1e5secoqt5AltJFyFWlTJSI2P3HrIiAXRPzHJ23mtuHTkUVrzNV3NMleVL67VyMq0dyVIOBYwvWcODvRTy/ehudgz2FGlanxpAeX1Um0seIVOmvCINez0/ZKvLmqbfJ6rkuHsksKu0vyXKMeSRZQudgz8hre/HIYrqvka3QNI3cDYfx4OnLBFtjydgetK5TOtqx5z5vyFZnqMnsJmdHe57um4qrs+1jcASC/xqv/QJ44euPR1JXUiR1JWPNQfi8LygZX9xdnfh9YEu6ftDGIzFQVZW+9jlMihGLkSSaTxpBxZ5tsXd2wqDXM6dFHy5t3hPRH+r97VzWKWiaRrdV0yjWvG78100kRKr0f5Qr2/bx+vFzs+MCfd9aNJ+9sxOhgYFIUsTTiqZp2Ds703vz3EQTLgCXbz9JUOECxPpElDZVMtrULc2KHSdirewrSRJ9WlcTwkUgiCc3H3jx87T1bDl4AVXVkCSoWDy3zYQLgF9AML1/Xczbd0EM7ljHZvOaQ9XrbSNcADQNN08P7J0jAnWPzFnJpc17QItexk/VG0CSWPjNAHJVKYNriq9vW1uIl6+IO4dPm6wLEIkkSWbdsLJOoeQ3jclQOC+39h9H0yBHhRKU7tAUJ/fE9Wj5BwTH63pZkkyWMJckKFsoe6znpv2vPd6v/Nh78ho6RUZvUKP+bl6jOL/0aRIv2wSC/zpX7z6lUsexBIWGRT0kaBocPXcrQdb7adoGOjQoR8rkifM9prO3J2X2TLy899hkZpKlHJq5jKxli+KROQP7/1xgfKCmYQjXc2LROmoM7h7vdT83hHj5DxLbdlAso9AMKhV7tqNiz3aJYpcxsmZIZZHgMkbx/Fk4d+1hrNs/iiJTt0JBMhnpU+Ts5MC26QPZf/oGy7Yd58UrPzKkTk6nxhUoUyj7fyIwTiBISPr9tpSgkLAYv5+GOFawNYdqUFm16xT92tZIkPljo0q/TqwZMNomc90/cY5xxRow8NBqfG6bTyp4fO6KTdb93BB1Xr4iclQqZVEgrqaqOLiargyrGgykK2hdC4CEIl2qZNQpXyDO1/drU4NCuSK2ueT3YkOSJCQi0jbnjOxi8npZlqleOh+LxnRn56whzBnVhbKFcwjhIhDEk9uPvDl28U6CVc2ODVmWeOLlm2jrAVTq/Q15a1U0P9ACNINKsN871vQbZbZAniRLKEY63n/pCPHyhaAaDFzZcYC1g35ldf9RnF29FX1Y9N5FBepVJXmmdGbnkmSJir2+Md55WpKwc3SgdPvPZ0tk0tC2cbrO2dGextWKcnDh/5j9cydKFMhKulTJKJY3M9N+7MDxpSNEvyKB4BNx55F3oq9pULVEbymg2Nnx7ZZ51B81wGQKtKWoBgO3D54ge/niJudT9QYKWND49kskUcTL9OnTyZw5M46OjpQqVYrTp42Xcl60KKJZ1Yd/HC2oNPg143P3IaPyVmd6vc4cnLaYwzOXMa91P/6XsSwPTl+MGqfodPTdvhDnpO4m56s7oh8NRg8iS+kiRqrvSnRaMjnRY1tMkS1DKqqWzGP1dWP6NcfB3g5HBzs6N6nIkcU/8uCfSRxf9hPdm1fG2Snx69UIBIII3M14gCPJnDaFzdbUNI0KRS1rCGtLFDs76o8cwK/3D5O/bhWbzKkPDTcaDCwrCimyZKBwo8TbHktMEly8rF69mkGDBjFy5EjOnz9PoUKFqFWrFj4+xnvquLm54eXlFfXn0aNHCW3mZ0tIQCBTqrbh1b3HABjC9RjeF2l79+o1U6u15fbhkzw4dYE7R07jlNSN0XcOUKV/Z+w/yoKxc3IkTb4cPL18kzMrt9Bnyzwa/TaEpOk8gQiPTP66lRlyZO1nmV43rJvpFvIf07NFZfq2NdHfSSAQfFJKF8xGquSmvSBODvYcX/Yz80d3pXyRHDibqTxrCbV6TeDA6RvxnicupMiYjr7bFzLuyQm+mft7vOZ6fP5K1NZR5DZ25ANp0vSpGbBnGYrd17ltlOB1XkqVKkWJEiWYNm0aEJHzniFDBvr168ewYcNijF+0aBEDBgzg7du3cVrva6vzcnjWMlb0GRF7Lm9sSJC/ThWajh+O78On3D95gScXrnJt5yE0NFC1qIBdN08P+u9dTtp8OQkNDEJnb4fOPv5fDObwfRvA/A2HWLf7DAFBIRTIkZ6eLatSpWQeJEnizNX7LNx0hAdPX5IyuRtt6pTG3k5hxN/rOXf9Ycy3LP0bxC8BhXNnYsLgVlQs/nnE7AgEAuPMXXeQb39bYvT8iJ4N+blX46jXpdv+wvkb8XuglSUJJ0d77u6Y8Em3jYP93zE4ReF4FQ39kIzFC5Aya0YKNapJkWa1sfsEldDjw2dT5yUsLIxz584xfPjwqGOyLFO9enVOnDhh9LqAgAAyZcqEqqoULVqUsWPHki9fvljHhoaGEhoaGvXa3992dQE+B86t2U7ELdlC9aLBtV0HubrzoNG0vMhMo4BXb/izejt+vXfYoi6ntuDq3afU7D6e136BUenLD5+/YuP+8/RoXpmwcD2LNh+NSkdWZJlVO08C/wbbfogENKlWnP91q0/K5G64OjuQxOW/26xMIPjS6N68Mn4BwYycvgGDQY3oj6SqSEj0b1+TET0aRhtvi7pKqqYRHBLG4i1HGdQhcauFf4iTWxLSF8zD4/NX4z+ZJBEWEES3VdP+E8kECSpeXr16hcFgwNPTM9pxT09Pbt68Ges1uXLlYsGCBRQsWBA/Pz8mTpxI2bJluXbtGunTp48xfty4cfzyyy8JYv/nQLB/gNW1ATQLUwxVgwH/F684s3JLjB4ZtiAkNJzl248zf8Mhnni/JlVyNx57v+ZdQHC0uit6Q4SYmrPuYIxjH2YhxFarRZZlnvu8oWCujDa3XyAQJA5DOtWhc+MKrN51iicvXuOZ3I2WtUqSNpaeYQVypOfo+dsmazdZgqppHDpz85OKF4C8tSraRrxoGt437+Fz5wGeObPGf77PnM+uzkuZMmUoU6ZM1OuyZcuSJ08eZs+eza+//hpj/PDhwxk0aFDUa39/fzJkSLzqrwlNugK5eXrpus3cih8jSRJXtu+3uXjxexdE7V4TOXf9YVSNlhc2rJYZiUFVOXn5HrceepErcxqbzy8QCBKHFEld6dPafGZMl6aVmL5qn03W1DSNN/6B/HPsCkHBYeTJmpbShbIlqueiYINq7Bo3w2bzhQbE7Lz9NZKg4sXDwwNFUXjx4kW04y9evCB16tQWzWFnZ0eRIkW4e/durOcdHBxw+ML29ayhQs82nFi0NsHm1zSN8JBQ8wOtZNCEFVy8+ThqjYTm0NlbQrwIBP8BCuRIz489GvLbnC3xmkcCAoNDyVh9YLRO9bmzpGHhr90oli9LPC21jCyli5KhSD6eXLgW77kUOx0pErF1y6ckQbON7O3tKVasGPv2/auSVVVl37590bwrpjAYDFy5coU0af6bNyZFp0vwIkMps2Wy6Xw+r/1ZueNkohaeWrndeAyVQCD4uhjZuzELx3QnSRzjXyRJQpZljl64HU24QETtmWrd/uD6vWe2MNUiW3pumBVvb4+sUyjWqgEuyUyXyvhaSPBU6UGDBjF37lwWL17MjRs36N27N4GBgXTu3BmADh06RAvoHT16NLt37+b+/fucP3+eb775hkePHtGtW7eENvWzw6DXM6NRdwzh4Qm6js7G4ujctYdRMSuJxbGLd/B5/XUFawsEAuO0q1eGfu2sr2EiSWCnUzCoaqzhhAZVIyxcz29zttrASsvwyJyBrOWKma2YawxZp+CeJhXNxg83P/grIcHFS6tWrZg4cSI///wzhQsX5uLFi+zatSsqiPfx48d4eXlFjX/z5g3du3cnT5481K1bF39/f44fP07evHkT2tTPjstb9+L3/IXladJxQFJkwoNDbDvnJwp093r59tMsLBAIPglNqhWz+hpNgzZ1S6Moxm9/eoPKhr1nCQy2/Za6MaoN6Bqnxo32zk5U6NGW4We24J4mVYzz71768vzabd69TNyWCAlNogTs9u3bl759+8Z67uDBg9FeT5kyhSlTpiSCVZ8/D05eQLHTRRWlswZJlizKOpKApOksiz+ylFIFs+Fgp4vhjk1oUiZyyW+BQPBpOX7xjjWFJICI3kY37j9HliRMpUEYVJU3/oG4JFIV7iJNa1O6YzNOLl5v8TX2Ls6U7dycmkN74uaZMtq5p5dvsOl/47m642CEKJIk8tepTOOxQ0lf6Mt3BojeRp8xsqJYJcRlOx09N8xiyNG1ZCpe0KJrNFWjlI17GCVzc6Fj4/LIcuK4YBRZolLxXLGmVQoEgq8Xr1d+6HTW9QpSZBkJyezWtixJpHBPvAJ2kiTRYcEE8tSoYPE1YYFBHJ61nDGF6/D08r8Vgx+dvcwfpZtwfdfhf705msb1fw7zR5km0drKfKkI8fIZk7dWRVS95d4LOwd7ijSpTfZyJRh2ajMjr++lw4IJOCRxMdqEscbQHqTIFLN+TnyZMKh1ovQPkeWIwLsx/Zon+FoCgeDzInUKdwxWxtfp9QbyZktrNgtS1TR8/QLiY57VyLKM983YM2uNoeoNhPgHMqdFHzRNQ9M0lnT9AX1YWIy+R6rBgD40nGXdhiVKFmhCIsTLZ0yOiqVIXzgvsgVPFrJOIVeV6BlcafJkp2znFgw7tZmsZYtGO+fk7kaTP4bR5PeYLRriS0hoOCt3nOThM+P9q2xFhtQp2D5jEKUKZkvwtQQCwedFi5olkI08mBlDA5ZtO27R2F1HL8fBqvgRFhhs9TWqwYDP7Qfc2HuUJxeu8ezyDTQjok5TVZ5ducnjc1fia+on5bMrUvdfI+RdAMcXruXE4vUEvHyNR9YMVOjRlmIt6qLY2dFnyzymVG3Ly7sPTc6j6g1UG9g11nNp8mRn6JF1eN24i/eNuzi4OpOjYknsEqBbt39AMLV7TeDsNdP2WossSaRPnZz82dNRIGcGMqVJQfaMnlQslsvqLy+BQPB1kDK5GyN6NmTUjI1WXRduQdFPWZYIDk3YTM/YSJs/J3ePnTUqPkwxq3EPCjQwX+gPwOfOA4vDCz5HhHj5hLx55s3kSq14eT+imBuaxttn3tw5dIpj81bx7faFJM+Qlp+v7OLs6m0cnL6Ex2evRHP3SYqMZlBpOuF/5KpS1uR6afJkJ02e7PGyWdM0zl57wJmrD9ApMtVK5yNbhlRR51oNmR5r88T4omoaj718SZHUlS5NKtGwShGbryEQCL48hnerj7OjPaNmbiQoOMxm86qqRoEctt9SN0elPu25c/h0nK4NCwrm3OptFo11dPuyExwSvKt0YvMldZWeWLEF90+cN1r63zmZO9UGdKFCr3a4pfLA5+5D/q7TKYYXJnmmdPTfvTTB+1ncefSCdsNmcvHm44iCSpoGEjSsXJSJQ1rTeuh0zl2PX7dXc8iyhKpq/D28PT1bVknQtQQCwZdDSGg4S7YcZeO+c1y89Rjft/GLV1FkmXenZlsdEBxfVFVlfpt+nFu7I06p05bg6J6ECd5nEsT7Hh+suX8L8fKJeHrpOmMK1zU7TpJlnJO60WfLPOa0/JZ3L17FCMKSdQquHskZeW0PLsmTJoi9L3z9KNZyJK/9AmJE6SuyhJ1OISQs8VKjdTqFh/9MIlXyz/ffWCAQfDqSlOwR73INVzb+9knajqgGAwf+XsS+qQt4/Sii0q+bZ0r8X7y0yfzNJv5IjcHdbTKXLbHm/i2CBRKR59fvcGjmUg7NXMrZ1dssKgetqSrBfu+Y3qAr/l4+MYQLRMS7vPPx5dj81QlhNgDTVu7F921M4QIRFSkTU7hAxNPJ0q3HEnVNgUDw5VCxeG6ThegswdpMJlshKwrVBnRlzP0jjPc+w8SX5xn37CSV+rSP83xIErJOR/1RA6g+6MuvWC9iXhIBP28fFrQbwK39x/8tP2uFw0s1GAh642dyjKaqnFq+iZpDe8bHVKMs3XIsUXsVmUOWJG4/9P7UZggEgs+U/t/UZM+Jq3G+3l6nsP3wJTKlSYHLBz2UwsL12OmUROk8LctytOJzbab/SrmurZhQoTnhQZZXRlcNBnJUKkW31dNw/6iY3ZeKEC8JTGhgEJMqteLVB0G5CUXw24Tr7fPaPzDB5o4rbi5On9oEgUDwmaFpGhdvPSYkNJzuzSoxd/0hdIpsdb+1ML2BH/9ax4i/19OsWlFCww3sP32DwOBQHOx0tKpdisGd6pAna9oEeiexk7Fofqr268SeiXNj9cQb486hUzw6c5mC9SOykZ5cvMa1nQfRh4WTqXhB8tWuFOGh+UIQ4iWBOblkPT53HiRofyKIcAumzh2/TCJTZPBMzp3HL+I9jwTY2+sItWCbSZIko4WU9AaVZjWKx9segUDw9XDk3C2++30Z1+7+2xE6VQo3cmZKzdU7T3n7LsjqOTVNY93ec9GOhYbrWbrtGGv+Oc3OWYMpVyRnvG23lLDgEGQ7HZpmnRiTFYUDfy0ia5mizG35Lbf2H4/aTlL1epJnTEvP9bO+mPRpEfOSwET0qUh496JqMFCxV9sEm79bs0rxcpNWLZWX82tH8/zAXzzeMwWdBXvRkhR7k0dFlqlSIo8oTCcQCKI4ev42tXpN5Ma959GO+/j6c/T8bcYPbk3t8gUA4h0LAxFO9JCwcNp+PxO9BXVjbEFYcAh/1viGXWNnWNS77kNUg4FbB44zMmcVbh88GXUssor766deTKrS+t/SHZ85QrwkMP4+vgm6VQSAJFGkWR0KNrS+PbyldG9emXzZ01n9Sy/LEoVyZWTtpG/Jnz09KZK6kszNhXb1yhidS5FlsqRLyZqJfUnyfq/ZTqdECZ5qpfKyZtK3ibLnLBAIvgwGTViBalBRjXzfDpuymlXj+7Bucj9qlMlHek/b9ELzeuXHjiOJU4l317gZ3D9xHi2O8Yeq3kDg67exX69qhAUEsWXExHhamTiIbaMExiNLBl4/ehbnD5s5kqRKQdX+Xaj5fc8EqzR7+5E3K7afoFieTOgUmat3n1n0pJHExZFBHWrT/5uauDpHryfwx6BWnLxynzuPvFE/eILQKTJODvasHN+bonkz83jPFNbtOcv1e89wcrSnUdWiFM6V0ebvUSAQfLlcu/eMizdNewxe+wWy5+Q1GlUpSsMqRWj03VS8X/lZHQvzMbIsceHmowQvnGnQ6zk0Y2mC3UsiObNqK62n/4pLMvcEXSe+CPGSwBRpViciyygBsHNx4vdnp1B0CfPPqNcb6DduKfM3HEZRZGQpokCcqqk0q16cfaeu8fZd7H04sqTzYO2kvhTImSFWD0lyd1eOLv6Rv1bsYc7ag7zw9cPZ0Z529coysEMtsmf0BMDZyYEODcslyPsTCARfB8993lg0btaa/SzYcBgnR3sOnbkZb+ECEY51R3u7eM9jDv8Xrwj0tex9xgtN48TCtZ99OrUoUpdAXNt1kK0/T+HhmUsJMr+sUyjarA7dVk1LkPkBvp+8ij+X7Y7Xrlf+7OkZ3bcp9SsVNjlOrzegKLLYChIIBFZz6dZjSrQeZXacLEmomhZVqdtWnF87mvzZE7aVQMCr1wxJWdT8QBuQpUwRfjhuXb8oWyCK1H1iTi3byN91O/MoAbt2agbVaCNGW+D7NoAZq/bFO1zn2r1nNB3wF8u3nzA5TpdIdRMEAsHXR8GcGcidJY3Z75DIeBhbCpes6VMmuHABcPVITqYSBWPPYogFOR4e+dAA67OyEhshXmxMyLsAlvUcDpqWYHuTkizTcdFEspRKuD3WXceuEBYe/wj6SMdev7FLCAwOjfd8AoFA8DGSJDFhcOv3/5+4a99/+pIHz2xTtt8cdf73rcUJIA1/HYS9s/W1sGSdQvpCea2+LrER4sXGnFm1lfAEvElLskzZzi0o3aFZgq0BEGTj9xAQFMrGfefMDxQIBII4UKtcAdZP6UealEkTfe2O/5vDE+/XCb5O4ca1aPnnSLMKzS11SmoM7Um5rq2QrcwQVfUGKvX+Jj5mJgpCvNgYn9sPUBKwC6msyHFS09Zi66qROp2SaE8nAoHgv0n9SoW5t2MiO2cOZvbPnVg6LmHapXzMqcv3KNxsBGeu3k/wtap+15mxD4+SJo/xoqT+3i/Z/ccsGo4ZTLpCeZA+zkSNRftIcsTBGkN7kq1sMVuanCAI8WJjnNyTWF08yBoM4XqylknYlDyAckVykCOTJ4psGx+salBJlsTZJnMJBAKBMRRFplrpfHRuUpGWtUqSOZ1Hgm8laUBQSBhN+v9FWDw7WVuCJMt437xncszmERP5KUdlPLJkoEKPNiTLGPFAau/iTPlurak/agCpcmSOGp82Xy46L51C0z+GJaTpNkNkG9kY75t3GZWnutHzkiyTJl8Onl+5Faf57V2cmeR7ATsHh7iaaBaDQeX2I28u3XpEj18WEa43xLu7qixL3N85kbSpbFMYSiAQCCzh7xV7GDJxZYLXCo2kWY3idGpUgRpl8iVY7a2j81axrLtlIkPWKah6Ay2m/ESV7zpHs0nTNILe+CHJEs5JP31dF5Ft9AlJnTs7xVvVj+mmg4h9Sk2j6fjhuHokj9P8hrAwwoMt7yZqDaqqMmXJLrLUHkyhZiPo8L+52OkUcryvuRIf6pQvSP/fl1GyzSga9ZvK2t2nCU+EJxSBQPDfpnfLqtSrWBggUTIaN+w9S4O+U8jdcBgXbj5KkDX0oWEWvxf1fUHRtQN/5dFHpTskScIleVIc3ZJwcdM//F23Ez/nrMwfZZtwcMZSQgI+v4a8kQjPSwIQFhzCki5DObtqK7KiIMkyhvBwHFxdaD/vd4o0rc2yHsM5sWid9ZNL0H7uH5Tr2sqmNmuaRs9fFrJo89HYlrS4r6SbqyP+ASHIshSxfSZBhtTJeez1GkWRMRhUFFnCoGqUKpCV7TMG4+YqukMLBIKEQ683sHjLUaav3MeN+89xsNeRJX1Krt19ZrIBbHxQZBkXJ3vOrhlN5rQeNp37/olzjC9rXdKGrFMo3qoBXZZNjXZcHxbGnOa9ubx1H7KiRHSqfi+MPLJkYPDhNSRLl9pWppvEmvu3EC8JiPete1xYv4sQ/3ekypmV4q3q8+6lL3/WaM/Luw+jPDFRfPw6FmSdQsPRg6g9/Fub2nr47C2qd/8jXnMkcXEkb9a0nLpyPyoezNS7UWSZJtWLseKP3vFaVyAQCKxF0zSWbz/BhIU7uHE/opmjTpHfVxG3zW1Rp8j0blWVSUNt2zQ36K0fowvUwu/ZC6uEl1uaVIx/fhqA0MAgDs1Yys6x0wl+6x/reFmnkLlEIb4/vsEmdptDiJfPRLx8jCE8nFF5a+D78EmUKy8udFoymdLtm9rQMujwv9ms230mXuWyZVlCliSr5pAkiTvbx5MxTYo4rysQCARxRdM0Xvj6ozcYeBcQQrVuv/PGPwiDjep0JXd3wfvg39GOGQwqJy/fxfdtIFnSp6RADsuL3O2dMo/N/5tAeEjcylnkrl6e2sN6sX7IWJ5evmFRgsnws1vJVKxAnNazBmvu36K3USJyacveCI9LPFDs7SjStLZtDPqAmw+84t3nQ1U1VIs3mCLQNI1DZ2/SvoHoXyQQCBIfSZJI7fE+WNUTzq0ZzbSVe1m29Tiv3r4jPB4PmgD+gdFjFJdtO86Iv9fx3Odt1LHCuTPy9/D2lCqYzeRch2YuZd2gMfGy5/aB49zadwwkySLhIskytw+eTBTxYg0iYDcRCAsKxs/Lh4ubdiPHswaMYxIXHFxsn3KczM3F5nNaiprAXVIFAoHAUtKkTMpv3zXn0Z7JvDk+k1IFsiLHMdBXkiBz2n+9yvM3HKLLT/OiCReAy7efUL3bH5y99sDoXPqwMLaMmBQnOz5ENahoVlaA/xw3aIR4SUCeXb3F3FbfMsAtPz+kLcmZFZsjgqHiQdAbPxtZF8Hdxy/4bc4Wrt19ZtN5raFUQePFlgQCgeBTYW+nY/uMwZQqmDVO12sa9GheBYDA4FCGTloV6zhV1dAbDPwwebXRuW4dOEHg67dm15RsXCRVU1VyVCxp0zltgdg2SiAenLrA5CptMISHRwkWW/Q6cnRLEu85AMLC9Xw7ZgmLtxy1ONrezcUxhgs0PugUmYrFcpE7SxqbzSkQCAS2xM3ViZG9m1C710Srr7XTKXRpXAGAzQfOExBkPE7FoGocOX+bB89ekiVdyhjngywQLgAZi+Tj0ZnLVtsaG7JOIUPhfGQuUcgm89kS4XlJADRNY8E3A9CHhsUrMPdjZJ1is0DdAb8vZ+nWY4DlLkFbChdZksiQJgULfu1mszkFAoEgvmiaFqMGVaXiubG3s/5ZP1xv4MrdpwA893mLYkGfoec+b2I97pE1o0Vr2kq4ACRN60mPdTMSpT6OtQjPSwJw5/ApXt61bXEiWVFwcHGm2qCu8Z7rifdr5m88bPN9TGP1YCQgV5Y06BSFZz5vSJU8CZ0aV6Bb00q4i5YBAoHgM+DircdMWrSTjfvOERauJ1PaFPRuVY0+rarh6GBH+aI52X/qutXz+gdEPPSlSu5mUaXyVMljr3SbuWRhUufOxovbD2zixTeFYxJX6v8ygHJdWuLk/nll7UYixIsFPLt6i8Mzl3Hv2FkUOx3561WlQo+2JE0be+XZ59fuWFSzxSLez5Mic3p6rJuBR+YM8Z5y8/5zVhWesxQNSJcqKW/fBRP4viu1q5MDPVpU4Zdvm+Bgb2fjFQUCgSD+/HPsCk0H/IWmaVFZl4+e+/K/qWvZcuA8O2cOYVTvxnESL9kypgIgf/Z06BTZaFanLEsUyZOJHJliv69IkkS7OeOYWq0dKvEPQ0hXKA/PLt2Iah8QWaAuS+ki9N2xCJdkn75dgCmEeDHDgWmLWf3dKGRFjtoCenz+GnsmzOHb7QvIVblMjGscXJxsI1yAir3aUbhJLXJXK2ezPhnvgiIq4KoG28oXWZYoli8Li8Z058rtCFdpwVwZcHFKuD5MAoFAEB+CgkNpN2wW+vdZOB+iahonL99j/MId/NyrETXK5mfP8asWzavIMqULZSNj6hR0/N8cVu48aXT7RZIkJCR+H9DS5Jw5KpRk8OHVbPh+HHePnLHsDcZC4Sa16L5mOs8u3+TovFW8vPcI1xTJKNG2EfnrVEZWbBv0mxCIInUmuHPkNJMqxv5hkmQJeycnfnt4NEafIn+fVwxLVxpVb1nvnlgDZiUo06kFHeaPt/l+47o9Z2j7/UybzhnJ8j960aLm5xeZLhAIBLGxePMRuo9aaHJMCndXnuydAkCtnhM4cv622XmdHe05unQEExbsYPU/p1BN1FTJkDo5M0Z0pFY5y2upvHr4hNH5ahIWFGzZBVLEvabZpBFU69+Fe8fP8fzKTeydnchbuxJuqWzbwiAuiCJ1NmLf5HlRLrWP0VSNsOAQji9cS82hPaOOq6pKkpQpqNirHYemLzEbVyIpMqmyZeLVw6cYwsIBcE7mTvXB3ak9rHeCBEo1rFyEFEld8X0bYLM5FUUmT9a0NKpS1GZzCgQCQUJz8eZj7HSKyWJ0vn4BePv6kd4zOb/2a0blzuPMztu3bQ3s7XSs3HnS6BhJgtxZ0nJh7WirPesemTPg5unBqwdPTMwv4ZY6JRmL5SdziUKU69Yaf++X/JK3Ot4370WNk3U6KvRsS4vJI9DZ20ebQx8WxoOTFwgNDCJ1nuw2CV2wBSLbyAQ39h0zmS2kqSo39h5FNRg4Nn81vxasRR9dNvo65OTN42fkrV3J7BqaQQVJYrzXGfrvWUadH78lU4mCXN2+nxW9R/Do3JV4v4+374LYfOA8a3ef5t4TH+ztdMwd1QVbyKLI4k1lCmVn16whcYrIFwgEgk+Fg72dRbv8Du+/2yQLvjklSSJ1Cjc27D2LYkKUaBrcuP8c71dxq99VpnMLJJPzawS99SdF5gyU7tiMkHcBTKrUEp870YvhqXo9h2csZXHnodGu3TtlHj+kLcWkSq2YVrczI7JW5K86HU0KpsRCbBuZ4DvXPIQFmnbJ5apaFtcUyTi3dnu07R9Zp6AZVJyTuxPo+9bkHKnzZKffzkVMrtIG3wdPkN53ZI70+tT8vidNfh9mtRcmLFzP8KlrmbP2AKEfpP5VL52P2SM7s27PaX6YvMaqOT9GliXmjerKNw3KxmsegUAg+BQcOXeLat2MN6WVZYnCuTNxcvnPQESMTPrqAwkIMl064vza0SzffoK/lu0222Lg8obf4lTvKsD3DWMK18Xf28fkg7asU3BM4kK28iW4tvOgybEjLu0kde5sLOnyPaeXb4o5l6LgkiIp/zu3jWTpbVujy5r7t/C8mCB7hZImA5ckWcYxiQvn1m4HotdLUfUGNE0j8I2fyTlkRSFvrYpMq9eFN08iOptG9puI/IDtHj+bE4vWWmW7pmm0HzaL6Sv3RhMuAAfP3KBSp99oV7cMjavGb5tHQmL93rgHjgkEAsGnpHzRnBTPl8VoDRZV1RjWtV7U69uPX1CpeC6T/pcU7q54v/Tj4bOXZoWLvZ2OdKmSxsFycE2RjCFH1pgtIqfqDQT7BXBl6z6zImftgNEM9Sweq3ABUA0GAl+/ZceYv2M9n1gI8WKCagO6GC/nL0nIOoUXt+6b9ohooGkRW0OxzYEskaFwXryu3Tb+oZIk/vljllV1WY5fvMPG/edjbe2uN6h4vfRj2qp9LP+9F0M61cH1g4wgO51C9dJ5cXIwn9psUFV2HLnMOzMeKoFAIPgckSSJjX9+R75s6YCIyt+SJKHIEX9PGNyaxlWLcfn2E0q1/YWSrUex/fAlk6UmfP0CqNtnEuv3nDW5tk6RaVu3NElcnOJsv0fmDHx/fAMD9q9Ako3fiyxJrdZUlVsHThD81t/kOFVv4OSS9ejDwqy211aIAAUT5KtVifqjBrBt1NRogbsRzRUluq2axuymPU1PAmQsVoDH56/BB82wZEVBkmW6rf6b+ycuIOt0xrOTNI0Xt+7j5+VjtLbMxyzdetxkTQGDqvL38j14v3zL85dvyZ8jPcGh4eTJmpbeLauwcd85Tly6F+u1Mc3TeBcYEq9fQIFAIPhUeKZw59SKkew6dpkNe88REBRC7ixp6NykIpnTenD7kTdVu4wjMNh2N2udIpPaw51fvrVN1XQJLOoSbQprrg8PDiXojR9unjFbGSQGQryYof7IAeSsXJoD0xZz/9g5FDsdBRpUp0rfDnjmyoZip8MQbiolWuPZpRtoBgOSLOOczB33tKkoWL8aFXq1wyNzBu4eOROrY+ZjLE29hogS08aESySBwaEs2nw02rErd56w6n09Aks9PS5ODngks03PJYFAIPgUKIpMvYqFqVexcIxzY2ZvJjAkDIONKttKEhTOnZGGVYoS8j7LNL4oH2UJJTSynQ4n90/3vS/EiwXkrFSanJVKx3quQL2qXN5mYh9RA/37D6emqoS8CyD8Xgj561WNSjnLUroI+6bMN2mDW+qUJE2X2mKb06RMatLzYozIWgSWChdFkenUqLzIMhIIBF8lQcGhrNtz1qLS/paiaXDu+kPOXX/EyOkbaFajBHNGdsbV2dHKeTRuHTjB8YVreHX/iQUP07ZBUmSKNa+LnaN19toSEfMST2oM7RmR7mwhqt6APiycea36YnjvSfHMlRWdg3HVLMkSVfp1sqrqYfsG5awWLtaiKDLpUiVjePcGCbqOQCAQfCrevAtCb8MGu5FoWoT40DTYuPcsLQdPtyqu0RAezpwWfZharS1nV23l/vFzcW4EbGdlFXRFp6PuT9/FaS1bIcRLPMlWthidlkxGttNF5Nu/D8I1haaq+Hn5cGzearb9MpU/SjU2qZbz1alMzaE9rLKrXJEcNKpSJKoOS0KQxNmROSM7kyr559m4SyAQCOJDQFAIF28+QmdBN+j4YFA19p68xlELKvdGsuWnSVzcsAv4NzM1mvix4qvfKam7VeNLtG1EmjzZLb8gARB1XmyEn5cPR+et4vH5q4QFBnNjzxHTF1jYuDF5pnT03jyX2wdOoBpUspQuQrayxSyq+RIaFs4PU9Ywb/1BwsJt/+SgyDLOjvacWPEzOTNZvqUlEAgEnzPh4Xp+nrGRmav2ERSSOBk1OkWmU+MKzBjR0ezYkIBAvk9d3GwdsozF8vP4nGW9mKwhZ5UyDNq/0ubzivYAnwD3NKmo996N5nXjLr/krW76Ags14+tHz/itcN2oKoqaqpKuQC56rJuJZ86sJq91sLdj6g/t+LlXI/advE73UQts+otoUFWCQ8MYN3crC8d0t9m8AoFA8KnQNI0O/5vDhn3nrNrGiS8GVbO4ZcvD05fMCheAir2+Yde4Gfg+fBprqrSsKOSoXJpb+45ZZ2u4bYKM44PYNkoAPHNlxdnG7cQ1VY368HnduMvECi3wf/HSomuTu7ui0ykJ8gShN6is+ec0oTaKmBcIBIJPyeFzt1i/96xFwsWWvecUWSJzWsuaI1qaeaqpKl2WTUHnYBcjZlJSZHQO9ji4OOHg6myxnbKikLVMMYvHJxRCvCQAql4flWGUMPMbCPB9w6EZSy2+5s4j7wTbtw3XG/ALEEXqBALBl8/izUfNfld6pnBj7HfNbeqZ0RtUOjWuYNHY9IXzvq83ZpospYuQtUwxhp3aTOGmtaIEjKTIaAaV8NAwrm4/YHlnaiI8UxV7trV4fEIhxEsC8PDMZcICgxJ0Dc2gcmLReovHu7s6Y4hnASNjONrbkTSJ5cpdIBAIPlcePX9lNlPTLyAYVdNMNl2MjcjqvbExsH0t8mRNa9E8bqk8KN6qgdEMVFmnkLVMUdIXzANAugK56bFmBlP8rlCua+uoDFnNYEA1GKIXpzNin6xTkCSJ9vP/IGW2TBbZmZAI8WJDvG7c5eb+4/jcfmB+sA0IfP3W4rENKhdOkMwjnSLzTYOyos6LQCD4KvBM4Wa0z1EkHkldURQZzWSTgH+RJYlL635l45/9SflRQU+dIlMifxaCQsKYvnIvb/wDLZqz1V+j8MydLYYYkhSZJKk86LLizxjXhIeEcnKp6YdeSZZxSZGUJKk8SJE5PXZOjji6uVKkaW2+P7GBsp1aWGRfQiPuODbg9qGTrBs0hsfnbRPVHVXd1lRGkiThkTWDxXOmTZWMHi0qM2vNAaOuzmJ5M3Pt3jNCw8ItiidWFBn3JM4M61rfYjsEAoHgc6Zd/bKsM9GTSJFlOjaqQLXS+Rg+1bKGuaqmUaTlz2gaSB8JHr1B5czVB1y48QiDqjJs6hpm/tSJb+qXNTmnS/Kk/HByI0fnrOTw7OW8feqNq0dyynZpQaU+7UmSMkWMa27sPozBTEiDZjDQbdU08lQvb9F7+1QI8RJPbu47xl+1O8S7pwQAkoR7mlRU6deRlNkzM7dFH5PDK/RsZ9X0Ewe3JlxvYP6GQ8iShCzL6A0G7O3s+GNgS/q0rsaOI5doMWgamqZFuU5lWUJVtRgVeysUzcmMER3JmCbmL4lAIBB8idQuV5AKRXNy/OKdGFvtOkUmZXI3+rSqSsrkbpQvmpMTl+5aVH03qnq5kfOR362hYXq6/jQPzxRu1CiT3+Scjq4uVB/UjeqDupl/Y0BYcKhF48KDQywa9ykRdV7igaZpjMxVhZf3HsVbvCh2Osp0akGLKT/h4OKMpmks7DCQ08s3x/C+yIpMxuIFGXxwlcnyzLceejFr9X52Hr2MwaBSrmhOvm1djZTJ3Vj7z2le+weSNV1KWtYqifsHMStX7jzlr2X/sHHfeULDwsmXPR19WlejWfUSnLx8l6CQMPJkTUv2jJY1iRQIBIIviYCgEHqNXsTa3WeieapLF8zGknE9o7KCXvj6UavnBK7fe27T9WVZokyh7BxYMNym8z46d4Vxxc1XRB9z/wjJM6Xj6o4DHJ27kpf3HpEkZQpKtW9KiTYNsXdKmLYA1ty/hXiJB/eOn2NCuWbxmiN1nuw0m/gjWUoVxjVFsmjnVIOBXeNmsHfyPILe+AFg5+RI2S4tafL7Dzi6uhidd/OB87T5fiZ84EGJ9JyMH9SKAe1roaoq6/acZerSf7h+7xmO9na0qFWSfu1qmCw6FxQcitcrP9xdnURDRoFA8NXyxPs1B05fR69XKZ4/CwVzxtyqDw0Lp+mAv9lzwvbF4J7v/9Pm37G/Fa3Hs8s3UQ0xC5fKikKuqmX5dtt85rTow+Ute5EVBdVgQJIlNFUjTd4cDNy/IkG6SQvxkkji5czKzcxv2z/O10uyTP2R/an3s+k5wkNDIz5sej1p8uXEyc30h/mJ92tyN/gBvcFgNHZl79wfmLxkJzuOXI5xzk6nsHXaQKqWyhvtuNfLt4yetYll205E1XWpXCI3P/dqTPmiOU3aJBAIBF8jgcGhpKvaP0HqaN3ZPp5MFtZ+MUV4aCiXNu3G585DQgODOTRjCWFBwdF6Ick6BdcUyfj+5EaOzF7B7vGzYt1RkBWFHJVKMXDfinjb9TGiwm4i4eKRPM7XSpKEzsGe8t3bmB1r5+BA5hKFLJ573vqDqKpmVLjoFJm+Y5dw84FXrOfD9QYa9/+T5/v/jOpy6vXyLeXa/4r3K79ocS9Hzt2mRvfxrJ74LQ2rFLHYRoFAIPgauPXAK0GESxJnR1J7xL/Y6YWNu1ja9QeC3vghyXJUsVNHtySEhwRjCNPj4OpM2S4tqfVDb5yTunFw+hKjoRCqwcCt/cd5dvUW6fLnird9cUWkSseDXJVL45rSegEjKTI6Rwe+3Tof9zSpbG7XobM3McRSCjoSvUE1KlwiCQkNZ9Gmo1Gvh/+5Fq+PhAtEtAhQNZVuI+cTEiqq7AoEgv8W5tKq4zSnLNO1aUUc7O3iNc/N/ceZ07xPVNjBhy0CQvzfYQjTU65bKya/vUKrP0eRNK0nTy5eJ/Sd6XRtSZK4tf94vGyLL0K8xAPFzo4mvw+zeLwky2QsXoC6I/rx691D5K5WzuhY1RBRRTc81LLo8GjrWNMe1AQb9kWkC759F8Taf04bjajXtIgxm/afs8m6AoFA8KWQN2taUia3Li5FliQUOfbvaQlIntSFrk0rxdu2zSMmmq0CfGzeao7M/ncLyKJIkshyHp8QIV7iSbkuLWk7cwwOSYwHz0aiqSpuqTxoMGogSdPGnqkT4PuG9UPHMjhFYYZ4FKG/S15mt+jNk4vXLLapSqk8yEZ+MQCLi9UFhUQIp0fPXxGuN92V2k6ncOuht8U2CgQCwdeAnZ2Oge1rWzxekiBpEmdSJXcjZ2ZP8mZL99F5Cd+3ARRu/hPjF2yPs11vnnrx4MR5i5oA75kwG/W9VyZ9wdzYmckm0lSV7OVLxNk2WyDEiw2o2OsbJnifJWk686nD1/45ZLSPxLuXvvxRqjH7pswn2O8dEOGBubRpN3+UbsKtA5a56bo1rYS9TmesyjOqhYq5UM6MACRxMZ8WZ1BVi8YJBALB18agDrXo0qQiYLS6fhSaBq/9A/F65cf9Jy+5fu9ZtPOqpqGqGgZVZcTf61m48XCcbIrcKrIE34dPef04wg7HJK6U794ayUjrA1mnkKVUYTIVKxAnu2yFEC82wt7ZiRAz+4QQ0ZPoxe37sZ7b8P3v+D58GiOFTdUbMITrmd/mO4takadNlYzVE7/FXqeL1nsjoq8G/DmsnUWBYD/3agRAlnQpyZ89vckOqpqm0bhqUbNzCgQCwdeGLMvM/Kkjhxb+j9QeSS2+zlwPJYBRMzdFeUWsIWn6NEZ7H8XGmMJ16Z8kH5OrtiFr2WJkKxfROfpjEaOpGq8ePGVF7x/xunHXartshRAvNsTe2cmicYq9fYxjQW/9OL1iU6y59xDhpvN/8Yor2/dbtEadCgW5smksAzrUIl/2dOTKnJrOjStyZtUvhIUb8H5lXpXvOnYFiHBjjuzT2OgepyxLtKtbhqzpbR98LBAIBF8CkiRRpnB2GlQqbLYrtTV4vXzLpVtPrL7OJZk76Qrmtnh8iN87QgMCuXv4FPNb9yNN3hx0WDiRLKUKR93bJElCU1Xe+bzi6LxVjClUh8vb9lltmy0Q4sVGBPu/Q2+mZwSAczJ3UufKGuP4y3uPzfackHU6nl+9bbFNmdN6MK5/Cy6s/ZUrG8cyfUQHXr72Z+ikVRZd32fMYk5cjFDWjaoUZdZPnXCwj9iOstMpUVH2LWuWZMZPnSy2SyAQCL5WOjeuYJFHxRruPI5bPKGss9zzEon63vYjs1dg7+RAjaE9okIdPnyAVfUGDHo9c1r0wd/nVZzsiw+izouNODJ7BUEWdHmu879vY3XlWeK10VTVYu+OMSYv+QdFkS3qxaHIMlOX/UOZwtkB6NK0Ik2qF2PljhOcvvIAg0GldoUCtK5dOkHSBQUCgeBzwT8gmC0HL+D7NoAMqZNTr2KhWFOZi+XLQvfmlZm77qDt1g6MW68hY558S5AUmX1/LkTRKUiKjBbbPUPTMISFc3zBGmoPM92Lz9YI8WIjjs6zzJuRLFO6WI+nzp2NlNky8vLeY6PXaqpKwYbV42QfRKjmg2duWCRcIGI/ds+J6FlON+97sWDjES7fjnBjrv7nFD/+tY6x/VvQtm6ZONsmEAgEnyOapjFh4Q7GzNlCSGh4VKPaZG7OTB32DW3qlI5xzd/DvyFzWg8mL96Fr19AvG1IGccWARkK53tfnd16EaMZVB6duRSRFm3inqGpKveOGe/CnVCIx2Ub4ff8hUXj1g4YzbOrt2IclyTJbJuAvLUrkSp75riYF4W1ufmGD5T76Sv3qNFjPFfvPo025rnPWzr9ODfOUfECgUDwOXL/qQ9df57PiL/XRxXhjOwO/cY/iI7/mxNrfStZlhnauS6P9kzm2NIR7J//A7mzpImTh9pep1CxWNwq2Vbq0z5OwiUSVW9A1etNjpEkyarAYFshxIuNSJIyhUXj/J6/4NcCtdg7ZV6Mc87JTGcAeV27bVG2kTEkSaJUwWxGiyN9jCLLlC6YPer1kEmrMBgMUb+8HzNk0iqCLGy5LhAIBJ8rD569pE6vieRuMIxl24yXqJAk+N+f64w+FNrb6SiRPyvli+Zi3ZR+pHB3NVmDK8b8QNdmlUjmZr6OWGxkKlaAej9/FzGXkdRns5h53tWA3NXLx23ueCDEi40o26WlVePXDRrD9d3RPRX//DELyYQyf/PEi4ub91g0f1BwKEu2HGPIxJX8+Nc6Tl66i6ZpfNeuJgYj4uNjDKqKhsaRc7e4+/gFJy/dM3ntu8AQth66aNHcAoFA8Dny3OcNFTv+xsGzN82O1TS4+/gFF28a3+6PJGem1JxfO5r/dW+Ai5ODRbZ4JHNl075zpKrYl7Lf/MrizUcIDzftCfmYBr8Movua6XjmjpkoIskyWCGmYrveyT0JpTs0jfMccSVRxMv06dPJnDkzjo6OlCpVitOnT5scv3btWnLnzo2joyMFChRgx44diWFmvKjUp71Zz8mHSLLMnolzol6HBYdw79hZk3uLsk7h+q5DZuf+59gVMtUcRLeR85m5ej9TluyiYqexVO48jnKFs1MoV8y27sY4ev421br9wbe/LTE7VpFlnvm8sXhugUAg+NyYsHAHr94GWBwbCFgc15IquRs/92pM58YVLPKAv3wTgNcrP96+C+LctQd0H7WQhv2mEmpBZuuHeGTNiO+DJzEejjVNAwsfZj9GkiUcXJ3pt3MRTm5xi8mJDwkuXlavXs2gQYMYOXIk58+fp1ChQtSqVQsfH59Yxx8/fpw2bdrQtWtXLly4QOPGjWncuDFXr15NaFPjhUvypHx/ciM6h5g1XGJDU1Vu7T8R5W60KCpcA4OZ/ccLNx/RdMBfUdHp4XpDVNre6av3qdZ9vFU1AyKvPXD6htmxBlUlVXLTbcwFAoHgc8VgUFm0+ahVwgUgYxrLwgYiaVO3tMUe8EgiRx84fYOxc7dade3q70ahDwuP+XCsaSBFiJCMxQqan0iCpOk8yVq2KI1+G8qvdw+RtfSnKU6a4OJl8uTJdO/enc6dO5M3b15mzZqFs7MzCxYsiHX8n3/+Se3atRk6dCh58uTh119/pWjRokybNi2hTY03qXNmxTN3NovHa5oaJV4cXJxJlSOzydrSqqqSuWRhk3NOXLgTTdNi3YM1GFRumekmHR+cHe1pVKVIgs0vEAgECUlgcCiBVsTtKbJE6YLZyJkptVXrFM+XhfqVClsV/xKJqmnMWrPfYu/LizsPuH/8nHGvvqYRGhBEybYNLZhNotrAbnx/bAO1h/WxONYzIUhQ8RIWFsa5c+eoXv3f9F5ZlqlevTonTpyI9ZoTJ05EGw9Qq1Yto+NDQ0Px9/eP9udT8fLeI55dMu+hiCR94bzI74OoJEmi6oCuRsdKsoSDsxOlvmlsdIyqqmzaf87mBZIsZVSfJiRxiV8dGoFAIPhUuDg54BhL7ZbYUGQZO52OKd+3tXodSZJY/nsv2tYpjSRJZvshfcwb/yDuPol99+JjXj96ZnaMJEtoaOZDHzSNG3uOEOz/zqK1E5IEFS+vXr3CYDDg6Rm9YaGnpyfe3rFXDPT29rZq/Lhx43B3d4/6kyGD5fEctsbn7kOrxqfOnT3a64o921K8VX0gemS4rFOQdTp6rJ9pcm8xLNxgtvuzLfj4F83N1YnJQ9vQ/5uaCb62QCAQJBSKItO2XhmLUprLFMrGwYXDKZYvi8lxmqax+/hVmg/6m7wNh1G67S9MWbKLkLBwFozpzp3t4/lrWHtSJbcubsTSFgQuKZKaHaOpGu6pU1FtQBeznSVv7D3K33U6mQ1hSGi++CJ1w4cPZ9CgQVGv/f39P5mAcXK37sPn4Ooc7bWsKHRZ/icF6lfj4N+LeHb1FnaODhRtVocq/buQNm8O0/PZ60ibKinPfd5aa7pVaBrMGdUFTVVJntSVmmXy4+RoWayPQCAQfM780LUe6/eeISAwFEMsDRGrlcrLtB87kC2D+V5uqqrSY9RClmw9Fq2y+cWbj5my5B+W/t6TJ96vcXK0I3tGT3zfBlgUC5M2VVKyZ/A0Ow4iCtWlypEZn7uPIr68Y0G205G7ejmKtayH1427nF1lPKZGM6jcP36Oy1v2UqRpbYtsSAgSVLx4eHigKAovXkQv4PbixQtSp459jzB16tRWjXdwcMDBwbK0s4Qmc4lCJPFMybsXL80PliRcYnHRybJMqXaNKdWu8f/ZO+vwKK4uDr8zs3ElkBDc3d3d3V0KpWihQGmLtBSKFErbr0iheHEoDsXd3d1dAoGQhHiyO98fIQshyVp2Q6D3fR4eyMyde8+y2Z0z557zO2avL0kSfdvWYtSMtUlqsViLqqXyikaMAoHgkyNHJm/2/T2C7j/MiVcCbW+n0LtNTSYOaoOdnWm3zukrdrPo38MA8ZKAdarKs5dB1Ok5ySIbv+5a32TBO0mSaDlpODNb9E5yjC46hhlNv2Dw7mX0WDaVW4dOEvjIQD8lSWLTT1PIXq44aTKZl+9jLWy6bWRvb0+pUqXYvftt10mdTsfu3bupUCFxKfkKFSrEGw+wc+fOJMenJmRFofqXXUwbrKqUbt/E6jYM6FibUgWyI5u7iWoiEpAzszc5MnnbZH6BQCD40BTKlYkTy0dzbOmPzP3pc5ZM7MODnX/w+7cdTHZcdDodfyzanuR5Sx8ve7SsSv8O5rWJKd68Hp8v+QPJQILw/VMX2PD9r0iSRGRImOEJVZXHF64yImtFFvX4jugIy3ovJQebbxt9/fXXfPbZZ5QuXZqyZcsyefJkQkND6d69OwBdu3YlU6ZMTJgwAYCBAwdSrVo1fv/9dxo1asSKFSs4deoUs2fPNrRMqqHW4B5sGTsVrREhoezlipOleCGrr+/s5MCOOd/Rd+wCVmw9bvX5VaBBlaJINnKOBAKBILVQsmB2ShbMbtG1D/0CePQswKJr4/onQewDYxoPF2qWK0i/drWoVCKPRd+/bum9UQ1E5FWtjv1/LSFjkfy4+XgRHmi8+EXV6Ti6YDWhAYH0WTsrRe8LNnde2rVrh7+/Pz/++CN+fn4UL16cbdu26ZNyHzx4oK+4AahYsSLLli3jhx9+YMSIEeTJk4f169dTuHBhW5tqFRxdXajcqyMHZi5JsjTNzsmRQTuX2MwGFycHfh7YxibOC8DsVfvo1642ebKZtucqEAgE/zXe7wFnDjkz+zDp63aoqkqZwjnxTWe6AGpS3DtxHlmjGOx1pI2KZskXQ82aV9XpOL9+B/dOnieHESkPayKp5nbqS+UEBwfj4eFBUFAQ7u4fRjAtPCiY36u15/HFa6jvJHxJsoTGwYHBu5eSs0Ipm9vR/KvJbD9yyWzBJWMoiky/djX5/VvzSwQFAoHgU+VVcCgnLt5h5J9rOXftvsXzpHF34dn+aVa0DLZPmsn6EZMMqrhbiqxRqNa3C+2mjk7WPObcv0VvIxvg5OHON4dW0WTM13hmjk1msnNypGL3tvxwbkuKOC4AfwzthJe7i8mNGE1Fq9Wx+cB5q84pEAgEHyvPXgbR/Yc5ZK41iCb9/0iW4yJJkDl9GitaF1uuHeTnbxPHJW7+kBeWbZFZykdfKp1acXR1oeH3/Wn4fX90Wi2yovDs5l0OzlzKnaNn0DjYU7hRTSp2b4NrWuv+osaRI5M3R5f+SM0eE3jw1Lq/WB9KCE8gEAhSE/4BwVTuOp5HzwKsFuXu0bKaVeaJY8u4aez5Y55V53wXSZLwypbJZvMnhnBeUgBZUTg4ZznL+owASdJ7vzf3H2fruGkM2LbQZv0hsmZIS2BwuFXn1CgyFYrlNj5QIBAIPnF+mb/ZLMfFTiOTLaM3tx8+SyC7oigyBXNmpFuzylazL+RFAJvHTLXafImhi9FSsXsbm67xPmLbKAW4dfgUS3sPR9Wp8cJ2qqoSHvSaafU/IywwyCZrR0fHEG1lJcQYrY4v29ey6pwCgUDwsREdHcP8dQfNirjEaHVsnDaIPm1r4mD/Nn6gKDJt6pZh19yhODtZT7vs1D+bUE1p/JsM6nzTi/R5c9p0jfcRkZcUYOu4aQaL+sODXnN04RpqDfzcquvefexPw76/Ex5pXvv0pNAoMjFaHeO/ak15EXkRCAT/cV69DiMkzDyNE1WFIi2+p1vzyhxbOoqHfi/R6nSULpSD9GmTX1X0PsF+/sgaxah8hyW4pvOi/vB+1BqcdF8+WyGcl2Sg02q5c+ws4UGv8cmdLUnP8+quw0bn2jjyd7aMnYaDixOl2jWhRv+ueGW1fA8xKjqG+n1+4+HTlxbPAbEtB3Q6FZ2qksXXi2E9GtO9RdVkzSkQCASfAm7OjvE0WUxFq9OxYMMhNu49y8FF39tUrdwjo4/B8mhzkCSJut/1pkDdqtg5OpC9TFEUO9MaWVobsW1kIYfnr2R41or8Vrk10xt1Z1S+mvxapQ2PL11PMFZnwrZN5OtQQl++IuDBE3b/by4/FarDnWNnLLZv/Z4z3H3kn+zE2sioGFRVRafT8dAvgN5jFjDsj5V8YhX2AoFAYJQLNx4yffku/ly2k3PXH+DkaE+TasVNlup/F61WR0BwKP3HL7aBpW8p3a4JsgFVYEmWsXNyNGkuVVV5fOkG+WtWJFfFUh/McQHhvFjE7snzWNzjO4KexO/BdPfoGX6t2JInl28Q/Myf0FdBvLj70Oz5dVotUeERzGj6BdGRkRbZuGn/ORTZ8rf33eLqGK0OVX1bYfS/RduYseJtC4eAoBCu33tKQFCIxesJBAJBauWpfyC1vphI6XajGPLrcr75bQVl24+mWref+aJVdSxVo9Bqdew6dpm7j03oh2chLl6eNB07JNFzkiKjcbCjfJcWyBrFpPluHTjOlw55GOxZhCW9huN37ZY1zTUZsW1kJqGvglg7dGKi53RaLZEhYfxcqjExkVHJWkfV6gjxD+DM6q0WNWkMj4xCp1oWdVFkOdFuqu/yy/zNVC6Zl5/+Ws/mA+dRVRVJkmhctRg/9W9J4dyZLVpbIBAIUhOh4ZHU+uIX7r1xMHTvRJ1PXrrDVxOXUKdCEbYctFz76tqdpzbtF1f32944uDjz76g/CH35Sn88U+H8dJ4zgTtHzxhsHfAuEa9DAQiPiubI3ys5tngtA7b8Tb4aFW1ie1IIhV0zOTBzCcv6jUyytbg1Uew0VPqiPR1njDNpvKqqHDpzg3nrDrDv5DWePH9l/KJ3kCTIl92XEvmz8c+2E/E+pInh6GBHdIw2Xqa9osg42GnYM2+YxT1BBAKBILUwa+Vevpqw2GAjRVmSjH5fGmLnnO+oVjq/xdebSkxUFNf2HCU8KBjffDn1/fWCnj5neJby6CxIM5BkGScPNyY+Po69idtPSSEUdm1IwMOnKCaG16yBrJi2llar44tR86j1xS+s3HbcbMcFYv2x6/f8WL71uEkfxKjomAQlglqtjsioGHqPWWD2+gKBQJDaWLL5SPx99ERIjuPi5uKAf8Brjpy7ic5IxDs5XNy8h6n1ujK9UTfmtR/A4i+GcWLZBlRVxSODD7UGfxH7BGsmqk5H2KsgTq/cZAOrk0Y4L2bi5u2FzsY183Foo2PIX7uSSWN/X7iVJf8eAZKnfmvOZzCpDHutTsf56w84e9VyiWyBQCBIDbx49dqmgfbXoZF0HPoX1btPIG/joazbfdrqa2z/5S+mN/6cWwdP6LeHHp69zPxOA/lnwChUVaXFL8OoN7QPiv2bJNw3foysMZ5dothpuHciZVvGCOfFTEq3a5Iybb8lCQdXF/xv3jPaMyI6OobJS3YYDGta1zTTXv+N+342tkQgEAhsS87M3skqfjCHB09f0u6b6azcfsJqcz46f4V1w34BiLctFNc0eN/0RVzashdZlmkxYSi/PDlB1/mTaP37D/TdMIcJD4+YtI7e6UkhhPNiJh4ZfKjzbW/bL6SqRIdHsHboRIZmKseRBauSHHrp9mNevHptcDpZlrDXKMlu0ihJ4JvWtFwidxenZK0lEAgEH5rPW1QzWsBgbb6etJRoC0XlVFXl8vb9TG/yOd/6lubXyq0NPnDKisLmsVOZ2ao3X3sV48e81bm4eQ/ZyxSjWNM6OHu66xsMJ4U2OobCDWtYZK+liGojC2g2/lvsHB3YPvEvoiMsK2U2hbjtKW2UjkWff4dnxvQUrJtQIM6UJCtVVYnR6pK1Nxs7D/i9MN7KwN3ViRplCyRrLYFAIPjQNK9ZkroVC7Pr6OUE35+SZJvajecBr9l9/Ar1Kxc16zpVVVk9ZBy7/5iHrFFMEqfTabXcO34u3vjzG3Zyds02Wk4azrl12wl8lHQUXdYopM+Xi/y1TEtxsBYi8mIBsizTeNQgJj07RY/lU+k4czyd50xEsbdDSmZkIykkWWLLuGmJnsufMyMuRnphqGryksrizWXCmBE9m+Do8OEEjAQCgcAaKIrMmj8GMKhrPVzf+Z51drSnW9MqNlv3yfNAs685s3oLu990jzZXVffd8XH/XvvdBO4eP2fwOq9smRmw5W/kFNpai0NEXpKBk7sbZdo31f+cJksG5rTpR8TrUCSNEtuE0VoOg1bHrYMnCX0VhEua+P0vXJwc6NGyKtOX70KbSBKtoshWa9VuDEWWGfZFYwZ3qZci6wkEAoGtcbC3Y+Kgtozs3Yzz1x+gqirF8mVlzc6T/L3hoE3WTJ/OfKmPXX/MQ5JlfT6LNTA2V8e/xiWrlY2liMiLFSlUrxq/PD1J1T6dsHOwj+e4ZCtTNLZleDKTfaPDE28CNubLlpQrmguJ+Am1iiyTxs2Z7BnTpUii8YJxPRnVt3nKJDULBAJBCvA8IJjfFmyl//hFLN10lJCwSJwd7Xn07BUaG0ln1KlQ2KzxOp2Oe8fPWtVxMYasKDw8cynF1nsXEXmxMmuHTuTAzKUJjt8/dZGnV27i5OZKZGhYgnJrSZKM9gty9nTHzdsr8XNODmyf9S2LNh5m9uq93H30Ak83Zzo3qUiftjVZs/MkX/+63PIXZiK6FKt5EggEAtuz+N/D9BmzQJ+0KwFz1uyjSJ7MdGxUwSZRbe80btgb6EeUGLEPjBKmbOxLsoyq6kzLATCAqqomlVLbAuG8WJEza7awf/qixE+qKlFhEeQoV5ygp88JuP8YxU4Tm4sSE4N37my8eviU6MioRLeaJEWmSp9OBhthOdjb0bN1dXq2rp7gXI+W1Vi14wTHL9yOt7UUl3BWumB2Tl25Z+5LTkBOG0pcCwQCQUqy98RVvhg1L9Hd/4s3HzF16U4UGcxJLzGW5CsBg7vWN9tWSZLIW6M8N/cdN6hFlrVUEYL9/Al8nHwpC1Wno0CdysmexxLEtpGVUFWVlYPGGBvE3WNn+XrfCvr9O49ag3tQ55uefLVjMaOv7aHbov8hSVICVV1JkclcJD8NRnxpsX2ODnZsmTGEwV3r4+76toQ5W8Z0/DXyM9KmcbN4boiVx86bzZeyRXImax6BQCBILUycuwnJgLzuU/9AJMm82+jsUd1pV69sohkEsiyRL0cGeiXyAGoKdYb0TNJxkWQZ5zQe6LRaqzgusqKQr2ZFMhf9MFWloreRlfC7fpvR+WuZNHbIgZXkqVI23rUnl20g5MUrdFotz67f4cb+46CquKRNQ7W+nak7tA+Ori5WsTUiMpq7j/2xt9OQI1M6ZFmm3TfT2bD3TJKquYaQZQlZltn61xC8PFw5efEOiiJRo2xBsmZIaxWbBQKBICUJC4/Es2Jfq80nyxJVS+Vj8/SvkSSJMbM28OeyXYSExeYxKopMm7pl+OO7TqT1dLV4ne2TZrJu6MR4pc+SLOPg5kK6nFl5dPayVV5P+nw5+ebgKty8rfcdb879W2wbWYnwwGCTx7qkTQOANjqapX2+58j8lciKgiRL6LQ6JAka/TiQ6l92wcXL0+T+Rqbi6GBHgZwZ4x1rUr2ExbLUZQvnZFCXeoyevo7D527qj0uSRKs6pZk5slu8aI9AIBCkdkLCrKfh5ersSK821RndtwV2b3JZxnzZkmGfN+Lk5btEx2gpmjcLPl7Jf+Cu910fCtatwv4ZS7h34hx2jg4Ua16XdLmyMbet5dH7d5FkiZwVSlrVcTHbBhF5sdK6z/z5LkNZo6XRabJk4Of7R5AkiX++Gs3ePxcmeU3HmeOp2ruTLcxNQERkNEVafs/jZwEGeyMpiky2DGnZMG0QL169xjedJ55uzpRpPwq/F0EJrlVkmXJFc7JrzlCbZeULBAKBNQl8HUbDvr9x6vI9i+eQJKhZtiA/D2xDvuy+OBvR4rI1C7oN4fiSdbESHlbA3sWZqSFXrDJXHKKr9AfAPb03xZrWNloK3XbKKO4eO8PMlr3ZO22BQWdn85ipKdYE8tnLIGqUzp+kkF3cy8rkk4Ytfw0hX/YMVCqRl1xZfJi5cg9P/AMTdXq0Oh1Hzt1iy8ELtjRfIBAIrEaPkXM5e/VBsuZQVdh38hr5c2T44I4LQOjLV1ZzXACiQsOMVsjaErFtZEVa//4DNw+cICwwOFGnpNbgHjy/eY9ZLfsgmaBGGPTkGfdPXSBHuRK2MFfPmSv3qNtrEqERUQlyXjxcnSiWPytp3FxoWqMEreuUwcnRPt6YhRsOGcyVUWSZxf8epmkN274OgUAgSC63Hjzj3/3nrDKXVqcjODQ8wXfmhyBt9iwmtwwwhXQ5s3xQPS8RebEi3rmyMfzkRkq0qh+vTYBb+nRU7dcF9/TpWDd0ImBctTCOgIdPbWJrHFqtjtZf/0loeFSiegVBIeFk9E7Dqv/1p0uTSol+CF8EGm4KqdXp8HtpvB+SQCAQfGj2HL9ioL7IPJwd7fFyN1xooaoqB09fZ/aqvSzZdISXgSFWWj0+lXq0tZrjIkkSVft2scpcliIiL1bGO1c2eq/6i9f+L9k6/k8OzlnO62cvODBjsUXzrRr0E3mqleXixt08vngNe2cnijWvS/Yyxazi9W49dIFHzwIMjlmx9Rib9p8lZ2YfvmhVjc+aVo7nxGTyScON+35J7oBp3uTJCAQCQWonRquzSsdFRZb5rFllfYJuYpy8dIduP8zh5v1n+mN2GoW+7WoycVBbo3mC2uhozq7dxuH5K3n18CmemdJToVsbSrVpiMY+9js64OETji5Yzcu7D8lUrACPz19N1usC8M6djepfdk32PMlBOC824sj8leyZ8ney5wl8/IzvfEoDoNjZoaoq2ybMIG/18vReMxMXL89kzX/y0h00imwwSRdiM+8v3nzIwAlLWLjxEDtmfYubS2wFUY+W1Rj6x0qSkmuM0ero3tx2DcwEAoHAWpQtkjPZuRyyBL7pPBj+RZMkx1y+/ZjaPScRFRUd73h0jJZpy3bxOjSCWaO6J3l9REgo0xp04/ahk0iKjKrV8ez6Ha7tOszeqX8zcMdi9k1fzMaRv4EkvVFxj71WsbdD+9665tBw5FfYOzlafL01ENtGNiA8KJh/R0+2+rza6Gh0MTEA3Dp4khlNv0j2h0yjUUzuNq2qse7JuasP+Pb3f/THv2hVLUk9F0mSaFajBDXLFUyWnQKBQJASlCqYnRIFsqFRLL89NqlegkOLf8A3nUeSY8bN2kB0dEyizXRVVeXv9Qe5djfptIF/vhrNnaOx8hZxibhx6Qj3T19kct0ubPj+V1SdiqrVoYvRor4pANFGx+Du6x0vvcFUJEkiX40KZl9nbYTzYgPOrd9BTIT1NAISQ6fVcvvwKW4eOJ6seepWKGy2MJ1Wp2PJpsO8Cg4FYM/xq9x/8iLRsRoltsu0aNQoEAg+BiRJYunEPqT1dEWx4OYOUDBXJjL5pEnyfGh4JOt3nzEqS7F8y9FEz732f8nxxUmXPataHfdPnE/aQFUl2M8f1czvfllRKN6yPmkyZzDrOlsgnBcbcGWHbVqkv4+s0XB61ZZkzVG2SE5yZfEx+7qoaC3nrz8gOjqGvmMXJFkhrtOpDP3fymTZKBAIBClJ7qzpOb1yDMO+aEIWXy9cnOzJncUHV2cHk5J5Z63aS3R0TJLng16H6Rs9JoUsSbx4lXjy7u0jp/VReIuRwM7J0aTKVyQJJMhQMA+dZ09I3rpWQjgvViY0IJDTKzel0GoqkSGhyZpBkiT++bWfRddOmLuJDXvP4v/qdZK5bVqdjgOnr3Pn0fNkWCkQCAQpi4+XO6P6Nuf21t94dWQmVzZO5Piy0XiboIIbEBTKE//AJM97ebjiYKRrtE6nktk3ieiNFfRVZEWhYvfWOLg4xXNg5DdJwoUb1SBrqSK4Z/Aha8nCdJwxjqHH1iU7z9JaiIRdK3N04eoUE5ZTdSoZCuRO9jx3HvtbdN3eE1c5feWeSYn59x6/IGdm8yM8AoFAkFrIky09XZtW4o/F2xOVlniX4xduky1jukTPOTrY0alxBRZuPJzkPCoqXZpUSvRcjnIlkGTZZMmNxNDFaCncsCYNR37FodnLObd+B1HhEWQvU4xq/TqTs3xJi+dOCUTkxco8uXQDWUkpn1DFKY0H0ZHJy69JTg+P4JBwkx4C0nhYp6mkQCAQfEgaVS1m1HEB6Dx8FnNW70vy/Pe9muHl7oKSRGLw8C+akDm9V6LnPDL4UKptI4v73kmyjGcmXwrVr4aHrw+NfhzI92c289PV3XRf9L9U77iAcF6sjr2zZQ0Iuy+ZTKl2jWN/MDm5VWJZ7xEMy1iOcxt2WLQuQMH3mjRaE0mK3T8uni+rzdYQCASClKJi8TyUKpgd2YRk3q8mLElSRyuLrxcHF31PzbIF433le6dx44/vOvJjn2YG5+4wYxwZC+cDCbMKImSNgmJvR49lU6ze9DclEY0Zrcy13YeZXNv8Zoqjr+7CJ29Ojsxfye7J83l6+QaSLJG3RgVc06bh8vYDRAQloWT7poZ/0O6l5KtufgmbqqqUaT+ay7ceG00is4QVv/ajZe3SVp9XIBAIUpI9x68w6e8t7DluWkNCRZYY3rMJP/ZpbnDcvScvuH73KS5ODpQrktOgsN27RIVHcHzxWg7OWc6jc1eMKuhKskzJ1g2oNfgLXt57SPCzF3hm8qVo45rYOX5Y3RYw7/4tnBcro6oqE8s14+HZyyZLMcuKzG8vzuLs+VYTQBsdjSTLes/46bXb/FSgVpJzSLJMrkql+ObAKovsPnf9ATU/n0BEZLRRwTpTcXNx5I/vOtG8Zkm0Oh2ebs6iZFogEHyULFh/kN4//Y0sS4lqsySGJEHzmqX457cvbWrby/uP+D57ZYNjZEWhwQ/9cU3nxfrhvxAZEgYSoILGwZ7GPw2m/tC+QOz9J+TlKxzdXHFwcbap7e8iukp/QCRJov/mv8lSolDsz0bCcnF18+86LhCrpvtuSO/Chh1IBkSTVJ2OWwdPEvTUsqqe4vmycmTJj7SqUyZZ4kxxODnaU7NsQb79fTnpqnxJ+moDKNB0GDNX7kFng+iOQCAQ2Iqn/oH0G7cQFUx2XABkWU6RpoxRYRFGx0iyxN1jZ/lnwKhYxwX0ougxkVGsH/YLM5r15J+Bo/naqxhDM5RlkHsh/mrWk/unL9rQessQzosNcPNOy7DjGxi0aynV+nYmW5miiY6TFQUHV2eajfvG6Jxhr4KQZeP7k2GBwWbbG0f+HBlYPKE3/genc2fbb5QokM1ikabwiCg27D3Dq+Aw/bE7j/z5asISPh85TzgwAoHgo2HBhoMmK5G/i1aro2n1EjawKD5ps2XCzohcvzY6hluHThocc2HjTvZOW6h3blSdysXNe5hUoQVXdx2ymr3WQDgvNkKSJPLXqkT7aT8x/MRGOs2egLuvd7wxuSqX5ruj60ifN6fR+dLlzIrWiCiRrNHgmTH55cguTg5kTu/Fil/7kd6AvLWlLNtylHW7z1h9XoFAILAFl24+NvsajSKTO1t6gkPCqdfrV4q3/oFmX01mw94zJlUrmYO9sxMVP2+bZAKuJEs4uDoTFRpufLL3nDSdVotOq2V+p4Fooy3vh2RthM6LjYmOjOTc2m08u36H8p+1Im3WTHhlz0z6vDnwyZ3dpDkenL1EVHgEikZBm4Rqo6xRKN2uMU4e1svzyZHJm9P/jGH26r2Mm7WRaCu1U5cliZkrd9OqjkjiFQgEqR+dqkuq72yS5MjkjUZR6PUmT0anU7l+14+tBy9Qp0Jh1vwxAEcHO6vZ2HTsEK7vOcKzG3fitQ2QFQUVKFS/OmdWW6bIrupUXj9/yYVNuynRor6VLE4ewnmxITf2H2NW676EvniFYqdBVVV0MVqyly1Ov41zEr3m4bnL7JnyN5e37UcXo0Wn0xIWEGRwHVlRcPHypPnP31r9NaT1dGX4F01I7+VBn7ELrDKnTlUtepIRCASClGbhhoOs23UKc9oAVS+THycHe3YcvQSg7x8XV825+/hlRkxZxf++62g1O13SePDdkTVs/2UmB2ctJexVMJIsU6RxTTQO9pxeuTlZ88saDU8v30w1zouoNrIRT6/e4ueSjYiJik6ggihrFDIUyMOIM5tQNG/9x01jprBp1B9mrSMrMsVa1KP1b9+TNltmq9ieGDqdjl6j/2bRv4dRZDnZJdWZ03txZ9tvVrJOIBAIko+qqly7+5RXwaFkzZCWOw/9qdPrF7PU+DUahZ2zv6XG5xMNjnN0sOPRrsm4u1qmDWYI/9v3eXD2Mq5envjffciSL4Yme05Jlmn12whqD/7CChYmjjn3bxF5sRE7f5uNNiYmUflmXYyWxxevceHfXXov9uCc5WY7Lm0m/0jZjs1w805rFZsNIcsyc376nIZVizF5yQ7OX7sfm3mv1Vm0nVSrfEHrGykQCAQWsvnAOX6YtobLt2KjwpIEaT1czZrD2dGe7bO/5bIJkeWIyGhOXrpDrfKFLLI3MZ7fusfyfiO5uvNtc2BZUfQl0clBVVWKNaubvEmsiEjYtRGnV24yqPMiKwpn3nSEjgoLZ0X/H81e4+TyjSniuMSh06kcv3CbkxfvEBkVY7HjAtCqThkrWycQCASW8c+247QcNJUrt5/oj6kqvAgMMTnqUr9yEQIOz6BckVyoJnoK1tz2eHHvIb+Ub8H1vUfiHddptcleSJJlynRoinfO1KOULiIvNkBVVaLCDGd167RaIl7Htjs/vWoz2ijzs7jvHT+H/+37eOfKZpGd5jLyzzVMXrxd/zkwVYTvfWRZYv/Ja/ikcaNkwexWs08gEAjiuP3wOdOW7WTZ5qOEhEXg5GBPwdwZ+b5XU+pWKIz8ppNyRGQ0/X9eBMR+d1vKziOX8XsRREafNFQoZrxhrixJZPL2tHi999n80xTCg4It/l42RLFmdegy9xerz5scROTFBkiSFOtQGFCTlTUK6fPlAuDxhWuWLsSBWcssu9ZMXrx6zZQlO6zzpKDClCXbKd9pDPV7/0rg6zDj1wgEAoGJHD57g1Jtf+SvFbsJfB1GjFbH67AIjl+4Q9P+k2nc/w+u3H7Mxr1nGTd7I0GvTWswawitTkeXEbMAKJgrE9VK5zco+KmqKo2+/B9P/QP1x6LCIzi+dD2bfprM7inzefXYz6S1I0PDOLFsg00cF1eftPRZOwt7IzoyKY1wXmxEtX5dMCTvpovREvryFXeOnUHj6GBGM8Z3UFXuHE0ZvZR/9521Wqm0TlX1LQj2n7pOy4FTkvXEIxAIBHFEREbTavA0wiOjknzY2nX0MsVbj6T119OYND95VTjvcvD0De49eQHAwvE9yeKb9La+Cjx9EcSPf64B4NQ//zI0Qxn+7jyIreP/ZPXX4xiRtSLLvxxpVOMr5EWARdF7U9CY2GcppRHOi42o2rczuSqXRpIT/y+WZJnjS9YzqUJLru48lEAYyFQ09gl1Au6fvsjePxey/6/FPLtxx6J530Wr1bF40+Fkz5Po3Dodh87eZNuh1Cc/LRAIPj5W7zxJQFBosiMplnL68j0AMvqk4euuhsuKtVody7ce4+S6Hczt8BXhwbGpBNro2GIPVafjwF9LWDnwJ4PzOKfxSPJekxSSLCFrFKM7BHlrVDRr3pQidbpUnwB2Dg58tX0x236ezr7piwh7FV+rJe4XE+DhmUs4e3kQHvg60eokQxRpVFP/7xd3HzK3/QDunTiHJEmxTx2qSqEG1em++A9c06ax6LWM/HMNh87ctOhaU2k5aCpff1afMV+2RLFCbyWBQPDf5OSlO1aRc4hDkiQypPPA72WQXq/FEBrN2++vR88DsNMoBqPWUdFaNo78HUmKFYN7H1VVOTBzKfWH9yNN5gxA7DbR8SXrOL5kPaEvX+GTJzvZyxbj/skLsQm6xl6TLKHqVFSd4bG6GC01BnxmdL4PgbhL2BB7J0eajh3CJL+TZCySL0kPV6eNFaLLWCRv7AEztpBKtm4IQMjLV/xWpQ0PzsRGMFRV1Udzru44yJQ6nYmJijL7NbwMDGHKkh1mX2cuWp2O3xZsod+4hTZfSyAQfLpYo7FsHLFfxSozRn7GpulfGx1vp1GoXCKv/mc3Z0ejDo9rZDj+l68n6ri8S5w67qtHTxlXrAHL+n7PncOn8Lt6i0ub93L32FlUVTUpAmNsLVkT22ag3bSfyFG2uNH5PgTCeUkBQl8G8uTidYNbQ7JGoVjTugzes4wqvU1XXYwKj61qOjBzKUFPnyeasKXTanl49jJn124z2/ZpS3eYlOsiv2ngKFuSu/MGVYW/1x/k8m2hvisQCCyjdvnCyY66xH2fuTo7snhCHxpWKUbt8oVoXTdpiQdZkujeogppPd9qw7SoVdqgLbIkUTy78X50siITFhiMqqrMatWXl/cfgfq2Oiou2qLqdDh5uJn0GpPCPYMPZTs2Z/jJjdTonzqjLiCclxQhMtR4NY0kyUSHR5CvRkU6/TUejwymNVh0co/9RT26YLXBLSdJljm2aK1pBr9h8uLt/Dx3k0lj//qhG8sn9aNW+YLkzeZLgZwZzVorDlmWWPyvbfJrBALBp0/dioXJky29wYKJpJCIdSjioiWvQyOYsmSH/oFq7ujPqVUuVmAzzsGJ2+auXaEQvw3pEG++PNnS07Fhef3Y91FVlUFftkE2Ei3SRsfgnSsb906e596JcwarilRVxcnTMnV5WVGo1rcz3Rb+TrbSRS2aI6UQzksK4JnJF3sXZ4NjtNHRZCj4VhugxlfdjM6bpVQRvZMT+jLA4FhVp+P185fGjX3DwdPX+e5//5g8vlb5grSqU5rNM4Zwaf3PlC+ay6LwrU6nsmnfWc5cuWf2tQKBQKAoMv/+OZiMPubn+KnEVkO+y5kr96je/WduP3yOs5MDm2d8zYapg2hZqxTli+aiZa1S/PvnYDZOG5Roo8WZP3anXb1ysbbJMnYaBUkCJ0d75o39gqaNKlOsRT39Vk1iOLq5ULJVA27sPZpk5+g4wgOD9RpiZiNB8LMXll2bwoiE3RTA3smRyl+0Y9+fixJPppIkHF2dKd2uif5Q3e/6cGDmMgLuP0py3ubjv9H/2ytbZsICrya9NSVJpMuZxWSbpy3biUaR9SXNSaEoMjXKFCBrhvglgVHRMRZn+9+4/4zyncbQpm4Z/h7XE/s3pXqqqnLs/G2e+Afim86dCsVy64WmBAKBII6cmX24vP5neoyax5qdp5I1l1anIzQskglz/mXumB7IskyDKkVpUMW0yISjgx0Lf+7FiF5NWLPzFMGh4eTJmp629cri5hLb16jVpBHc2HuM8MDgePcISZZQVeg482ciQ8N4cOaSSUUdqpHv7aTQxWhJk9nXomtTGvHNn0I0Hj2I9PlyJvCaZUVBliW6Lf4De+fYX2RVVXly8RptJ48kY9H8CebSODjw+dIpFKpXTX+scs8OhsutVRUPX2+T7d1/6rpRxwXA1dkh0c6oJQtmT/AEYy5rdp7i299XALD14AXyNxlGte4/0+G7GdT4fCJ5Gw9l/Z7TyVpDIBB8mjg7OZA9kzd2BiIaphKj1bFi23EiIi3XUsmXPQMjejZh4qC29GhZTe+4AKTLkYXhJzdSrHmdeFtImYsVpO+6Wdw5eoahGctxeuVmm2tilevcwqbzWwsReUkhnD09+PbwarZNmMHB2csJDwwGSaJA3So0/GEAuSqWAuDKzoOsGjyWp5dv6K/1yZuDXJVK4+btRfq8OSnVrjGOri7x5nc3wTG5sGkPbaeMRjIhqdaUvNu0Hi4cWPgDebKlT3Cuc+OK/DBtDRGRURZHYHSqypzV+6hYLDddv5+T4PxDv5e0+2Y6yyf1o2Xt0pYtIhAIPlnSebparWQ6KjqGwNdh+Dp4WGW+90mXIwu9V88k5EUAAQ+e4OTpjnfOrMzr+BWnVvybIkKekizry7FTOyLykoI4e3rQ8pfh/OZ/hknPTjHl9WUGbFmgd1z2TV/I1Hpd4zkuAP637nF80Rry165MpR7tEjguAHcOnzK4Zwrw8u5DAp88M8nWmmULGsxZkWWJvu1rJeq4AKRxd2HJhN4osoySjK2dGK2Or39dDiTsOxJXDT540jK0FoZJBQLBp0ubumWtdtO3t9Pg6WY4d9EauKbzImvJwnjnzMqDs5c4uXyjVV6DQyL3jXhIEtnKFkv2OimFcF4+AIpGg7tPOhzeJPGGvAjg9xrtWdF/VKJbP7FiQirL+41M8pdYVVWTIiqmhkEGdKyT5LaRJIG9RsMXLaslej6OJtVLcGTpj7Sqk7yoiP+r1wY/vE/9A9l/ysL+UAKB4JMiJkbLut2n6TR0Jv3GLcQxERVyc9EoMu3rl0s0IdeWnFiy3uhDqalEhoQaHqCq1B70uVXWSgmE8/KB0UZHM6VuF24dOGFwnKqq+N+6x91jifcyyl25DNpow/0v0mTJgEfGxCMl71OheG6mDu+MJMUXfVJkGXuNhn9++9KkbP7i+bIyb0wPapcvaNK6lvL4+Subzi8QCFI/zwOCKdN+FO2+mc6qHSfYceQS4cnIU4HY7zxnJweG92xifLCVef38Jdbphmuc9PlyUqpt45RZzAqInJcPzPmNu3h49rLJ4wMePCFnhVIJjhdtWhvPzBkIfvo8yYqmWoN7mFWd06dtTSoWz8OslXs5cPoaGo1C/cpF6d2mBtkzpjNpjjNX7tF0wGSeBwSbvO5bkyVyZvbm9sPnRsf6prPNPrRAIPg4UFWVJv3/4PLtJxZdL0mJB6az+HqxbupAcmUxTXvLGqiqyulVm7m254hRuX9JkS2uLnoXXYzWtOh9KkE4Lx+YU//8a9Yvn6t3/JLkwCfP2PW/uZxbt53X/i9jy+je+RTKioJOq6VM+ybU/Kq72fYVzZuF6T90NTouNDySf7Ye5/jF22gUhToVC1GqYHbq9v6V0LAIs9cFsNPIrPz9S1oMnMpDv5dJ7nj5eLlTo0wBi9YQCASfBscu3Obs1fsWX5/U98u9Jy+4cvsxhXJlsnhu8+xQWTV4LHumzDdaOSErCpV6tuPCxt0EmZjPmBRKKu0enRQfl7WfIKEvA012XDwy+JCnalkAXvu/ZOWgMZxcvjHhp06K/aV2SetJ5mIFqdavM0Wb1rGZJsreE1dp8/U0XodGxKpNShJz1uzD082Z16HhFlUbSRL0bF2dInmy8Ns37Wn3zfQkx/76TXs0VtoXFggEHyd/Lt9p0XXKG/VbrYF+PyOnraF1nTIpEpm4sn1/rOMCRlvKuHmnpfGPg2j/51h+Klib5zfuJhwoSbimTUPYq6AkoziyolCkcS1rmJ9iiJyXD4xPnuwmJ2S1nDQcRaMhNCCQSRVacnL5hsR/uVVAgjRZMjJwx2KKN69nM8fl+r2nNB0wmZCwSFRiq4Ni3khXB74Os7hMWlWhX7vaADSvWYrlk/qRwdsz3hiftO4s/LkXHRqUT8YrEAgEnwI371sWeXB0sDPouADceeTPuesPLJrfXPZOW2BURRegQJ0qDD22Do8MPiiKwuiru2k0amC8qiKNgz1VenVg0K4lSG8eLBMgScgahap9O1vzZdgcEXn5wFTu2YGDs5YZHWfv4sSxRWtx8nTn8Lx/8L9tODyqi9Hy4PRF7p+6YNMeFX8u20WMVptsQbr3KZAjA5P+3kzRvFno3LgiLWuXplmNkuw/dY3Hz1/hm86DGmUKiIiLQCAAwMvD1figRAgNjzJpXNBr4z3qrMG9kxeM5rlkKJSHAVsWxDsmyzJNRg+m4Q8DeHzhGjFRUWQokBsnj9g+R33WzWZWqz5oo6L1Kr2SLKPY29F7zUy8c2a1yeuxFcJ5+cBkK1WEGgO6sXfaAoPjokLDub7nCFd3HjR9ckni7vFzNnVe1uw6aVWNlbh0nRv3/bj54BmLdCrfT1nN3+N60qpOaWqWs23VkkAg+Di49+QFh8/eRFVVKpXIQ6vapdlz/IrN1sueyXSF8uSgsbc3OsZQ52hFoyFrycIJjhdpWIPxdw9yaM4Kru89CkC+6uWp3LODyY2AUxPCeUkFtJ0yCu/c2dgxaRaBj/2SHGfMG08Ma2kEJEV4RPLKEDdNH4yHqzOXbj1i3KyN+L0IRKuqb8K4sdGciKhoOg37iyy+IyhbJJcVrBYIBB8rAUEh9Bw9n037z+m3pSUJ6lUqgrOjPWERpkVSzCFXFh+TKyyTS/EW9Tgwc0mSnaMlWaZYs7oWze3h60OjkV/RaORXyTExVSByXlIBkiRR86vu/Hz/MD9e2kHNgd2Rkmihbi4Fale2yjxJUSh3piTbvSdFXNJb/w61qVOhMOWK5sI7jTuPn79Kcu9Zp1Pp+N1fBIeEJ9tmgUDwcRIRGU3dXr+y5eCFePl0qgrbD18iItL6jgvEtjtJKWp81Q1ZURJPDpYk7JwcKNuhaYrZk1qxqfMSEBBAp06dcHd3x9PTkx49ehASYrhVd/Xq1ZEkKd6fPn362NLMVIOsKGQslJeX9x9bnOgahyTLFGtaG+9c2axjXBL0bVcLnZFkt/fJnyMDc3/6nN+/7aD/gG7cd0af9Z8UD/wCqNd7ElsOnGfB+oNsOXieKCPCfAKB4NNhxdZjXLjxMNGtalVVMfOrSI+hbx6NItOnbU3LJraA9Hly0HfDHOycHBI6MKpKVGg4PxWuy87f56RIv6PUik23jTp16sTTp0/ZuXMn0dHRdO/enV69erFsmeEE1Z49ezJmzBj9z87Otu8nkZqQFQWJ5AkrahztyVu9PNroaBQ720lat69fjs37z7LaxLbzm2d8Te3yheJ9KE9eusOOI5eMZvwDnL5yn+YDp+h/TuvhysTBbfisWRXzjRcIBB8VCzYcQpIkq9y0FVlGq9PxWbPKLNxwKNExEjC4a33SelqWDGwphepVY8LDY2weM4W90xagvvfdGBEcwppvxhMdEUnD7/unqG2pBZtFXq5evcq2bduYO3cu5cqVo3LlykybNo0VK1bw5IlhBURnZ2d8fX31f9zd3W1lZqqkQO1KqMnUhI4Oi2DV4LFMa9id6MjI2GMRERxduJp5nQYyp92X7Px9DqEBgclaR1FkFk/oQ7MaJU0a7/Le08SOI5eo1m0Cz16ar8AL8DIohJ6j/2bhBjMSmQUCwUeJ34tAq0UbKhbPzYapg5gz+nPmjO4e+90E2GkUZElCUWS+7taAsf1bWmU9QwQ/f8Hd42fxu3YLVVVRVZVHF65yZvUWg69348jfuXPsrM3tS41Iqo3iTvPnz2fIkCG8evW250xMTAyOjo6sWrWKFi1aJHpd9erVuXz5Mqqq4uvrS5MmTRg5cmSS0ZfIyEgi39ycAYKDg8mSJQtBQUEfrdMT8TqE73NUJiwwOPmyz5JEox+/omTrhkyt24Wgp8+RFeXNB0JF4+BAz5XTKZpMgaITF29Tuet4g2OcHOx4tHsybi5OAERGRZO93hBeBYUmu9Q6rYcr93f+D/uPTCVSIBCYTp2ev3DwzA2zt6rfp1LxPOz9e3i8YyFhEazddZr7T1+Q1sOVlrVL27ztyIu7D1k9ZBznN+zUly+nz5cTSZLwu3bbpDnsHB34/uxmfPPntqWpKUJwcDAeHh4m3b9tFnnx8/PDxyd++ZVGo8HLyws/v6Qrajp27MiSJUvYu3cvw4cPZ/HixXTunLR4zoQJE/Dw8ND/yZIli9Vew4fC0c2Vr7YtwsndNV7irqxRQJIo2aYhjgZK5eKhqmyf+Bdji9Qj6GlsjyCdVouq06HqVKIjIpnVsjePL11Pls1lCuekRIFs8Zo4vosiy3RvXlXvuABs3HeWl4EhVtGIeRkUws6jl5I9j0AgSL10a1412Y4LgKd7wodhV2dHujatxMjezejXvpbtHZd7D5lYthkXNu7SOy4Az67fMdlxAYiJjGLloDHGB35imO28DBs2LEFC7ft/rl27ZrFBvXr1ol69ehQpUoROnTqxaNEi1q1bx+3bib+Zw4cPJygoSP/n4cOHFq+dmshWuihjbu6n5aQR5Klajuxli1G1T2d+vLSDXitnMOnpSTr+Nc6kuWIMZeC/CVHumTw/WfZKksTySX3x8XKPV30kv9kiKlskB+MHto53zdU7T7CzYin3cwu3ngQCwcdBm7plKFUwe7LmkABPtw+fR7l+2C+EBSYt2W8qqqpyZcdBAh5a1pDyY8XsGPuQIUPo1q2bwTE5c+bE19eX58/jdwOOiYkhICAAX19fk9crV64cALdu3SJXroQaHw4ODjg4OJg838eEa9o01BnSkzpDeiY4Z+/kaLW9X12MluNL1lG1b2eylSpi8Tw5M/tweuUY5qzZx+KNh3kZFEL2jOno1boGnRpXwME+fuKwi5MDWp31BO4ypfey2lwCgSD1YW+nYetfX+NTzXKdEkmSKJhCTRaTIvRVEGfWbE1Sy8VsVJWX9x7hlSWjdeb7CDDbefH29sbb27jSYIUKFQgMDOT06dOUKlUKgD179qDT6fQOiSmcO3cOgAwZMphr6idPdESk8UEmEhMZxYTSTagxoBttp4yyuAFZWk9XhvVozLAejY2ObVK9BMMnr7JonfdJn9aDmmVFZ2mB4FNHNVjYbBxZkfmsmW31r4wR+Oip9RyXNzh7fpw5npZis5yXAgUKUL9+fXr27MmJEyc4fPgw/fv3p3379mTMGOsdPn78mPz583PixAkAbt++zdixYzl9+jT37t1j48aNdO3alapVq1K0qO0k7j9WXj18avU5905bwL4/F1p93sTIm82X1nXLGOv6DsQ2TzMkhle/UhHR50gg+MR5HhBM4y//Z9G1cTpS04Z3xscr5W/00ZGRPL50nadXb+Hg5mL8AjPwyZuDjIXzWXXO1I5NSzOWLl1K//79qVWrFrIs06pVK6ZOnao/Hx0dzfXr1wkLi214ZW9vz65du5g8eTKhoaFkyZKFVq1a8cMPP9jSzI8SVVW5uHmPTebePmkm1fp1MamzaXL564eubNhzhmgjTyHfdW/I2t2nuHTzcaLnF248BBIcv3Cbh34BeHm40LVpZaqWysvqHac4d/0+Lk4OtKhVik6NKuLu6pToPAKBIHWi0+mo3/s3rt4xLbejZe1S7D1xlVfBsfeXckVzMaxHY+pXTtkH4ejISLaMnca+6YsID4zNy3P39cYrWyZePXwaL1nXUlpMGGpxtPxjxWal0h8Kc0qtPmaiwiP4yjm/zeYfdWUXGQrYvvTuwdOX5G74rdXmi2vsGPvvWDGrODGquM92ei8Pts/+lgI5De8Pa7U6jl24xYvAELJmSEvxfFn/c18QAkFKExkVzZpdp5i/dj9PXwSR0duThlWLsXjjYS7dSvzhJTGK5s1CFl8vMnp70rVpZcoVTfm+aNqYGP5s2J1ruw9bxUlJjMKNatJ/U/IKLlIL5ty/hSjGR4rypmw62X0EkkAbHb/hYnRkJDf2HSM86DXp8+YgS/FCVlnH2ros8fudxP4QlxQcd84/8DWNv/wf1zZOxC6J9VdsPcawySt58jxQf6xQ7kxMG96FyiXzWtVmgUAAF28+4o9F21i5/US8th837z9j/ynzpRwu3HjIhRsP0Sgyc9bsZ0TPJozq2zxFH0D2/bmIqzsNC2jaOTkSHR5h8RodZ5hWdfqpIZyXjxTFzo78tSpyY+8xg6V2Dm4uRL4ONWtuB1dnfHJnB2IdgD1T5rP5pymEBb4tRXbzSUubyaMo26EpD85c4sTS9YS8CMArayYqdG+Dd86sJq2VPq07RfNm4dLNR1bRezEFrVbHQ78ANuw7S+s6ZRKcX7TxEF+MSvgkc/XOE+r1/pVdc4ZSofjHLwglEKQWJs7bxI9/rrXJ3DFvhD5/nvMv2TOmo1vzlGklcuHfXaz6eqzBMbJGIUPBPDw4fdGiNXJVLIVX1v9OhdG7iK7SHzF1v+uTpOMiKwppc2Sh08yfzZtUlqjcswP2zk48unCVKXU6s2rw2HiOC8Dr5y+Z3/ErhmYsw8+lGrNn6t+cWLaBbRNmMDJ3NdaPmGRSKbckSQz7onGKOS5xaBSZPcevJDgeERnNkF+XJ3qNTqei1en45vcVtjZPIPjP8L9F22zmuLzPxHmbbN7M8Nahk0xv8jkzmn5hNDKui9ES+vKVwTFJYefoQJd5v1h07aeAcF4+YgrWqULHmeORZFmfXCvJsW+pZ6b09Fo1g4XdvzFvUp2Ko4cbU+t3ZVyxBlzbfdjg8KCn/rGXxWhj/2i1oKpsmzCDPVP/NmnJ1nXKMGFQGyQpVok3pYhJJEl404FzBIWEJ3mNTqdy8tIdrt+zfqWXQPBf4/eFWxn2x8oUW+/OI39uP3xufGASvLj7kHXDf2Fag8+Y1aoPRxeuJurNlo+qqqwb/gu/VWnDxc17TZ7TK1smkxXT477fvXNlY8iBlZ9ESwBLEdtGHzlVe3eiYL2qHJqzgkfnr2Lv5EjRprUp1aYha4f+gjYq2vgk77F59GSkJGT+zWHbz9Op3q+LSV2th3zWgOY1SzF/3QFOXLrN/pPJa1dgjBitjvJFE37wnzx/hSxLRiXI7zx8Tr7sQntIILCUnUcvWU3nyRwi38mnMYf9fy1mRf8fkSQZnVaLJMucXbuNDSN+pc/62by4+5DtE/+KHWxGdOfR+avkrlSaS1uMOzz5alSg/ogvyVejwn++eEBUG33CfJehDMF+/h/WhiNryFmhlFnX6HQ68jYeyoOnL21ikyxJ2NkpeLq5EBAUgixJpEvjRrdmlUmfzoOvJiwxOkflknnZPfe/V54oEBjC70UQs1btZfmWowSFhJM3my+929agbd2yCXSYGvb9nb0nrlpVZdsYrs4OPN49BSdHe7Ouu7LzIFPrdjE4RuPoQIyFwqGSIuPi5UnYqyDD4nWSxNib+/DOlc2idVI7qaIxo+DDE2Fmoq4tiAo3/8MsyzIjezdN8nxy3AVJktCpKpFRMTx7GUR0jJbI6BgeP3/F+Dn/8t3vK3B0MB4pOnTmBicv3UmGJQLBp8XFm48o3voHJs79lzuP/HkZGMKxC7fo9v0c3Mr1okz70fy97gDRbyIf+09dS1HHRZFlerSoZrbjArD9l7+M6l5Z6rgAqFodoS8DwUgoQZZlji5cY/E6nxLCefmESZfjw3bYlmQZ3/yWaSt81qwKPw9sgyLLyLKERpH1Hatb1SlDRm9Pi+Z1cTLcBysiKgadCV+oGkVm+ZZjFtkgEHxqaLU6Wg2eStDrcLTvbLnGxfW1OpUL1x/Qe8wCmvT/g8ioaGP36WTxvhq3LEkUz5+VUf2amz2XNjqa63uOJruBojFUnc74GhIEPDBd6+ZTRjgvnzDV+nX+YGvLGoViTWvjmTG9xXN8060Bt7f+ypgvW9KteRUGd63P6ZVjWDapL16ermbP16ZuWULCjOspREUb/5JSVQgIThjZ0ul07D91jYUbDrJx71kiIs3PORIIPjZ2Hr3EvccvDEZS4pyVfSevMWHuJioWy21ygr6jgx39O9RiwsA2ONgbTtW00yh0bFhB/6CSLWNaxg9sze65Q3F1djRpvXfRxmhtpqdlCW7eaT+0CakCkbD7CVOhWxsOz/2HB2cvGQ1HWoQsgU5FUmRU7dsvLVlRcPf1od20n5K9REafNHz3eaMEx1++CjF5DhcnB777vCERkdEmJeMCKIqMVmsgAiNB9ozp4h3adewy/cYu5N6TF/pj7q5OjOrbnP4daov8GMEny5Hzt7DTKEbbfADoVJWJczdRr1Jhg86OJEn8+nVbShbMQamC2fXbPSowYkriib6SBP071OaXr9sxf+wX6HQ65GRWMNo5OuCTNwfPb95LESfm/e/Td9HFaCnXubnNbfgYEJGXTxh7J0cG711Oxe5tkS1pWvj+zVZCn3CicXSgco/2fLVjMWU7NtdXFDm4OlN9wGeMOLWRNJltV43j6Gg8L8XJwY7lk/rxcNcfDP+iCRqNYrLGg5uzI4qBiiudThdP7Org6es07f8H95++iDcuOCScIb8u54/F201aVyD4WLh48xErt59gy8HzaLU6s/RTdKrKjiOXDEZeVFVl7OyN5M+RIV6eypDP6vP1Z/X10grvbil3a1aF8V+11o9NjuPy2v8lrx49RafVUnPg5xbPYw5OHm7YOzkiJ/LdI8kSpds3JXOxgiliS2pHVBv9Rwh5+YqHZy8T7OfP310GJzlOkiR8C+Smzre92Tp+Gv637gNg7+xEpR7taDx6ELIi4+DqEi+BTRsdTURIGE7urinS0LHL8Fms2nHCYBSlUdVirJsyUP/z0XO3qNbdNNE+WZLwSeuO/6vXiUZgvu/VlFF9m+t/Lt1uFBduPExyPkcHOx7tmiwaQgo+ei7dekSv0X9z6vJd/TF7O8Wk7VZLKJAzA+fXjE9w/O5jfxb/e5jHz17hk9adTo0qkj9H8h+Yzq7bxtZxf/LgzCUAXNKmoWqfTjy5fIPz63dYPrEkkbFwXp5euZlkZKX5z99SoG5V5ncayLPrd2IfFtXYbfjKPTvQdvKPaOzNTzj+WDDn/i2cl/8g8zsP4uTyjUk2Cuu5agYlWtbnwZlL+F29hXsGb3JVKIWDi3MKW5o0h8/eoMbnEw2O2frXEGqVf9uDSVVVynccw9lr901aQ6PI1CpfiN3HLuslxtN5upI9Uzoio2Jwd3Gidd0ylC2Sk0pdjPcXmftTD7o2rWTS2gJBauTm/WdU6PQToeFRKVopdO3fieTM7GPzdXZPnseqwWORZDne96Mky+QoX4LyXVuwvO9Is6JMsqKg02op1a4xHWeOZ3brvlzffQRZo6CL0er/rtKrIx3+Gocsy6iqyq1DJ3ly6Tp2To4UblgDd590xhf7yBGNGQUG6TxnIjGRUZxZvQVZo8SWD2u1yIqGNpN/JDo8gh9yViHg/pusdkmiYL2qtJs6mvR5cnxQ2+OoVCIv33ZvyK9/b4mXxyK/KYX+qlMdapaLH16VJIk1kweQp+F3Jn3xxoXCH+6azI17T5m+Yjcrt58g8HUYMdrYLtVHzt/E1UgFU+za8OxlkGUvViBIJYybvYGwiJR1XACWbznG972Slk+wBi/vP2L1kNiHkPcf7FSdjrvHzlK8eV1cfdLy+tmLxKZIgMbBnkL1q1G5V0cKN6iOJEkM2rmU63uOcHzJuth+cNkyU6lHW7KWKKy/TpIk8lQpS54qZa33Aj8xhPPyH8TeyZFeq2bw+OI1Tq/cTFhgMN65slKucwtOLNvAgq5fx79AVbm28xC/lG/O8BMbU41A0rgBrSiePyv/W7SN05fvAVA0XxYGdalHhwblE02QzZzeC28vN/xeGHckVGKrKAAu337Myu0ngLeN3uIevl6HGdd3UFXYceQS3ZtXIV0a06TABYLURFh4JKt2nNT//qckKdH77PC8lUiSjEri21+qTse+6YtQNKbfNmMio+ixfBr2Tm+rnCRJIn+tSuSvJaKwyUE4L/9hMhXJT6Yi+fU/h74KYs23ieeE6LRaIoJCWNJ7OK5p03D7yGkUjYYijWtRvX9XfPOZr+ei0+l4dv0OUWHh+OTOhpOHedt8kiTRpm5Z2tQtqy9JNkVgLr2Xu0nOC8Q6HS8CX/P7wm1IUvKKDQ6euU7lruM4vHgkaS0o9RYIPiQBwaGJ9gNLCZrVKGHzNfyu3kpyKz2OgPuPyVu9PEF+z5PMW3mfxJJvBclHOC8CPSeXb0RnoO+HTqvl+u4j8Ur5DsxcwsFZy+i1egbFmtbhtf9LLm7eQ2RIGBkK5CZvjQqJZvwfXbiazWOm8uLOAwAUezvKdWpBy0nDcE3nZbbtpjgtcTSuXoLzBpJr30WjyKCqyWrmFodOp3L/yUt+nrOR37/tmOz5BAJroqoqx87fZsPeM4RFRFIoV2Y6NCyvTzJP4+6CRqOkuAOTLWNaiubNavN1HFydY7/bjLy+QvWrcWOfcYFKSZHJWaHUJ51g+yERCbsCAF499mNag894ctGChoiShGKnoVznlhxbtAZdTAySJKGqKmmzZ6b7ksnkrlRaP3zbxBmsHz4pwTSyRiFt9iwMO74eFy/PZLwawzx+/orcDb81rONCbP5Mm3plGdu/JXkbD7Xa+q7ODvjtm4a9nXh2ENiW05fvsnDjIR49e4WPlzudGlWgcsm8CbZUA4JCaP31nxw6cwONIiNJEjFaLY4O9swb04PWdcoA0HXELFabsXUkyxKKLOv1X97NTzMlkmlvp3Bh7fgUSda9sGk3M5r0MDrOydONrCWLcGPfUVQjmlH9Ns6laJPa1jLxk0dUGwnnxSwCHj5hYtlmvH7+wuiHMUnelPQlOCzLKPZ2DDu2jszFChLw8AnfZ6+U5DqyolDr6y9oNWm4ZXaYyPItR/ns+zkGx3i4OnFs2Sh+W7CFeWsPWHX9e9t/J6NPGqvOKRDEodXq6DN2AQs3HEKjyMRodfq/G1QpyopJ/d6KvqkqNT+fyLGLtxM49JIUuz27a85QKpfMy437flToOMaspN007s7071CH2hUKsXDDQU5euoujgx1NqpXg1oNnLPr3cKKOTK6sPuybN4z06Tyt8V9iFJ1Wy8+lmvD44jWD20eyolD7m54oGg17pv5N5Hs95OIi0y0mDqXe0L62NvuTQjgvwnkxi1lt+nJ+/Q7D3UyTgawoFG1Siz7rZrN5zBQ2j5mCzsCTm5OnO7+/PJdsZUxjbDl4nk5DZxKaSPPI8kVzMXdMD1RVpUiL7626riSB/4HpCTRfLt58xOnLd7Gz01CrXEF803kAsTeXq3eeEBYRRY5M3iJf5j/Cq+BQlm0+ys37z3B1caRVndKUyG9asvzoGeuYMPffRCMbsizRpXFFZv7YHUWROXj6OrW++CXJuRRFpla5gmyaHpvIf+HGQ3r99DdnrtwzyRZFlnF0sOPo0h8T6LCoqsrf6w7yx+LtXL/3FIB82TMwuEs9ureokuKq1MHP/Pkxbw0igg0reHtly8TP9w4THRHBvRPnubhlL3ePnyMmIpKsJQtTtU+nePmEAtMQzotwXkwm+PkLhmUsa9CZsAaSLPNH4AVW9P+RE8s2GHWU/vfqPM6eHja1CSAyKpp1u09z+OxNXga+pkCuTHRoWJ7cWWJ7Mo2esY5f5m82usVkKrIsUbt8If2NAODOo+d0+34Oxy7c1h9TZJnOjStSsXgeJv29WZ9zo1FkWtctw8RBbRNEbiKjojl24Tah4ZHkz5EhRULtAuuiqir7T11j1sq9rN97Bq1Wh90bZegYrY5GVYuxZGIfgw1Gw8IjyVx7sEl9vIrnz0o6T1f2nrgar6FiYgQe+Qvnd9Y9d/0B2w5dYNnmo1y7+9TgtRpFplWdMiye0DvR86qq8upNr7A07i4ftJXG+FKNeHjmssExzl4e/O/l+RSy6L+D0HkRmMyLOw9s7rhAbJlhWGAwzmk80PcYSAJZo2DvnDJKtA72drRvUJ72Dconev55QDCyJCVRPGk+Op3KV53q6n9+9jKI6t0m8CLwdbxxWp2OhRsPsXDjoXjHY7Q6Vu84yaEzNzm6dCTp03qgqiqTF2/nl/mbCQh6G8KuWa4g07/vSq4sKevEREZFs3zLMeatO8AjvwB803nwWbPKdGlSyWhX7/8yl28/pt2Q6dy47xfv+Lv9grYdushnI2az+o8BSc5z9PwtkxwXgPPXHqBi7BMZS+5G39KpUUX6ta9FjkzeFM+XleL5sjKsR2O+mrCY2av3Jal4HaPVsWbXKWaP6h5P6j8OSZLw8rBtRNHv+m32z1jMjX3HkN5oV1Xt05l0ObLEG5ehYF4eX7iW5AOWJMukz5fTprYKjCNquP7jOLi6JH8SE775NA72uKbzonT7Juhikq5okjUKJVs1SDUZ+hm901hdkOva3Sf6f09duhP/V6/N0s6I0ep4+iKQ8bM3AjDyz7UM/WNlPMcFYP+pa1TpOo4HT19ax3ATCA4Jp+bnE+n109+cvHSHx89fcebqPQZOXEKFTmN4HhCcYrakVgJfh/H3ugNMnLeJRRsP8zo0nMfPX1Hz84lGq9q0Oh0b953l8u3HSY4xR6Zffe9vQ7x4FcKUJTvI13goM1fuiXcuRqsz2iE6JkZL4Oswk22zJscWreGngnXYP2Mxjy9c49H5q+z6fS6j8tXk3Ib4kv9Ve3c0GBlWdTqKN6/H2qETmNW6L4t7DuPkP/9y79QFXj32S/I6gXURzst/nIyF8pIup3lliO82eZQUGTsHByQ5aQ9G1iiU6dCUR+cuE/oykOzliifu8EgSsqJQf3g/s+yxJZ2bVDSpC7U5bD14Qf/vhRsOWeQcabU6Fm44zI17T/n1781Jjgl8HcbEeZssttVcBk9aypmrse0X4v7fVDX2z80Hz+g5an6K2ZLaUFWV3xZsJUutQfQes4Axf62n56h5ZK41mB4j5xIcEm7S74KiyKzbdTrJ80XyZrb5tstXE5boBRwBMvmkMfo5cbDTkMbdCg9LZvLo/BUWdvsGVaeL55TotFq0MTHMafMlL+69lU7IVak0Vft0TnI+V28v1g2dyI5fZ3N2zVYOz13BvPYDmFimKcMzl+ePmh24f+pCktcLrINwXv7jSJJEiVYNTBsryxSoW4VKPdqRsXBespQoRIPhXzLm5j6ajBmS6DWyomDn5MTl7QeYVLEV0xt/zr3j5xJ/1FNVag3ukaq6pmb19cLN2dH4QDOIfEdL5+V720XmEB4Zxby1B5ClpD/GMVodS/49QmRUtMXrmIp/QDDLtxxL8gas1erYeuiCVTRzPkamLdvJiCmr9O9/jFaHSuz7uOfEVZOdWFmSCAlPelsonacbadxt24dMkWV+/XuL/ufOjSuiUw3br9EoXLxpmr6SNdkzdQFSUkJxqoqq03Fw5lL9IUmSaDdtNDUGdscl3du8MicPdxQ7O0L8A/TXJsbNA8f5tXJrbh9J2sEUJB+R8yLg6eUbSLJktExa1eko2aoBVXolFFhrMOJLXNOlYfNPUwh6+ubmJEn45s/Fk8s3iHxtOHs/jt2T51N/WF+z1XZtxZ1H/rw2MX/AFGRZomyRt/vlTo72hJjQXiAxJAleBIbERr0M3DcioqJ5FRymr16yFScv3zVp++vw2ZspnofzoQmPiGLMzA1WmSs6RkuBJLon33n0nN4//Z1gC9HaaHU69p28RlR0DPZ2GrJlTMc33RrGc2jeJzwikrq9fuXE8tHkyZbepvbdP3WBs2u3ERkaxtm12wxuA+m0Wk4s20D6/LkoVK8aN/YdZc23Ewh8ZwsobY7MhPgHoI02/hCg0+pQ1RiW9BrOjxe3f9Dk408Z4bwIuH/6okn6Li7p0lC2U/N4xyJeh3Blx0EiXoeQuVgBxt8/zIPTF4kMCcMzU3omlDavmVpMZBTHl26ger8uSY55duMOh+b+w7Prt3F0c6Vk6wYUaVzLrJ4jpmKLBnS9WlfX/ztWqM5850WRZepVKkxGH0+jkuYajYKHqxMvA0PYtP8sga/DyZ3Vh3oVi6B5ZwswuUgmpX3GOl3/NXYdu0xwSHiy55EkcHVypHXdhA375q3dz5fjF1l9m9MQ0TFavdjiuAGtCAgKSVITSafGJnP/sXgbM374zKL1dDodl7bs5eiC1bx69JQ0mTNQoVtrCjeojqwohAcFM7vNl1zdeVDfdFZrQDU8jlcPn7Ko+7dJKue9vPfYrN4gqk7H08s3uH/qAtnLFDPrNQpMQzgvAuwcjCfHyhqFgdsX4+ASG47W6XSs+nos+6cvivdU45nJl16rZ1CgdmWOLFhFVLh5X9gSsG7YRPZNW0DxlvWp1rczaTK/fcrcMm4aG0f+/radvKJwYul6MhUtwMAdi3BP723WesbImcmbtB6uvAwyLXJkjA4NyjN/3UFcnOxpWr2Exb2SJCl2e2DmP3sMlrgqskSr2qUZN3sjU5ZsJypaq1c5TZ/Wg9mjutOgSlELX018yhbJiZ1GiVcdk5jdVUrls8p6KUHQ6zBW7zz5RqHWjdZ1yuDtZTgqeOz8Lf5auYdj529jb6ehcfXieHtapxmnqsKgLvX0VVvnrz/gzJV73H38gl/mbTIp8dZa5Mrig/M7lUOSJKHV6lBkKcnfyRitjmWbjzL9+65mRySiwsKZ0ewLru06jKwo6LRaHpy6yNk1W8lfuxJ9N8xlVqu+3Nh3FMAy3aqkPpAWflD9b98XzouNEDovAlYOHsO+aQvRaZP4sEvQaORAmvw0WH9obsevOLV8Y+LDZZkRp//lwr+72TxmqsHqIoPIEnb29jT7+Tsqdm/Nxc17+bvzoMSHKgrZyhTluyNrrR6mHTtrA+NnbUy0s60kSXi6OVG1ZD42HThnVCsDwE6joNOpFkd1ZAl803ny7GWwSXM0rFyUrYcuJLixSZKELEnsmP0tVUrlIzo6hofPArC305DJJ41F/499xy7k7/UHEn36l2WJMoVyUrNcATQahTrlC1GuaK5UG1afvnwXwyevIjI6Go2i6Ctqvvu8IaP6Nk/U7p/n/MvoGev0arYQGyVTFMmsKqCkiGu78VWnOhy7cJsTF+8ke05LmTy0I/3ax5e+bzPkTzbuPWP0Xh92co7ZUb8lvYZzeN4/iUYaJVmmaJNanN+w06w5bc2ArQsoVL/6hzbjo0GI1AnnxSz8b9/np8J10UZFJdg+khQZRzdXxt7cp2+Y+OzGHUblq2lwzkxF8lGtXxeW9RuZvFbMb1Ds7XBwcSYsMNjgfN8eXkOuiqWSvd67REXH0GrwNLYfvhivN4siS7i7OrNj9reEhEVQ4/OJVl03MSQJ8mbz5dbD51YRzpNlibKFc1K9bAFmrdzDq+DYUtZ82TMwtEcjOjeuaNZ8oeGRNOn/B4fO3NA/gcf9n8VFZTSKAsSKrpUpnJPV/+tPBm/PZL8Wa7Jww0F6jv47yfM/fdmC4V80iXds++GLNOn/R5LXSFLs1lriTnBsIq4pzm8c7/4ufgge7ZqMT9r437FD//cP05btNJj7lMHbk/s7/mfWWq/9XzI0YznDD0KSFOvc2WCr1xJcvDyZ+OQ4dg5C28hUzLl/i2ojAd65stF/03zsnZ1jvwBkGemNZoOzpweDdi6J1+l548jfjc75+OJ18teujGKlnAptVDRhr4IMOi6yRsPFzXuSPG8p9nYa1k3+ivljv6BM4ZykcXcha4a0fPt5I86uGkOxfFmpWDwPNcsWMKp1kVxUFW5byXGB2HLmYxduM2neZr3jAnDj/lM+HzmXsbPeJpk+ef6Ky7cfG9TqcHFyYPvMb1gysQ/VyxQgT7b0lC6UAycHO/2NNkar1d/czl69R91ev6ZINZSpxMRo+X7qGoNjfpm3mdeh8bdEJy/ejpJUVQtvfnWlWKcjsXPmOC7AB3VcANRENqm6Na9i0HGRZSlezldSaGNiOL9xJ+u//5V/R/2Pg7OXG4/gvqkcMoa7r3W3lpOi8U+DheNiQ0TOiwCA/LUqMfHRUY4tWsvtw6eQZJl8NStSpkNTfZ5LHH7XbicxS3xCAwJp8H1/No2enOSYuL1rayBJsQm/tkCjUejcuGKSkQhJklj1v/50HTGbzQfOo8gysiwZzP8wa/032xBfd63P/xZts8qc7/J+NCDux7EzN5AtQ1rmrzvAkXO39La0qlOGcQNakS1jugRz2dlpaFuvLG3rxSaVDvtjJaev3Et0iytGq+P6vaes2XWKjg0rWPlVWcbhszeMiumFRUSx+cB5KpfMR2RUFOnTenDwzA2jTqV3Gjc83Jy5ce/jFjPLnN4L7zQJ83gK5MzIN90a8NuCrQnOKYpMvuy+DOhYx+Dc909f5K/mvQh89BTFToOqYvnW83s4ebjTefYE/mrRC9XcB4A3zWfjGi8mQJZBVdHY29FkzNdU/7KrVWwWJI5wXgR6nDzcqTGgGzUGdDM4zsHNNKEpN5+0NPpxIIqdHVvH/0lU2NsnVc9M6SnVtnFsx9r/zU2O2Xq00TFkK1XYKnNZgpuLE+umDOTy7cds2neO8MgoMvmk4cvxiyyaz95Og6qqKIpM7XIFGdSlPh5uTjZxXpJCliV6jpofT4QwRqtj9c6T7D52mcNLRpIjk+En2WVbjhq8qcuSxMptJ1KN87L9yCXjg4CuI2br/y2bIDUA8OxlMJFR1rkRW4skGsInPV6C/h1rJ9k4dfxXrcmaIS2/zNvM4+evAHCw19ClSSV+HtgmQUPSd3l5/xF/1OxAZGhsdM+USiFTkRWZ/HUq8VfzXmZvLUmx7bVp+OMAru85wq2DJwHIWrIwlXt3BFUl2M8fjww+lGzTCJc0tu/L9l9HOC8Cs6nUox13DhsWYHL0cCNttlilzwYjvqTGgM+4tGUvYYHBpMuZlfw1KyIrsVtKtw6d5P6pi8neq5Y0ChmLFiD4mb/Vq47MoVCuTBTKlQmA6OgYhv2x0mytGEWR6d+xNhMHtY13XKvVkcknjf6mYGv0Krnv3Zi1Wh2vgsNoMXAKtcoVJIN3Gjo0LE+m95pFAkZLhHWqStDrMAKCQjh09ibBr8PI4O1JlVL59GW473Pk3E2mLt3B7mNX0KkqFYrlpk6FQjja2+PkaEe9SkVIn9ayG8jxi6ZFFuO9BjO2cD6URH5iaBSZLBnSUjhXJjYfPG/wdcRVETeuVoKvDERPJEmiT9ua9GxVnSt3nhAVFU2ebL4GnZY49k5dQFRouPlRESNIsoxP3pyxDRdNyMHT2NsTE/U2iuuZ2ZeOf42nSKOaNBk9GG1MDKgqip2dVe0UmI5I2BWYjTYmhm99SsXmoCRBy0nDqftt4h1k3+f0qs3MafultcwDIHOxAjT4YQClWje06ryW8O1vK/hzxS6T81QUWcbZ0Z6zq8eSNUPaBOdnr9pL/58XW9tMi9Eosn7baejnjRjdr4W+EufGfT9KtB5pcPtMkWW8PJzxfxW/HN3TzZmx/VvRu22NeMdnr9rLgAmLUWQ5yfwKRZHp0aIqv3/bAQd7824w5TqM5uy1B2Zdk9p4N5lXlmKThO3tlNhS+TfvjU5VKV80F8sm9eX5y2Aqdx2HVqeS2C1BliRKFMhGv/a16NiwgsHcnuTwXYYyBPv522Ruj0zpCXr8zOi4cp1bUq5rC44tXENUaBi5Kpeh5qDPURTraSIJEkdUGwnnxeb4Xb/NxLLNiQhOKG9fsUc7usyZaHIJ7Nm125jVqo9V7YtTDG756wjqftPLqnObS0BQCJW6jOPekxfxHJh3w/V2bxKbo2O0pE/rztrJX1GmcOKda1VVZfSMdUyctwlZlmMVPU2wI0emdNx9/CJ5L8YEfhnclsFd6xMcEkb+JsN4EZg8jZzBXeoxYVAbZFnmyu3HlGgz0qQCNlmSaFm7FMsmmdYrS1VVZqzYzbA/VsZr4ZCaUGQJFUjr6UpAUGgCh1iSJNrWK8uin3vxxD+QLQfOExIWQYGcGalToTAXbz3i4OnrqKpKlZL5KFEgm/7aLQfP02X4LF6HRmCnUVDV2IqwckVzsfaPAUb1bZJCp9Px5OI1Il6H4p0rGx4ZEqorP7lyk8NzV7Bn6t9Wj7rokaVYpTwjpMmSkVcPn+h7uOlitPgWyE3f9bNJn1d0k7YlwnkRzkuKEPE6hCMLVnFk3koiQ8LIVKwA9Yf1NVuUaXyJhjy6cNWknAGzkSTG3T6QoO19SvPi1WtGz1jHon8PExEZW1lTJE9mvu/VFGdHe3Yfu4JWp6N8sdw0r1kyye2Sd7n98DkLNhzk4Onr+mTapGhYpSizR3Unc+3BBsdZA083Z65smEDNHhO4dtc6iamZfDwZ0bMpF28+Yu6afWZ14T6+bFS8m3RSDJ+yit8TSTRNLfh4udOpUQV6tq6Om4sjX/28mA37zuojLK5ODvTrUJvRfZtbrJwcGh7Jqu0nOH/9AY6O9jSpVpwKxXJbrMVzfOl6No78nZd3Y3saSZJEkcY1aTtlNOlyZEFVVTZ8/yvbJszQC09+aCRZTrCFLSsKrt5e/HhpB65pE26NCqyDcF6E8/LR8OqxH8Mzl7fZ/LKiUHdoH5qP/9Zma5hDSFgED56+xMXJgawZ0lpFoC06OoZirUdy77F/ojd1SZLYPXcoWXy9yNPou2SvZwqFc2fm0q1HVp/Xx8vdaCXQu2gUmX7ta/HbNx30x7RaHZsPnGfeuv3cfeSPdxo3alcozKjpa61urzVZNqkvreuUiXfs8fNXnL/+AHs7DRWK5dYr76YG9v65kH8GjEpwXFYUnNN4MPzURq7sOMjSXsM/gHXmI8kyzcZ/Q/1hqafr/aeGOfdvkbAr+KC8W4FkC3Q6HX5XDUclUhJXZ0cKvknmtRZ2dhq2/DWEBn1+4/bD5yiKrM9bkGWZ2aO6U7lkXqKiY3B3dbJKjx1j2MJxAcxyXCA2N9P/1dutzajoGNoM+ZOtBy+gyDJanY7r9/w4eOaGtU21Goos4+3lRrPqJRKcy+STJtEk6Q9NyMtXrB4yLtFzOq2WsMAgNnz/W2zn5ST6CdkUc0usiO1XdHzxOuG8pBKE8yL4oHhlyYCDqzORIbapwJBlGQdX00q7P2ayZ0zHhTXj+Hf/OTbtP0dEVDTF8malW/PK+qobO43CF62qMXnR9kRVXj8G4gJVppovSZDF923S84/T17L90EXgbdPN1BZ8jqfirMQmb6+d/BV2JmwlphZOLt+IzkDekC5Gy6l/NllNv8UcZI0GN5+0BD15m7zr5pMWSVEIfvrc4LXhgeY5zwLb8fF8GgSfJHaOjlT6oj17py6wiay3TqulZOsGRsdpY2KQZDlJ7YqPATs7DS1rl6Zl7dL6Y/4BwYz8cw3z1x3AP+A1aT1cSOvpGi8a8TGhqrGRCBXVJAcsRqujY8MKbNp/jhv3njJ92S6LHbe4qh1bUrpQDhRF5trdp7g6O9Cufjn6tauVaNVZaubFnQexuSMGBCg/iOOiKFT4rBWdZv3MjX3HCHzsh1v6dOSvWZHZbfpxcfOeJPNuJEXGJ59I2E0tCOdF8MFpMnoQ13Yd5smVGyZVA5iKrChkKJSXIo0S78Ok0+k4Mn8le6bM58mlG0iyTMF6Van7bS/y1TCvp09q5KFfANW6jeepf5A+yvAyKBRFlo12f06taBSZWuUKcvDMDSIio406E472dlTtNp7gkPBk704oimzThFJJgvYNyvFVp7o2WyMleHLlJkf+XmWScra9ixNRocncxjTxjY3LtWn041fIikL+WpXina/Su6PBxo6qVkfV3h2TZ6vAany8j5mCTwYnD3e+PbyaBsO/xP69VgTmothpkDWxPnnWUkUYuGORXgzvXXQ6HfM7DWJJz2E8vXwTiN3TvrrjIH/U6sTBOcuTZUdqoM+Yv/F7EZRAll+r06HT6YxWNLm5ONrSPIuI0eoY2KUeNzdPYvgXjY0mPEdERetzfJIbNLG1s+fkYE/XppVtuoatCQ0I5H/V2xMRbLg8XlYU8teuTJVeHZEs1IyJ67+mMVHHJ3fVsgw9tg6vrInnnBWqX53S7Zu+3Zt8d603VVIlU4FulCAWEXkRpAqc3N1oNu4bmoz5mqCnzzmxdD3rhprepVmSZUq0boBnBh80DvYUaVyL3JXLxHaZVVXuHjvDqX82EfYqCO9c2XBwc+XUio1A/JyHuKfFZX2+p2DdKqTNlhmITSy+suMAQU/9CXkRgEcGH7xzZyNP1XKpcqvp9sPn7Dx6OcnzWp2KVhdDifzZOHvtfoLzPl5ubJ4xhF3HLjN88ipbmoqTgx3tGpTnn63HCI9MukGjIsuUK5qTmmULIMsyNcsVZPycf21qmyUosoQsSUSbUc4tyxJrJ3+Fp1vynPcPzeF5/xD6MsC47IEk0XTMYDIWyf9GYfuCyQm0kizjmi4Npds3oXCD6mz/dTY39hwxel2xprXxzpV0ybwkSXy+5A8yF8vP7j/m8fr5SyC2O3T1AZ/R8Pv+iT4ICT4MwnkRpCpkWSZNJl/qfdeHB2cucWb1FhNFq1RyVSxFrYGfxzsaERLKzBZ9uLbr4NvwclylgaFwswSH5qyg6dgh7J48j02jJyf6NJk2e2Y6z5lIgdqp64n5nIkKsYO61qNk/mxMW7aTG/f98EnrTt0KRWhbryyODnYUy5eVPFl96Tj0L6KiY5CIFQA0JiMvS5JJXZId7DVsnfkNFYvn4c8RXbh+z4+LNx7w/dTVPH4eiEaR33Rc1lGiQDbGDmitj7bYWaljuTWRZYkm1UswdkArfpi6mk0HzhtVVnaw1/Dvn4OpXqZACllpO47MX2nUcZEVhf6b55OzQikAhuz7h5F5qxtVv40TnsxRvjj9NszVd7p/+eCJUedFkmUeX7hm1H5ZUag/rB91hvTk2Y27qKpK+rw50NjbG71WkLIInRdBqiUiJJRZLftwdedBk8b/dH1PAgXMKfW6cHWHade/T6H61chbvTzrhv2S9CAp9gtv8J7l5KlS1qJ1bMG/+87SavA0o+NW/NovXoJvUgQEhbD43yMcPX8LRZYpni8rk5dsj1V5fWdbSpYlJCT+HvcF/2w7zuYD5w3Oe2DBCMoXy53guFarY/uRi2zYc4btRy7y5Hmg/lze7L78Mrgtm/efZ+7a/UZtN0asLyRhp1GIslBZVwKyZkzLsaWjSOvpCsBT/0CqfDaex89eJdpRG6BR1WL8OqQ9ubOmt8z4ZKKqKrcOncT/9n2cPd0pWLcq9s7GexAlxr+j/sfmMVONjvPIlJ5fHh3X/xwTFUV/h7yGL5IkfPPnosvcX8hZoWS87cKwoGC+9ixq8HJZo6FKrw50mD7WqH2CD4cQqRPOyyeDqqrcOniCtUMncvfY2UTHyIpC4YY16Lcxtjt18PMXHJn3D5e3HeDmgeOJXmMSkhQbpDHyEZFkmezlijP0SOoROQt6HUbm2oOJjEp6G8beTuHBzj/w8nC1aI0HT1/y4/S1rNp+Qp8PUrVUPn7s05yqpfOhqiqDflnKX//siV/++0ZfZXS/Fozo2STJ+Q+fvUHdXr++ydF5+x7E3rhUq0iDeLg6kTVDWro0qcTTF4FMXbIzSUfDEJIk8ds37RnwXsPCF69e88fi7cxbu5+AoFBcnBxoVLUYrWqXpnyx3GTw9kz+izCDxxevsWHk7zy7dhudTkdYQCChLwP15x3cXGj040DqDOlploDizv/NYc2Q8cYHShJps2dmwJa/8c0f67Sa4rzIikKuyqVx9nDn1WM/vLJmpGL3NhRuWANZUfi9ervYz7qB34mvdiymYJ0qJr8mQcojnBfhvHxyqKrKyoE/sXfaAr2MeNzfuSqVpv/m+Th5uHPh313MbtMPbXSMTUqvDTH29gG8c2ZN0TUN8d3vK5iydGeSjfZ6t63BlGGdk71OcEg4T/wD8XRzxjdd/E7OqqqyeudJJi/ewclLd5AkqFwiL4O71qdxteIG5y3TfjQXbz40q2OzObi5OPJo12ScHGO3BB49CyB/k2FEx8SY5RgpskzJAtnYNXeofq73UVWVqOgY7O00VlFVNhedVsvstv04t3a7SeObjh1Cwx8GmDTW/84DRuauZnJGdJz8fs1Bn9P69x+QZZlfKrbk3olzRreIJUVG1eqQFQWdVkuBOlXou2EOd46eYXLtTonaIGsUMhXOx/DTm1JlfprgLcJ5Ec7LJ8uj81c4NPcfXtx5gEvaNJTt2JQCdasiyzJPr95iXLH6aGO0Ka/YCTSfOJRcFUqSs2IpFM2HTyeLjo6h2w9zWLXjJBoltgNz3N/Na5Zk8YTeZndcTg5arS42H8aEG8iFGw8p3S6htLw1mfvT5wmqezYfOEe7b2ag1er0ERiNEhspmv59VyIio/l1wVae+gcC4OLkwOctqvDTly1xdU591VlxLOk1jENzVpg8XrGz45enJ0zq47N26AR2/Drbos9ci1+GUe+7PoabsxrITZNkmSq9OtLxr3EcXbiaJT2Ho9NqYx1ESUIXE0PmYgUYsG0hHr4JG0IKUhfCeRHOy3+SZX2/59DcFWZrccQlAloLjww+NBv/DRW7t7XanJaiqirHL9xm0b+HefI8kAzeHnRuXJGKxfN8kAiAqWw+cI4WA43nT1iKl7sLfvsTzwm69+QFs1btZfvhi2i1OqqWykfvtjUonDu28kyr1XHt3lOiY7TkyZo+VfUTSoyQFwF8m76UWb/jkiTRYcZYqvTuROCTZ6haLZ6ZfBOttvlfjfbc2HfMItuc03jwy9MT2Dk46HNm3m3QaMpnU7G3Y9LTk7h4efLa/yVHF6zm8cXr2Ds7UrxFPQrUqSIiLh8JwnkRzst/kqEZyxJkRN77fRxcXaj4eRv2Tl1gdXuq9O6InaMjrx4+wd03HfnrVKFwg+rYOaTum11q4MTF21TuakIOhYVkTp+GO9t+t9n8qYkjf69k0efmNeSUNQqFGlTn2bU7PL95F4h1ymt81Y06Q3qi02rRaXXYOzsxrcFnXNl+wGL7vt63grzVYpuz3j1xjv3TF3P/9EXsnRzxzpWVU/9sMjpHv41zKdqktsU2CFIHojGj4D9JjIHk1KRo8EN/7iWRCJxcDs5aFu/n/TOW4OjuSqtfR1Cll1DqNETpQjnInikd9x6/SHKMJEnIEglKso313NMoMrXLF7KOoR8B4UHmt4LQxWi5+O/ueIJtQU+fs37Er2wdP53IkFAgNnKSvWyxZDVXjI6I1P87R9ni5ChbXP/z8SXrTHJeTFHzFXxaiFia4JMhe9liZolIFW5UkxoDPuOKhaXUlhARHMLS3iM4MHOJWdf5377P9kkz2Tjyd44tXktUeISNLEwdyLLMxEGGt91G9m5KgZyxaqkaRdbrvvim80CjyIkJpQKxzk6/Dv+dp3SfvMnox/O+Q6KqescFIOxVEFe2H0CSJL3irTlIkkTGQklXGuUon7CTdoI5ZJlsZYqZvbbg40ZsGwk+GS5t3cufDbsbHiRLZCqcjxoDulGxexvun77IL+Wam7eQJJE2eyZe3n1ksa2OHm5MenoSeyfDSZ7RkZEs6Tmc40vWIckSsiyjjY7BycONLvMmUbKV8aaTHzMrth5j8C/LeBkUoldLdnV2ZGz/lnzZoTaqqrL/1DV2H7+CVqujQrHcNKxSjI37ztJp2ExUVdWLxMUm3qrMHtWNz5r9d0pmdVot36YvTejLVzZdR+NgT0xklMnjZc0biYMNcw2Om1r/M67tPpRoLpusKBRvUY9eq2aYba8g9SFyXoTz8p9EVVXWfDOeXf+bqy+pBPQJgO2mjqbGgG7xrrl95DS/Vmpl9lppsmTg1cOnybI3Xc4sOHm4k7NiKar160LGgnkSjJnXaSAnl29M+AQsSUiSxMCdS8hf8+NvImmIqOgYth26yKNnAXh7udGoSjGcTUiSvfXgGbNW7mXH0Uuoqkr1Mvnp3bYmhXIl3tvmY0NVVSJDw7BzdDBa3XZl50Gm1u1iU3tkjUK9Yf3YOs64OCKShGcmX4YeXUuazBkMDg3ye85vldvw4u6Dt8m7b8Jqvvlz8c2BlXq1XcHHjXBehPPyn0VVVc6t387uP+Zx59hZZFkmf+3K1BnyRaKdosODgvnWtwwx7+y7G0KSZbKWKsz9kxesZrOsUdBpdbT/cwzV+3XRv46tP//Jxh+STiqVZJmcFUvx7cHY3kNR4REE+/nj6O5qUomr4OMkPPg1u36fw/6/lhLi/xJZo1CydUPqD+9H5qKJtxg4MHMJy/r+kOg5BxdnIkPDrGJbn/Wzmdm8l9FxOSuWos/ambin9zZp3vCgYA7OWcHhuf8Q/Mwfz4zpqdyzPZW+aI+jq0tyzRakEoTzIpwXgRks6/s9h+asMJr0p9hpyFerEk8v3+TVwyc2sWXIgZXkqVKWzWOm8O+oP0y65ocLW9k/fTHHFq7RJz/mq1WRJqMHk7tyGXRaLZe37efKjgPEREXjmcGHvNXLk6VkYfHF/5ERFhjEb1Xa8vTqzXiCbrJGie0ZtGVBgkhc8DN/hmUun7SEgLEMZzP49vBqFnQdgv+dBwYTeEec3kTWkoWts6jgk0FUGwkEZtBy0nDunbrAw9OXYr/D33zpSoqMk4c7TX4ajFfWjAQ+9mP5lz/azA5Zo7Dr9zl4Zc3IptGTTb5uar2uhDwPiOd83dh3jP9Vb0eHGePY+dscnt+8q1c2jUPjYE/Vvp1pPv5bfT+b0IBAIkNCcUufTpR0G0BVVa7uOsTBWUvxu3ob5zQelOnYjPJdWuDoZlm7BVPYOPJ/+F29lUCJVhejRdWpzG3Xn4mPj8VrJHh0wWrDWilWclwkWca3QB7qj/iSxT0SL82Ok/kXjosguQjnRfCfx9HNlW8OrOLw3BUcmLmEl/ce4+zlQYXPWlO9f1c8fH2ICAnlO98yNlXu1cVoubrrEEf+XhXraJhQ/inJUgLHBUDV6lAliWV9vtfnB7zfLiEmMoo9U/7m/qmLNPxhANsmTOfm/theUA5uLlTq0Y5GI7/CxcvTOi/wE0Gn1bKw+zccX7zuraCaJHH7yGl2TJrJ1/tWkC57FquuGfE6hH3TF7F/+qIke22pOh0hLwI4t34Hpds21h9/dv3OG7E3q5qUgGLN6uKSxoOK3dvw8u5Dtoyb9raVxxs5/8zFCtB79V+2NUTwn0BsGwkEJnB4/koWf/GdyU+pxZrX5f7J8wQ+fmbWOnaODpRs04iTyzYY166Q3zSOtJI68PuRGVlRSJcrK0OPrvvPOTA6nY6rOw9yfsNOosLCyVQkPxU+a4VrOi92/Dabtd9NSLKPToaCefjh3FarKRiHvAjgt6pt8bt6y+hYxU5D3e/60GzcN/pj/wwczf4ZS9DFGO6Y/W6Su7mkyZKRH85vxSXN295WT6/e4vDcFTy7eRcndzdKt2usb6QoECSG2DYSCKyM/617KBoN2mjDNwAkiXrf9ab5hKEATK3flWu7DpvUJFKSJXwL5MY5jTtJipS8g2vaNIT4B5hkvym8b6NOq+XF7Qds+mky7aaMtto6qZ0gv+f82aAbD89dQdYooIKq6lg/YhKd50xk9//mJhmB08VoeXzhGtf3HiEyJIyAB09wTZeGIo1r4ejqwt0T59j9xzwub92HTqsjZ4WS1Bz0OUUa1kjSnqW9R/D8xl2TbFd1KnaO8bf7vLJmMui4yIpC3hoVCHryjKdXbiJrNKg6ncmNTUu0akDX+ZNwcneLdzxDgdy0/j3xJGGBILmIyItAYALbJ81k/YhJRp9Mhx5fH08h9OquQ0ypY17nZndfb4L9/A2OSZs9M58vnWJRmbe52Ls48/uLM9g5Jr/xoDY6mvMbd3HvxDlkjYaCdauQp2q5VNNnSafT8XOpxjy5dN3sHllxSLKMxsGe6PAIfW8eexdnijSuyel/NsXr3RO3nVJ/eD+a/5wwTyTg4RO+z1Ypya2ixPjh/FZ91dHuKfNZNWiMAWMlZEXm20OryVa6KJe27uP8hp1c3XGAV4+eGo3qVendkY5/jU8175/g40ZEXgQCK1OydUPWDfslyfOSLJO9bLF4jgtgUVVSsJ//Gx2XhFtCkiyjsbejz7rZ3Nh/DMXODm20+W0RzCEqNIzAJ8/xzpk1WfPcPXGOmc17EfT0OYqdBlWFbT9PJ0uJQvTbONeo3ochYqKiOLtmKydX/EtoQCC++XJRuWd7cpQzrtD6Lld3HuTRuStJDzBBBl/V6Yh+o4Ac9/5FhYZx+o3M/btOUdzW4LYJM8hTtSyF6lePulX9JAAAGxJJREFUN9f9kxdMdlxkRaFAncp6x8Xv+m1WDR5r8Bo7R3u+WPGn/v+paONaFG1ci3HFGxDwwPDvroOri3BcBB8M4bwIBCbgnTMrFbu34eiCVQmfRt/c0JqM+TreYZ1WywYDOi3GcPNJR/CzF0hSrNOii9HikTE9ny+ZzNrvJnB11yGDN1Jrdst2cHVO1vUv7j1kcu1ORIWFA8Tbfnt88Rp/1OrIyAvbLKpwCn7mz+RanXhy+YY+b+fusbMcnvcP1fp1of2fYxLcYFVV5eLmPeybvohH565g5+RIydYNCXrih6zRJL3NYqNAtawo7Jn6dwLnRVJMl9zPVakUX6x4KxB3YOZSZEU2UCItkaVEIYo1rZPglEu6NEZ/fzwy+gjHRfDBEM6LQGAiHf8ahyRLHJ63MrYpoBIr1e/o5kLnORMpWCe+5Pzd4+cIemJewq4eVSXYz5/hp/7l9uFTRIdHkLFIflBVFnz2NQH3HxudomTrhqTNkYUdv8y0zAZinaYc5Uvg7pPO4jkA9kz5m+iwiES33XQxWp7fuMuZVVso17mF2XPPat0Xv2u3gbd5O3E37P0zFuOTNwe1Bn6uH6+qKkv7jODQ7OX6bRsgNpdFwqwtGmuh02q5czRhg9DclUqj2BnJtZIkeq2eQYkW9eM5Ew9OXzK89aWqPL5wPdFT5To15/ruI0kvKcuU79Iy6bkFAhsjnBeBwEQ09vZ0mfMLDb7vz9k124gIfo1PnhyUaNUg0R5F4UHByV7TwdWZml/F9ms6uWIj8zoONP70L0lU/qIdnWdPJOTlK3b8OhuMJF++X2kUh6qqNPrxqwTH75+6wJ2jZ5AUhQK1K5H+TfO/gAePObniX0JevMIra0bKdGiKa9o0nFy20WD1lCTLnF65mXKdW6CqKrePnObS5j3EREWTrVRhvPNk58beY+hiYshetjj5alZEkiTunTzP7UOnDL62HZNmkadqWfxvP8DJw40Xdx5waPZyIH43Yp1Wm6zuyMklsSocl7RpKNOhGccWr03SLneftMRERKGLiUGxs9Mft3N0MPp6NI72iR4v3b4pOybN4vmtewkcIFmj4JrOi6p9OpnysgQCmyCcF4HATNJlz0KdIT2NjvPOnT1Z60iyhIdvrHx6VFg4S3sNN+1CVSXwyXMenL3Eii9/NOq4AKTPlxO/q7eQNQqSJKGN0aJxsKfzrJ8pVK+afpz/nQfMbdef+6cuxDZKfLNeoYY18MqSIdYpkKQ3EY0YVn89jha/DCUyNDTJtSE2YhIWGETwM3/+ataTu8fPvbUlLuogxTam1Gm1+OTJQe+1M7m681C86EliBD15xs8l3+qeGOx+/KEcF41CgbpVOLJgFUFPnuPm7UV40GsOzFqK/637bwcm4oy89g9gfqeBrB8+iWr9OlOmYzO8smSkWLM6sVuLBtYs0bxeoufsnRwZvHc5s9v04/ahU0iKjISETqslQ4Hc9FozU/QTEnxQRLWRQGBDfqvahjtHzhjXbEmETEXzM/L8NgCOLVrDgs+GmHSdJMvkqVqOO0dPo42OManktcOMseQoX4Izq7cSERyCb4HclOvUDCePt5+hkBcBjC1an9f+L82uxEmTJQOBj/2SzqGQJLyyZSI6LJzQl4FG/79kRcHJw40K3duwZ8p8iyuDEjUlLgplQRTGwc2FqNBwk8uM3y4qobG3IyYq6o1AYcLr47pqG59Kolq/LjQeM5ifCtRO/P9TklA0Ct+f3ULGQnkNzvfgzCWu7TmCqtORq2IpclUqLXJdBDYhVVQbjR8/ns2bN3Pu3Dns7e0JDAw0eo2qqowaNYo5c+YQGBhIpUqV+Ouvv8iTJ2G3XYHgY6DDjHH8WrElUWERZjswLSYO0//7+a37xnMf3qDqdDy+dM1kxwWgYN2qeOfKRtYSScu275+xmOBnL8y/MQORIWFGJOpVAu49Mnk+nVZLeFAwAfcfWdVxgdiIV8F61Xl575FJwnDx7IqJiX2fYmLiOyBvHCE7JwdiIqP0/xeSIoOqoupUYiKjAJIsxzf1OVNVVfbNWIys0TBo9zKm1OlMsJ8/sqLEzqGqaBwd6LlyulHHBSBrycJCzl+Q6jA9ld1MoqKiaNOmDX379jX5mkmTJjF16lRmzpzJ8ePHcXFxoV69ekRERNjKTIHApmQqnI+hxzdQtEmteNsV6fPlNHhdnmrlKNyguv5nZ093dCaon8qKglv6dIS+eGWyk+GSNg3eubLpf44MDePQ3BX81aIX44o34LeqbVk7dAIHZy+3yHEBCHsVRLYyxZBk6z2x67Q6bh48SbqcWa2q2qqL0VK2U3O+ObgK2c6857vo8Ej6rJtNtjLF4h138fKky/xJTHh4jBa/DCd/7crkrVaeOt/0wjmNp9Vs16Oq7Ju+ENd0aRh/9yDdFv2PUu0aU7J1A1r9/j0THx2jaONa1l9XIEghbL5ttGDBAgYNGmQ08qKqKhkzZmTIkCF8802stHVQUBDp06dnwYIFtG/f3qT1xLaRILUS8iKAoKfPcU3nhbuvN//++L+3/V+0utjSVK2OXJXL0H/TvHhbNi/vP+KHHFWMPn1758pG9nLFOLlso8l2ZS1dhBEn/wXg3snzTK3flbCAIMtepAG+3DSfowtXc2bVFqvNaefkSJ1ve7Fl7DSr5KvIioKrtxfj7x3CzsGBbROms37Er2bN4erthWKnIejJ87elzmrsdk6byT9So/9nAERHRHBuw07mtR+QbLsTRZLoMH0M1fp2sc38AoGVSRXbRuZy9+5d/Pz8qF27tv6Yh4cH5cqV4+jRoyY7LwJBasU1nVe8JMemY4dQrmtLDs9dgf/tBzh7ulOmQ1N9Jc27pM2WmUo923N4zookHZiGPwwgZ6VS/Nmwu8k2yRqFXBVKARD8/AVT6nQmPDjEgldnnAwF8/Dq4dMkK5ssQbGzY8uYqVaZC0nCydOdr7Yt1OvN1BvWDzsnRzaO/B+RIYaTjuN4t2XDu1tAKvDPgFHYOzty/+QFji5cTXR4pHVsTwRZkQkPem2z+QWCD0mqcV78/PwASJ8+fbzj6dOn159LjMjISCIj334BBAcnvzxVIEgp0ufJQctfTKsi6vDnGFDh8NwVeln3OJ2ZTrN+pnT7powr3tCsPFOdVkeVNyWvh+asiHVcbBCMzVamKB4Zfbh7LKGWSXKIDLGio6WqVOndkczFCuoPSZJErUE9KNupGUMzlkt2fo0kSyzt8z2oqtVzdd5HF6NNdsWbQJBaMSvnZdiwYUiSZPDPtWvXbGVrokyYMAEPDw/9nyxZrNuKXiBILSh2dnSePYFxdw/SctJw6g3rR7eFvzPJ7xRlOjTj6dVbPL5w1SRV3bjITtvJP5KxYGxC/Ll1221TKixJfDb/V5vMbS0F4Th2/PIXIS8SNrt0805H8RaJlxWbg6pT0UXHJMtxMSm/R5JwSZuGYk1rGx8rEHyEmBV5GTJkCN26dTM4JmdOw4mISeHr6wvAs2fPyJDhbY+TZ8+eUbx48SSvGz58OF9//VaWPTg4WDgwgk+atNkyJ6oz8/r5C9MmkKBA3SrU+aYXBWpX1h+O68djCvGaC9q9kdNPwo+oP6wvGQvnAyBTkfw8uXw9+U6HJOHi5Unoy1fJm+c9dFodp1Zupnq/+Hki2yfN5Mxq6+XqWIqjuytf713B/VMXODBzKY/OX02wBReXGN5l3i9o7BMXoRMIPnbMcl68vb3x9va2iSE5cuTA19eX3bt3652V4OBgjh8/brBiycHBAQcL+qEIBJ8anpl8TRr3xfJplG7XJMHxbKWL4nf9ttHO2QC91/yFk4c7skZDhkJ5Wd73e06t+BdZo0FVdaDGlmzXG9qHZuO/1V9X6+seLOr+rYGZY/HKnhk1RsurR08TnpRiu2pb23GJ49n1O/F+PrFsA+uGTrTJWuYg22kYcXoTPrmzk7VkYar06oj/nQesGzaRc2u36avRcpQvQbNxQ8hXo+IHtlggsB02y3l58OABAQEBPHjwAK1Wy7lz5wDInTs3rq6uAOTPn58JEybQokULJEli0KBBjBs3jjx58pAjRw5GjhxJxowZad68ua3MFAg+GdLnyUGOCiW5d+Jckg6Ik4cbxZolbMQHUO3LLhxbtMbwIhKkyZyRQg1qoHkjRa+NjqZk64aEBwbz7MYd7JycyFO1LHW+6ZWgE3WFz1pz99hZDs5alqgyrptPOuycHHh1/3GigRyvbJmo3v8zMuTPxfQmPQzbaiHOnm76f6uqypaxU1O0bUCcHktcREWSZTQO9vRdPxuf93JYvHNmpdfKGYQGBPLq0VNcvDyT1Z1bIPhYsJnz8uOPP7Jw4UL9zyVKxLZc37t3L9WrVwfg+vXrBAW9Lcn87rvvCA0NpVevXgQGBlK5cmW2bduGo2PCvjECgSAhbf8YyW9V26JTSbSip83kH7FL4vOUo2xxGo0ayOafpiS9gAqvHj7h+2yVqDmwO2U6NmNag248vXxD74zIisLTyzdIkzkDDUZ8Ge9ySZLo+Nd4ijapzb7pC3lw5jL2To6UaNWAKn06cmTuP+z4dXaiFVWSLBMTEUmtgd05t36Hef8xZlCxx9vKxpf3HumbPiYXSZGRFQVtVHTSYySJ746u5cr2A1zfexRJkshXsyKVvmhnsDmmi5cnLl6eVrFTIPgYEO0BBIJPjDtHT7O830genruiP5YmSwZa/jKMMh2aGb3+3PrtbB0/nfunLhgcJ0kSju6uRISEJhnp6bF8KmXaNwXgyeUbPDhzCY29HflrV8Y1bZp4Y6MjI/kufWmj5b09V80gTWZfJlWwflfj7GWLMez4Bv3PT67cZEyhxCNV5uCSNg3V+nXBK2smlvQcmugYSZYp16Ul3Rb8luz1BIKPkY9S50UgEFiHnBVK8f3ZLTy6cJWX9x7hms6LHOVLIBtqSPgOxZvXo3jzemhjYrix7xhT6nROdJyqqgYdDUmW2DbhL7KVLsrC7t/E6/6s2Gmo3LMDrf/3g15T5eW9R0YdF8VOw4NTFyjZqgE+ebLjf+u+ybL5sqKgcXQgKiws0eRil3Rp6PfvvHjH0mXPjL2zE1Fh4QbnzlQkP08uXdfb4pHBh0ajB1GuSwu0kVE4urvp//8jQ0NZ8+3PqFodsiKjvimbLtW2MZ1mjTfptQgE/3WE8yIQfKJkLlqAzEULWHy9otFwfPG6eJVF5qDqVB5fuMqkCi0JexVfsVcbHcOBmUsJevqc3mtmIkmSSZUxqqqicbBHkiTaTx/Lnw0+A138vj9xZeCVe7bn5sGTvLz7EEcPN8p3aUnNgd15cecBm8dM5druwwBoHB2o9Hlbmvw0OEGnZHtnJyr1aMf+GYsT7U0lyTIuXp4MP7URWaN509vILr7IoJNTvGtqDfycMh2acnzxOl7ceYCLlyel2zcxqc+QQCCIRWwbCQSCJPm5dGMenL6UrDmMKep+d2QNOSuUim3Mmq8Gz2/dN5gcO/T4enKULQ7A1V2HWDloDE8v39Cf982fi9b/+4HCDWoYtCssMIiI16G4+aTVR38SIzwomN+qtOXJlRvxtsdkjYKsKPTfsoD8NUVlj0CQXMS2kUAgsApOHu5IkmTy1kwCJMmg4yJrNBxdGOu8SJJE/RFfJllKLWsUcpQrTvZ3mh4WqF2ZHy9u59H5KwQ+foZHBh+ylCiUoL1CYjh7euDs6WF0nJOHO98cWsWu/81l/4wlhPi/RNYolGzdkPrD+sZT5BUIBCmDcF4EAkGSlGrbiOt7j1h0rSk9jHQxMQQ9fa7/ucJnrXlx5yFbxk7Vb1fFVTFlLJSP3mtnJXBMJEkiS/FCZCleyCI7TcHJ3Y0mowfTeNQgosLC0TjYo2jE16dA8KEQnz6BQJAkZTs1Z+v46QQ9eZYg50NSZOwcHdBGx6DqdG/zYiQJCchduTRPLt80KCYnazTxxPUkSaLpmK8p06Eph+Ys59mNuzi5u1KqbSOKNK71wR0GSZJwcHH+oDYIBAKR8yIQCIzgf+cB0xt/jt/VW8gaDZIUm3DrkcGHfv/Ow87JkV2/zeHUyk1EhYXjkyc71b/sSpXeHdk0ejI7f52daLJrHMNObIi3FSQQCP6bmHP/Fs6LQCAwik6n49quQ1zddRhVqyVnxVIUa1ob5Y3Kbhyqqsbb1nnt/5LxJRsT7Pc8YcWSJFG2YzM+XzI5BV6BQCBI7QjnRTgvAkGq4dWjpyzuOYwr2w/oq4jsnZ2oMeAzmo775oNvBQkEgtSBqDYSCASphjSZM/DV1oW8uPuQh+cuo3FwIE+VMji6uX5o0wQCwUeKcF4EAkGKkC5HFtLlyPKhzRAIBJ8ApumFCwQCgUAgEKQShPMiEAgEAoHgo0I4LwKBQCAQCD4qhPMiEAgEAoHgo0I4LwKBQCAQCD4qhPMiEAgEAoHgo0I4LwKBQCAQCD4qhPMiEAgEAoHgo0I4LwKBQCAQCD4qPjmF3bhWTcHBwR/YEoFAIBAIBKYSd982peXiJ+e8vH79GoAsWYQMuUAgEAgEHxuvX7/Gw8PD4JhPrqu0TqfjyZMnuLm5IUnShzaH4OBgsmTJwsOHD0WX61SOeK8+LsT79XEh3q+Piw/xfqmqyuvXr8mYMSOybDir5ZOLvMiyTObMmT+0GQlwd3cXH9iPBPFefVyI9+vjQrxfHxcp/X4Zi7jEIRJ2BQKBQCAQfFQI50UgEAgEAsFHhXBebIyDgwOjRo3CwcHhQ5siMIJ4rz4uxPv1cSHer4+L1P5+fXIJuwKBQCAQCD5tRORFIBAIBALBR4VwXgQCgUAgEHxUCOdFIBAIBALBR4VwXgQCgUAgEHxUCOfFyowfP56KFSvi7OyMp6enSdeoqsqPP/5IhgwZcHJyonbt2ty8edO2hgoACAgIoFOnTri7u+Pp6UmPHj0ICQkxeE316tWRJCnenz59+qSQxf8tpk+fTvbs2XF0dKRcuXKcOHHC4PhVq1aRP39+HB0dKVKkCFu2bEkhSwVg3vu1YMGCBJ8jR0fHFLT2v8uBAwdo0qQJGTNmRJIk1q9fb/Saffv2UbJkSRwcHMidOzcLFiywuZ2GEM6LlYmKiqJNmzb07dvX5GsmTZrE1KlTmTlzJsePH8fFxYV69eoRERFhQ0sFAJ06deLy5cvs3LmTTZs2ceDAAXr16mX0up49e/L06VP9n0mTJqWAtf8t/vnnH77++mtGjRrFmTNnKFasGPXq1eP58+eJjj9y5AgdOnSgR48enD17lubNm9O8eXMuXbqUwpb/NzH3/YJY9dZ3P0f3799PQYv/u4SGhlKsWDGmT59u0vi7d+/SqFEjatSowblz5xg0aBBffPEF27dvt7GlBlAFNuHvv/9WPTw8jI7T6XSqr6+v+uuvv+qPBQYGqg4ODury5cttaKHgypUrKqCePHlSf2zr1q2qJEnq48ePk7yuWrVq6sCBA1PAwv82ZcuWVb/88kv9z1qtVs2YMaM6YcKERMe3bdtWbdSoUbxj5cqVU3v37m1TOwWxmPt+mfodKbAtgLpu3TqDY7777ju1UKFC8Y61a9dOrVevng0tM4yIvHxg7t69i5+fH7Vr19Yf8/DwoFy5chw9evQDWvbpc/ToUTw9PSldurT+WO3atZFlmePHjxu8dunSpaRLl47ChQszfPhwwsLCbG3uf4qoqChOnz4d73MhyzK1a9dO8nNx9OjReOMB6tWrJz5HKYAl7xdASEgI2bJlI0uWLDRr1ozLly+nhLkCM0mNn61PrjHjx4afnx8A6dOnj3c8ffr0+nMC2+Dn54ePj0+8YxqNBi8vL4P/9x07diRbtmxkzJiRCxcuMHToUK5fv87atWttbfJ/hhcvXqDVahP9XFy7di3Ra/z8/MTn6ANhyfuVL18+5s+fT9GiRQkKCuK3336jYsWKXL58OVU21/0vk9RnKzg4mPDwcJycnFLcJhF5MYFhw4YlSCx7/09SH1BBymPr96tXr17Uq1ePIkWK0KlTJxYtWsS6deu4ffu2FV+FQPBpU6FCBbp27Urx4sWpVq0aa9euxdvbm1mzZn1o0wQfASLyYgJDhgyhW7duBsfkzJnTorl9fX0BePbsGRkyZNAff/bsGcWLF7dozv86pr5fvr6+CZIJY2JiCAgI0L8vplCuXDkAbt26Ra5cucy2V5CQdOnSoSgKz549i3f82bNnSb43vr6+Zo0XWA9L3q/3sbOzo0SJEty6dcsWJgqSQVKfLXd39w8SdQHhvJiEt7c33t7eNpk7R44c+Pr6snv3br2zEhwczPHjx82qWBK8xdT3q0KFCgQGBnL69GlKlSoFwJ49e9DpdHqHxBTOnTsHEM/5FCQPe3t7Sv2/nTsGaV0Nwzj+HdREpEhx6SZY1A4uygGhSzu4SBcd7VCCi5NDl0IXkTo5iIs46ygOQgdBkdBFwYIasGgR1FJxcHGQDk72f6Yb8Opy5F5D7PODDGnewPfyUr6H0uT3b+O6rpmdnTXGGNNut43rumZxcfHTe5LJpHFd1+Tzef+zo6Mjk0wmv2HFne0r8/q3t7c3U6vVTCaT+R9XKl+RTCY/vHYg8O9WYH8V/qGazSae51EqlYhEInieh+d5tFotvyaRSLC3t+efr66uEo1GKZfLXF5eMjMzw9DQEK+vr0G00FGmp6eZmJigWq1yfHzMyMgI2WzWv/74+EgikaBarQJwe3vLysoKZ2dnNBoNyuUy8XicVCoVVAs/1s7ODrZts729zfX1NQsLC0SjUZ6engDI5XIUi0W//uTkhO7ubtbW1qjX6ywvL9PT00OtVguqhY7yt/MqlUocHh5yd3fH+fk5c3Nz9Pb2cnV1FVQLHaPVavl7kzGG9fV1PM+j2WwCUCwWyeVyfv39/T19fX0UCgXq9Tqbm5t0dXVxcHAQVAsovPzHHMfBGPPhqFQqfo0xhq2tLf+83W6ztLRELBbDtm2mpqa4ubn5/sV3oOfnZ7LZLJFIhP7+fubn598FzUaj8W5+Dw8PpFIpBgYGsG2b4eFhCoUCLy8vAXXws21sbDA4OIhlWUxOTnJ6eupfS6fTOI7zrn53d5fR0VEsy2JsbIz9/f1vXnFn+5t55fN5vzYWi5HJZLi4uAhg1Z2nUql8uk/9Mx/HcUin0x/uGR8fx7Is4vH4uz0sCL8AAvnJR0REROQL9LSRiIiIhIrCi4iIiISKwouIiIiEisKLiIiIhIrCi4iIiISKwouIiIiEisKLiIiIhIrCi4iIiISKwouIiIiEisKLiIiIhIrCi4iIiISKwouIiIiEyh8FKxuXlj57WAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# convent our dataset to tensors"
      ],
      "metadata": {
        "id": "qGZJbuzoIAAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if gpu is avaliable, use it.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "QWX_jBZNwdz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.from_numpy(X).type(torch.float).to(device) # numpy uses float64 but pytorch normally likes float 32\n",
        "y = torch.from_numpy(y).type(torch.float).to(device)"
      ],
      "metadata": {
        "id": "Lk8lYWwnFrQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.squeeze()\n",
        "y = y.squeeze()"
      ],
      "metadata": {
        "id": "kyTQhBx-IUPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the dataset"
      ],
      "metadata": {
        "id": "ZU4qDZ3whJf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=42)\n",
        "len(X_train),len(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYOfXtu4hMI2",
        "outputId": "8f92ef42-fa58-4407-cfc6-a0170ce2eb8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 800)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time to build our model"
      ],
      "metadata": {
        "id": "JRd90VuonDAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CircleModelV0(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_1 = nn.Linear(in_features = 2, out_features= 5) #5 neurons\n",
        "    self.layer_2 = nn.Linear(in_features = 5, out_features=1) # 1 neuron\n",
        "\n",
        "  def forward(self,x: torch.Tensor) -> torch.Tensor:\n",
        "    return self.layer_2(self.layer_1(x))\n",
        "\n"
      ],
      "metadata": {
        "id": "VTtQNcYikWIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seeding\n",
        "torch.manual_seed(42)\n",
        "# create instance of circleModelV0\n",
        "model_0 = CircleModelV0().to(device) # also use gpu if it's avaliable\n",
        "model_0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uybVBAlcvHJj",
        "outputId": "be2df8d0-48f1-46d6-d94f-e77ebdfd4ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CircleModelV0(\n",
              "  (layer_1): Linear(in_features=2, out_features=5, bias=True)\n",
              "  (layer_2): Linear(in_features=5, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create an acccuracy metric**"
      ],
      "metadata": {
        "id": "Ae6-7VlROCYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_pred, y_true):\n",
        "  correct = torch.eq(y_pred, y_true).sum().item()\n",
        "  accuracy = correct / len(y_pred)\n",
        "  return accuracy\n",
        "\n",
        "accuracy(y_pred=y_train, y_true=y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7ylHdedN_I9",
        "outputId": "274b58d6-dcd8-446a-c4d1-16d97ebd8c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model,epochs, lr):\n",
        "  epochs_count = []\n",
        "  train_losses = []\n",
        "  test_losses = []\n",
        "\n",
        "  # define loss function\n",
        "  loss_fn = nn.BCEWithLogitsLoss()\n",
        "  # define optimizer\n",
        "  optimizer = torch.optim.SGD(params=model.parameters(), lr=lr)\n",
        "  for epoch in range(epochs):\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "    # calculate loss\n",
        "    logit = model(X_train).squeeze()\n",
        "    y_pred = torch.round(torch.sigmoid(logit))\n",
        "    loss = loss_fn(logit, y_train)\n",
        "    # calculate accuracy\n",
        "    train_accuracy = accuracy(y_pred=y_pred, y_true=y_train)\n",
        "    # zero grad\n",
        "    optimizer.zero_grad()\n",
        "    #perform backpropagation\n",
        "    loss.backward()\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    ##### evaluation ###########\n",
        "\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "      test_logit = model(X_test).squeeze()\n",
        "      test_pred = torch.round(torch.sigmoid(test_logit))\n",
        "      #calculate loss on test data\n",
        "      test_loss = loss_fn(test_logit, y_test)\n",
        "      # accuracy\n",
        "      test_accuracy = accuracy(y_pred=test_pred, y_true=y_test)\n",
        "\n",
        "    # on every tenth epoch, print something\n",
        "    epochs_count.append(epoch)\n",
        "    train_losses.append(loss.detach().item())\n",
        "    test_losses.append(test_loss.detach().item())\n",
        "\n",
        "    print(f\"train loss {loss} accuracy {train_accuracy:.2f} | test loss {test_loss:}  accuracy {test_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "zoQEzM1JxbrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model=model_0, epochs=500, lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAVBVKyxVyyS",
        "outputId": "170578a2-d1e3-48e9-96ce-deadab0453ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 0.6929897665977478 accuracy 0.51 | test loss 0.6950352191925049  accuracy 0.47\n",
            "train loss 0.6929897665977478 accuracy 0.52 | test loss 0.695034921169281  accuracy 0.47\n",
            "train loss 0.6929897665977478 accuracy 0.52 | test loss 0.6950348019599915  accuracy 0.47\n",
            "train loss 0.6929897665977478 accuracy 0.52 | test loss 0.6950344443321228  accuracy 0.47\n",
            "train loss 0.6929897665977478 accuracy 0.52 | test loss 0.6950341463088989  accuracy 0.47\n",
            "train loss 0.6929897665977478 accuracy 0.52 | test loss 0.6950339078903198  accuracy 0.47\n",
            "train loss 0.6929896473884583 accuracy 0.52 | test loss 0.695033609867096  accuracy 0.47\n",
            "train loss 0.692989706993103 accuracy 0.52 | test loss 0.6950333714485168  accuracy 0.47\n",
            "train loss 0.692989706993103 accuracy 0.52 | test loss 0.695033073425293  accuracy 0.47\n",
            "train loss 0.692989706993103 accuracy 0.52 | test loss 0.6950328946113586  accuracy 0.47\n",
            "train loss 0.6929896473884583 accuracy 0.52 | test loss 0.6950326561927795  accuracy 0.47\n",
            "train loss 0.6929896473884583 accuracy 0.52 | test loss 0.6950323581695557  accuracy 0.47\n",
            "train loss 0.6929896473884583 accuracy 0.52 | test loss 0.6950321197509766  accuracy 0.47\n",
            "train loss 0.6929896473884583 accuracy 0.52 | test loss 0.6950318813323975  accuracy 0.47\n",
            "train loss 0.6929896473884583 accuracy 0.52 | test loss 0.6950315833091736  accuracy 0.47\n",
            "train loss 0.6929896473884583 accuracy 0.52 | test loss 0.6950312852859497  accuracy 0.47\n",
            "train loss 0.6929896473884583 accuracy 0.52 | test loss 0.6950310468673706  accuracy 0.47\n",
            "train loss 0.6929895877838135 accuracy 0.52 | test loss 0.6950308084487915  accuracy 0.47\n",
            "train loss 0.6929895877838135 accuracy 0.52 | test loss 0.6950305104255676  accuracy 0.47\n",
            "train loss 0.6929895877838135 accuracy 0.52 | test loss 0.6950302720069885  accuracy 0.47\n",
            "train loss 0.6929894685745239 accuracy 0.52 | test loss 0.6950300335884094  accuracy 0.47\n",
            "train loss 0.6929894685745239 accuracy 0.52 | test loss 0.6950297355651855  accuracy 0.47\n",
            "train loss 0.6929894685745239 accuracy 0.52 | test loss 0.6950294971466064  accuracy 0.47\n",
            "train loss 0.6929894685745239 accuracy 0.52 | test loss 0.6950291991233826  accuracy 0.47\n",
            "train loss 0.6929894685745239 accuracy 0.52 | test loss 0.6950289607048035  accuracy 0.47\n",
            "train loss 0.6929894685745239 accuracy 0.52 | test loss 0.6950286626815796  accuracy 0.47\n",
            "train loss 0.6929894685745239 accuracy 0.52 | test loss 0.6950284242630005  accuracy 0.47\n",
            "train loss 0.6929894685745239 accuracy 0.52 | test loss 0.6950281858444214  accuracy 0.47\n",
            "train loss 0.6929894089698792 accuracy 0.52 | test loss 0.6950278878211975  accuracy 0.47\n",
            "train loss 0.6929894089698792 accuracy 0.52 | test loss 0.695027768611908  accuracy 0.47\n",
            "train loss 0.6929893493652344 accuracy 0.52 | test loss 0.6950273513793945  accuracy 0.47\n",
            "train loss 0.6929894089698792 accuracy 0.52 | test loss 0.6950271725654602  accuracy 0.47\n",
            "train loss 0.6929893493652344 accuracy 0.52 | test loss 0.6950269341468811  accuracy 0.47\n",
            "train loss 0.6929893493652344 accuracy 0.52 | test loss 0.695026695728302  accuracy 0.47\n",
            "train loss 0.6929893493652344 accuracy 0.52 | test loss 0.6950263977050781  accuracy 0.47\n",
            "train loss 0.6929893493652344 accuracy 0.52 | test loss 0.6950260996818542  accuracy 0.47\n",
            "train loss 0.6929893493652344 accuracy 0.52 | test loss 0.6950259208679199  accuracy 0.47\n",
            "train loss 0.6929893493652344 accuracy 0.52 | test loss 0.695025622844696  accuracy 0.47\n",
            "train loss 0.6929893493652344 accuracy 0.52 | test loss 0.6950253844261169  accuracy 0.47\n",
            "train loss 0.6929893493652344 accuracy 0.52 | test loss 0.6950251460075378  accuracy 0.47\n",
            "train loss 0.6929892301559448 accuracy 0.52 | test loss 0.695024847984314  accuracy 0.47\n",
            "train loss 0.6929892301559448 accuracy 0.52 | test loss 0.6950245499610901  accuracy 0.47\n",
            "train loss 0.6929892301559448 accuracy 0.52 | test loss 0.695024311542511  accuracy 0.47\n",
            "train loss 0.6929891705513 accuracy 0.52 | test loss 0.6950240731239319  accuracy 0.47\n",
            "train loss 0.6929891705513 accuracy 0.52 | test loss 0.695023775100708  accuracy 0.47\n",
            "train loss 0.6929891705513 accuracy 0.52 | test loss 0.6950235366821289  accuracy 0.47\n",
            "train loss 0.6929891705513 accuracy 0.52 | test loss 0.6950233578681946  accuracy 0.47\n",
            "train loss 0.6929891705513 accuracy 0.52 | test loss 0.6950231194496155  accuracy 0.47\n",
            "train loss 0.6929891705513 accuracy 0.52 | test loss 0.6950228810310364  accuracy 0.47\n",
            "train loss 0.6929891705513 accuracy 0.52 | test loss 0.6950225830078125  accuracy 0.47\n",
            "train loss 0.6929891109466553 accuracy 0.52 | test loss 0.6950222849845886  accuracy 0.47\n",
            "train loss 0.6929891109466553 accuracy 0.52 | test loss 0.6950220465660095  accuracy 0.47\n",
            "train loss 0.6929891109466553 accuracy 0.52 | test loss 0.6950218081474304  accuracy 0.47\n",
            "train loss 0.6929890513420105 accuracy 0.52 | test loss 0.6950215101242065  accuracy 0.47\n",
            "train loss 0.6929890513420105 accuracy 0.52 | test loss 0.6950213313102722  accuracy 0.47\n",
            "train loss 0.6929890513420105 accuracy 0.52 | test loss 0.6950210332870483  accuracy 0.47\n",
            "train loss 0.6929890513420105 accuracy 0.52 | test loss 0.6950207948684692  accuracy 0.47\n",
            "train loss 0.6929890513420105 accuracy 0.52 | test loss 0.6950205564498901  accuracy 0.47\n",
            "train loss 0.6929890513420105 accuracy 0.52 | test loss 0.6950202584266663  accuracy 0.47\n",
            "train loss 0.6929890513420105 accuracy 0.52 | test loss 0.6950199604034424  accuracy 0.47\n",
            "train loss 0.6929890513420105 accuracy 0.52 | test loss 0.6950198411941528  accuracy 0.47\n",
            "train loss 0.692988932132721 accuracy 0.52 | test loss 0.695019543170929  accuracy 0.47\n",
            "train loss 0.692988932132721 accuracy 0.52 | test loss 0.6950193047523499  accuracy 0.47\n",
            "train loss 0.692988932132721 accuracy 0.52 | test loss 0.6950190663337708  accuracy 0.47\n",
            "train loss 0.6929888725280762 accuracy 0.52 | test loss 0.6950187683105469  accuracy 0.47\n",
            "train loss 0.6929888725280762 accuracy 0.52 | test loss 0.695018470287323  accuracy 0.47\n",
            "train loss 0.6929888725280762 accuracy 0.52 | test loss 0.6950182914733887  accuracy 0.47\n",
            "train loss 0.6929888725280762 accuracy 0.52 | test loss 0.6950179934501648  accuracy 0.47\n",
            "train loss 0.6929888725280762 accuracy 0.52 | test loss 0.6950177550315857  accuracy 0.47\n",
            "train loss 0.6929888725280762 accuracy 0.52 | test loss 0.6950175166130066  accuracy 0.47\n",
            "train loss 0.6929888725280762 accuracy 0.52 | test loss 0.6950172185897827  accuracy 0.47\n",
            "train loss 0.6929888725280762 accuracy 0.52 | test loss 0.6950169801712036  accuracy 0.47\n",
            "train loss 0.6929888129234314 accuracy 0.52 | test loss 0.6950167417526245  accuracy 0.47\n",
            "train loss 0.6929888129234314 accuracy 0.52 | test loss 0.6950164437294006  accuracy 0.47\n",
            "train loss 0.6929888129234314 accuracy 0.52 | test loss 0.6950162053108215  accuracy 0.47\n",
            "train loss 0.6929888725280762 accuracy 0.52 | test loss 0.6950160264968872  accuracy 0.47\n",
            "train loss 0.6929887533187866 accuracy 0.52 | test loss 0.6950157284736633  accuracy 0.47\n",
            "train loss 0.6929887533187866 accuracy 0.52 | test loss 0.695015549659729  accuracy 0.47\n",
            "train loss 0.6929887533187866 accuracy 0.52 | test loss 0.6950152516365051  accuracy 0.47\n",
            "train loss 0.6929887533187866 accuracy 0.52 | test loss 0.695015013217926  accuracy 0.47\n",
            "train loss 0.6929887533187866 accuracy 0.52 | test loss 0.6950147151947021  accuracy 0.47\n",
            "train loss 0.6929887533187866 accuracy 0.52 | test loss 0.6950145363807678  accuracy 0.47\n",
            "train loss 0.6929887533187866 accuracy 0.52 | test loss 0.695014238357544  accuracy 0.47\n",
            "train loss 0.6929886341094971 accuracy 0.52 | test loss 0.6950139999389648  accuracy 0.47\n",
            "train loss 0.6929886341094971 accuracy 0.52 | test loss 0.6950138211250305  accuracy 0.47\n",
            "train loss 0.6929886341094971 accuracy 0.52 | test loss 0.6950134634971619  accuracy 0.47\n",
            "train loss 0.6929887533187866 accuracy 0.52 | test loss 0.6950132846832275  accuracy 0.47\n",
            "train loss 0.6929885745048523 accuracy 0.52 | test loss 0.6950130462646484  accuracy 0.47\n",
            "train loss 0.6929886341094971 accuracy 0.52 | test loss 0.6950128078460693  accuracy 0.47\n",
            "train loss 0.6929885745048523 accuracy 0.52 | test loss 0.6950125098228455  accuracy 0.47\n",
            "train loss 0.6929885745048523 accuracy 0.52 | test loss 0.6950122714042664  accuracy 0.47\n",
            "train loss 0.6929885745048523 accuracy 0.52 | test loss 0.6950120329856873  accuracy 0.47\n",
            "train loss 0.6929885745048523 accuracy 0.52 | test loss 0.6950117349624634  accuracy 0.47\n",
            "train loss 0.6929885745048523 accuracy 0.52 | test loss 0.695011556148529  accuracy 0.47\n",
            "train loss 0.6929885745048523 accuracy 0.52 | test loss 0.6950112581253052  accuracy 0.47\n",
            "train loss 0.6929885149002075 accuracy 0.52 | test loss 0.6950111389160156  accuracy 0.47\n",
            "train loss 0.6929885149002075 accuracy 0.52 | test loss 0.6950108408927917  accuracy 0.47\n",
            "train loss 0.6929885149002075 accuracy 0.52 | test loss 0.6950106024742126  accuracy 0.47\n",
            "train loss 0.6929885745048523 accuracy 0.52 | test loss 0.6950103640556335  accuracy 0.47\n",
            "train loss 0.6929885149002075 accuracy 0.52 | test loss 0.6950100660324097  accuracy 0.47\n",
            "train loss 0.6929885149002075 accuracy 0.52 | test loss 0.6950098276138306  accuracy 0.47\n",
            "train loss 0.692988395690918 accuracy 0.52 | test loss 0.6950095891952515  accuracy 0.47\n",
            "train loss 0.6929885149002075 accuracy 0.52 | test loss 0.6950092911720276  accuracy 0.47\n",
            "train loss 0.692988395690918 accuracy 0.52 | test loss 0.6950091123580933  accuracy 0.47\n",
            "train loss 0.692988395690918 accuracy 0.52 | test loss 0.6950088143348694  accuracy 0.47\n",
            "train loss 0.692988395690918 accuracy 0.52 | test loss 0.6950085759162903  accuracy 0.47\n",
            "train loss 0.692988395690918 accuracy 0.52 | test loss 0.695008397102356  accuracy 0.47\n",
            "train loss 0.6929883360862732 accuracy 0.52 | test loss 0.6950081586837769  accuracy 0.47\n",
            "train loss 0.692988395690918 accuracy 0.52 | test loss 0.6950079202651978  accuracy 0.47\n",
            "train loss 0.6929883360862732 accuracy 0.52 | test loss 0.6950076222419739  accuracy 0.47\n",
            "train loss 0.692988395690918 accuracy 0.52 | test loss 0.6950073838233948  accuracy 0.47\n",
            "train loss 0.6929883360862732 accuracy 0.52 | test loss 0.6950071454048157  accuracy 0.47\n",
            "train loss 0.6929882764816284 accuracy 0.52 | test loss 0.6950070261955261  accuracy 0.47\n",
            "train loss 0.6929883360862732 accuracy 0.52 | test loss 0.6950066685676575  accuracy 0.47\n",
            "train loss 0.6929882764816284 accuracy 0.52 | test loss 0.6950064897537231  accuracy 0.47\n",
            "train loss 0.6929882764816284 accuracy 0.52 | test loss 0.695006251335144  accuracy 0.47\n",
            "train loss 0.6929882764816284 accuracy 0.52 | test loss 0.6950059533119202  accuracy 0.47\n",
            "train loss 0.6929882764816284 accuracy 0.52 | test loss 0.6950057148933411  accuracy 0.47\n",
            "train loss 0.6929882764816284 accuracy 0.52 | test loss 0.695005476474762  accuracy 0.47\n",
            "train loss 0.6929882764816284 accuracy 0.52 | test loss 0.6950051784515381  accuracy 0.47\n",
            "train loss 0.6929882764816284 accuracy 0.52 | test loss 0.695004940032959  accuracy 0.47\n",
            "train loss 0.6929882764816284 accuracy 0.52 | test loss 0.6950047016143799  accuracy 0.47\n",
            "train loss 0.6929882764816284 accuracy 0.52 | test loss 0.6950044631958008  accuracy 0.47\n",
            "train loss 0.6929882764816284 accuracy 0.52 | test loss 0.6950042843818665  accuracy 0.47\n",
            "train loss 0.6929880976676941 accuracy 0.52 | test loss 0.6950039267539978  accuracy 0.47\n",
            "train loss 0.6929882168769836 accuracy 0.51 | test loss 0.6950038075447083  accuracy 0.47\n",
            "train loss 0.6929882168769836 accuracy 0.51 | test loss 0.6950035095214844  accuracy 0.47\n",
            "train loss 0.6929880976676941 accuracy 0.51 | test loss 0.6950032711029053  accuracy 0.47\n",
            "train loss 0.6929880976676941 accuracy 0.51 | test loss 0.6950030326843262  accuracy 0.47\n",
            "train loss 0.6929880976676941 accuracy 0.51 | test loss 0.6950027942657471  accuracy 0.47\n",
            "train loss 0.6929880976676941 accuracy 0.51 | test loss 0.695002555847168  accuracy 0.47\n",
            "train loss 0.6929880976676941 accuracy 0.51 | test loss 0.6950023770332336  accuracy 0.47\n",
            "train loss 0.6929880976676941 accuracy 0.51 | test loss 0.6950021386146545  accuracy 0.47\n",
            "train loss 0.6929880380630493 accuracy 0.51 | test loss 0.6950018405914307  accuracy 0.47\n",
            "train loss 0.6929880380630493 accuracy 0.51 | test loss 0.6950016021728516  accuracy 0.47\n",
            "train loss 0.6929880976676941 accuracy 0.51 | test loss 0.6950013637542725  accuracy 0.47\n",
            "train loss 0.6929880380630493 accuracy 0.51 | test loss 0.6950011849403381  accuracy 0.47\n",
            "train loss 0.6929880380630493 accuracy 0.51 | test loss 0.6950008869171143  accuracy 0.47\n",
            "train loss 0.6929879784584045 accuracy 0.51 | test loss 0.6950007677078247  accuracy 0.47\n",
            "train loss 0.6929879784584045 accuracy 0.51 | test loss 0.6950004696846008  accuracy 0.47\n",
            "train loss 0.6929879784584045 accuracy 0.51 | test loss 0.6950002312660217  accuracy 0.47\n",
            "train loss 0.6929879784584045 accuracy 0.51 | test loss 0.6949999928474426  accuracy 0.47\n",
            "train loss 0.6929879784584045 accuracy 0.51 | test loss 0.6949996948242188  accuracy 0.47\n",
            "train loss 0.6929879784584045 accuracy 0.51 | test loss 0.6949994564056396  accuracy 0.47\n",
            "train loss 0.6929879784584045 accuracy 0.51 | test loss 0.6949992179870605  accuracy 0.47\n",
            "train loss 0.6929879784584045 accuracy 0.51 | test loss 0.6949989795684814  accuracy 0.47\n",
            "train loss 0.6929879784584045 accuracy 0.51 | test loss 0.6949987411499023  accuracy 0.47\n",
            "train loss 0.692987859249115 accuracy 0.51 | test loss 0.694998562335968  accuracy 0.47\n",
            "train loss 0.692987859249115 accuracy 0.51 | test loss 0.6949983239173889  accuracy 0.47\n",
            "train loss 0.692987859249115 accuracy 0.51 | test loss 0.6949980854988098  accuracy 0.47\n",
            "train loss 0.692987859249115 accuracy 0.51 | test loss 0.6949978470802307  accuracy 0.47\n",
            "train loss 0.6929877996444702 accuracy 0.51 | test loss 0.6949976086616516  accuracy 0.47\n",
            "train loss 0.6929877996444702 accuracy 0.51 | test loss 0.6949973702430725  accuracy 0.47\n",
            "train loss 0.6929877996444702 accuracy 0.51 | test loss 0.6949970722198486  accuracy 0.47\n",
            "train loss 0.6929877996444702 accuracy 0.51 | test loss 0.6949968338012695  accuracy 0.47\n",
            "train loss 0.6929877996444702 accuracy 0.51 | test loss 0.6949966549873352  accuracy 0.47\n",
            "train loss 0.6929877996444702 accuracy 0.51 | test loss 0.6949964165687561  accuracy 0.47\n",
            "train loss 0.6929877996444702 accuracy 0.51 | test loss 0.694996178150177  accuracy 0.47\n",
            "train loss 0.6929877996444702 accuracy 0.51 | test loss 0.6949959397315979  accuracy 0.47\n",
            "train loss 0.6929877996444702 accuracy 0.51 | test loss 0.6949957013130188  accuracy 0.47\n",
            "train loss 0.6929877400398254 accuracy 0.51 | test loss 0.6949954628944397  accuracy 0.47\n",
            "train loss 0.6929877400398254 accuracy 0.51 | test loss 0.6949952244758606  accuracy 0.47\n",
            "train loss 0.6929877400398254 accuracy 0.51 | test loss 0.6949950456619263  accuracy 0.47\n",
            "train loss 0.6929877400398254 accuracy 0.51 | test loss 0.6949948072433472  accuracy 0.47\n",
            "train loss 0.6929876804351807 accuracy 0.51 | test loss 0.6949945688247681  accuracy 0.47\n",
            "train loss 0.6929876804351807 accuracy 0.51 | test loss 0.694994330406189  accuracy 0.47\n",
            "train loss 0.6929876804351807 accuracy 0.51 | test loss 0.6949940323829651  accuracy 0.47\n",
            "train loss 0.6929876804351807 accuracy 0.51 | test loss 0.6949938535690308  accuracy 0.47\n",
            "train loss 0.6929876804351807 accuracy 0.51 | test loss 0.6949935555458069  accuracy 0.47\n",
            "train loss 0.6929876804351807 accuracy 0.51 | test loss 0.6949934363365173  accuracy 0.47\n",
            "train loss 0.6929876804351807 accuracy 0.51 | test loss 0.6949931383132935  accuracy 0.47\n",
            "train loss 0.6929876804351807 accuracy 0.51 | test loss 0.6949929594993591  accuracy 0.47\n",
            "train loss 0.6929875612258911 accuracy 0.51 | test loss 0.6949926614761353  accuracy 0.47\n",
            "train loss 0.6929876804351807 accuracy 0.51 | test loss 0.6949924230575562  accuracy 0.47\n",
            "train loss 0.6929875612258911 accuracy 0.51 | test loss 0.694992184638977  accuracy 0.47\n",
            "train loss 0.6929875612258911 accuracy 0.51 | test loss 0.694991946220398  accuracy 0.47\n",
            "train loss 0.6929875612258911 accuracy 0.51 | test loss 0.6949917674064636  accuracy 0.47\n",
            "train loss 0.6929875016212463 accuracy 0.51 | test loss 0.6949915289878845  accuracy 0.47\n",
            "train loss 0.6929875016212463 accuracy 0.51 | test loss 0.6949912905693054  accuracy 0.47\n",
            "train loss 0.6929875016212463 accuracy 0.51 | test loss 0.6949911117553711  accuracy 0.47\n",
            "train loss 0.6929875016212463 accuracy 0.51 | test loss 0.6949908137321472  accuracy 0.47\n",
            "train loss 0.6929875016212463 accuracy 0.51 | test loss 0.6949905753135681  accuracy 0.47\n",
            "train loss 0.6929875016212463 accuracy 0.51 | test loss 0.6949903964996338  accuracy 0.47\n",
            "train loss 0.6929875016212463 accuracy 0.51 | test loss 0.6949901580810547  accuracy 0.47\n",
            "train loss 0.6929874420166016 accuracy 0.51 | test loss 0.6949899196624756  accuracy 0.47\n",
            "train loss 0.6929875016212463 accuracy 0.51 | test loss 0.6949896812438965  accuracy 0.47\n",
            "train loss 0.6929875016212463 accuracy 0.51 | test loss 0.6949894428253174  accuracy 0.47\n",
            "train loss 0.6929875016212463 accuracy 0.51 | test loss 0.6949892044067383  accuracy 0.47\n",
            "train loss 0.6929874420166016 accuracy 0.51 | test loss 0.694989025592804  accuracy 0.47\n",
            "train loss 0.6929874420166016 accuracy 0.51 | test loss 0.6949887871742249  accuracy 0.47\n",
            "train loss 0.6929874420166016 accuracy 0.51 | test loss 0.6949885487556458  accuracy 0.47\n",
            "train loss 0.692987322807312 accuracy 0.51 | test loss 0.6949883103370667  accuracy 0.47\n",
            "train loss 0.692987322807312 accuracy 0.51 | test loss 0.6949880719184875  accuracy 0.47\n",
            "train loss 0.6929874420166016 accuracy 0.51 | test loss 0.694987952709198  accuracy 0.47\n",
            "train loss 0.6929874420166016 accuracy 0.51 | test loss 0.6949875950813293  accuracy 0.47\n",
            "train loss 0.6929874420166016 accuracy 0.51 | test loss 0.694987416267395  accuracy 0.47\n",
            "train loss 0.692987322807312 accuracy 0.51 | test loss 0.6949871778488159  accuracy 0.47\n",
            "train loss 0.692987322807312 accuracy 0.51 | test loss 0.6949869394302368  accuracy 0.47\n",
            "train loss 0.692987322807312 accuracy 0.51 | test loss 0.6949867010116577  accuracy 0.47\n",
            "train loss 0.692987322807312 accuracy 0.51 | test loss 0.6949864625930786  accuracy 0.47\n",
            "train loss 0.692987322807312 accuracy 0.51 | test loss 0.6949862241744995  accuracy 0.47\n",
            "train loss 0.692987322807312 accuracy 0.51 | test loss 0.69498610496521  accuracy 0.47\n",
            "train loss 0.692987322807312 accuracy 0.51 | test loss 0.6949858069419861  accuracy 0.47\n",
            "train loss 0.6929872632026672 accuracy 0.51 | test loss 0.6949856281280518  accuracy 0.47\n",
            "train loss 0.6929872632026672 accuracy 0.51 | test loss 0.6949853301048279  accuracy 0.47\n",
            "train loss 0.6929872035980225 accuracy 0.51 | test loss 0.6949850916862488  accuracy 0.47\n",
            "train loss 0.6929872632026672 accuracy 0.51 | test loss 0.6949848532676697  accuracy 0.47\n",
            "train loss 0.6929872035980225 accuracy 0.51 | test loss 0.6949846744537354  accuracy 0.47\n",
            "train loss 0.6929872035980225 accuracy 0.51 | test loss 0.6949844360351562  accuracy 0.47\n",
            "train loss 0.6929872035980225 accuracy 0.51 | test loss 0.6949842572212219  accuracy 0.47\n",
            "train loss 0.6929872035980225 accuracy 0.51 | test loss 0.694983959197998  accuracy 0.47\n",
            "train loss 0.6929872035980225 accuracy 0.51 | test loss 0.6949837803840637  accuracy 0.47\n",
            "train loss 0.6929872035980225 accuracy 0.51 | test loss 0.6949834823608398  accuracy 0.47\n",
            "train loss 0.6929872035980225 accuracy 0.51 | test loss 0.6949833631515503  accuracy 0.47\n",
            "train loss 0.6929871439933777 accuracy 0.51 | test loss 0.6949831247329712  accuracy 0.47\n",
            "train loss 0.6929871439933777 accuracy 0.51 | test loss 0.6949828267097473  accuracy 0.47\n",
            "train loss 0.6929871439933777 accuracy 0.51 | test loss 0.694982647895813  accuracy 0.47\n",
            "train loss 0.6929871439933777 accuracy 0.51 | test loss 0.6949824094772339  accuracy 0.47\n",
            "train loss 0.6929871439933777 accuracy 0.51 | test loss 0.6949822306632996  accuracy 0.47\n",
            "train loss 0.6929870247840881 accuracy 0.51 | test loss 0.6949819922447205  accuracy 0.47\n",
            "train loss 0.6929870247840881 accuracy 0.51 | test loss 0.6949817538261414  accuracy 0.47\n",
            "train loss 0.6929870247840881 accuracy 0.51 | test loss 0.6949815154075623  accuracy 0.47\n",
            "train loss 0.6929870247840881 accuracy 0.51 | test loss 0.6949812769889832  accuracy 0.47\n",
            "train loss 0.6929870247840881 accuracy 0.51 | test loss 0.694981038570404  accuracy 0.47\n",
            "train loss 0.6929870247840881 accuracy 0.51 | test loss 0.6949809193611145  accuracy 0.47\n",
            "train loss 0.6929870247840881 accuracy 0.51 | test loss 0.6949806213378906  accuracy 0.47\n",
            "train loss 0.6929869651794434 accuracy 0.51 | test loss 0.6949804425239563  accuracy 0.47\n",
            "train loss 0.6929870247840881 accuracy 0.51 | test loss 0.6949802041053772  accuracy 0.47\n",
            "train loss 0.6929870247840881 accuracy 0.51 | test loss 0.6949799656867981  accuracy 0.47\n",
            "train loss 0.6929869651794434 accuracy 0.51 | test loss 0.6949796676635742  accuracy 0.47\n",
            "train loss 0.6929869651794434 accuracy 0.51 | test loss 0.6949795484542847  accuracy 0.47\n",
            "train loss 0.6929870247840881 accuracy 0.51 | test loss 0.6949793696403503  accuracy 0.47\n",
            "train loss 0.6929869651794434 accuracy 0.51 | test loss 0.6949790716171265  accuracy 0.47\n",
            "train loss 0.6929869055747986 accuracy 0.51 | test loss 0.6949788331985474  accuracy 0.47\n",
            "train loss 0.6929869055747986 accuracy 0.51 | test loss 0.6949787139892578  accuracy 0.47\n",
            "train loss 0.6929869055747986 accuracy 0.51 | test loss 0.6949784755706787  accuracy 0.47\n",
            "train loss 0.6929869055747986 accuracy 0.51 | test loss 0.6949781775474548  accuracy 0.47\n",
            "train loss 0.6929869055747986 accuracy 0.51 | test loss 0.6949779987335205  accuracy 0.47\n",
            "train loss 0.6929869055747986 accuracy 0.51 | test loss 0.6949777603149414  accuracy 0.47\n",
            "train loss 0.6929869055747986 accuracy 0.51 | test loss 0.6949775815010071  accuracy 0.47\n",
            "train loss 0.6929869055747986 accuracy 0.51 | test loss 0.6949772238731384  accuracy 0.47\n",
            "train loss 0.6929869055747986 accuracy 0.51 | test loss 0.6949771046638489  accuracy 0.47\n",
            "train loss 0.6929869055747986 accuracy 0.51 | test loss 0.6949769258499146  accuracy 0.47\n",
            "train loss 0.6929869055747986 accuracy 0.51 | test loss 0.6949766278266907  accuracy 0.47\n",
            "train loss 0.6929869055747986 accuracy 0.51 | test loss 0.6949763894081116  accuracy 0.47\n",
            "train loss 0.6929869055747986 accuracy 0.51 | test loss 0.6949761509895325  accuracy 0.47\n",
            "train loss 0.6929868459701538 accuracy 0.51 | test loss 0.6949760317802429  accuracy 0.47\n",
            "train loss 0.6929868459701538 accuracy 0.51 | test loss 0.6949757933616638  accuracy 0.47\n",
            "train loss 0.6929868459701538 accuracy 0.51 | test loss 0.6949755549430847  accuracy 0.47\n",
            "train loss 0.6929868459701538 accuracy 0.51 | test loss 0.6949754357337952  accuracy 0.47\n",
            "train loss 0.6929868459701538 accuracy 0.51 | test loss 0.6949751377105713  accuracy 0.47\n",
            "train loss 0.6929868459701538 accuracy 0.51 | test loss 0.6949748992919922  accuracy 0.47\n",
            "train loss 0.6929868459701538 accuracy 0.51 | test loss 0.6949746608734131  accuracy 0.47\n",
            "train loss 0.6929867267608643 accuracy 0.51 | test loss 0.6949744820594788  accuracy 0.47\n",
            "train loss 0.6929867267608643 accuracy 0.51 | test loss 0.6949742436408997  accuracy 0.47\n",
            "train loss 0.6929867267608643 accuracy 0.51 | test loss 0.6949740648269653  accuracy 0.47\n",
            "train loss 0.6929867267608643 accuracy 0.51 | test loss 0.6949738264083862  accuracy 0.47\n",
            "train loss 0.6929867267608643 accuracy 0.51 | test loss 0.6949735879898071  accuracy 0.47\n",
            "train loss 0.6929867267608643 accuracy 0.51 | test loss 0.6949734091758728  accuracy 0.47\n",
            "train loss 0.6929867267608643 accuracy 0.51 | test loss 0.6949732303619385  accuracy 0.47\n",
            "train loss 0.6929866671562195 accuracy 0.51 | test loss 0.6949729919433594  accuracy 0.47\n",
            "train loss 0.6929867267608643 accuracy 0.51 | test loss 0.6949727535247803  accuracy 0.47\n",
            "train loss 0.6929866671562195 accuracy 0.51 | test loss 0.6949725151062012  accuracy 0.47\n",
            "train loss 0.6929866671562195 accuracy 0.51 | test loss 0.6949723362922668  accuracy 0.47\n",
            "train loss 0.6929866075515747 accuracy 0.51 | test loss 0.694972038269043  accuracy 0.47\n",
            "train loss 0.6929866075515747 accuracy 0.51 | test loss 0.6949719190597534  accuracy 0.47\n",
            "train loss 0.6929866075515747 accuracy 0.51 | test loss 0.6949716806411743  accuracy 0.47\n",
            "train loss 0.6929866075515747 accuracy 0.51 | test loss 0.6949714422225952  accuracy 0.47\n",
            "train loss 0.6929866075515747 accuracy 0.51 | test loss 0.6949712038040161  accuracy 0.47\n",
            "train loss 0.6929866075515747 accuracy 0.51 | test loss 0.694970965385437  accuracy 0.47\n",
            "train loss 0.6929866075515747 accuracy 0.51 | test loss 0.6949707865715027  accuracy 0.47\n",
            "train loss 0.6929866075515747 accuracy 0.51 | test loss 0.6949706077575684  accuracy 0.47\n",
            "train loss 0.6929864883422852 accuracy 0.51 | test loss 0.6949703693389893  accuracy 0.47\n",
            "train loss 0.6929866075515747 accuracy 0.51 | test loss 0.6949701309204102  accuracy 0.47\n",
            "train loss 0.6929866075515747 accuracy 0.51 | test loss 0.6949699521064758  accuracy 0.47\n",
            "train loss 0.6929864883422852 accuracy 0.51 | test loss 0.6949697732925415  accuracy 0.47\n",
            "train loss 0.6929864883422852 accuracy 0.51 | test loss 0.6949694752693176  accuracy 0.47\n",
            "train loss 0.6929864883422852 accuracy 0.51 | test loss 0.6949692964553833  accuracy 0.47\n",
            "train loss 0.6929864883422852 accuracy 0.51 | test loss 0.6949691772460938  accuracy 0.47\n",
            "train loss 0.6929866075515747 accuracy 0.51 | test loss 0.6949688792228699  accuracy 0.47\n",
            "train loss 0.6929864287376404 accuracy 0.51 | test loss 0.6949686408042908  accuracy 0.47\n",
            "train loss 0.6929864287376404 accuracy 0.51 | test loss 0.6949684619903564  accuracy 0.47\n",
            "train loss 0.6929864287376404 accuracy 0.51 | test loss 0.6949682235717773  accuracy 0.47\n",
            "train loss 0.6929864883422852 accuracy 0.51 | test loss 0.6949679255485535  accuracy 0.47\n",
            "train loss 0.6929864287376404 accuracy 0.51 | test loss 0.6949678063392639  accuracy 0.47\n",
            "train loss 0.6929864287376404 accuracy 0.51 | test loss 0.6949676275253296  accuracy 0.47\n",
            "train loss 0.6929864287376404 accuracy 0.51 | test loss 0.6949673891067505  accuracy 0.47\n",
            "train loss 0.6929864287376404 accuracy 0.51 | test loss 0.6949671506881714  accuracy 0.47\n",
            "train loss 0.6929864287376404 accuracy 0.51 | test loss 0.6949669718742371  accuracy 0.47\n",
            "train loss 0.6929864287376404 accuracy 0.51 | test loss 0.694966733455658  accuracy 0.47\n",
            "train loss 0.6929864287376404 accuracy 0.51 | test loss 0.6949665546417236  accuracy 0.47\n",
            "train loss 0.6929864287376404 accuracy 0.51 | test loss 0.6949663162231445  accuracy 0.47\n",
            "train loss 0.6929864287376404 accuracy 0.51 | test loss 0.6949661374092102  accuracy 0.47\n",
            "train loss 0.6929863691329956 accuracy 0.51 | test loss 0.6949658989906311  accuracy 0.47\n",
            "train loss 0.6929864287376404 accuracy 0.51 | test loss 0.694965660572052  accuracy 0.47\n",
            "train loss 0.6929863691329956 accuracy 0.51 | test loss 0.6949654817581177  accuracy 0.47\n",
            "train loss 0.6929863691329956 accuracy 0.51 | test loss 0.6949652433395386  accuracy 0.47\n",
            "train loss 0.6929863095283508 accuracy 0.51 | test loss 0.6949650645256042  accuracy 0.47\n",
            "train loss 0.6929863095283508 accuracy 0.51 | test loss 0.6949648261070251  accuracy 0.47\n",
            "train loss 0.6929863095283508 accuracy 0.51 | test loss 0.6949646472930908  accuracy 0.47\n",
            "train loss 0.6929863691329956 accuracy 0.51 | test loss 0.6949644088745117  accuracy 0.47\n",
            "train loss 0.6929863095283508 accuracy 0.51 | test loss 0.6949642300605774  accuracy 0.47\n",
            "train loss 0.6929863095283508 accuracy 0.51 | test loss 0.6949639916419983  accuracy 0.47\n",
            "train loss 0.6929863095283508 accuracy 0.51 | test loss 0.6949637532234192  accuracy 0.47\n",
            "train loss 0.6929863095283508 accuracy 0.51 | test loss 0.6949635148048401  accuracy 0.47\n",
            "train loss 0.6929863095283508 accuracy 0.51 | test loss 0.6949633359909058  accuracy 0.47\n",
            "train loss 0.6929863095283508 accuracy 0.51 | test loss 0.6949631571769714  accuracy 0.47\n",
            "train loss 0.6929863095283508 accuracy 0.51 | test loss 0.6949629187583923  accuracy 0.47\n",
            "train loss 0.6929863095283508 accuracy 0.51 | test loss 0.694962739944458  accuracy 0.47\n",
            "train loss 0.6929861903190613 accuracy 0.51 | test loss 0.6949624419212341  accuracy 0.47\n",
            "train loss 0.6929861903190613 accuracy 0.51 | test loss 0.6949623227119446  accuracy 0.47\n",
            "train loss 0.6929863095283508 accuracy 0.51 | test loss 0.6949621438980103  accuracy 0.47\n",
            "train loss 0.6929861903190613 accuracy 0.51 | test loss 0.6949619054794312  accuracy 0.47\n",
            "train loss 0.6929861307144165 accuracy 0.51 | test loss 0.694961667060852  accuracy 0.47\n",
            "train loss 0.6929861307144165 accuracy 0.51 | test loss 0.694961428642273  accuracy 0.47\n",
            "train loss 0.6929861903190613 accuracy 0.51 | test loss 0.6949612498283386  accuracy 0.47\n",
            "train loss 0.6929861307144165 accuracy 0.51 | test loss 0.6949610710144043  accuracy 0.47\n",
            "train loss 0.6929861307144165 accuracy 0.51 | test loss 0.69496089220047  accuracy 0.47\n",
            "train loss 0.6929861307144165 accuracy 0.51 | test loss 0.6949607133865356  accuracy 0.47\n",
            "train loss 0.6929861307144165 accuracy 0.51 | test loss 0.6949604749679565  accuracy 0.47\n",
            "train loss 0.6929861307144165 accuracy 0.51 | test loss 0.6949602365493774  accuracy 0.47\n",
            "train loss 0.6929861307144165 accuracy 0.51 | test loss 0.6949599981307983  accuracy 0.47\n",
            "train loss 0.6929860711097717 accuracy 0.51 | test loss 0.6949597597122192  accuracy 0.47\n",
            "train loss 0.6929860711097717 accuracy 0.51 | test loss 0.6949596405029297  accuracy 0.47\n",
            "train loss 0.6929861307144165 accuracy 0.51 | test loss 0.6949594020843506  accuracy 0.47\n",
            "train loss 0.6929861307144165 accuracy 0.51 | test loss 0.6949592232704163  accuracy 0.47\n",
            "train loss 0.6929859519004822 accuracy 0.51 | test loss 0.6949589848518372  accuracy 0.47\n",
            "train loss 0.6929860711097717 accuracy 0.51 | test loss 0.6949588060379028  accuracy 0.47\n",
            "train loss 0.6929859519004822 accuracy 0.51 | test loss 0.6949586272239685  accuracy 0.47\n",
            "train loss 0.6929859519004822 accuracy 0.51 | test loss 0.6949583888053894  accuracy 0.47\n",
            "train loss 0.6929860711097717 accuracy 0.51 | test loss 0.6949581503868103  accuracy 0.47\n",
            "train loss 0.6929859519004822 accuracy 0.51 | test loss 0.6949580311775208  accuracy 0.47\n",
            "train loss 0.6929859519004822 accuracy 0.51 | test loss 0.6949577331542969  accuracy 0.47\n",
            "train loss 0.6929860711097717 accuracy 0.51 | test loss 0.6949575543403625  accuracy 0.47\n",
            "train loss 0.6929859519004822 accuracy 0.51 | test loss 0.6949573159217834  accuracy 0.47\n",
            "train loss 0.6929859519004822 accuracy 0.51 | test loss 0.6949570775032043  accuracy 0.47\n",
            "train loss 0.6929859519004822 accuracy 0.51 | test loss 0.6949569582939148  accuracy 0.47\n",
            "train loss 0.6929859519004822 accuracy 0.51 | test loss 0.6949567198753357  accuracy 0.47\n",
            "train loss 0.6929859519004822 accuracy 0.51 | test loss 0.6949564814567566  accuracy 0.47\n",
            "train loss 0.6929859519004822 accuracy 0.51 | test loss 0.694956362247467  accuracy 0.47\n",
            "train loss 0.6929859519004822 accuracy 0.51 | test loss 0.6949561834335327  accuracy 0.47\n",
            "train loss 0.6929858326911926 accuracy 0.51 | test loss 0.6949559450149536  accuracy 0.47\n",
            "train loss 0.6929859519004822 accuracy 0.51 | test loss 0.6949557065963745  accuracy 0.47\n",
            "train loss 0.6929859519004822 accuracy 0.51 | test loss 0.6949555277824402  accuracy 0.47\n",
            "train loss 0.6929859519004822 accuracy 0.51 | test loss 0.6949552893638611  accuracy 0.47\n",
            "train loss 0.6929858922958374 accuracy 0.51 | test loss 0.6949551105499268  accuracy 0.47\n",
            "train loss 0.6929858922958374 accuracy 0.51 | test loss 0.6949549913406372  accuracy 0.47\n",
            "train loss 0.6929858922958374 accuracy 0.51 | test loss 0.6949546933174133  accuracy 0.47\n",
            "train loss 0.6929858326911926 accuracy 0.51 | test loss 0.694954514503479  accuracy 0.47\n",
            "train loss 0.6929858326911926 accuracy 0.51 | test loss 0.6949542760848999  accuracy 0.47\n",
            "train loss 0.6929858326911926 accuracy 0.51 | test loss 0.6949540376663208  accuracy 0.47\n",
            "train loss 0.6929858326911926 accuracy 0.51 | test loss 0.6949539184570312  accuracy 0.47\n",
            "train loss 0.6929858326911926 accuracy 0.51 | test loss 0.6949536800384521  accuracy 0.47\n",
            "train loss 0.6929858326911926 accuracy 0.51 | test loss 0.6949535012245178  accuracy 0.47\n",
            "train loss 0.6929858326911926 accuracy 0.51 | test loss 0.6949532628059387  accuracy 0.47\n",
            "train loss 0.6929858326911926 accuracy 0.51 | test loss 0.6949531435966492  accuracy 0.47\n",
            "train loss 0.6929858326911926 accuracy 0.51 | test loss 0.6949528455734253  accuracy 0.47\n",
            "train loss 0.6929858326911926 accuracy 0.51 | test loss 0.694952666759491  accuracy 0.47\n",
            "train loss 0.6929858326911926 accuracy 0.51 | test loss 0.6949524283409119  accuracy 0.47\n",
            "train loss 0.6929857730865479 accuracy 0.51 | test loss 0.6949522495269775  accuracy 0.47\n",
            "train loss 0.6929858326911926 accuracy 0.51 | test loss 0.6949520707130432  accuracy 0.47\n",
            "train loss 0.6929858326911926 accuracy 0.51 | test loss 0.6949518918991089  accuracy 0.47\n",
            "train loss 0.6929858326911926 accuracy 0.51 | test loss 0.6949517130851746  accuracy 0.47\n",
            "train loss 0.6929857730865479 accuracy 0.51 | test loss 0.6949514746665955  accuracy 0.47\n",
            "train loss 0.6929856538772583 accuracy 0.51 | test loss 0.6949512958526611  accuracy 0.47\n",
            "train loss 0.6929857730865479 accuracy 0.51 | test loss 0.6949509978294373  accuracy 0.47\n",
            "train loss 0.6929856538772583 accuracy 0.51 | test loss 0.6949508786201477  accuracy 0.47\n",
            "train loss 0.6929856538772583 accuracy 0.51 | test loss 0.6949506998062134  accuracy 0.47\n",
            "train loss 0.6929856538772583 accuracy 0.51 | test loss 0.6949504613876343  accuracy 0.47\n",
            "train loss 0.6929857730865479 accuracy 0.51 | test loss 0.6949503421783447  accuracy 0.47\n",
            "train loss 0.6929856538772583 accuracy 0.51 | test loss 0.6949501037597656  accuracy 0.47\n",
            "train loss 0.6929856538772583 accuracy 0.51 | test loss 0.6949498653411865  accuracy 0.47\n",
            "train loss 0.6929856538772583 accuracy 0.51 | test loss 0.6949496269226074  accuracy 0.47\n",
            "train loss 0.6929856538772583 accuracy 0.51 | test loss 0.6949494481086731  accuracy 0.47\n",
            "train loss 0.6929856538772583 accuracy 0.51 | test loss 0.6949492692947388  accuracy 0.47\n",
            "train loss 0.6929856538772583 accuracy 0.51 | test loss 0.6949490308761597  accuracy 0.47\n",
            "train loss 0.6929856538772583 accuracy 0.51 | test loss 0.6949488520622253  accuracy 0.47\n",
            "train loss 0.6929855942726135 accuracy 0.51 | test loss 0.6949487328529358  accuracy 0.47\n",
            "train loss 0.6929856538772583 accuracy 0.51 | test loss 0.6949484944343567  accuracy 0.47\n",
            "train loss 0.6929856538772583 accuracy 0.51 | test loss 0.6949482560157776  accuracy 0.47\n",
            "train loss 0.6929856538772583 accuracy 0.51 | test loss 0.6949480175971985  accuracy 0.47\n",
            "train loss 0.6929855942726135 accuracy 0.51 | test loss 0.6949479579925537  accuracy 0.47\n",
            "train loss 0.6929855942726135 accuracy 0.51 | test loss 0.6949477195739746  accuracy 0.47\n",
            "train loss 0.6929855942726135 accuracy 0.51 | test loss 0.6949474811553955  accuracy 0.47\n",
            "train loss 0.6929855346679688 accuracy 0.51 | test loss 0.6949472427368164  accuracy 0.47\n",
            "train loss 0.6929855346679688 accuracy 0.51 | test loss 0.6949471235275269  accuracy 0.47\n",
            "train loss 0.6929855346679688 accuracy 0.51 | test loss 0.6949468851089478  accuracy 0.47\n",
            "train loss 0.6929855346679688 accuracy 0.51 | test loss 0.6949467062950134  accuracy 0.46\n",
            "train loss 0.6929855346679688 accuracy 0.51 | test loss 0.6949465274810791  accuracy 0.46\n",
            "train loss 0.6929855346679688 accuracy 0.51 | test loss 0.6949462890625  accuracy 0.46\n",
            "train loss 0.6929855346679688 accuracy 0.51 | test loss 0.6949461102485657  accuracy 0.46\n",
            "train loss 0.6929855346679688 accuracy 0.51 | test loss 0.6949458718299866  accuracy 0.46\n",
            "train loss 0.6929855346679688 accuracy 0.51 | test loss 0.694945752620697  accuracy 0.46\n",
            "train loss 0.6929855346679688 accuracy 0.51 | test loss 0.6949455142021179  accuracy 0.46\n",
            "train loss 0.6929855346679688 accuracy 0.51 | test loss 0.6949453353881836  accuracy 0.46\n",
            "train loss 0.6929855346679688 accuracy 0.51 | test loss 0.6949451565742493  accuracy 0.46\n",
            "train loss 0.6929854154586792 accuracy 0.51 | test loss 0.6949449181556702  accuracy 0.46\n",
            "train loss 0.6929854154586792 accuracy 0.51 | test loss 0.6949447393417358  accuracy 0.46\n",
            "train loss 0.6929854154586792 accuracy 0.51 | test loss 0.6949445009231567  accuracy 0.46\n",
            "train loss 0.6929854154586792 accuracy 0.51 | test loss 0.6949442625045776  accuracy 0.46\n",
            "train loss 0.6929853558540344 accuracy 0.51 | test loss 0.6949441432952881  accuracy 0.46\n",
            "train loss 0.6929853558540344 accuracy 0.51 | test loss 0.6949439644813538  accuracy 0.46\n",
            "train loss 0.6929853558540344 accuracy 0.51 | test loss 0.6949438452720642  accuracy 0.46\n",
            "train loss 0.6929853558540344 accuracy 0.51 | test loss 0.6949435472488403  accuracy 0.46\n",
            "train loss 0.6929853558540344 accuracy 0.51 | test loss 0.694943368434906  accuracy 0.46\n",
            "train loss 0.6929853558540344 accuracy 0.51 | test loss 0.6949432492256165  accuracy 0.46\n",
            "train loss 0.6929853558540344 accuracy 0.51 | test loss 0.6949430108070374  accuracy 0.46\n",
            "train loss 0.6929853558540344 accuracy 0.51 | test loss 0.6949427723884583  accuracy 0.46\n",
            "train loss 0.6929853558540344 accuracy 0.51 | test loss 0.6949425935745239  accuracy 0.46\n",
            "train loss 0.6929853558540344 accuracy 0.51 | test loss 0.6949424743652344  accuracy 0.46\n",
            "train loss 0.6929853558540344 accuracy 0.51 | test loss 0.6949422359466553  accuracy 0.46\n",
            "train loss 0.6929853558540344 accuracy 0.51 | test loss 0.6949419975280762  accuracy 0.46\n",
            "train loss 0.6929853558540344 accuracy 0.51 | test loss 0.6949418187141418  accuracy 0.46\n",
            "train loss 0.6929853558540344 accuracy 0.51 | test loss 0.6949416399002075  accuracy 0.46\n",
            "train loss 0.6929853558540344 accuracy 0.51 | test loss 0.6949414014816284  accuracy 0.46\n",
            "train loss 0.6929853558540344 accuracy 0.51 | test loss 0.6949412226676941  accuracy 0.46\n",
            "train loss 0.6929853558540344 accuracy 0.51 | test loss 0.694940984249115  accuracy 0.46\n",
            "train loss 0.6929852962493896 accuracy 0.51 | test loss 0.6949408650398254  accuracy 0.46\n",
            "train loss 0.6929852962493896 accuracy 0.51 | test loss 0.6949406266212463  accuracy 0.46\n",
            "train loss 0.6929852366447449 accuracy 0.51 | test loss 0.694940447807312  accuracy 0.46\n",
            "train loss 0.6929852962493896 accuracy 0.51 | test loss 0.6949402689933777  accuracy 0.46\n",
            "train loss 0.6929852366447449 accuracy 0.51 | test loss 0.6949400305747986  accuracy 0.46\n",
            "train loss 0.6929852962493896 accuracy 0.51 | test loss 0.6949398517608643  accuracy 0.46\n",
            "train loss 0.6929852962493896 accuracy 0.51 | test loss 0.6949397325515747  accuracy 0.46\n",
            "train loss 0.6929852366447449 accuracy 0.51 | test loss 0.6949394941329956  accuracy 0.46\n",
            "train loss 0.6929852366447449 accuracy 0.51 | test loss 0.6949393153190613  accuracy 0.46\n",
            "train loss 0.6929852366447449 accuracy 0.51 | test loss 0.6949390769004822  accuracy 0.46\n",
            "train loss 0.6929852366447449 accuracy 0.51 | test loss 0.6949389576911926  accuracy 0.46\n",
            "train loss 0.6929852366447449 accuracy 0.51 | test loss 0.6949387192726135  accuracy 0.46\n",
            "train loss 0.6929852366447449 accuracy 0.51 | test loss 0.6949385404586792  accuracy 0.46\n",
            "train loss 0.6929852366447449 accuracy 0.51 | test loss 0.6949383616447449  accuracy 0.46\n",
            "train loss 0.6929852366447449 accuracy 0.51 | test loss 0.6949381828308105  accuracy 0.46\n",
            "train loss 0.6929852366447449 accuracy 0.51 | test loss 0.6949379444122314  accuracy 0.46\n",
            "train loss 0.6929852366447449 accuracy 0.51 | test loss 0.6949378252029419  accuracy 0.46\n",
            "train loss 0.6929852366447449 accuracy 0.51 | test loss 0.6949375867843628  accuracy 0.46\n",
            "train loss 0.6929851174354553 accuracy 0.51 | test loss 0.6949374079704285  accuracy 0.46\n",
            "train loss 0.6929851174354553 accuracy 0.51 | test loss 0.6949372887611389  accuracy 0.46\n",
            "train loss 0.6929851174354553 accuracy 0.51 | test loss 0.6949370503425598  accuracy 0.46\n",
            "train loss 0.6929851174354553 accuracy 0.51 | test loss 0.6949368119239807  accuracy 0.46\n",
            "train loss 0.6929852366447449 accuracy 0.51 | test loss 0.6949366331100464  accuracy 0.46\n",
            "train loss 0.6929850578308105 accuracy 0.51 | test loss 0.6949364542961121  accuracy 0.46\n",
            "train loss 0.6929851174354553 accuracy 0.51 | test loss 0.6949362754821777  accuracy 0.46\n",
            "train loss 0.6929851174354553 accuracy 0.51 | test loss 0.6949360370635986  accuracy 0.46\n",
            "train loss 0.6929850578308105 accuracy 0.51 | test loss 0.6949359178543091  accuracy 0.46\n",
            "train loss 0.6929850578308105 accuracy 0.51 | test loss 0.69493567943573  accuracy 0.46\n",
            "train loss 0.6929850578308105 accuracy 0.51 | test loss 0.6949355006217957  accuracy 0.46\n",
            "train loss 0.6929850578308105 accuracy 0.51 | test loss 0.6949352622032166  accuracy 0.46\n",
            "train loss 0.6929850578308105 accuracy 0.51 | test loss 0.694935142993927  accuracy 0.46\n",
            "train loss 0.6929850578308105 accuracy 0.51 | test loss 0.6949349641799927  accuracy 0.46\n",
            "train loss 0.6929850578308105 accuracy 0.51 | test loss 0.6949347257614136  accuracy 0.46\n",
            "train loss 0.6929850578308105 accuracy 0.51 | test loss 0.6949345469474792  accuracy 0.46\n",
            "train loss 0.6929850578308105 accuracy 0.51 | test loss 0.6949343681335449  accuracy 0.46\n",
            "train loss 0.6929850578308105 accuracy 0.51 | test loss 0.6949341893196106  accuracy 0.46\n",
            "train loss 0.6929850578308105 accuracy 0.51 | test loss 0.6949340105056763  accuracy 0.46\n",
            "train loss 0.6929850578308105 accuracy 0.51 | test loss 0.6949338316917419  accuracy 0.46\n",
            "train loss 0.6929850578308105 accuracy 0.51 | test loss 0.6949335932731628  accuracy 0.46\n",
            "train loss 0.6929850578308105 accuracy 0.51 | test loss 0.6949334740638733  accuracy 0.46\n",
            "train loss 0.6929849982261658 accuracy 0.51 | test loss 0.694933295249939  accuracy 0.46\n",
            "train loss 0.6929849982261658 accuracy 0.51 | test loss 0.6949330568313599  accuracy 0.46\n",
            "train loss 0.6929849982261658 accuracy 0.51 | test loss 0.6949328184127808  accuracy 0.46\n",
            "train loss 0.6929849982261658 accuracy 0.51 | test loss 0.6949326992034912  accuracy 0.46\n",
            "train loss 0.6929849982261658 accuracy 0.51 | test loss 0.6949324607849121  accuracy 0.46\n",
            "train loss 0.692984938621521 accuracy 0.51 | test loss 0.6949324011802673  accuracy 0.46\n",
            "train loss 0.692984938621521 accuracy 0.51 | test loss 0.6949321031570435  accuracy 0.46\n",
            "train loss 0.6929849982261658 accuracy 0.51 | test loss 0.6949319243431091  accuracy 0.46\n",
            "train loss 0.692984938621521 accuracy 0.51 | test loss 0.6949318051338196  accuracy 0.46\n",
            "train loss 0.692984938621521 accuracy 0.51 | test loss 0.6949315667152405  accuracy 0.46\n",
            "train loss 0.692984938621521 accuracy 0.51 | test loss 0.6949313879013062  accuracy 0.46\n",
            "train loss 0.692984938621521 accuracy 0.51 | test loss 0.694931149482727  accuracy 0.46\n",
            "train loss 0.692984938621521 accuracy 0.51 | test loss 0.6949310302734375  accuracy 0.46\n",
            "train loss 0.692984938621521 accuracy 0.51 | test loss 0.6949308514595032  accuracy 0.46\n",
            "train loss 0.6929848194122314 accuracy 0.51 | test loss 0.6949306130409241  accuracy 0.46\n",
            "train loss 0.692984938621521 accuracy 0.51 | test loss 0.694930374622345  accuracy 0.46\n",
            "train loss 0.6929848194122314 accuracy 0.51 | test loss 0.6949302554130554  accuracy 0.46\n",
            "train loss 0.6929848194122314 accuracy 0.51 | test loss 0.6949300765991211  accuracy 0.46\n",
            "train loss 0.692984938621521 accuracy 0.51 | test loss 0.6949299573898315  accuracy 0.46\n",
            "train loss 0.692984938621521 accuracy 0.51 | test loss 0.6949297189712524  accuracy 0.46\n",
            "train loss 0.6929848194122314 accuracy 0.51 | test loss 0.6949294805526733  accuracy 0.46\n",
            "train loss 0.6929848194122314 accuracy 0.51 | test loss 0.6949293613433838  accuracy 0.46\n",
            "train loss 0.6929848194122314 accuracy 0.51 | test loss 0.6949291825294495  accuracy 0.46\n",
            "train loss 0.6929848194122314 accuracy 0.51 | test loss 0.6949290037155151  accuracy 0.46\n",
            "train loss 0.6929847598075867 accuracy 0.51 | test loss 0.6949288249015808  accuracy 0.46\n",
            "train loss 0.6929848194122314 accuracy 0.51 | test loss 0.6949286460876465  accuracy 0.46\n",
            "train loss 0.6929847598075867 accuracy 0.51 | test loss 0.6949284672737122  accuracy 0.46\n",
            "train loss 0.6929847598075867 accuracy 0.51 | test loss 0.6949282884597778  accuracy 0.46\n",
            "train loss 0.6929848194122314 accuracy 0.51 | test loss 0.6949281096458435  accuracy 0.46\n",
            "train loss 0.6929847598075867 accuracy 0.51 | test loss 0.694927990436554  accuracy 0.46\n",
            "train loss 0.6929848194122314 accuracy 0.51 | test loss 0.6949277520179749  accuracy 0.46\n",
            "train loss 0.6929847598075867 accuracy 0.51 | test loss 0.6949275135993958  accuracy 0.46\n",
            "train loss 0.6929847598075867 accuracy 0.51 | test loss 0.6949273347854614  accuracy 0.46\n",
            "train loss 0.6929847598075867 accuracy 0.51 | test loss 0.6949272155761719  accuracy 0.46\n",
            "train loss 0.6929847598075867 accuracy 0.51 | test loss 0.6949269771575928  accuracy 0.46\n",
            "train loss 0.6929847598075867 accuracy 0.51 | test loss 0.6949267983436584  accuracy 0.46\n",
            "train loss 0.6929847598075867 accuracy 0.51 | test loss 0.6949265599250793  accuracy 0.46\n",
            "train loss 0.6929847598075867 accuracy 0.51 | test loss 0.6949264407157898  accuracy 0.46\n",
            "train loss 0.6929847598075867 accuracy 0.51 | test loss 0.6949262619018555  accuracy 0.46\n",
            "train loss 0.6929847598075867 accuracy 0.51 | test loss 0.6949261426925659  accuracy 0.46\n",
            "train loss 0.6929847002029419 accuracy 0.51 | test loss 0.6949259042739868  accuracy 0.46\n",
            "train loss 0.6929847598075867 accuracy 0.51 | test loss 0.6949256658554077  accuracy 0.46\n",
            "train loss 0.6929847002029419 accuracy 0.51 | test loss 0.6949255466461182  accuracy 0.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# download helper functions for visualization"
      ],
      "metadata": {
        "id": "CJa6LkWNd8xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "FZDo5tFEd_3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download helper function for visualization\n",
        "if Path('helper_function.py').is_file():\n",
        "  print('helper function alreday exists')\n",
        "else:\n",
        "  print('downloading helper_function.py')\n",
        "  request = requests.get('https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py')\n",
        "  with open('helper_function.py','wb') as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMiqSad5ex7C",
        "outputId": "c9d9d337-ed1f-4706-a61b-97b0bcbcc299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading helper_function.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_function  import plot_decision_boundary"
      ],
      "metadata": {
        "id": "JRC5XhZHfE_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_decision_boundary(model_0, X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "SkBg5nt5fv6_",
        "outputId": "d9eba266-1bc4-45b1-df3d-f23cebbc12e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CircleModelV1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_1 = nn.Linear(in_features = 2, out_features= 10) #5 neurons\n",
        "    self.layer_2 = nn.Linear(in_features = 10, out_features=1) # 1 neuron\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self,x: torch.Tensor) -> torch.Tensor:\n",
        "    z0 = self.layer_1(x)\n",
        "    a0 = self.relu(z0)\n",
        "    z1 =  self.layer_2(a0)\n",
        "    a1 = self.relu(z1)\n",
        "    return a1\n",
        "\n"
      ],
      "metadata": {
        "id": "3kLR6mFVgFXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = CircleModelV1().to(device)\n",
        "train_model(model_1, 100000, 0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPzT-AEqgwoU",
        "outputId": "ca28ee10-a404-4c98-ca2d-b63ff13e050f"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "train loss 0.3585343062877655 accuracy 0.98 | test loss 0.37973693013191223  accuracy 0.92\n",
            "train loss 0.3585328161716461 accuracy 0.98 | test loss 0.3797302842140198  accuracy 0.92\n",
            "train loss 0.35853293538093567 accuracy 0.98 | test loss 0.37976211309432983  accuracy 0.92\n",
            "train loss 0.35853302478790283 accuracy 0.98 | test loss 0.3797312080860138  accuracy 0.92\n",
            "train loss 0.35853251814842224 accuracy 0.98 | test loss 0.3797246515750885  accuracy 0.92\n",
            "train loss 0.3585323989391327 accuracy 0.98 | test loss 0.37976524233818054  accuracy 0.92\n",
            "train loss 0.3585326373577118 accuracy 0.98 | test loss 0.37973424792289734  accuracy 0.92\n",
            "train loss 0.3585318326950073 accuracy 0.98 | test loss 0.37972769141197205  accuracy 0.92\n",
            "train loss 0.3585317134857178 accuracy 0.98 | test loss 0.3797682225704193  accuracy 0.92\n",
            "train loss 0.35853222012519836 accuracy 0.98 | test loss 0.3797371983528137  accuracy 0.92\n",
            "train loss 0.35853126645088196 accuracy 0.98 | test loss 0.37970656156539917  accuracy 0.92\n",
            "train loss 0.35853222012519836 accuracy 0.99 | test loss 0.3797891438007355  accuracy 0.92\n",
            "train loss 0.3585323989391327 accuracy 0.98 | test loss 0.37973707914352417  accuracy 0.92\n",
            "train loss 0.358530730009079 accuracy 0.98 | test loss 0.37970641255378723  accuracy 0.92\n",
            "train loss 0.35853156447410583 accuracy 0.99 | test loss 0.3797890245914459  accuracy 0.92\n",
            "train loss 0.3585318326950073 accuracy 0.98 | test loss 0.3797369599342346  accuracy 0.92\n",
            "train loss 0.3585302531719208 accuracy 0.98 | test loss 0.37973037362098694  accuracy 0.92\n",
            "train loss 0.35853010416030884 accuracy 0.98 | test loss 0.37976211309432983  accuracy 0.92\n",
            "train loss 0.3585304915904999 accuracy 0.98 | test loss 0.37973105907440186  accuracy 0.92\n",
            "train loss 0.3585299551486969 accuracy 0.98 | test loss 0.3797244429588318  accuracy 0.92\n",
            "train loss 0.35852956771850586 accuracy 0.98 | test loss 0.37976500391960144  accuracy 0.92\n",
            "train loss 0.35853007435798645 accuracy 0.98 | test loss 0.37973394989967346  accuracy 0.92\n",
            "train loss 0.358529269695282 accuracy 0.98 | test loss 0.379727303981781  accuracy 0.92\n",
            "train loss 0.3585289418697357 accuracy 0.98 | test loss 0.37976789474487305  accuracy 0.92\n",
            "train loss 0.358529657125473 accuracy 0.98 | test loss 0.37971749901771545  accuracy 0.92\n",
            "train loss 0.3585287034511566 accuracy 0.98 | test loss 0.3797109127044678  accuracy 0.92\n",
            "train loss 0.358528733253479 accuracy 0.99 | test loss 0.3797667622566223  accuracy 0.92\n",
            "train loss 0.358529269695282 accuracy 0.98 | test loss 0.3797356188297272  accuracy 0.92\n",
            "train loss 0.3585282862186432 accuracy 0.98 | test loss 0.37970489263534546  accuracy 0.92\n",
            "train loss 0.35852840542793274 accuracy 0.98 | test loss 0.37975236773490906  accuracy 0.92\n",
            "train loss 0.3585284352302551 accuracy 0.98 | test loss 0.37972140312194824  accuracy 0.92\n",
            "train loss 0.3585275709629059 accuracy 0.98 | test loss 0.37971481680870056  accuracy 0.92\n",
            "train loss 0.35852760076522827 accuracy 0.98 | test loss 0.37974655628204346  accuracy 0.92\n",
            "train loss 0.3585277497768402 accuracy 0.98 | test loss 0.3797156810760498  accuracy 0.92\n",
            "train loss 0.3585272431373596 accuracy 0.98 | test loss 0.37970900535583496  accuracy 0.92\n",
            "train loss 0.3585270643234253 accuracy 0.99 | test loss 0.3797764480113983  accuracy 0.92\n",
            "train loss 0.3585280478000641 accuracy 0.98 | test loss 0.3797244131565094  accuracy 0.92\n",
            "train loss 0.35852667689323425 accuracy 0.98 | test loss 0.3797089159488678  accuracy 0.92\n",
            "train loss 0.35852643847465515 accuracy 0.98 | test loss 0.37974944710731506  accuracy 0.92\n",
            "train loss 0.3585268259048462 accuracy 0.98 | test loss 0.3797184228897095  accuracy 0.92\n",
            "train loss 0.3585261106491089 accuracy 0.98 | test loss 0.3797118365764618  accuracy 0.92\n",
            "train loss 0.3585258424282074 accuracy 0.99 | test loss 0.37976759672164917  accuracy 0.92\n",
            "train loss 0.3585267663002014 accuracy 0.98 | test loss 0.37973636388778687  accuracy 0.92\n",
            "train loss 0.35852572321891785 accuracy 0.98 | test loss 0.3797054886817932  accuracy 0.92\n",
            "train loss 0.35852569341659546 accuracy 0.98 | test loss 0.37975284457206726  accuracy 0.92\n",
            "train loss 0.3585258722305298 accuracy 0.98 | test loss 0.37972182035446167  accuracy 0.92\n",
            "train loss 0.35852500796318054 accuracy 0.98 | test loss 0.3797151446342468  accuracy 0.92\n",
            "train loss 0.35852473974227905 accuracy 0.98 | test loss 0.3797195255756378  accuracy 0.92\n",
            "train loss 0.35852473974227905 accuracy 0.98 | test loss 0.3797127306461334  accuracy 0.92\n",
            "train loss 0.35852450132369995 accuracy 0.98 | test loss 0.3797600567340851  accuracy 0.92\n",
            "train loss 0.3585251569747925 accuracy 0.98 | test loss 0.37972888350486755  accuracy 0.92\n",
            "train loss 0.3585242033004761 accuracy 0.98 | test loss 0.3796980082988739  accuracy 0.92\n",
            "train loss 0.3585246205329895 accuracy 0.99 | test loss 0.3797806203365326  accuracy 0.92\n",
            "train loss 0.35852545499801636 accuracy 0.98 | test loss 0.3797283470630646  accuracy 0.92\n",
            "train loss 0.3585236966609955 accuracy 0.98 | test loss 0.3796974718570709  accuracy 0.92\n",
            "train loss 0.35852399468421936 accuracy 0.99 | test loss 0.37978002429008484  accuracy 0.92\n",
            "train loss 0.3585248589515686 accuracy 0.98 | test loss 0.3797277808189392  accuracy 0.92\n",
            "train loss 0.3585231602191925 accuracy 0.98 | test loss 0.37969687581062317  accuracy 0.92\n",
            "train loss 0.3585233986377716 accuracy 0.99 | test loss 0.3797527253627777  accuracy 0.92\n",
            "train loss 0.358523428440094 accuracy 0.98 | test loss 0.3797215521335602  accuracy 0.92\n",
            "train loss 0.3585227131843567 accuracy 0.98 | test loss 0.37971463799476624  accuracy 0.92\n",
            "train loss 0.3585222661495209 accuracy 0.98 | test loss 0.3797278106212616  accuracy 0.92\n",
            "train loss 0.3585222661495209 accuracy 0.98 | test loss 0.3796968460083008  accuracy 0.92\n",
            "train loss 0.3585226833820343 accuracy 0.99 | test loss 0.3797641694545746  accuracy 0.92\n",
            "train loss 0.3585229516029358 accuracy 0.98 | test loss 0.37973272800445557  accuracy 0.92\n",
            "train loss 0.3585219383239746 accuracy 0.98 | test loss 0.3797016739845276  accuracy 0.92\n",
            "train loss 0.35852158069610596 accuracy 0.98 | test loss 0.37974226474761963  accuracy 0.92\n",
            "train loss 0.35852187871932983 accuracy 0.98 | test loss 0.37971121072769165  accuracy 0.92\n",
            "train loss 0.3585211932659149 accuracy 0.98 | test loss 0.37970441579818726  accuracy 0.92\n",
            "train loss 0.3585209548473358 accuracy 0.99 | test loss 0.37976011633872986  accuracy 0.92\n",
            "train loss 0.35852178931236267 accuracy 0.98 | test loss 0.3797287940979004  accuracy 0.92\n",
            "train loss 0.3585208058357239 accuracy 0.98 | test loss 0.3796977996826172  accuracy 0.92\n",
            "train loss 0.3585206866264343 accuracy 0.98 | test loss 0.37974509596824646  accuracy 0.92\n",
            "train loss 0.3585209250450134 accuracy 0.98 | test loss 0.3797139525413513  accuracy 0.92\n",
            "train loss 0.3585200309753418 accuracy 0.98 | test loss 0.37970712780952454  accuracy 0.92\n",
            "train loss 0.35851988196372986 accuracy 0.98 | test loss 0.3797387480735779  accuracy 0.92\n",
            "train loss 0.35852017998695374 accuracy 0.98 | test loss 0.3797076642513275  accuracy 0.92\n",
            "train loss 0.3585197329521179 accuracy 0.98 | test loss 0.37970077991485596  accuracy 0.92\n",
            "train loss 0.35851943492889404 accuracy 0.98 | test loss 0.3797413110733032  accuracy 0.92\n",
            "train loss 0.3585197627544403 accuracy 0.98 | test loss 0.3797101378440857  accuracy 0.92\n",
            "train loss 0.358519047498703 accuracy 0.98 | test loss 0.37970319390296936  accuracy 0.92\n",
            "train loss 0.3585187494754791 accuracy 0.98 | test loss 0.3797437846660614  accuracy 0.92\n",
            "train loss 0.3585193455219269 accuracy 0.98 | test loss 0.3797125220298767  accuracy 0.92\n",
            "train loss 0.3585183620452881 accuracy 0.98 | test loss 0.37968170642852783  accuracy 0.92\n",
            "train loss 0.3585193455219269 accuracy 0.99 | test loss 0.37976422905921936  accuracy 0.92\n",
            "train loss 0.35851970314979553 accuracy 0.98 | test loss 0.37971195578575134  accuracy 0.92\n",
            "train loss 0.35851791501045227 accuracy 0.98 | test loss 0.3797050416469574  accuracy 0.92\n",
            "train loss 0.35851776599884033 accuracy 0.98 | test loss 0.37973663210868835  accuracy 0.92\n",
            "train loss 0.358518123626709 accuracy 0.98 | test loss 0.37970542907714844  accuracy 0.92\n",
            "train loss 0.3585176467895508 accuracy 0.98 | test loss 0.3796985149383545  accuracy 0.92\n",
            "train loss 0.35851728916168213 accuracy 0.98 | test loss 0.3797457814216614  accuracy 0.92\n",
            "train loss 0.35851791501045227 accuracy 0.98 | test loss 0.3797144889831543  accuracy 0.92\n",
            "train loss 0.3585169017314911 accuracy 0.98 | test loss 0.3796835243701935  accuracy 0.92\n",
            "train loss 0.3585175573825836 accuracy 0.99 | test loss 0.37976595759391785  accuracy 0.92\n",
            "train loss 0.35851818323135376 accuracy 0.98 | test loss 0.37971359491348267  accuracy 0.92\n",
            "train loss 0.3585163652896881 accuracy 0.98 | test loss 0.3796825706958771  accuracy 0.92\n",
            "train loss 0.35851699113845825 accuracy 0.99 | test loss 0.37976500391960144  accuracy 0.92\n",
            "train loss 0.3585175573825836 accuracy 0.98 | test loss 0.3797125816345215  accuracy 0.92\n",
            "train loss 0.3585158884525299 accuracy 0.98 | test loss 0.37970563769340515  accuracy 0.92\n",
            "train loss 0.3585158586502075 accuracy 0.98 | test loss 0.3797096908092499  accuracy 0.92\n",
            "train loss 0.3585156202316284 accuracy 0.98 | test loss 0.37970274686813354  accuracy 0.92\n",
            "train loss 0.358515202999115 accuracy 0.98 | test loss 0.3797430396080017  accuracy 0.92\n",
            "train loss 0.3585159182548523 accuracy 0.98 | test loss 0.3797116279602051  accuracy 0.92\n",
            "train loss 0.3585149347782135 accuracy 0.98 | test loss 0.3796806335449219  accuracy 0.92\n",
            "train loss 0.35851559042930603 accuracy 0.99 | test loss 0.3797629177570343  accuracy 0.92\n",
            "train loss 0.35851627588272095 accuracy 0.98 | test loss 0.37969130277633667  accuracy 0.92\n",
            "train loss 0.35851457715034485 accuracy 0.98 | test loss 0.3796845078468323  accuracy 0.92\n",
            "train loss 0.35851454734802246 accuracy 0.99 | test loss 0.3797402083873749  accuracy 0.92\n",
            "train loss 0.3585149943828583 accuracy 0.98 | test loss 0.379708856344223  accuracy 0.92\n",
            "train loss 0.3585141599178314 accuracy 0.98 | test loss 0.3797018826007843  accuracy 0.92\n",
            "train loss 0.35851362347602844 accuracy 0.98 | test loss 0.3796708583831787  accuracy 0.92\n",
            "train loss 0.35851454734802246 accuracy 0.99 | test loss 0.3797532618045807  accuracy 0.92\n",
            "train loss 0.35851481556892395 accuracy 0.98 | test loss 0.3797009289264679  accuracy 0.92\n",
            "train loss 0.3585131764411926 accuracy 0.98 | test loss 0.3796939253807068  accuracy 0.92\n",
            "train loss 0.3585130274295807 accuracy 0.98 | test loss 0.37971025705337524  accuracy 0.92\n",
            "train loss 0.3585130274295807 accuracy 0.98 | test loss 0.37967920303344727  accuracy 0.92\n",
            "train loss 0.35851287841796875 accuracy 0.98 | test loss 0.37971973419189453  accuracy 0.92\n",
            "train loss 0.3585129976272583 accuracy 0.98 | test loss 0.379688560962677  accuracy 0.92\n",
            "train loss 0.35851240158081055 accuracy 0.98 | test loss 0.37968164682388306  accuracy 0.92\n",
            "train loss 0.35851234197616577 accuracy 0.99 | test loss 0.37973731756210327  accuracy 0.92\n",
            "train loss 0.35851290822029114 accuracy 0.98 | test loss 0.3797059655189514  accuracy 0.92\n",
            "train loss 0.35851195454597473 accuracy 0.98 | test loss 0.37969890236854553  accuracy 0.92\n",
            "train loss 0.3585115373134613 accuracy 0.98 | test loss 0.37966787815093994  accuracy 0.92\n",
            "train loss 0.3585124909877777 accuracy 0.99 | test loss 0.37975019216537476  accuracy 0.92\n",
            "train loss 0.3585127890110016 accuracy 0.98 | test loss 0.3796977996826172  accuracy 0.92\n",
            "train loss 0.3585110306739807 accuracy 0.98 | test loss 0.3796907961368561  accuracy 0.92\n",
            "train loss 0.35851091146469116 accuracy 0.98 | test loss 0.37970709800720215  accuracy 0.92\n",
            "train loss 0.35851097106933594 accuracy 0.98 | test loss 0.3796760141849518  accuracy 0.92\n",
            "train loss 0.3585107624530792 accuracy 0.99 | test loss 0.3797582983970642  accuracy 0.92\n",
            "train loss 0.35851237177848816 accuracy 0.98 | test loss 0.3797057271003723  accuracy 0.92\n",
            "train loss 0.35851040482521057 accuracy 0.98 | test loss 0.37967467308044434  accuracy 0.92\n",
            "train loss 0.35851022601127625 accuracy 0.99 | test loss 0.37973037362098694  accuracy 0.92\n",
            "train loss 0.3585106432437897 accuracy 0.98 | test loss 0.3796989619731903  accuracy 0.92\n",
            "train loss 0.3585100769996643 accuracy 0.98 | test loss 0.3796919584274292  accuracy 0.92\n",
            "train loss 0.3585096001625061 accuracy 0.98 | test loss 0.3796849846839905  accuracy 0.92\n",
            "train loss 0.358509361743927 accuracy 0.98 | test loss 0.37972524762153625  accuracy 0.92\n",
            "train loss 0.3585098683834076 accuracy 0.98 | test loss 0.379693865776062  accuracy 0.92\n",
            "train loss 0.3585089147090912 accuracy 0.98 | test loss 0.3796868324279785  accuracy 0.92\n",
            "train loss 0.358508825302124 accuracy 0.98 | test loss 0.3797183930873871  accuracy 0.92\n",
            "train loss 0.3585091233253479 accuracy 0.98 | test loss 0.37968695163726807  accuracy 0.92\n",
            "train loss 0.3585085868835449 accuracy 0.98 | test loss 0.37968000769615173  accuracy 0.92\n",
            "train loss 0.35850852727890015 accuracy 0.98 | test loss 0.3797270357608795  accuracy 0.92\n",
            "train loss 0.3585089147090912 accuracy 0.98 | test loss 0.3796956241130829  accuracy 0.92\n",
            "train loss 0.35850790143013 accuracy 0.98 | test loss 0.3796645402908325  accuracy 0.92\n",
            "train loss 0.35850873589515686 accuracy 0.99 | test loss 0.37974685430526733  accuracy 0.92\n",
            "train loss 0.3585090637207031 accuracy 0.98 | test loss 0.3796943724155426  accuracy 0.92\n",
            "train loss 0.358507364988327 accuracy 0.98 | test loss 0.3796633183956146  accuracy 0.92\n",
            "train loss 0.35850822925567627 accuracy 0.99 | test loss 0.3797455430030823  accuracy 0.92\n",
            "train loss 0.358508437871933 accuracy 0.98 | test loss 0.37969306111335754  accuracy 0.92\n",
            "train loss 0.35850682854652405 accuracy 0.98 | test loss 0.3796860873699188  accuracy 0.92\n",
            "train loss 0.35850682854652405 accuracy 0.98 | test loss 0.3796900808811188  accuracy 0.92\n",
            "train loss 0.35850659012794495 accuracy 0.98 | test loss 0.3796829879283905  accuracy 0.92\n",
            "train loss 0.3585064113140106 accuracy 0.98 | test loss 0.3797231912612915  accuracy 0.92\n",
            "train loss 0.3585069179534912 accuracy 0.98 | test loss 0.3796917498111725  accuracy 0.92\n",
            "train loss 0.3585059344768524 accuracy 0.98 | test loss 0.37966054677963257  accuracy 0.92\n",
            "train loss 0.3585069179534912 accuracy 0.99 | test loss 0.37972763180732727  accuracy 0.92\n",
            "train loss 0.35850653052330017 accuracy 0.98 | test loss 0.3796960413455963  accuracy 0.92\n",
            "train loss 0.3585055470466614 accuracy 0.98 | test loss 0.3796648383140564  accuracy 0.92\n",
            "train loss 0.3585057854652405 accuracy 0.99 | test loss 0.37974706292152405  accuracy 0.92\n",
            "train loss 0.3585069179534912 accuracy 0.98 | test loss 0.37969446182250977  accuracy 0.92\n",
            "train loss 0.35850510001182556 accuracy 0.98 | test loss 0.37968724966049194  accuracy 0.92\n",
            "train loss 0.35850468277931213 accuracy 0.98 | test loss 0.3796759247779846  accuracy 0.92\n",
            "train loss 0.3585045635700226 accuracy 0.98 | test loss 0.37966904044151306  accuracy 0.92\n",
            "train loss 0.35850486159324646 accuracy 0.99 | test loss 0.37975120544433594  accuracy 0.92\n",
            "train loss 0.35850614309310913 accuracy 0.98 | test loss 0.37967926263809204  accuracy 0.92\n",
            "train loss 0.35850414633750916 accuracy 0.98 | test loss 0.37968748807907104  accuracy 0.92\n",
            "train loss 0.35850393772125244 accuracy 0.98 | test loss 0.37965622544288635  accuracy 0.92\n",
            "train loss 0.35850441455841064 accuracy 0.99 | test loss 0.379738450050354  accuracy 0.92\n",
            "train loss 0.35850510001182556 accuracy 0.98 | test loss 0.3796858787536621  accuracy 0.92\n",
            "train loss 0.35850340127944946 accuracy 0.98 | test loss 0.37965473532676697  accuracy 0.92\n",
            "train loss 0.35850387811660767 accuracy 0.99 | test loss 0.3797369599342346  accuracy 0.92\n",
            "train loss 0.3585044741630554 accuracy 0.98 | test loss 0.37968435883522034  accuracy 0.92\n",
            "train loss 0.35850295424461365 accuracy 0.98 | test loss 0.3796772360801697  accuracy 0.92\n",
            "train loss 0.35850271582603455 accuracy 0.98 | test loss 0.37966597080230713  accuracy 0.92\n",
            "train loss 0.35850265622138977 accuracy 0.98 | test loss 0.3797062337398529  accuracy 0.92\n",
            "train loss 0.35850295424461365 accuracy 0.98 | test loss 0.3796748220920563  accuracy 0.92\n",
            "train loss 0.35850226879119873 accuracy 0.98 | test loss 0.37966781854629517  accuracy 0.92\n",
            "train loss 0.35850203037261963 accuracy 0.99 | test loss 0.3797231614589691  accuracy 0.92\n",
            "train loss 0.3585028648376465 accuracy 0.98 | test loss 0.37969154119491577  accuracy 0.92\n",
            "train loss 0.3585018813610077 accuracy 0.98 | test loss 0.3796602487564087  accuracy 0.92\n",
            "train loss 0.35850173234939575 accuracy 0.99 | test loss 0.3797271251678467  accuracy 0.92\n",
            "train loss 0.35850250720977783 accuracy 0.98 | test loss 0.3796953558921814  accuracy 0.92\n",
            "train loss 0.35850149393081665 accuracy 0.98 | test loss 0.37966403365135193  accuracy 0.92\n",
            "train loss 0.3585010766983032 accuracy 0.98 | test loss 0.37965700030326843  accuracy 0.92\n",
            "train loss 0.35850104689598083 accuracy 0.99 | test loss 0.37971264123916626  accuracy 0.92\n",
            "train loss 0.3585014343261719 accuracy 0.98 | test loss 0.3796810209751129  accuracy 0.92\n",
            "train loss 0.3585006296634674 accuracy 0.98 | test loss 0.3796737492084503  accuracy 0.92\n",
            "train loss 0.3585001230239868 accuracy 0.98 | test loss 0.3796665072441101  accuracy 0.92\n",
            "train loss 0.3585001528263092 accuracy 0.98 | test loss 0.3796826899051666  accuracy 0.92\n",
            "train loss 0.3584999740123749 accuracy 0.98 | test loss 0.37965139746665955  accuracy 0.92\n",
            "train loss 0.35850024223327637 accuracy 0.99 | test loss 0.3797184228897095  accuracy 0.92\n",
            "train loss 0.358500599861145 accuracy 0.98 | test loss 0.37968677282333374  accuracy 0.92\n",
            "train loss 0.3584996461868286 accuracy 0.98 | test loss 0.3796553611755371  accuracy 0.92\n",
            "train loss 0.35849928855895996 accuracy 0.98 | test loss 0.3796910047531128  accuracy 0.92\n",
            "train loss 0.35849928855895996 accuracy 0.98 | test loss 0.3796595633029938  accuracy 0.92\n",
            "train loss 0.3584989011287689 accuracy 0.98 | test loss 0.37967994809150696  accuracy 0.92\n",
            "train loss 0.358498752117157 accuracy 0.98 | test loss 0.37967267632484436  accuracy 0.92\n",
            "train loss 0.35849836468696594 accuracy 0.98 | test loss 0.379656583070755  accuracy 0.92\n",
            "train loss 0.35849863290786743 accuracy 0.99 | test loss 0.3797234296798706  accuracy 0.92\n",
            "train loss 0.3584993779659271 accuracy 0.98 | test loss 0.37969154119491577  accuracy 0.92\n",
            "train loss 0.35849836468696594 accuracy 0.98 | test loss 0.37966009974479675  accuracy 0.92\n",
            "train loss 0.3584977686405182 accuracy 0.98 | test loss 0.37965312600135803  accuracy 0.92\n",
            "train loss 0.3584980070590973 accuracy 0.99 | test loss 0.37973517179489136  accuracy 0.92\n",
            "train loss 0.3584991991519928 accuracy 0.98 | test loss 0.3796824514865875  accuracy 0.92\n",
            "train loss 0.35849741101264954 accuracy 0.98 | test loss 0.3796510100364685  accuracy 0.92\n",
            "train loss 0.3584975302219391 accuracy 0.99 | test loss 0.3797064423561096  accuracy 0.92\n",
            "train loss 0.358497679233551 accuracy 0.98 | test loss 0.3796748220920563  accuracy 0.92\n",
            "train loss 0.35849684476852417 accuracy 0.98 | test loss 0.3796674609184265  accuracy 0.92\n",
            "train loss 0.35849639773368835 accuracy 0.98 | test loss 0.3796876072883606  accuracy 0.92\n",
            "train loss 0.35849669575691223 accuracy 0.98 | test loss 0.3796561658382416  accuracy 0.92\n",
            "train loss 0.35849639773368835 accuracy 0.99 | test loss 0.3797115981578827  accuracy 0.92\n",
            "train loss 0.35849693417549133 accuracy 0.98 | test loss 0.37967973947525024  accuracy 0.92\n",
            "train loss 0.35849592089653015 accuracy 0.98 | test loss 0.3796483874320984  accuracy 0.92\n",
            "train loss 0.3584963083267212 accuracy 0.99 | test loss 0.3797151744365692  accuracy 0.92\n",
            "train loss 0.3584965765476227 accuracy 0.98 | test loss 0.37968334555625916  accuracy 0.92\n",
            "train loss 0.3584955930709839 accuracy 0.98 | test loss 0.37965187430381775  accuracy 0.92\n",
            "train loss 0.35849520564079285 accuracy 0.98 | test loss 0.37967216968536377  accuracy 0.92\n",
            "train loss 0.35849496722221375 accuracy 0.98 | test loss 0.3796648383140564  accuracy 0.92\n",
            "train loss 0.3584948182106018 accuracy 0.98 | test loss 0.379668653011322  accuracy 0.92\n",
            "train loss 0.35849469900131226 accuracy 0.98 | test loss 0.37966132164001465  accuracy 0.92\n",
            "train loss 0.358494371175766 accuracy 0.98 | test loss 0.3797014057636261  accuracy 0.92\n",
            "train loss 0.3584950268268585 accuracy 0.98 | test loss 0.37966957688331604  accuracy 0.92\n",
            "train loss 0.35849401354789734 accuracy 0.98 | test loss 0.3796381950378418  accuracy 0.92\n",
            "train loss 0.3584948778152466 accuracy 0.99 | test loss 0.3797050416469574  accuracy 0.92\n",
            "train loss 0.35849466919898987 accuracy 0.98 | test loss 0.37967321276664734  accuracy 0.92\n",
            "train loss 0.3584936857223511 accuracy 0.98 | test loss 0.37966591119766235  accuracy 0.92\n",
            "train loss 0.35849326848983765 accuracy 0.98 | test loss 0.3796344995498657  accuracy 0.92\n",
            "train loss 0.3584944009780884 accuracy 0.99 | test loss 0.3797166645526886  accuracy 0.92\n",
            "train loss 0.3584944009780884 accuracy 0.98 | test loss 0.3796639144420624  accuracy 0.92\n",
            "train loss 0.35849273204803467 accuracy 0.98 | test loss 0.3796325922012329  accuracy 0.92\n",
            "train loss 0.3584938645362854 accuracy 0.99 | test loss 0.37971481680870056  accuracy 0.92\n",
            "train loss 0.35849374532699585 accuracy 0.98 | test loss 0.37966200709342957  accuracy 0.92\n",
            "train loss 0.3584922254085541 accuracy 0.98 | test loss 0.37965473532676697  accuracy 0.92\n",
            "train loss 0.3584924340248108 accuracy 0.98 | test loss 0.3796858787536621  accuracy 0.92\n",
            "train loss 0.3584924638271332 accuracy 0.98 | test loss 0.37965431809425354  accuracy 0.92\n",
            "train loss 0.3584919273853302 accuracy 0.98 | test loss 0.37964704632759094  accuracy 0.92\n",
            "train loss 0.35849180817604065 accuracy 0.98 | test loss 0.37968724966049194  accuracy 0.92\n",
            "train loss 0.35849201679229736 accuracy 0.98 | test loss 0.37965551018714905  accuracy 0.92\n",
            "train loss 0.35849127173423767 accuracy 0.98 | test loss 0.37964826822280884  accuracy 0.92\n",
            "train loss 0.35849133133888245 accuracy 0.99 | test loss 0.3797036409378052  accuracy 0.92\n",
            "train loss 0.3584918975830078 accuracy 0.98 | test loss 0.3796524107456207  accuracy 0.92\n",
            "train loss 0.35849088430404663 accuracy 0.98 | test loss 0.37964513897895813  accuracy 0.92\n",
            "train loss 0.358490526676178 accuracy 0.98 | test loss 0.37968531250953674  accuracy 0.92\n",
            "train loss 0.35849112272262573 accuracy 0.98 | test loss 0.37965360283851624  accuracy 0.92\n",
            "train loss 0.3584901988506317 accuracy 0.98 | test loss 0.3796464204788208  accuracy 0.92\n",
            "train loss 0.3584900200366974 accuracy 0.98 | test loss 0.37967756390571594  accuracy 0.92\n",
            "train loss 0.35849037766456604 accuracy 0.98 | test loss 0.3796459436416626  accuracy 0.92\n",
            "train loss 0.35848990082740784 accuracy 0.98 | test loss 0.379638671875  accuracy 0.92\n",
            "train loss 0.3584897518157959 accuracy 0.98 | test loss 0.37968558073043823  accuracy 0.92\n",
            "train loss 0.3584900498390198 accuracy 0.98 | test loss 0.37965384125709534  accuracy 0.92\n",
            "train loss 0.35848909616470337 accuracy 0.98 | test loss 0.3796224594116211  accuracy 0.92\n",
            "train loss 0.35849013924598694 accuracy 0.99 | test loss 0.37970465421676636  accuracy 0.92\n",
            "train loss 0.3584902882575989 accuracy 0.98 | test loss 0.37965187430381775  accuracy 0.92\n",
            "train loss 0.35848861932754517 accuracy 0.98 | test loss 0.37964457273483276  accuracy 0.92\n",
            "train loss 0.35848864912986755 accuracy 0.98 | test loss 0.3796757459640503  accuracy 0.92\n",
            "train loss 0.3584887981414795 accuracy 0.98 | test loss 0.37964415550231934  accuracy 0.92\n",
            "train loss 0.3584882318973541 accuracy 0.98 | test loss 0.37963682413101196  accuracy 0.92\n",
            "train loss 0.3584880828857422 accuracy 0.99 | test loss 0.3797035813331604  accuracy 0.92\n",
            "train loss 0.358489066362381 accuracy 0.98 | test loss 0.3796508014202118  accuracy 0.92\n",
            "train loss 0.35848766565322876 accuracy 0.98 | test loss 0.3796345293521881  accuracy 0.92\n",
            "train loss 0.3584875762462616 accuracy 0.98 | test loss 0.37967467308044434  accuracy 0.92\n",
            "train loss 0.3584877550601959 accuracy 0.98 | test loss 0.37964293360710144  accuracy 0.92\n",
            "train loss 0.3584871292114258 accuracy 0.98 | test loss 0.37963569164276123  accuracy 0.92\n",
            "train loss 0.358487069606781 accuracy 0.99 | test loss 0.3796910047531128  accuracy 0.92\n",
            "train loss 0.35848769545555115 accuracy 0.98 | test loss 0.37965911626815796  accuracy 0.92\n",
            "train loss 0.3584866523742676 accuracy 0.98 | test loss 0.3796275556087494  accuracy 0.92\n",
            "train loss 0.35848692059516907 accuracy 0.99 | test loss 0.37969428300857544  accuracy 0.92\n",
            "train loss 0.35848739743232727 accuracy 0.98 | test loss 0.3796415627002716  accuracy 0.92\n",
            "train loss 0.35848596692085266 accuracy 0.98 | test loss 0.37964943051338196  accuracy 0.92\n",
            "train loss 0.35848569869995117 accuracy 0.98 | test loss 0.37961798906326294  accuracy 0.92\n",
            "train loss 0.3584868609905243 accuracy 0.99 | test loss 0.3796999156475067  accuracy 0.92\n",
            "train loss 0.3584868609905243 accuracy 0.98 | test loss 0.3796471357345581  accuracy 0.92\n",
            "train loss 0.35848525166511536 accuracy 0.98 | test loss 0.37963977456092834  accuracy 0.92\n",
            "train loss 0.35848528146743774 accuracy 0.98 | test loss 0.3796556293964386  accuracy 0.92\n",
            "train loss 0.3584851026535034 accuracy 0.98 | test loss 0.37962400913238525  accuracy 0.92\n",
            "train loss 0.35848528146743774 accuracy 0.99 | test loss 0.3797060251235962  accuracy 0.92\n",
            "train loss 0.3584863543510437 accuracy 0.98 | test loss 0.3796530067920685  accuracy 0.92\n",
            "train loss 0.35848456621170044 accuracy 0.98 | test loss 0.37964552640914917  accuracy 0.92\n",
            "train loss 0.3584842085838318 accuracy 0.98 | test loss 0.37963393330574036  accuracy 0.92\n",
            "train loss 0.35848402976989746 accuracy 0.98 | test loss 0.37965407967567444  accuracy 0.92\n",
            "train loss 0.35848402976989746 accuracy 0.98 | test loss 0.3796224892139435  accuracy 0.92\n",
            "train loss 0.35848432779312134 accuracy 0.99 | test loss 0.37970441579818726  accuracy 0.92\n",
            "train loss 0.3584851026535034 accuracy 0.98 | test loss 0.3796514570713043  accuracy 0.92\n",
            "train loss 0.3584834933280945 accuracy 0.98 | test loss 0.37961989641189575  accuracy 0.92\n",
            "train loss 0.3584839105606079 accuracy 0.99 | test loss 0.3797019124031067  accuracy 0.92\n",
            "train loss 0.3584844172000885 accuracy 0.98 | test loss 0.379669725894928  accuracy 0.92\n",
            "train loss 0.3584834337234497 accuracy 0.98 | test loss 0.3796378970146179  accuracy 0.92\n",
            "train loss 0.3584829568862915 accuracy 0.98 | test loss 0.37963056564331055  accuracy 0.92\n",
            "train loss 0.35848262906074524 accuracy 0.98 | test loss 0.3796583414077759  accuracy 0.92\n",
            "train loss 0.35848256945610046 accuracy 0.98 | test loss 0.3796265423297882  accuracy 0.92\n",
            "train loss 0.3584825396537781 accuracy 0.99 | test loss 0.3796931505203247  accuracy 0.92\n",
            "train loss 0.3584831953048706 accuracy 0.98 | test loss 0.37966102361679077  accuracy 0.92\n",
            "train loss 0.3584822118282318 accuracy 0.98 | test loss 0.37965330481529236  accuracy 0.92\n",
            "train loss 0.3584817945957184 accuracy 0.98 | test loss 0.379621684551239  accuracy 0.92\n",
            "train loss 0.35848185420036316 accuracy 0.99 | test loss 0.37968847155570984  accuracy 0.92\n",
            "train loss 0.3584824204444885 accuracy 0.98 | test loss 0.3796564042568207  accuracy 0.92\n",
            "train loss 0.35848143696784973 accuracy 0.98 | test loss 0.3796246349811554  accuracy 0.92\n",
            "train loss 0.3584810793399811 accuracy 0.98 | test loss 0.3796524405479431  accuracy 0.92\n",
            "train loss 0.3584810495376587 accuracy 0.98 | test loss 0.3796447813510895  accuracy 0.92\n",
            "train loss 0.3584805727005005 accuracy 0.98 | test loss 0.37963709235191345  accuracy 0.92\n",
            "train loss 0.35848045349121094 accuracy 0.98 | test loss 0.37965285778045654  accuracy 0.92\n",
            "train loss 0.35848045349121094 accuracy 0.98 | test loss 0.3796210289001465  accuracy 0.92\n",
            "train loss 0.3584803342819214 accuracy 0.99 | test loss 0.37968769669532776  accuracy 0.92\n",
            "train loss 0.3584810495376587 accuracy 0.98 | test loss 0.3796555995941162  accuracy 0.92\n",
            "train loss 0.3584800660610199 accuracy 0.98 | test loss 0.37962380051612854  accuracy 0.92\n",
            "train loss 0.35847964882850647 accuracy 0.98 | test loss 0.37963157892227173  accuracy 0.92\n",
            "train loss 0.358479380607605 accuracy 0.98 | test loss 0.3796515166759491  accuracy 0.92\n",
            "train loss 0.358479380607605 accuracy 0.98 | test loss 0.3796197474002838  accuracy 0.92\n",
            "train loss 0.3584792912006378 accuracy 0.99 | test loss 0.3797016739845276  accuracy 0.92\n",
            "train loss 0.3584807813167572 accuracy 0.98 | test loss 0.37964847683906555  accuracy 0.92\n",
            "train loss 0.3584788143634796 accuracy 0.98 | test loss 0.3796166777610779  accuracy 0.92\n",
            "train loss 0.358478844165802 accuracy 0.99 | test loss 0.37969866394996643  accuracy 0.92\n",
            "train loss 0.3584800660610199 accuracy 0.98 | test loss 0.37964552640914917  accuracy 0.92\n",
            "train loss 0.35847827792167664 accuracy 0.98 | test loss 0.37963783740997314  accuracy 0.92\n",
            "train loss 0.35847797989845276 accuracy 0.98 | test loss 0.37962606549263  accuracy 0.92\n",
            "train loss 0.35847777128219604 accuracy 0.98 | test loss 0.37963852286338806  accuracy 0.92\n",
            "train loss 0.3584775924682617 accuracy 0.98 | test loss 0.3796308934688568  accuracy 0.92\n",
            "train loss 0.358477383852005 accuracy 0.98 | test loss 0.37966176867485046  accuracy 0.92\n",
            "train loss 0.35847780108451843 accuracy 0.98 | test loss 0.37962982058525085  accuracy 0.92\n",
            "train loss 0.35847732424736023 accuracy 0.98 | test loss 0.3796221911907196  accuracy 0.92\n",
            "train loss 0.35847708582878113 accuracy 0.98 | test loss 0.37966886162757874  accuracy 0.92\n",
            "train loss 0.35847753286361694 accuracy 0.98 | test loss 0.3796367943286896  accuracy 0.92\n",
            "train loss 0.3584764897823334 accuracy 0.98 | test loss 0.37960508465766907  accuracy 0.92\n",
            "train loss 0.35847747325897217 accuracy 0.99 | test loss 0.37968695163726807  accuracy 0.92\n",
            "train loss 0.35847753286361694 accuracy 0.98 | test loss 0.3796338438987732  accuracy 0.92\n",
            "train loss 0.3584759533405304 accuracy 0.98 | test loss 0.37962621450424194  accuracy 0.92\n",
            "train loss 0.35847610235214233 accuracy 0.98 | test loss 0.379657119512558  accuracy 0.92\n",
            "train loss 0.3584761619567871 accuracy 0.98 | test loss 0.3796251714229584  accuracy 0.92\n",
            "train loss 0.35847562551498413 accuracy 0.98 | test loss 0.3796175420284271  accuracy 0.92\n",
            "train loss 0.35847556591033936 accuracy 0.99 | test loss 0.3796839714050293  accuracy 0.92\n",
            "train loss 0.3584764003753662 accuracy 0.98 | test loss 0.379651814699173  accuracy 0.92\n",
            "train loss 0.35847535729408264 accuracy 0.98 | test loss 0.37961992621421814  accuracy 0.92\n",
            "train loss 0.3584747910499573 accuracy 0.98 | test loss 0.3796323835849762  accuracy 0.92\n",
            "train loss 0.35847464203834534 accuracy 0.98 | test loss 0.37962469458580017  accuracy 0.92\n",
            "train loss 0.35847440361976624 accuracy 0.98 | test loss 0.3796556890010834  accuracy 0.92\n",
            "train loss 0.3584747910499573 accuracy 0.98 | test loss 0.3796236217021942  accuracy 0.92\n",
            "train loss 0.35847434401512146 accuracy 0.98 | test loss 0.37961599230766296  accuracy 0.92\n",
            "train loss 0.35847410559654236 accuracy 0.98 | test loss 0.3796626329421997  accuracy 0.92\n",
            "train loss 0.3584744930267334 accuracy 0.98 | test loss 0.37963056564331055  accuracy 0.92\n",
            "train loss 0.3584735095500946 accuracy 0.98 | test loss 0.3795987665653229  accuracy 0.92\n",
            "train loss 0.3584745228290558 accuracy 0.99 | test loss 0.37968066334724426  accuracy 0.92\n",
            "train loss 0.3584744930267334 accuracy 0.98 | test loss 0.3796275556087494  accuracy 0.92\n",
            "train loss 0.358473002910614 accuracy 0.98 | test loss 0.37961986660957336  accuracy 0.92\n",
            "train loss 0.35847312211990356 accuracy 0.98 | test loss 0.3796508014202118  accuracy 0.92\n",
            "train loss 0.3584732115268707 accuracy 0.98 | test loss 0.3796187937259674  accuracy 0.92\n",
            "train loss 0.35847267508506775 accuracy 0.98 | test loss 0.37961113452911377  accuracy 0.92\n",
            "train loss 0.3584725856781006 accuracy 0.98 | test loss 0.3796509802341461  accuracy 0.92\n",
            "train loss 0.35847267508506775 accuracy 0.98 | test loss 0.37961897253990173  accuracy 0.92\n",
            "train loss 0.35847198963165283 accuracy 0.98 | test loss 0.3796112835407257  accuracy 0.92\n",
            "train loss 0.35847213864326477 accuracy 0.99 | test loss 0.3796663284301758  accuracy 0.92\n",
            "train loss 0.3584725856781006 accuracy 0.98 | test loss 0.37961477041244507  accuracy 0.92\n",
            "train loss 0.3584716022014618 accuracy 0.98 | test loss 0.3796071410179138  accuracy 0.92\n",
            "train loss 0.3584713637828827 accuracy 0.98 | test loss 0.37964701652526855  accuracy 0.92\n",
            "train loss 0.35847175121307373 accuracy 0.98 | test loss 0.37961500883102417  accuracy 0.92\n",
            "train loss 0.3584709167480469 accuracy 0.98 | test loss 0.37960731983184814  accuracy 0.92\n",
            "train loss 0.3584709167480469 accuracy 0.99 | test loss 0.3796623945236206  accuracy 0.92\n",
            "train loss 0.3584716022014618 accuracy 0.98 | test loss 0.3796302080154419  accuracy 0.92\n",
            "train loss 0.3584705889225006 accuracy 0.98 | test loss 0.37959834933280945  accuracy 0.92\n",
            "train loss 0.35847076773643494 accuracy 0.99 | test loss 0.3796648383140564  accuracy 0.92\n",
            "train loss 0.3584713041782379 accuracy 0.98 | test loss 0.3796118199825287  accuracy 0.92\n",
            "train loss 0.3584699034690857 accuracy 0.98 | test loss 0.3796193599700928  accuracy 0.92\n",
            "train loss 0.3584696054458618 accuracy 0.98 | test loss 0.3795876204967499  accuracy 0.92\n",
            "train loss 0.3584708273410797 accuracy 0.99 | test loss 0.3796694874763489  accuracy 0.92\n",
            "train loss 0.3584706783294678 accuracy 0.98 | test loss 0.3796163499355316  accuracy 0.92\n",
            "train loss 0.35846903920173645 accuracy 0.98 | test loss 0.37958458065986633  accuracy 0.92\n",
            "train loss 0.3584703803062439 accuracy 0.99 | test loss 0.37966644763946533  accuracy 0.92\n",
            "train loss 0.35847002267837524 accuracy 0.98 | test loss 0.3796341121196747  accuracy 0.92\n",
            "train loss 0.35846900939941406 accuracy 0.98 | test loss 0.3796021044254303  accuracy 0.92\n",
            "train loss 0.3584686815738678 accuracy 0.98 | test loss 0.37962204217910767  accuracy 0.92\n",
            "train loss 0.35846835374832153 accuracy 0.98 | test loss 0.37961432337760925  accuracy 0.92\n",
            "train loss 0.35846808552742004 accuracy 0.98 | test loss 0.37960243225097656  accuracy 0.92\n",
            "train loss 0.3584679961204529 accuracy 0.98 | test loss 0.37964215874671936  accuracy 0.92\n",
            "train loss 0.3584684431552887 accuracy 0.98 | test loss 0.3796100616455078  accuracy 0.92\n",
            "train loss 0.35846763849258423 accuracy 0.98 | test loss 0.379602313041687  accuracy 0.92\n",
            "train loss 0.35846754908561707 accuracy 0.99 | test loss 0.3796573579311371  accuracy 0.92\n",
            "train loss 0.35846826434135437 accuracy 0.98 | test loss 0.3796251118183136  accuracy 0.92\n",
            "train loss 0.3584672510623932 accuracy 0.98 | test loss 0.3795930743217468  accuracy 0.92\n",
            "train loss 0.3584674894809723 accuracy 0.99 | test loss 0.37965965270996094  accuracy 0.92\n",
            "train loss 0.3584679365158081 accuracy 0.98 | test loss 0.3796064555644989  accuracy 0.92\n",
            "train loss 0.35846656560897827 accuracy 0.98 | test loss 0.3796139359474182  accuracy 0.92\n",
            "train loss 0.3584662675857544 accuracy 0.98 | test loss 0.37958207726478577  accuracy 0.92\n",
            "train loss 0.35846754908561707 accuracy 0.99 | test loss 0.3796639144420624  accuracy 0.92\n",
            "train loss 0.35846737027168274 accuracy 0.98 | test loss 0.37961065769195557  accuracy 0.92\n",
            "train loss 0.3584657311439514 accuracy 0.98 | test loss 0.37960296869277954  accuracy 0.92\n",
            "train loss 0.35846593976020813 accuracy 0.98 | test loss 0.37963369488716125  accuracy 0.92\n",
            "train loss 0.35846593976020813 accuracy 0.98 | test loss 0.3796015977859497  accuracy 0.92\n",
            "train loss 0.3584655821323395 accuracy 0.98 | test loss 0.37962135672569275  accuracy 0.92\n",
            "train loss 0.358465313911438 accuracy 0.98 | test loss 0.3795892894268036  accuracy 0.92\n",
            "train loss 0.3584655821323395 accuracy 0.99 | test loss 0.37965577840805054  accuracy 0.92\n",
            "train loss 0.35846593976020813 accuracy 0.98 | test loss 0.3796234428882599  accuracy 0.92\n",
            "train loss 0.35846492648124695 accuracy 0.98 | test loss 0.3795914351940155  accuracy 0.92\n",
            "train loss 0.3584645688533783 accuracy 0.98 | test loss 0.3796312212944031  accuracy 0.92\n",
            "train loss 0.3584648072719574 accuracy 0.98 | test loss 0.37959906458854675  accuracy 0.92\n",
            "train loss 0.3584642708301544 accuracy 0.98 | test loss 0.3795913755893707  accuracy 0.92\n",
            "train loss 0.35846418142318726 accuracy 0.99 | test loss 0.3796464204788208  accuracy 0.92\n",
            "train loss 0.35846468806266785 accuracy 0.98 | test loss 0.3796141743659973  accuracy 0.92\n",
            "train loss 0.3584638237953186 accuracy 0.98 | test loss 0.3796062767505646  accuracy 0.92\n",
            "train loss 0.3584633469581604 accuracy 0.98 | test loss 0.3795985281467438  accuracy 0.92\n",
            "train loss 0.3584633469581604 accuracy 0.98 | test loss 0.3796292841434479  accuracy 0.92\n",
            "train loss 0.35846349596977234 accuracy 0.98 | test loss 0.37959715723991394  accuracy 0.92\n",
            "train loss 0.3584631681442261 accuracy 0.98 | test loss 0.3796434700489044  accuracy 0.92\n",
            "train loss 0.3584635853767395 accuracy 0.98 | test loss 0.3796112835407257  accuracy 0.92\n",
            "train loss 0.3584626615047455 accuracy 0.98 | test loss 0.3796033263206482  accuracy 0.92\n",
            "train loss 0.35846221446990967 accuracy 0.98 | test loss 0.37957149744033813  accuracy 0.92\n",
            "train loss 0.35846373438835144 accuracy 0.99 | test loss 0.3796531856060028  accuracy 0.92\n",
            "train loss 0.35846319794654846 accuracy 0.98 | test loss 0.3795998692512512  accuracy 0.92\n",
            "train loss 0.35846176743507385 accuracy 0.98 | test loss 0.3796119689941406  accuracy 0.92\n",
            "train loss 0.35846176743507385 accuracy 0.98 | test loss 0.37957996129989624  accuracy 0.92\n",
            "train loss 0.3584623634815216 accuracy 0.99 | test loss 0.3796616196632385  accuracy 0.92\n",
            "train loss 0.3584628999233246 accuracy 0.98 | test loss 0.3796081840991974  accuracy 0.92\n",
            "train loss 0.3584611415863037 accuracy 0.98 | test loss 0.3795762062072754  accuracy 0.92\n",
            "train loss 0.35846197605133057 accuracy 0.99 | test loss 0.37965789437294006  accuracy 0.92\n",
            "train loss 0.35846221446990967 accuracy 0.98 | test loss 0.3796044886112213  accuracy 0.92\n",
            "train loss 0.35846060514450073 accuracy 0.98 | test loss 0.37959662079811096  accuracy 0.92\n",
            "train loss 0.3584606349468231 accuracy 0.98 | test loss 0.3796272575855255  accuracy 0.92\n",
            "train loss 0.35846075415611267 accuracy 0.98 | test loss 0.3795950710773468  accuracy 0.92\n",
            "train loss 0.35846027731895447 accuracy 0.98 | test loss 0.379587322473526  accuracy 0.92\n",
            "train loss 0.3584601879119873 accuracy 0.99 | test loss 0.379653662443161  accuracy 0.92\n",
            "train loss 0.35846102237701416 accuracy 0.98 | test loss 0.37962111830711365  accuracy 0.92\n",
            "train loss 0.358460009098053 accuracy 0.98 | test loss 0.37958893179893494  accuracy 0.92\n",
            "train loss 0.3584594130516052 accuracy 0.98 | test loss 0.37961623072624207  accuracy 0.92\n",
            "train loss 0.3584595024585724 accuracy 0.98 | test loss 0.379608154296875  accuracy 0.92\n",
            "train loss 0.35845908522605896 accuracy 0.98 | test loss 0.37957602739334106  accuracy 0.92\n",
            "train loss 0.35845986008644104 accuracy 0.99 | test loss 0.37964242696762085  accuracy 0.92\n",
            "train loss 0.3584596812725067 accuracy 0.98 | test loss 0.3796100616455078  accuracy 0.92\n",
            "train loss 0.3584586977958679 accuracy 0.98 | test loss 0.3795779347419739  accuracy 0.92\n",
            "train loss 0.3584587872028351 accuracy 0.99 | test loss 0.3796595633029938  accuracy 0.92\n",
            "train loss 0.35846003890037537 accuracy 0.98 | test loss 0.3796060085296631  accuracy 0.92\n",
            "train loss 0.35845819115638733 accuracy 0.98 | test loss 0.3795979917049408  accuracy 0.92\n",
            "train loss 0.3584577143192291 accuracy 0.98 | test loss 0.37958595156669617  accuracy 0.92\n",
            "train loss 0.3584577143192291 accuracy 0.98 | test loss 0.37960556149482727  accuracy 0.92\n",
            "train loss 0.3584575653076172 accuracy 0.98 | test loss 0.37957343459129333  accuracy 0.92\n",
            "train loss 0.358458012342453 accuracy 0.99 | test loss 0.3796551525592804  accuracy 0.92\n",
            "train loss 0.3584586977958679 accuracy 0.98 | test loss 0.3796016275882721  accuracy 0.92\n",
            "train loss 0.3584570288658142 accuracy 0.98 | test loss 0.3795936405658722  accuracy 0.92\n",
            "train loss 0.3584569990634918 accuracy 0.98 | test loss 0.3795967698097229  accuracy 0.92\n",
            "train loss 0.35845673084259033 accuracy 0.98 | test loss 0.3795887529850006  accuracy 0.92\n",
            "train loss 0.35845649242401123 accuracy 0.98 | test loss 0.37962833046913147  accuracy 0.92\n",
            "train loss 0.35845693945884705 accuracy 0.98 | test loss 0.37959596514701843  accuracy 0.92\n",
            "train loss 0.3584560453891754 accuracy 0.98 | test loss 0.37958791851997375  accuracy 0.92\n",
            "train loss 0.3584560453891754 accuracy 0.98 | test loss 0.3796185255050659  accuracy 0.92\n",
            "train loss 0.35845619440078735 accuracy 0.98 | test loss 0.3795861601829529  accuracy 0.92\n",
            "train loss 0.3584557771682739 accuracy 0.98 | test loss 0.3796057403087616  accuracy 0.92\n",
            "train loss 0.3584555387496948 accuracy 0.98 | test loss 0.3795735836029053  accuracy 0.92\n",
            "train loss 0.3584557771682739 accuracy 0.99 | test loss 0.3796399235725403  accuracy 0.92\n",
            "train loss 0.35845619440078735 accuracy 0.98 | test loss 0.3796074092388153  accuracy 0.92\n",
            "train loss 0.3584551513195038 accuracy 0.98 | test loss 0.3795992434024811  accuracy 0.92\n",
            "train loss 0.35845473408699036 accuracy 0.98 | test loss 0.37956708669662476  accuracy 0.92\n",
            "train loss 0.3584553897380829 accuracy 0.99 | test loss 0.37964874505996704  accuracy 0.92\n",
            "train loss 0.3584558367729187 accuracy 0.98 | test loss 0.37959519028663635  accuracy 0.92\n",
            "train loss 0.358454167842865 accuracy 0.98 | test loss 0.37958717346191406  accuracy 0.92\n",
            "train loss 0.3584541380405426 accuracy 0.98 | test loss 0.37959030270576477  accuracy 0.92\n",
            "train loss 0.3584538996219635 accuracy 0.98 | test loss 0.3795822858810425  accuracy 0.92\n",
            "train loss 0.35845375061035156 accuracy 0.99 | test loss 0.3796484172344208  accuracy 0.92\n",
            "train loss 0.35845503211021423 accuracy 0.98 | test loss 0.37959644198417664  accuracy 0.92\n",
            "train loss 0.35845354199409485 accuracy 0.98 | test loss 0.3795642852783203  accuracy 0.92\n",
            "train loss 0.3584534227848053 accuracy 0.99 | test loss 0.37961921095848083  accuracy 0.92\n",
            "train loss 0.35845375061035156 accuracy 0.98 | test loss 0.3795868158340454  accuracy 0.92\n",
            "train loss 0.3584531843662262 accuracy 0.98 | test loss 0.3795787990093231  accuracy 0.92\n",
            "train loss 0.3584526777267456 accuracy 0.98 | test loss 0.3795709013938904  accuracy 0.92\n",
            "train loss 0.35845252871513367 accuracy 0.99 | test loss 0.37962570786476135  accuracy 0.92\n",
            "train loss 0.3584532141685486 accuracy 0.98 | test loss 0.379593163728714  accuracy 0.92\n",
            "train loss 0.3584522306919098 accuracy 0.98 | test loss 0.3795851171016693  accuracy 0.92\n",
            "train loss 0.35845184326171875 accuracy 0.98 | test loss 0.3795802891254425  accuracy 0.92\n",
            "train loss 0.35845163464546204 accuracy 0.98 | test loss 0.3795723617076874  accuracy 0.92\n",
            "train loss 0.3584516942501068 accuracy 0.99 | test loss 0.3796297013759613  accuracy 0.92\n",
            "train loss 0.3584526777267456 accuracy 0.98 | test loss 0.37957626581192017  accuracy 0.92\n",
            "train loss 0.35845115780830383 accuracy 0.98 | test loss 0.37956827878952026  accuracy 0.92\n",
            "train loss 0.35845130681991577 accuracy 0.99 | test loss 0.3796497881412506  accuracy 0.92\n",
            "train loss 0.3584527373313904 accuracy 0.98 | test loss 0.3795960247516632  accuracy 0.92\n",
            "train loss 0.35845091938972473 accuracy 0.98 | test loss 0.3795638680458069  accuracy 0.92\n",
            "train loss 0.3584509491920471 accuracy 0.99 | test loss 0.37964537739753723  accuracy 0.92\n",
            "train loss 0.3584519922733307 accuracy 0.98 | test loss 0.379591703414917  accuracy 0.92\n",
            "train loss 0.35845035314559937 accuracy 0.98 | test loss 0.37955954670906067  accuracy 0.92\n",
            "train loss 0.35845062136650085 accuracy 0.99 | test loss 0.3796411156654358  accuracy 0.92\n",
            "train loss 0.35845130681991577 accuracy 0.98 | test loss 0.3796083629131317  accuracy 0.92\n",
            "train loss 0.3584502339363098 accuracy 0.98 | test loss 0.37957602739334106  accuracy 0.92\n",
            "train loss 0.3584496080875397 accuracy 0.98 | test loss 0.379567950963974  accuracy 0.92\n",
            "train loss 0.35844945907592773 accuracy 0.98 | test loss 0.3796074688434601  accuracy 0.92\n",
            "train loss 0.358449786901474 accuracy 0.98 | test loss 0.37957510352134705  accuracy 0.92\n",
            "train loss 0.35844886302948 accuracy 0.98 | test loss 0.37956705689430237  accuracy 0.92\n",
            "train loss 0.3584491014480591 accuracy 0.99 | test loss 0.37962180376052856  accuracy 0.92\n",
            "train loss 0.3584496080875397 accuracy 0.98 | test loss 0.3795892000198364  accuracy 0.92\n",
            "train loss 0.3584485650062561 accuracy 0.98 | test loss 0.37955695390701294  accuracy 0.92\n",
            "train loss 0.35844886302948 accuracy 0.99 | test loss 0.3796231746673584  accuracy 0.92\n",
            "train loss 0.35844916105270386 accuracy 0.98 | test loss 0.3795905113220215  accuracy 0.92\n",
            "train loss 0.3584481477737427 accuracy 0.98 | test loss 0.3795583248138428  accuracy 0.92\n",
            "train loss 0.35844793915748596 accuracy 0.99 | test loss 0.37961313128471375  accuracy 0.92\n",
            "train loss 0.3584483563899994 accuracy 0.98 | test loss 0.3795805275440216  accuracy 0.92\n",
            "train loss 0.35844776034355164 accuracy 0.98 | test loss 0.37957239151000977  accuracy 0.92\n",
            "train loss 0.35844722390174866 accuracy 0.98 | test loss 0.3795643448829651  accuracy 0.92\n",
            "train loss 0.35844719409942627 accuracy 0.98 | test loss 0.379603773355484  accuracy 0.92\n",
            "train loss 0.35844749212265015 accuracy 0.98 | test loss 0.37957122921943665  accuracy 0.92\n",
            "train loss 0.35844650864601135 accuracy 0.98 | test loss 0.37956321239471436  accuracy 0.92\n",
            "train loss 0.3584468364715576 accuracy 0.99 | test loss 0.3796204924583435  accuracy 0.92\n",
            "train loss 0.358447402715683 accuracy 0.98 | test loss 0.379587858915329  accuracy 0.92\n",
            "train loss 0.3584464192390442 accuracy 0.98 | test loss 0.3795796036720276  accuracy 0.92\n",
            "train loss 0.3584459722042084 accuracy 0.98 | test loss 0.37954744696617126  accuracy 0.92\n",
            "train loss 0.35844671726226807 accuracy 0.99 | test loss 0.37962889671325684  accuracy 0.92\n",
            "train loss 0.35844719409942627 accuracy 0.98 | test loss 0.3795751929283142  accuracy 0.92\n",
            "train loss 0.3584454357624054 accuracy 0.98 | test loss 0.37956702709198  accuracy 0.92\n",
            "train loss 0.35844534635543823 accuracy 0.98 | test loss 0.37958231568336487  accuracy 0.92\n",
            "train loss 0.35844528675079346 accuracy 0.98 | test loss 0.3795500099658966  accuracy 0.92\n",
            "train loss 0.35844534635543823 accuracy 0.99 | test loss 0.37963148951530457  accuracy 0.92\n",
            "train loss 0.35844653844833374 accuracy 0.98 | test loss 0.37957778573036194  accuracy 0.92\n",
            "train loss 0.3584447503089905 accuracy 0.98 | test loss 0.3795696198940277  accuracy 0.92\n",
            "train loss 0.3584442734718323 accuracy 0.98 | test loss 0.3795726001262665  accuracy 0.92\n",
            "train loss 0.3584444224834442 accuracy 0.98 | test loss 0.37956446409225464  accuracy 0.92\n",
            "train loss 0.35844412446022034 accuracy 0.98 | test loss 0.3795838952064514  accuracy 0.92\n",
            "train loss 0.35844406485557556 accuracy 0.98 | test loss 0.379551500082016  accuracy 0.92\n",
            "train loss 0.3584442734718323 accuracy 0.99 | test loss 0.3796176016330719  accuracy 0.92\n",
            "train loss 0.3584446609020233 accuracy 0.98 | test loss 0.3795848786830902  accuracy 0.92\n",
            "train loss 0.3584436774253845 accuracy 0.98 | test loss 0.3795525133609772  accuracy 0.92\n",
            "train loss 0.3584434688091278 accuracy 0.99 | test loss 0.379607230424881  accuracy 0.92\n",
            "train loss 0.35844388604164124 accuracy 0.98 | test loss 0.37957456707954407  accuracy 0.92\n",
            "train loss 0.3584430515766144 accuracy 0.98 | test loss 0.37956640124320984  accuracy 0.92\n",
            "train loss 0.3584425747394562 accuracy 0.98 | test loss 0.3795582950115204  accuracy 0.92\n",
            "train loss 0.3584426939487457 accuracy 0.98 | test loss 0.3795887231826782  accuracy 0.92\n",
            "train loss 0.3584427237510681 accuracy 0.98 | test loss 0.37955617904663086  accuracy 0.92\n",
            "train loss 0.358442485332489 accuracy 0.98 | test loss 0.37960222363471985  accuracy 0.92\n",
            "train loss 0.3584427535533905 accuracy 0.98 | test loss 0.3795696198940277  accuracy 0.92\n",
            "train loss 0.3584418296813965 accuracy 0.98 | test loss 0.3795613646507263  accuracy 0.92\n",
            "train loss 0.3584415316581726 accuracy 0.98 | test loss 0.3796005845069885  accuracy 0.92\n",
            "train loss 0.3584422171115875 accuracy 0.98 | test loss 0.3795679807662964  accuracy 0.92\n",
            "train loss 0.35844123363494873 accuracy 0.98 | test loss 0.3795357942581177  accuracy 0.92\n",
            "train loss 0.3584422171115875 accuracy 0.99 | test loss 0.3796171545982361  accuracy 0.92\n",
            "train loss 0.3584423065185547 accuracy 0.98 | test loss 0.3795633912086487  accuracy 0.92\n",
            "train loss 0.35844069719314575 accuracy 0.98 | test loss 0.37955522537231445  accuracy 0.92\n",
            "train loss 0.3584408462047577 accuracy 0.98 | test loss 0.3795856833457947  accuracy 0.92\n",
            "train loss 0.3584408164024353 accuracy 0.98 | test loss 0.3795531392097473  accuracy 0.92\n",
            "train loss 0.3584403395652771 accuracy 0.98 | test loss 0.3795725107192993  accuracy 0.92\n",
            "train loss 0.3584401607513428 accuracy 0.98 | test loss 0.37956416606903076  accuracy 0.92\n",
            "train loss 0.35843977332115173 accuracy 0.98 | test loss 0.37955179810523987  accuracy 0.92\n",
            "train loss 0.35843971371650696 accuracy 0.98 | test loss 0.3795711398124695  accuracy 0.92\n",
            "train loss 0.3584396243095398 accuracy 0.98 | test loss 0.37953874468803406  accuracy 0.92\n",
            "train loss 0.3584401309490204 accuracy 0.99 | test loss 0.37962013483047485  accuracy 0.92\n",
            "train loss 0.35844072699546814 accuracy 0.98 | test loss 0.37956634163856506  accuracy 0.92\n",
            "train loss 0.35843902826309204 accuracy 0.98 | test loss 0.37953394651412964  accuracy 0.92\n",
            "train loss 0.3584398329257965 accuracy 0.99 | test loss 0.37961530685424805  accuracy 0.92\n",
            "train loss 0.35844001173973083 accuracy 0.98 | test loss 0.37956157326698303  accuracy 0.92\n",
            "train loss 0.35843852162361145 accuracy 0.98 | test loss 0.3795686364173889  accuracy 0.92\n",
            "train loss 0.3584383428096771 accuracy 0.98 | test loss 0.37953615188598633  accuracy 0.92\n",
            "train loss 0.35843902826309204 accuracy 0.99 | test loss 0.3796175420284271  accuracy 0.92\n",
            "train loss 0.3584393262863159 accuracy 0.98 | test loss 0.37956365942955017  accuracy 0.92\n",
            "train loss 0.358437716960907 accuracy 0.98 | test loss 0.37957534193992615  accuracy 0.92\n",
            "train loss 0.3584378659725189 accuracy 0.98 | test loss 0.3795427978038788  accuracy 0.92\n",
            "train loss 0.35843780636787415 accuracy 0.99 | test loss 0.3796088695526123  accuracy 0.92\n",
            "train loss 0.35843849182128906 accuracy 0.98 | test loss 0.3795759379863739  accuracy 0.92\n",
            "train loss 0.3584374487400055 accuracy 0.98 | test loss 0.37954336404800415  accuracy 0.92\n",
            "train loss 0.3584371507167816 accuracy 0.99 | test loss 0.3795979619026184  accuracy 0.92\n",
            "train loss 0.3584376573562622 accuracy 0.98 | test loss 0.37956517934799194  accuracy 0.92\n",
            "train loss 0.3584368824958801 accuracy 0.98 | test loss 0.3795567750930786  accuracy 0.92\n",
            "train loss 0.35843637585639954 accuracy 0.98 | test loss 0.37954840064048767  accuracy 0.92\n",
            "train loss 0.35843634605407715 accuracy 0.99 | test loss 0.3796028792858124  accuracy 0.92\n",
            "train loss 0.35843712091445923 accuracy 0.98 | test loss 0.3795507848262787  accuracy 0.92\n",
            "train loss 0.35843604803085327 accuracy 0.98 | test loss 0.3795424699783325  accuracy 0.92\n",
            "train loss 0.3584356904029846 accuracy 0.98 | test loss 0.3795817494392395  accuracy 0.92\n",
            "train loss 0.3584362268447876 accuracy 0.98 | test loss 0.3795490860939026  accuracy 0.92\n",
            "train loss 0.3584352731704712 accuracy 0.98 | test loss 0.3795408606529236  accuracy 0.92\n",
            "train loss 0.3584352731704712 accuracy 0.98 | test loss 0.37957125902175903  accuracy 0.92\n",
            "train loss 0.35843542218208313 accuracy 0.98 | test loss 0.37953871488571167  accuracy 0.92\n",
            "train loss 0.3584350049495697 accuracy 0.98 | test loss 0.3795579969882965  accuracy 0.92\n",
            "train loss 0.358434796333313 accuracy 0.98 | test loss 0.3795495629310608  accuracy 0.92\n",
            "train loss 0.3584343492984772 accuracy 0.98 | test loss 0.37951719760894775  accuracy 0.92\n",
            "train loss 0.3584356904029846 accuracy 0.99 | test loss 0.37959855794906616  accuracy 0.92\n",
            "train loss 0.3584353029727936 accuracy 0.98 | test loss 0.37956568598747253  accuracy 0.92\n",
            "train loss 0.3584342896938324 accuracy 0.98 | test loss 0.3795330822467804  accuracy 0.92\n",
            "train loss 0.3584339916706085 accuracy 0.98 | test loss 0.3795791268348694  accuracy 0.92\n",
            "train loss 0.3584343194961548 accuracy 0.98 | test loss 0.37954649329185486  accuracy 0.92\n",
            "train loss 0.35843339562416077 accuracy 0.98 | test loss 0.37953826785087585  accuracy 0.92\n",
            "train loss 0.35843345522880554 accuracy 0.99 | test loss 0.37959274649620056  accuracy 0.92\n",
            "train loss 0.35843417048454285 accuracy 0.98 | test loss 0.37955978512763977  accuracy 0.92\n",
            "train loss 0.35843315720558167 accuracy 0.98 | test loss 0.3795272409915924  accuracy 0.92\n",
            "train loss 0.35843315720558167 accuracy 0.99 | test loss 0.3795934319496155  accuracy 0.92\n",
            "train loss 0.35843372344970703 accuracy 0.98 | test loss 0.3795604705810547  accuracy 0.92\n",
            "train loss 0.35843268036842346 accuracy 0.98 | test loss 0.37952789664268494  accuracy 0.92\n",
            "train loss 0.3584323823451996 accuracy 0.99 | test loss 0.3795825242996216  accuracy 0.92\n",
            "train loss 0.35843297839164734 accuracy 0.98 | test loss 0.3795287609100342  accuracy 0.92\n",
            "train loss 0.35843193531036377 accuracy 0.98 | test loss 0.37956804037094116  accuracy 0.92\n",
            "train loss 0.35843223333358765 accuracy 0.98 | test loss 0.379535436630249  accuracy 0.92\n",
            "train loss 0.35843169689178467 accuracy 0.98 | test loss 0.37952715158462524  accuracy 0.92\n",
            "train loss 0.3584316074848175 accuracy 0.99 | test loss 0.3795817494392395  accuracy 0.92\n",
            "train loss 0.3584320843219757 accuracy 0.98 | test loss 0.3795488178730011  accuracy 0.92\n",
            "train loss 0.3584311902523041 accuracy 0.98 | test loss 0.37954047322273254  accuracy 0.92\n",
            "train loss 0.3584307134151459 accuracy 0.98 | test loss 0.3795320391654968  accuracy 0.92\n",
            "train loss 0.3584308922290802 accuracy 0.99 | test loss 0.37958914041519165  accuracy 0.92\n",
            "train loss 0.35843169689178467 accuracy 0.98 | test loss 0.3795352876186371  accuracy 0.92\n",
            "train loss 0.35843023657798767 accuracy 0.98 | test loss 0.37954702973365784  accuracy 0.92\n",
            "train loss 0.3584301173686981 accuracy 0.98 | test loss 0.3795144557952881  accuracy 0.92\n",
            "train loss 0.3584309220314026 accuracy 0.99 | test loss 0.3795958161354065  accuracy 0.92\n",
            "train loss 0.35843130946159363 accuracy 0.98 | test loss 0.3795418441295624  accuracy 0.92\n",
            "train loss 0.35842955112457275 accuracy 0.98 | test loss 0.37953343987464905  accuracy 0.92\n",
            "train loss 0.35842955112457275 accuracy 0.98 | test loss 0.37956371903419495  accuracy 0.92\n",
            "train loss 0.35842975974082947 accuracy 0.98 | test loss 0.3795309364795685  accuracy 0.92\n",
            "train loss 0.3584292232990265 accuracy 0.98 | test loss 0.37955015897750854  accuracy 0.92\n",
            "train loss 0.35842907428741455 accuracy 0.98 | test loss 0.3795417845249176  accuracy 0.92\n",
            "train loss 0.35842862725257874 accuracy 0.98 | test loss 0.37950918078422546  accuracy 0.92\n",
            "train loss 0.3584299087524414 accuracy 0.99 | test loss 0.3795904815196991  accuracy 0.92\n",
            "train loss 0.3584296405315399 accuracy 0.98 | test loss 0.3795574903488159  accuracy 0.92\n",
            "train loss 0.35842856764793396 accuracy 0.98 | test loss 0.3795247972011566  accuracy 0.92\n",
            "train loss 0.3584281802177429 accuracy 0.99 | test loss 0.3795906603336334  accuracy 0.92\n",
            "train loss 0.3584291636943817 accuracy 0.98 | test loss 0.3795367479324341  accuracy 0.92\n",
            "train loss 0.3584277331829071 accuracy 0.98 | test loss 0.37954363226890564  accuracy 0.92\n",
            "train loss 0.358427494764328 accuracy 0.98 | test loss 0.3795110881328583  accuracy 0.92\n",
            "train loss 0.35842832922935486 accuracy 0.99 | test loss 0.3795923590660095  accuracy 0.92\n",
            "train loss 0.3584284782409668 accuracy 0.98 | test loss 0.37953832745552063  accuracy 0.92\n",
            "train loss 0.358426958322525 accuracy 0.98 | test loss 0.37954986095428467  accuracy 0.92\n",
            "train loss 0.3584270477294922 accuracy 0.98 | test loss 0.37951722741127014  accuracy 0.92\n",
            "train loss 0.35842710733413696 accuracy 0.99 | test loss 0.3795832097530365  accuracy 0.92\n",
            "train loss 0.35842764377593994 accuracy 0.98 | test loss 0.37955018877983093  accuracy 0.92\n",
            "train loss 0.358426570892334 accuracy 0.98 | test loss 0.3795175850391388  accuracy 0.92\n",
            "train loss 0.35842642188072205 accuracy 0.99 | test loss 0.3795720338821411  accuracy 0.92\n",
            "train loss 0.3584268093109131 accuracy 0.98 | test loss 0.3795391023159027  accuracy 0.92\n",
            "train loss 0.358426034450531 accuracy 0.98 | test loss 0.379530668258667  accuracy 0.92\n",
            "train loss 0.3584255874156952 accuracy 0.98 | test loss 0.3795222342014313  accuracy 0.92\n",
            "train loss 0.35842567682266235 accuracy 0.99 | test loss 0.3795766234397888  accuracy 0.92\n",
            "train loss 0.3584262430667877 accuracy 0.98 | test loss 0.3795436918735504  accuracy 0.92\n",
            "train loss 0.35842519998550415 accuracy 0.98 | test loss 0.37951093912124634  accuracy 0.92\n",
            "train loss 0.35842573642730713 accuracy 0.99 | test loss 0.3795768618583679  accuracy 0.92\n",
            "train loss 0.3584257662296295 accuracy 0.98 | test loss 0.37954387068748474  accuracy 0.92\n",
            "train loss 0.35842475295066833 accuracy 0.98 | test loss 0.37953540682792664  accuracy 0.92\n",
            "train loss 0.3584243059158325 accuracy 0.98 | test loss 0.3795027732849121  accuracy 0.92\n",
            "train loss 0.35842543840408325 accuracy 0.99 | test loss 0.3795841634273529  accuracy 0.92\n",
            "train loss 0.3584252893924713 accuracy 0.98 | test loss 0.379550963640213  accuracy 0.92\n",
            "train loss 0.35842421650886536 accuracy 0.98 | test loss 0.37951818108558655  accuracy 0.92\n",
            "train loss 0.35842376947402954 accuracy 0.98 | test loss 0.3795373737812042  accuracy 0.92\n",
            "train loss 0.35842353105545044 accuracy 0.98 | test loss 0.3795047402381897  accuracy 0.92\n",
            "train loss 0.3584241271018982 accuracy 0.99 | test loss 0.3795861005783081  accuracy 0.92\n",
            "train loss 0.35842466354370117 accuracy 0.98 | test loss 0.3795319199562073  accuracy 0.92\n",
            "train loss 0.3584230840206146 accuracy 0.98 | test loss 0.37952354550361633  accuracy 0.92\n",
            "train loss 0.3584229052066803 accuracy 0.98 | test loss 0.37955036759376526  accuracy 0.92\n",
            "train loss 0.35842299461364746 accuracy 0.98 | test loss 0.37951746582984924  accuracy 0.92\n",
            "train loss 0.35842275619506836 accuracy 0.99 | test loss 0.37958335876464844  accuracy 0.92\n",
            "train loss 0.3584236204624176 accuracy 0.98 | test loss 0.37955015897750854  accuracy 0.92\n",
            "train loss 0.35842254757881165 accuracy 0.98 | test loss 0.37951722741127014  accuracy 0.92\n",
            "train loss 0.35842201113700867 accuracy 0.98 | test loss 0.3795563280582428  accuracy 0.92\n",
            "train loss 0.3584224283695221 accuracy 0.98 | test loss 0.3795233964920044  accuracy 0.92\n",
            "train loss 0.35842165350914 accuracy 0.98 | test loss 0.3795149624347687  accuracy 0.92\n",
            "train loss 0.3584216237068176 accuracy 0.99 | test loss 0.37956932187080383  accuracy 0.92\n",
            "train loss 0.3584222197532654 accuracy 0.98 | test loss 0.3795362114906311  accuracy 0.92\n",
            "train loss 0.3584212362766266 accuracy 0.98 | test loss 0.37952756881713867  accuracy 0.92\n",
            "train loss 0.35842078924179077 accuracy 0.98 | test loss 0.37949496507644653  accuracy 0.92\n",
            "train loss 0.3584221303462982 accuracy 0.99 | test loss 0.379576176404953  accuracy 0.92\n",
            "train loss 0.35842177271842957 accuracy 0.98 | test loss 0.3795219957828522  accuracy 0.92\n",
            "train loss 0.3584202527999878 accuracy 0.98 | test loss 0.3795334994792938  accuracy 0.92\n",
            "train loss 0.3584202826023102 accuracy 0.98 | test loss 0.37950068712234497  accuracy 0.92\n",
            "train loss 0.3584209382534027 accuracy 0.99 | test loss 0.37958183884620667  accuracy 0.92\n",
            "train loss 0.35842135548591614 accuracy 0.98 | test loss 0.37952762842178345  accuracy 0.92\n",
            "train loss 0.35841962695121765 accuracy 0.98 | test loss 0.37949493527412415  accuracy 0.92\n",
            "train loss 0.3584206998348236 accuracy 0.99 | test loss 0.3795761168003082  accuracy 0.92\n",
            "train loss 0.35842064023017883 accuracy 0.98 | test loss 0.37954282760620117  accuracy 0.92\n",
            "train loss 0.3584195375442505 accuracy 0.98 | test loss 0.3795098662376404  accuracy 0.92\n",
            "train loss 0.35841917991638184 accuracy 0.98 | test loss 0.3795289397239685  accuracy 0.92\n",
            "train loss 0.35841888189315796 accuracy 0.98 | test loss 0.37952032685279846  accuracy 0.92\n",
            "train loss 0.35841861367225647 accuracy 0.98 | test loss 0.3795076012611389  accuracy 0.92\n",
            "train loss 0.35841861367225647 accuracy 0.98 | test loss 0.3795467019081116  accuracy 0.92\n",
            "train loss 0.35841888189315796 accuracy 0.98 | test loss 0.379513680934906  accuracy 0.92\n",
            "train loss 0.3584181070327759 accuracy 0.98 | test loss 0.37950530648231506  accuracy 0.92\n",
            "train loss 0.358418345451355 accuracy 0.99 | test loss 0.3795863389968872  accuracy 0.92\n",
            "train loss 0.3584195673465729 accuracy 0.98 | test loss 0.37953200936317444  accuracy 0.92\n",
            "train loss 0.358417809009552 accuracy 0.98 | test loss 0.37949907779693604  accuracy 0.92\n",
            "train loss 0.3584181070327759 accuracy 0.99 | test loss 0.3795802593231201  accuracy 0.92\n",
            "train loss 0.3584187924861908 accuracy 0.98 | test loss 0.3795468807220459  accuracy 0.92\n",
            "train loss 0.35841771960258484 accuracy 0.98 | test loss 0.37951385974884033  accuracy 0.92\n",
            "train loss 0.35841700434684753 accuracy 0.98 | test loss 0.379505455493927  accuracy 0.92\n",
            "train loss 0.35841700434684753 accuracy 0.99 | test loss 0.3795596957206726  accuracy 0.92\n",
            "train loss 0.3584175109863281 accuracy 0.98 | test loss 0.3795265853404999  accuracy 0.92\n",
            "train loss 0.3584165573120117 accuracy 0.98 | test loss 0.3795178234577179  accuracy 0.92\n",
            "train loss 0.35841605067253113 accuracy 0.98 | test loss 0.37951263785362244  accuracy 0.92\n",
            "train loss 0.35841599106788635 accuracy 0.98 | test loss 0.37950414419174194  accuracy 0.92\n",
            "train loss 0.35841619968414307 accuracy 0.99 | test loss 0.3795851767063141  accuracy 0.92\n",
            "train loss 0.3584175109863281 accuracy 0.98 | test loss 0.3795114755630493  accuracy 0.92\n",
            "train loss 0.35841548442840576 accuracy 0.98 | test loss 0.3795182406902313  accuracy 0.92\n",
            "train loss 0.3584153652191162 accuracy 0.98 | test loss 0.37948545813560486  accuracy 0.92\n",
            "train loss 0.35841619968414307 accuracy 0.99 | test loss 0.37956658005714417  accuracy 0.92\n",
            "train loss 0.358416348695755 accuracy 0.98 | test loss 0.3795332610607147  accuracy 0.92\n",
            "train loss 0.35841527581214905 accuracy 0.98 | test loss 0.37950029969215393  accuracy 0.92\n",
            "train loss 0.35841476917266846 accuracy 0.98 | test loss 0.37953925132751465  accuracy 0.92\n",
            "train loss 0.3584151268005371 accuracy 0.98 | test loss 0.37950626015663147  accuracy 0.92\n",
            "train loss 0.3584144413471222 accuracy 0.98 | test loss 0.37949779629707336  accuracy 0.92\n",
            "train loss 0.35841426253318787 accuracy 0.98 | test loss 0.3795366883277893  accuracy 0.92\n",
            "train loss 0.35841459035873413 accuracy 0.98 | test loss 0.37950369715690613  accuracy 0.92\n",
            "train loss 0.3584137558937073 accuracy 0.98 | test loss 0.379495233297348  accuracy 0.92\n",
            "train loss 0.3584138751029968 accuracy 0.99 | test loss 0.37954947352409363  accuracy 0.92\n",
            "train loss 0.3584144115447998 accuracy 0.98 | test loss 0.37951627373695374  accuracy 0.92\n",
            "train loss 0.35841333866119385 accuracy 0.98 | test loss 0.3794834017753601  accuracy 0.92\n",
            "train loss 0.3584139049053192 accuracy 0.99 | test loss 0.37954920530319214  accuracy 0.92\n",
            "train loss 0.358413964509964 accuracy 0.98 | test loss 0.379516065120697  accuracy 0.92\n",
            "train loss 0.35841289162635803 accuracy 0.98 | test loss 0.37950727343559265  accuracy 0.92\n",
            "train loss 0.3584124743938446 accuracy 0.98 | test loss 0.3794745206832886  accuracy 0.92\n",
            "train loss 0.3584137558937073 accuracy 0.99 | test loss 0.3795556426048279  accuracy 0.92\n",
            "train loss 0.358413428068161 accuracy 0.98 | test loss 0.3795223534107208  accuracy 0.92\n",
            "train loss 0.35841238498687744 accuracy 0.98 | test loss 0.37948939204216003  accuracy 0.92\n",
            "train loss 0.3584119975566864 accuracy 0.98 | test loss 0.3795284330844879  accuracy 0.92\n",
            "train loss 0.3584122359752655 accuracy 0.98 | test loss 0.37949541211128235  accuracy 0.92\n",
            "train loss 0.35841163992881775 accuracy 0.98 | test loss 0.37948691844940186  accuracy 0.92\n",
            "train loss 0.35841163992881775 accuracy 0.99 | test loss 0.37956804037094116  accuracy 0.92\n",
            "train loss 0.3584131598472595 accuracy 0.98 | test loss 0.379513680934906  accuracy 0.92\n",
            "train loss 0.35841116309165955 accuracy 0.98 | test loss 0.3794807493686676  accuracy 0.92\n",
            "train loss 0.35841140151023865 accuracy 0.99 | test loss 0.3795618414878845  accuracy 0.92\n",
            "train loss 0.35841232538223267 accuracy 0.98 | test loss 0.37950751185417175  accuracy 0.92\n",
            "train loss 0.3584105670452118 accuracy 0.98 | test loss 0.3794988989830017  accuracy 0.92\n",
            "train loss 0.35841047763824463 accuracy 0.98 | test loss 0.3795013427734375  accuracy 0.92\n",
            "train loss 0.3584102690219879 accuracy 0.98 | test loss 0.37949255108833313  accuracy 0.92\n",
            "train loss 0.3584100604057312 accuracy 0.98 | test loss 0.37953147292137146  accuracy 0.92\n",
            "train loss 0.35841044783592224 accuracy 0.98 | test loss 0.37949833273887634  accuracy 0.92\n",
            "train loss 0.35840949416160583 accuracy 0.98 | test loss 0.3794896602630615  accuracy 0.92\n",
            "train loss 0.3584096431732178 accuracy 0.99 | test loss 0.3795437812805176  accuracy 0.92\n",
            "train loss 0.3584102690219879 accuracy 0.98 | test loss 0.3795104920864105  accuracy 0.92\n",
            "train loss 0.35840919613838196 accuracy 0.98 | test loss 0.37947753071784973  accuracy 0.92\n",
            "train loss 0.3584097921848297 accuracy 0.99 | test loss 0.37954336404800415  accuracy 0.92\n",
            "train loss 0.3584097921848297 accuracy 0.98 | test loss 0.3795100450515747  accuracy 0.92\n",
            "train loss 0.35840871930122375 accuracy 0.98 | test loss 0.3794770836830139  accuracy 0.92\n",
            "train loss 0.35840892791748047 accuracy 0.99 | test loss 0.37954291701316833  accuracy 0.92\n",
            "train loss 0.3584093451499939 accuracy 0.98 | test loss 0.3795095980167389  accuracy 0.92\n",
            "train loss 0.3584083616733551 accuracy 0.98 | test loss 0.3795008063316345  accuracy 0.92\n",
            "train loss 0.3584078848361969 accuracy 0.98 | test loss 0.379483163356781  accuracy 0.92\n",
            "train loss 0.3584078550338745 accuracy 0.98 | test loss 0.37952888011932373  accuracy 0.92\n",
            "train loss 0.35840824246406555 accuracy 0.98 | test loss 0.37949568033218384  accuracy 0.92\n",
            "train loss 0.35840728878974915 accuracy 0.98 | test loss 0.3794870376586914  accuracy 0.92\n",
            "train loss 0.35840749740600586 accuracy 0.98 | test loss 0.37951698899269104  accuracy 0.92\n",
            "train loss 0.3584074378013611 accuracy 0.98 | test loss 0.3794839382171631  accuracy 0.92\n",
            "train loss 0.3584069609642029 accuracy 0.98 | test loss 0.3795028626918793  accuracy 0.92\n",
            "train loss 0.35840675234794617 accuracy 0.98 | test loss 0.3794941008090973  accuracy 0.92\n",
            "train loss 0.3584064543247223 accuracy 0.98 | test loss 0.3794964849948883  accuracy 0.92\n",
            "train loss 0.3584064841270447 accuracy 0.98 | test loss 0.3794877231121063  accuracy 0.92\n",
            "train loss 0.3584061861038208 accuracy 0.98 | test loss 0.3795265555381775  accuracy 0.92\n",
            "train loss 0.358406662940979 accuracy 0.98 | test loss 0.3794933259487152  accuracy 0.92\n",
            "train loss 0.3584057092666626 accuracy 0.98 | test loss 0.37948447465896606  accuracy 0.92\n",
            "train loss 0.358405739068985 accuracy 0.99 | test loss 0.37955009937286377  accuracy 0.92\n",
            "train loss 0.3584068715572357 accuracy 0.98 | test loss 0.3795166611671448  accuracy 0.92\n",
            "train loss 0.35840579867362976 accuracy 0.98 | test loss 0.37948352098464966  accuracy 0.92\n",
            "train loss 0.35840511322021484 accuracy 0.99 | test loss 0.3795376121997833  accuracy 0.92\n",
            "train loss 0.35840606689453125 accuracy 0.98 | test loss 0.3794833719730377  accuracy 0.92\n",
            "train loss 0.3584046959877014 accuracy 0.98 | test loss 0.3795222342014313  accuracy 0.92\n",
            "train loss 0.35840529203414917 accuracy 0.98 | test loss 0.3794889450073242  accuracy 0.92\n",
            "train loss 0.3584043085575104 accuracy 0.98 | test loss 0.3794802129268646  accuracy 0.92\n",
            "train loss 0.3584044575691223 accuracy 0.98 | test loss 0.3795100748538971  accuracy 0.92\n",
            "train loss 0.3584044277667999 accuracy 0.98 | test loss 0.37947699427604675  accuracy 0.92\n",
            "train loss 0.35840415954589844 accuracy 0.98 | test loss 0.3795226216316223  accuracy 0.92\n",
            "train loss 0.3584044575691223 accuracy 0.98 | test loss 0.37948936223983765  accuracy 0.92\n",
            "train loss 0.35840362310409546 accuracy 0.98 | test loss 0.3794805407524109  accuracy 0.92\n",
            "train loss 0.35840341448783875 accuracy 0.99 | test loss 0.37953466176986694  accuracy 0.92\n",
            "train loss 0.3584043085575104 accuracy 0.98 | test loss 0.37950122356414795  accuracy 0.92\n",
            "train loss 0.35840320587158203 accuracy 0.98 | test loss 0.37946826219558716  accuracy 0.92\n",
            "train loss 0.3584033250808716 accuracy 0.99 | test loss 0.379533976316452  accuracy 0.92\n",
            "train loss 0.3584038317203522 accuracy 0.98 | test loss 0.37947970628738403  accuracy 0.92\n",
            "train loss 0.35840263962745667 accuracy 0.98 | test loss 0.37950626015663147  accuracy 0.92\n",
            "train loss 0.35840266942977905 accuracy 0.98 | test loss 0.37947314977645874  accuracy 0.92\n",
            "train loss 0.3584023118019104 accuracy 0.98 | test loss 0.3795188069343567  accuracy 0.92\n",
            "train loss 0.35840269923210144 accuracy 0.98 | test loss 0.37948545813560486  accuracy 0.92\n",
            "train loss 0.3584018349647522 accuracy 0.98 | test loss 0.37949201464653015  accuracy 0.92\n",
            "train loss 0.3584015667438507 accuracy 0.98 | test loss 0.3794589936733246  accuracy 0.92\n",
            "train loss 0.35840263962745667 accuracy 0.99 | test loss 0.37954002618789673  accuracy 0.92\n",
            "train loss 0.35840272903442383 accuracy 0.98 | test loss 0.37948545813560486  accuracy 0.92\n",
            "train loss 0.35840094089508057 accuracy 0.98 | test loss 0.37949660420417786  accuracy 0.92\n",
            "train loss 0.35840103030204773 accuracy 0.98 | test loss 0.3794635832309723  accuracy 0.92\n",
            "train loss 0.35840150713920593 accuracy 0.99 | test loss 0.3795446455478668  accuracy 0.92\n",
            "train loss 0.3584022521972656 accuracy 0.98 | test loss 0.37949004769325256  accuracy 0.92\n",
            "train loss 0.3584004044532776 accuracy 0.98 | test loss 0.3794569671154022  accuracy 0.92\n",
            "train loss 0.3584013283252716 accuracy 0.99 | test loss 0.37953802943229675  accuracy 0.92\n",
            "train loss 0.35840141773223877 accuracy 0.98 | test loss 0.37948355078697205  accuracy 0.92\n",
            "train loss 0.3583998382091522 accuracy 0.98 | test loss 0.37949466705322266  accuracy 0.92\n",
            "train loss 0.3583998382091522 accuracy 0.98 | test loss 0.37946149706840515  accuracy 0.92\n",
            "train loss 0.35840025544166565 accuracy 0.99 | test loss 0.3795425295829773  accuracy 0.92\n",
            "train loss 0.3584009110927582 accuracy 0.98 | test loss 0.3794879913330078  accuracy 0.92\n",
            "train loss 0.3583991825580597 accuracy 0.98 | test loss 0.3794790506362915  accuracy 0.92\n",
            "train loss 0.3583991825580597 accuracy 0.98 | test loss 0.379508912563324  accuracy 0.92\n",
            "train loss 0.3583994209766388 accuracy 0.98 | test loss 0.3794756233692169  accuracy 0.92\n",
            "train loss 0.3583988547325134 accuracy 0.98 | test loss 0.37946680188179016  accuracy 0.92\n",
            "train loss 0.3583988547325134 accuracy 0.99 | test loss 0.3795323967933655  accuracy 0.92\n",
            "train loss 0.35839956998825073 accuracy 0.98 | test loss 0.3794988691806793  accuracy 0.92\n",
            "train loss 0.3583984971046448 accuracy 0.98 | test loss 0.37946566939353943  accuracy 0.92\n",
            "train loss 0.3583981990814209 accuracy 0.99 | test loss 0.3795197308063507  accuracy 0.92\n",
            "train loss 0.3583987355232239 accuracy 0.98 | test loss 0.3794863522052765  accuracy 0.92\n",
            "train loss 0.3583979606628418 accuracy 0.98 | test loss 0.3794773817062378  accuracy 0.92\n",
            "train loss 0.3583974242210388 accuracy 0.98 | test loss 0.37946853041648865  accuracy 0.92\n",
            "train loss 0.358397513628006 accuracy 0.98 | test loss 0.3795072138309479  accuracy 0.92\n",
            "train loss 0.3583976924419403 accuracy 0.98 | test loss 0.37947386503219604  accuracy 0.92\n",
            "train loss 0.35839682817459106 accuracy 0.98 | test loss 0.3795125484466553  accuracy 0.92\n",
            "train loss 0.35839760303497314 accuracy 0.98 | test loss 0.37947916984558105  accuracy 0.92\n",
            "train loss 0.3583965301513672 accuracy 0.98 | test loss 0.3794703185558319  accuracy 0.92\n",
            "train loss 0.3583966791629791 accuracy 0.98 | test loss 0.379500150680542  accuracy 0.92\n",
            "train loss 0.3583967089653015 accuracy 0.98 | test loss 0.37946686148643494  accuracy 0.92\n",
            "train loss 0.3583962023258209 accuracy 0.98 | test loss 0.379485547542572  accuracy 0.92\n",
            "train loss 0.3583959937095642 accuracy 0.98 | test loss 0.3794523775577545  accuracy 0.92\n",
            "train loss 0.35839641094207764 accuracy 0.99 | test loss 0.3795333504676819  accuracy 0.92\n",
            "train loss 0.3583972752094269 accuracy 0.98 | test loss 0.3794787526130676  accuracy 0.92\n",
            "train loss 0.35839545726776123 accuracy 0.98 | test loss 0.37946978211402893  accuracy 0.92\n",
            "train loss 0.35839515924453735 accuracy 0.99 | test loss 0.37952369451522827  accuracy 0.92\n",
            "train loss 0.35839617252349854 accuracy 0.98 | test loss 0.37949007749557495  accuracy 0.92\n",
            "train loss 0.3583950698375702 accuracy 0.98 | test loss 0.3794567286968231  accuracy 0.92\n",
            "train loss 0.35839515924453735 accuracy 0.99 | test loss 0.3795223534107208  accuracy 0.92\n",
            "train loss 0.35839569568634033 accuracy 0.98 | test loss 0.3794887959957123  accuracy 0.92\n",
            "train loss 0.35839465260505676 accuracy 0.98 | test loss 0.37947967648506165  accuracy 0.92\n",
            "train loss 0.35839420557022095 accuracy 0.98 | test loss 0.37944647669792175  accuracy 0.92\n",
            "train loss 0.3583950400352478 accuracy 0.99 | test loss 0.37952741980552673  accuracy 0.92\n",
            "train loss 0.35839518904685974 accuracy 0.98 | test loss 0.37947285175323486  accuracy 0.92\n",
            "train loss 0.3583936095237732 accuracy 0.98 | test loss 0.37947916984558105  accuracy 0.92\n",
            "train loss 0.35839346051216125 accuracy 0.98 | test loss 0.3794459104537964  accuracy 0.92\n",
            "train loss 0.35839447379112244 accuracy 0.99 | test loss 0.3795267343521118  accuracy 0.92\n",
            "train loss 0.35839447379112244 accuracy 0.98 | test loss 0.37949296832084656  accuracy 0.92\n",
            "train loss 0.3583933115005493 accuracy 0.98 | test loss 0.3794596493244171  accuracy 0.92\n",
            "train loss 0.3583929240703583 accuracy 0.98 | test loss 0.3794783353805542  accuracy 0.92\n",
            "train loss 0.3583926260471344 accuracy 0.98 | test loss 0.37946924567222595  accuracy 0.92\n",
            "train loss 0.3583924472332001 accuracy 0.98 | test loss 0.3794836401939392  accuracy 0.92\n",
            "train loss 0.35839247703552246 accuracy 0.98 | test loss 0.37945032119750977  accuracy 0.92\n",
            "train loss 0.35839247703552246 accuracy 0.99 | test loss 0.3795311748981476  accuracy 0.92\n",
            "train loss 0.35839372873306274 accuracy 0.98 | test loss 0.379476398229599  accuracy 0.92\n",
            "train loss 0.3583919405937195 accuracy 0.98 | test loss 0.37946727871894836  accuracy 0.92\n",
            "train loss 0.35839155316352844 accuracy 0.98 | test loss 0.3794935941696167  accuracy 0.92\n",
            "train loss 0.3583918809890747 accuracy 0.98 | test loss 0.3794602155685425  accuracy 0.92\n",
            "train loss 0.3583913743495941 accuracy 0.99 | test loss 0.3795255720615387  accuracy 0.92\n",
            "train loss 0.35839247703552246 accuracy 0.98 | test loss 0.3794918358325958  accuracy 0.92\n",
            "train loss 0.3583914041519165 accuracy 0.98 | test loss 0.3794584572315216  accuracy 0.92\n",
            "train loss 0.3583907186985016 accuracy 0.98 | test loss 0.3794495761394501  accuracy 0.92\n",
            "train loss 0.3583911061286926 accuracy 0.99 | test loss 0.3795303404331207  accuracy 0.92\n",
            "train loss 0.35839203000068665 accuracy 0.98 | test loss 0.37947553396224976  accuracy 0.92\n",
            "train loss 0.35839027166366577 accuracy 0.98 | test loss 0.3794422447681427  accuracy 0.92\n",
            "train loss 0.3583909571170807 accuracy 0.99 | test loss 0.37952300906181335  accuracy 0.92\n",
            "train loss 0.35839125514030457 accuracy 0.98 | test loss 0.3794892728328705  accuracy 0.92\n",
            "train loss 0.3583901524543762 accuracy 0.98 | test loss 0.37945595383644104  accuracy 0.92\n",
            "train loss 0.35838958621025085 accuracy 0.98 | test loss 0.3794670104980469  accuracy 0.92\n",
            "train loss 0.3583894371986389 accuracy 0.98 | test loss 0.37945789098739624  accuracy 0.92\n",
            "train loss 0.3583891987800598 accuracy 0.98 | test loss 0.3794964849948883  accuracy 0.92\n",
            "train loss 0.3583897352218628 accuracy 0.98 | test loss 0.37946298718452454  accuracy 0.92\n",
            "train loss 0.35838866233825684 accuracy 0.98 | test loss 0.37945395708084106  accuracy 0.92\n",
            "train loss 0.3583889603614807 accuracy 0.98 | test loss 0.37948355078697205  accuracy 0.92\n",
            "train loss 0.3583888113498688 accuracy 0.98 | test loss 0.3794502317905426  accuracy 0.92\n",
            "train loss 0.3583885133266449 accuracy 0.98 | test loss 0.3794955611228943  accuracy 0.92\n",
            "train loss 0.35838890075683594 accuracy 0.98 | test loss 0.3794620931148529  accuracy 0.92\n",
            "train loss 0.3583879768848419 accuracy 0.98 | test loss 0.37945303320884705  accuracy 0.92\n",
            "train loss 0.3583879768848419 accuracy 0.99 | test loss 0.3795069456100464  accuracy 0.92\n",
            "train loss 0.35838866233825684 accuracy 0.98 | test loss 0.3794732689857483  accuracy 0.92\n",
            "train loss 0.3583875596523285 accuracy 0.98 | test loss 0.3794398903846741  accuracy 0.92\n",
            "train loss 0.35838785767555237 accuracy 0.99 | test loss 0.37950536608695984  accuracy 0.92\n",
            "train loss 0.35838815569877625 accuracy 0.98 | test loss 0.37947171926498413  accuracy 0.92\n",
            "train loss 0.35838714241981506 accuracy 0.98 | test loss 0.3794625699520111  accuracy 0.92\n",
            "train loss 0.35838666558265686 accuracy 0.98 | test loss 0.37944456934928894  accuracy 0.92\n",
            "train loss 0.35838690400123596 accuracy 0.99 | test loss 0.37950995564460754  accuracy 0.92\n",
            "train loss 0.35838761925697327 accuracy 0.98 | test loss 0.3794762194156647  accuracy 0.92\n",
            "train loss 0.3583865165710449 accuracy 0.98 | test loss 0.37944281101226807  accuracy 0.92\n",
            "train loss 0.35838615894317627 accuracy 0.98 | test loss 0.3794814348220825  accuracy 0.92\n",
            "train loss 0.358386367559433 accuracy 0.98 | test loss 0.3794479966163635  accuracy 0.92\n",
            "train loss 0.35838583111763 accuracy 0.98 | test loss 0.3794390857219696  accuracy 0.92\n",
            "train loss 0.35838595032691956 accuracy 0.99 | test loss 0.37949293851852417  accuracy 0.92\n",
            "train loss 0.35838615894317627 accuracy 0.98 | test loss 0.37945932149887085  accuracy 0.92\n",
            "train loss 0.3583853840827942 accuracy 0.98 | test loss 0.3794502317905426  accuracy 0.92\n",
            "train loss 0.3583849370479584 accuracy 0.98 | test loss 0.379468709230423  accuracy 0.92\n",
            "train loss 0.35838499665260315 accuracy 0.98 | test loss 0.37943533062934875  accuracy 0.92\n",
            "train loss 0.3583854138851166 accuracy 0.99 | test loss 0.379516065120697  accuracy 0.92\n",
            "train loss 0.3583860695362091 accuracy 0.98 | test loss 0.3794611990451813  accuracy 0.92\n",
            "train loss 0.35838431119918823 accuracy 0.98 | test loss 0.37944310903549194  accuracy 0.92\n",
            "train loss 0.35838431119918823 accuracy 0.99 | test loss 0.37950849533081055  accuracy 0.92\n",
            "train loss 0.35838526487350464 accuracy 0.98 | test loss 0.3794747591018677  accuracy 0.92\n",
            "train loss 0.3583841621875763 accuracy 0.98 | test loss 0.3794413208961487  accuracy 0.92\n",
            "train loss 0.3583837151527405 accuracy 0.98 | test loss 0.3794524371623993  accuracy 0.92\n",
            "train loss 0.35838350653648376 accuracy 0.98 | test loss 0.3794432282447815  accuracy 0.92\n",
            "train loss 0.358383446931839 accuracy 0.99 | test loss 0.3794970214366913  accuracy 0.92\n",
            "train loss 0.35838407278060913 accuracy 0.98 | test loss 0.379463255405426  accuracy 0.92\n",
            "train loss 0.35838305950164795 accuracy 0.98 | test loss 0.379454106092453  accuracy 0.92\n",
            "train loss 0.35838255286216736 accuracy 0.98 | test loss 0.3794483244419098  accuracy 0.92\n",
            "train loss 0.3583824038505554 accuracy 0.98 | test loss 0.3794391453266144  accuracy 0.92\n",
            "train loss 0.35838285088539124 accuracy 0.99 | test loss 0.37951987981796265  accuracy 0.92\n",
            "train loss 0.35838404297828674 accuracy 0.98 | test loss 0.37946486473083496  accuracy 0.92\n",
            "train loss 0.3583822548389435 accuracy 0.98 | test loss 0.37943145632743835  accuracy 0.92\n",
            "train loss 0.3583827614784241 accuracy 0.99 | test loss 0.37951216101646423  accuracy 0.92\n",
            "train loss 0.3583832383155823 accuracy 0.98 | test loss 0.3794781267642975  accuracy 0.92\n",
            "train loss 0.35838210582733154 accuracy 0.98 | test loss 0.37944450974464417  accuracy 0.92\n",
            "train loss 0.35838133096694946 accuracy 0.98 | test loss 0.37945547699928284  accuracy 0.92\n",
            "train loss 0.35838115215301514 accuracy 0.98 | test loss 0.37942206859588623  accuracy 0.92\n",
            "train loss 0.35838210582733154 accuracy 0.99 | test loss 0.3795028626918793  accuracy 0.92\n",
            "train loss 0.35838228464126587 accuracy 0.98 | test loss 0.37944793701171875  accuracy 0.92\n",
            "train loss 0.35838061571121216 accuracy 0.98 | test loss 0.3794387876987457  accuracy 0.92\n",
            "train loss 0.3583807647228241 accuracy 0.99 | test loss 0.37949249148368835  accuracy 0.92\n",
            "train loss 0.35838133096694946 accuracy 0.98 | test loss 0.3794586956501007  accuracy 0.92\n",
            "train loss 0.3583802282810211 accuracy 0.98 | test loss 0.37942519783973694  accuracy 0.92\n",
            "train loss 0.35838085412979126 accuracy 0.99 | test loss 0.37949058413505554  accuracy 0.92\n",
            "train loss 0.3583807945251465 accuracy 0.98 | test loss 0.37945690751075745  accuracy 0.92\n",
            "train loss 0.3583797514438629 accuracy 0.98 | test loss 0.3794476091861725  accuracy 0.92\n",
            "train loss 0.3583793640136719 accuracy 0.98 | test loss 0.3794495165348053  accuracy 0.92\n",
            "train loss 0.3583795130252838 accuracy 0.98 | test loss 0.3794403076171875  accuracy 0.92\n",
            "train loss 0.35837921500205994 accuracy 0.98 | test loss 0.37948545813560486  accuracy 0.92\n",
            "train loss 0.3583798110485077 accuracy 0.98 | test loss 0.3794517517089844  accuracy 0.92\n",
            "train loss 0.35837873816490173 accuracy 0.98 | test loss 0.379418283700943  accuracy 0.92\n",
            "train loss 0.3583798110485077 accuracy 0.99 | test loss 0.37949901819229126  accuracy 0.92\n",
            "train loss 0.3583797514438629 accuracy 0.98 | test loss 0.3794650435447693  accuracy 0.92\n",
            "train loss 0.3583785891532898 accuracy 0.98 | test loss 0.37943145632743835  accuracy 0.92\n",
            "train loss 0.35837826132774353 accuracy 0.98 | test loss 0.37946999073028564  accuracy 0.92\n",
            "train loss 0.35837844014167786 accuracy 0.98 | test loss 0.3794362545013428  accuracy 0.92\n",
            "train loss 0.3583778440952301 accuracy 0.98 | test loss 0.37942713499069214  accuracy 0.92\n",
            "train loss 0.3583779036998749 accuracy 0.99 | test loss 0.3795076906681061  accuracy 0.92\n",
            "train loss 0.3583792746067047 accuracy 0.98 | test loss 0.379452645778656  accuracy 0.92\n",
            "train loss 0.3583773076534271 accuracy 0.98 | test loss 0.3794191777706146  accuracy 0.92\n",
            "train loss 0.3583778440952301 accuracy 0.99 | test loss 0.3794998824596405  accuracy 0.92\n",
            "train loss 0.35837841033935547 accuracy 0.98 | test loss 0.3794448673725128  accuracy 0.92\n",
            "train loss 0.35837671160697937 accuracy 0.98 | test loss 0.3794356882572174  accuracy 0.92\n",
            "train loss 0.35837677121162415 accuracy 0.99 | test loss 0.37948939204216003  accuracy 0.92\n",
            "train loss 0.35837745666503906 accuracy 0.98 | test loss 0.37945547699928284  accuracy 0.92\n",
            "train loss 0.3583763837814331 accuracy 0.98 | test loss 0.3794219195842743  accuracy 0.92\n",
            "train loss 0.35837650299072266 accuracy 0.99 | test loss 0.3794870972633362  accuracy 0.92\n",
            "train loss 0.35837697982788086 accuracy 0.98 | test loss 0.379453182220459  accuracy 0.92\n",
            "train loss 0.3583758473396301 accuracy 0.98 | test loss 0.37944379448890686  accuracy 0.92\n",
            "train loss 0.35837554931640625 accuracy 0.98 | test loss 0.3794456422328949  accuracy 0.92\n",
            "train loss 0.35837554931640625 accuracy 0.98 | test loss 0.3794362545013428  accuracy 0.92\n",
            "train loss 0.35837507247924805 accuracy 0.98 | test loss 0.3794545531272888  accuracy 0.92\n",
            "train loss 0.3583751916885376 accuracy 0.98 | test loss 0.3794208765029907  accuracy 0.92\n",
            "train loss 0.3583754003047943 accuracy 0.99 | test loss 0.3795014023780823  accuracy 0.92\n",
            "train loss 0.35837623476982117 accuracy 0.98 | test loss 0.3794463276863098  accuracy 0.92\n",
            "train loss 0.3583744764328003 accuracy 0.98 | test loss 0.37941280007362366  accuracy 0.92\n",
            "train loss 0.35837531089782715 accuracy 0.99 | test loss 0.37949347496032715  accuracy 0.92\n",
            "train loss 0.3583754599094391 accuracy 0.98 | test loss 0.3794594407081604  accuracy 0.92\n",
            "train loss 0.35837432742118835 accuracy 0.98 | test loss 0.3794257342815399  accuracy 0.92\n",
            "train loss 0.3583739101886749 accuracy 0.98 | test loss 0.3794640898704529  accuracy 0.92\n",
            "train loss 0.3583741784095764 accuracy 0.98 | test loss 0.3794304132461548  accuracy 0.92\n",
            "train loss 0.35837358236312866 accuracy 0.98 | test loss 0.3794211447238922  accuracy 0.92\n",
            "train loss 0.3583735525608063 accuracy 0.99 | test loss 0.379474937915802  accuracy 0.92\n",
            "train loss 0.3583739399909973 accuracy 0.98 | test loss 0.3794409930706024  accuracy 0.92\n",
            "train loss 0.35837313532829285 accuracy 0.98 | test loss 0.3794316053390503  accuracy 0.92\n",
            "train loss 0.35837268829345703 accuracy 0.98 | test loss 0.3794699013233185  accuracy 0.92\n",
            "train loss 0.3583733141422272 accuracy 0.98 | test loss 0.37943601608276367  accuracy 0.92\n",
            "train loss 0.3583723306655884 accuracy 0.98 | test loss 0.3794266879558563  accuracy 0.92\n",
            "train loss 0.358372300863266 accuracy 0.99 | test loss 0.3794803023338318  accuracy 0.92\n",
            "train loss 0.35837310552597046 accuracy 0.98 | test loss 0.3794461786746979  accuracy 0.92\n",
            "train loss 0.3583720028400421 accuracy 0.98 | test loss 0.37941253185272217  accuracy 0.92\n",
            "train loss 0.35837242007255554 accuracy 0.99 | test loss 0.37947776913642883  accuracy 0.92\n",
            "train loss 0.35837259888648987 accuracy 0.98 | test loss 0.3794437348842621  accuracy 0.92\n",
            "train loss 0.3583714962005615 accuracy 0.98 | test loss 0.3794342577457428  accuracy 0.92\n",
            "train loss 0.3583710491657257 accuracy 0.98 | test loss 0.37940073013305664  accuracy 0.92\n",
            "train loss 0.35837242007255554 accuracy 0.99 | test loss 0.37948137521743774  accuracy 0.92\n",
            "train loss 0.3583720326423645 accuracy 0.98 | test loss 0.3794472813606262  accuracy 0.92\n",
            "train loss 0.35837092995643616 accuracy 0.98 | test loss 0.3794136345386505  accuracy 0.92\n",
            "train loss 0.35837072134017944 accuracy 0.99 | test loss 0.3794788420200348  accuracy 0.92\n",
            "train loss 0.3583714962005615 accuracy 0.98 | test loss 0.3794447183609009  accuracy 0.92\n",
            "train loss 0.35837051272392273 accuracy 0.98 | test loss 0.379435271024704  accuracy 0.92\n",
            "train loss 0.35836997628211975 accuracy 0.98 | test loss 0.3794170022010803  accuracy 0.92\n",
            "train loss 0.3583698868751526 accuracy 0.98 | test loss 0.3794553279876709  accuracy 0.92\n",
            "train loss 0.35837021470069885 accuracy 0.98 | test loss 0.37942156195640564  accuracy 0.92\n",
            "train loss 0.35836949944496155 accuracy 0.98 | test loss 0.3794122338294983  accuracy 0.92\n",
            "train loss 0.3583695888519287 accuracy 0.99 | test loss 0.3794926404953003  accuracy 0.92\n",
            "train loss 0.3583710789680481 accuracy 0.98 | test loss 0.37943747639656067  accuracy 0.92\n",
            "train loss 0.35836899280548096 accuracy 0.98 | test loss 0.37940382957458496  accuracy 0.92\n",
            "train loss 0.35836949944496155 accuracy 0.99 | test loss 0.3794843256473541  accuracy 0.92\n",
            "train loss 0.3583701252937317 accuracy 0.98 | test loss 0.3794291615486145  accuracy 0.92\n",
            "train loss 0.358368456363678 accuracy 0.98 | test loss 0.37941974401474  accuracy 0.92\n",
            "train loss 0.35836848616600037 accuracy 0.99 | test loss 0.37947335839271545  accuracy 0.92\n",
            "train loss 0.3583691716194153 accuracy 0.98 | test loss 0.37943926453590393  accuracy 0.92\n",
            "train loss 0.35836803913116455 accuracy 0.98 | test loss 0.37940549850463867  accuracy 0.92\n",
            "train loss 0.35836830735206604 accuracy 0.99 | test loss 0.37947070598602295  accuracy 0.92\n",
            "train loss 0.3583686351776123 accuracy 0.98 | test loss 0.3794366419315338  accuracy 0.92\n",
            "train loss 0.35836753249168396 accuracy 0.98 | test loss 0.3794271647930145  accuracy 0.92\n",
            "train loss 0.3583672344684601 accuracy 0.98 | test loss 0.3794288635253906  accuracy 0.92\n",
            "train loss 0.35836729407310486 accuracy 0.98 | test loss 0.37941932678222656  accuracy 0.92\n",
            "train loss 0.35836684703826904 accuracy 0.98 | test loss 0.37945759296417236  accuracy 0.92\n",
            "train loss 0.358367383480072 accuracy 0.98 | test loss 0.3794235289096832  accuracy 0.92\n",
            "train loss 0.3583664894104004 accuracy 0.98 | test loss 0.37941405177116394  accuracy 0.92\n",
            "train loss 0.3583664298057556 accuracy 0.99 | test loss 0.37946757674217224  accuracy 0.92\n",
            "train loss 0.3583671748638153 accuracy 0.98 | test loss 0.3794334828853607  accuracy 0.92\n",
            "train loss 0.35836607217788696 accuracy 0.98 | test loss 0.37939977645874023  accuracy 0.92\n",
            "train loss 0.3583666980266571 accuracy 0.99 | test loss 0.3794649839401245  accuracy 0.92\n",
            "train loss 0.3583666980266571 accuracy 0.98 | test loss 0.3794308304786682  accuracy 0.92\n",
            "train loss 0.35836565494537354 accuracy 0.98 | test loss 0.3794213533401489  accuracy 0.92\n",
            "train loss 0.35836508870124817 accuracy 0.98 | test loss 0.37938764691352844  accuracy 0.92\n",
            "train loss 0.3583666980266571 accuracy 0.99 | test loss 0.3794681429862976  accuracy 0.92\n",
            "train loss 0.35836613178253174 accuracy 0.98 | test loss 0.37941303849220276  accuracy 0.92\n",
            "train loss 0.3583647906780243 accuracy 0.99 | test loss 0.37946653366088867  accuracy 0.92\n",
            "train loss 0.3583656847476959 accuracy 0.98 | test loss 0.37943235039711  accuracy 0.92\n",
            "train loss 0.35836464166641235 accuracy 0.98 | test loss 0.3794228136539459  accuracy 0.92\n",
            "train loss 0.35836416482925415 accuracy 0.98 | test loss 0.37938910722732544  accuracy 0.92\n",
            "train loss 0.3583654463291168 accuracy 0.99 | test loss 0.3794696033000946  accuracy 0.92\n",
            "train loss 0.3583652377128601 accuracy 0.98 | test loss 0.379414439201355  accuracy 0.92\n",
            "train loss 0.35836368799209595 accuracy 0.98 | test loss 0.379452645778656  accuracy 0.92\n",
            "train loss 0.35836437344551086 accuracy 0.98 | test loss 0.37941858172416687  accuracy 0.92\n",
            "train loss 0.3583633601665497 accuracy 0.98 | test loss 0.3794090151786804  accuracy 0.92\n",
            "train loss 0.3583633601665497 accuracy 0.99 | test loss 0.3794625699520111  accuracy 0.92\n",
            "train loss 0.3583641052246094 accuracy 0.98 | test loss 0.3794283866882324  accuracy 0.92\n",
            "train loss 0.35836300253868103 accuracy 0.98 | test loss 0.37939468026161194  accuracy 0.92\n",
            "train loss 0.35836347937583923 accuracy 0.99 | test loss 0.37945982813835144  accuracy 0.92\n",
            "train loss 0.3583635687828064 accuracy 0.98 | test loss 0.37942567467689514  accuracy 0.92\n",
            "train loss 0.35836249589920044 accuracy 0.98 | test loss 0.3794160783290863  accuracy 0.92\n",
            "train loss 0.3583620488643646 accuracy 0.98 | test loss 0.3793824315071106  accuracy 0.92\n",
            "train loss 0.3583635687828064 accuracy 0.99 | test loss 0.379462867975235  accuracy 0.92\n",
            "train loss 0.3583630323410034 accuracy 0.98 | test loss 0.3794287145137787  accuracy 0.92\n",
            "train loss 0.3583618700504303 accuracy 0.98 | test loss 0.37939491868019104  accuracy 0.92\n",
            "train loss 0.3583618700504303 accuracy 0.99 | test loss 0.37946006655693054  accuracy 0.92\n",
            "train loss 0.35836249589920044 accuracy 0.98 | test loss 0.37942594289779663  accuracy 0.92\n",
            "train loss 0.35836151242256165 accuracy 0.98 | test loss 0.3794163465499878  accuracy 0.92\n",
            "train loss 0.35836097598075867 accuracy 0.98 | test loss 0.37942206859588623  accuracy 0.92\n",
            "train loss 0.3583608567714691 accuracy 0.98 | test loss 0.37938830256462097  accuracy 0.92\n",
            "train loss 0.3583616614341736 accuracy 0.99 | test loss 0.37946879863739014  accuracy 0.92\n",
            "train loss 0.35836195945739746 accuracy 0.98 | test loss 0.3794134855270386  accuracy 0.92\n",
            "train loss 0.3583601415157318 accuracy 0.98 | test loss 0.3794238567352295  accuracy 0.92\n",
            "train loss 0.358360230922699 accuracy 0.98 | test loss 0.37939006090164185  accuracy 0.92\n",
            "train loss 0.35836073756217957 accuracy 0.99 | test loss 0.37947046756744385  accuracy 0.92\n",
            "train loss 0.3583613634109497 accuracy 0.98 | test loss 0.3794151246547699  accuracy 0.92\n",
            "train loss 0.35835951566696167 accuracy 0.98 | test loss 0.379381388425827  accuracy 0.92\n",
            "train loss 0.3583606779575348 accuracy 0.99 | test loss 0.3794618248939514  accuracy 0.92\n",
            "train loss 0.35836049914360046 accuracy 0.98 | test loss 0.3794275224208832  accuracy 0.92\n",
            "train loss 0.3583593964576721 accuracy 0.98 | test loss 0.379393607378006  accuracy 0.92\n",
            "train loss 0.3583591878414154 accuracy 0.98 | test loss 0.3794318437576294  accuracy 0.92\n",
            "train loss 0.3583592176437378 accuracy 0.98 | test loss 0.37939783930778503  accuracy 0.92\n",
            "train loss 0.3583586812019348 accuracy 0.98 | test loss 0.37938833236694336  accuracy 0.92\n",
            "train loss 0.3583589196205139 accuracy 0.99 | test loss 0.37946876883506775  accuracy 0.92\n",
            "train loss 0.3583599328994751 accuracy 0.98 | test loss 0.379413366317749  accuracy 0.92\n",
            "train loss 0.35835811495780945 accuracy 0.98 | test loss 0.3794037401676178  accuracy 0.92\n",
            "train loss 0.3583580255508423 accuracy 0.98 | test loss 0.3794329762458801  accuracy 0.92\n",
            "train loss 0.358358234167099 accuracy 0.98 | test loss 0.379398912191391  accuracy 0.92\n",
            "train loss 0.358357697725296 accuracy 0.98 | test loss 0.37938934564590454  accuracy 0.92\n",
            "train loss 0.3583577573299408 accuracy 0.99 | test loss 0.3794543445110321  accuracy 0.92\n",
            "train loss 0.35835838317871094 accuracy 0.98 | test loss 0.3794201612472534  accuracy 0.92\n",
            "train loss 0.3583572804927826 accuracy 0.98 | test loss 0.37938621640205383  accuracy 0.92\n",
            "train loss 0.3583572208881378 accuracy 0.99 | test loss 0.37943974137306213  accuracy 0.92\n",
            "train loss 0.3583574593067169 accuracy 0.98 | test loss 0.37940558791160583  accuracy 0.92\n",
            "train loss 0.35835686326026917 accuracy 0.98 | test loss 0.3793959617614746  accuracy 0.92\n",
            "train loss 0.35835638642311096 accuracy 0.98 | test loss 0.37941405177116394  accuracy 0.92\n",
            "train loss 0.358356237411499 accuracy 0.98 | test loss 0.37938010692596436  accuracy 0.92\n",
            "train loss 0.3583568036556244 accuracy 0.99 | test loss 0.37946054339408875  accuracy 0.92\n",
            "train loss 0.3583572208881378 accuracy 0.98 | test loss 0.3794052004814148  accuracy 0.92\n",
            "train loss 0.3583555817604065 accuracy 0.98 | test loss 0.37939566373825073  accuracy 0.92\n",
            "train loss 0.358355849981308 accuracy 0.98 | test loss 0.3794248104095459  accuracy 0.92\n",
            "train loss 0.35835570096969604 accuracy 0.98 | test loss 0.3793907165527344  accuracy 0.92\n",
            "train loss 0.35835525393486023 accuracy 0.98 | test loss 0.37940874695777893  accuracy 0.92\n",
            "train loss 0.3583550453186035 accuracy 0.98 | test loss 0.37939906120300293  accuracy 0.92\n",
            "train loss 0.358354777097702 accuracy 0.98 | test loss 0.3794005811214447  accuracy 0.92\n",
            "train loss 0.35835471749305725 accuracy 0.98 | test loss 0.37939098477363586  accuracy 0.92\n",
            "train loss 0.35835471749305725 accuracy 0.99 | test loss 0.3794558644294739  accuracy 0.92\n",
            "train loss 0.35835564136505127 accuracy 0.98 | test loss 0.3794214427471161  accuracy 0.92\n",
            "train loss 0.35835447907447815 accuracy 0.98 | test loss 0.37938737869262695  accuracy 0.92\n",
            "train loss 0.3583540916442871 accuracy 0.98 | test loss 0.3794254958629608  accuracy 0.92\n",
            "train loss 0.3583543300628662 accuracy 0.98 | test loss 0.3793914020061493  accuracy 0.92\n",
            "train loss 0.35835355520248413 accuracy 0.98 | test loss 0.37938186526298523  accuracy 0.92\n",
            "train loss 0.3583539128303528 accuracy 0.99 | test loss 0.37943530082702637  accuracy 0.92\n",
            "train loss 0.3583540618419647 accuracy 0.98 | test loss 0.3794010877609253  accuracy 0.92\n",
            "train loss 0.3583531081676483 accuracy 0.98 | test loss 0.3793913424015045  accuracy 0.92\n",
            "train loss 0.358352929353714 accuracy 0.98 | test loss 0.379429429769516  accuracy 0.92\n",
            "train loss 0.3583534061908722 accuracy 0.98 | test loss 0.3793952763080597  accuracy 0.92\n",
            "train loss 0.35835233330726624 accuracy 0.98 | test loss 0.37938567996025085  accuracy 0.92\n",
            "train loss 0.35835281014442444 accuracy 0.99 | test loss 0.3794417381286621  accuracy 0.92\n",
            "train loss 0.35835325717926025 accuracy 0.98 | test loss 0.3794073462486267  accuracy 0.92\n",
            "train loss 0.3583522439002991 accuracy 0.98 | test loss 0.37939751148223877  accuracy 0.92\n",
            "train loss 0.3583517074584961 accuracy 0.98 | test loss 0.3793635368347168  accuracy 0.92\n",
            "train loss 0.3583531081676483 accuracy 0.99 | test loss 0.37944403290748596  accuracy 0.92\n",
            "train loss 0.3583526909351349 accuracy 0.98 | test loss 0.3793886601924896  accuracy 0.92\n",
            "train loss 0.35835129022598267 accuracy 0.98 | test loss 0.37942662835121155  accuracy 0.92\n",
            "train loss 0.3583518862724304 accuracy 0.98 | test loss 0.37939247488975525  accuracy 0.92\n",
            "train loss 0.358350932598114 accuracy 0.98 | test loss 0.379382848739624  accuracy 0.92\n",
            "train loss 0.3583511412143707 accuracy 0.99 | test loss 0.3794362545013428  accuracy 0.92\n",
            "train loss 0.3583516478538513 accuracy 0.98 | test loss 0.379401832818985  accuracy 0.92\n",
            "train loss 0.3583505153656006 accuracy 0.98 | test loss 0.3793678283691406  accuracy 0.92\n",
            "train loss 0.3583512008190155 accuracy 0.99 | test loss 0.3794480860233307  accuracy 0.92\n",
            "train loss 0.3583517372608185 accuracy 0.98 | test loss 0.3793926537036896  accuracy 0.92\n",
            "train loss 0.3583499491214752 accuracy 0.98 | test loss 0.3793829381465912  accuracy 0.92\n",
            "train loss 0.3583499789237976 accuracy 0.99 | test loss 0.3794362246990204  accuracy 0.92\n",
            "train loss 0.3583506643772125 accuracy 0.98 | test loss 0.3794018030166626  accuracy 0.92\n",
            "train loss 0.3583495318889618 accuracy 0.98 | test loss 0.37936776876449585  accuracy 0.92\n",
            "train loss 0.3583502173423767 accuracy 0.99 | test loss 0.37943267822265625  accuracy 0.92\n",
            "train loss 0.35835009813308716 accuracy 0.98 | test loss 0.37939825654029846  accuracy 0.92\n",
            "train loss 0.3583490550518036 accuracy 0.98 | test loss 0.3793884217739105  accuracy 0.92\n",
            "train loss 0.3583485186100006 accuracy 0.98 | test loss 0.37937453389167786  accuracy 0.92\n",
            "train loss 0.3583487570285797 accuracy 0.98 | test loss 0.3794194459915161  accuracy 0.92\n",
            "train loss 0.35834911465644836 accuracy 0.98 | test loss 0.3793852925300598  accuracy 0.92\n",
            "train loss 0.3583483099937439 accuracy 0.98 | test loss 0.3793908953666687  accuracy 0.92\n",
            "train loss 0.35834792256355286 accuracy 0.98 | test loss 0.37935683131217957  accuracy 0.92\n",
            "train loss 0.35834938287734985 accuracy 0.99 | test loss 0.37943729758262634  accuracy 0.92\n",
            "train loss 0.35834887623786926 accuracy 0.98 | test loss 0.3794027864933014  accuracy 0.92\n",
            "train loss 0.3583477735519409 accuracy 0.98 | test loss 0.3793686628341675  accuracy 0.92\n",
            "train loss 0.3583478331565857 accuracy 0.99 | test loss 0.37943363189697266  accuracy 0.92\n",
            "train loss 0.3583483397960663 accuracy 0.98 | test loss 0.3793991804122925  accuracy 0.92\n",
            "train loss 0.3583473563194275 accuracy 0.98 | test loss 0.37938928604125977  accuracy 0.92\n",
            "train loss 0.3583468198776245 accuracy 0.98 | test loss 0.3793795704841614  accuracy 0.92\n",
            "train loss 0.35834693908691406 accuracy 0.98 | test loss 0.3794085681438446  accuracy 0.92\n",
            "train loss 0.35834696888923645 accuracy 0.98 | test loss 0.37937435507774353  accuracy 0.92\n",
            "train loss 0.35834646224975586 accuracy 0.98 | test loss 0.37939223647117615  accuracy 0.92\n",
            "train loss 0.35834625363349915 accuracy 0.98 | test loss 0.3793824017047882  accuracy 0.92\n",
            "train loss 0.3583459258079529 accuracy 0.98 | test loss 0.3793838322162628  accuracy 0.92\n",
            "train loss 0.3583459258079529 accuracy 0.98 | test loss 0.3793739378452301  accuracy 0.92\n",
            "train loss 0.3583459258079529 accuracy 0.99 | test loss 0.3794388175010681  accuracy 0.92\n",
            "train loss 0.3583468496799469 accuracy 0.98 | test loss 0.3793832063674927  accuracy 0.92\n",
            "train loss 0.35834529995918274 accuracy 0.98 | test loss 0.3793845772743225  accuracy 0.92\n",
            "train loss 0.35834524035453796 accuracy 0.98 | test loss 0.3793746829032898  accuracy 0.92\n",
            "train loss 0.358345091342926 accuracy 0.99 | test loss 0.37943947315216064  accuracy 0.92\n",
            "train loss 0.35834625363349915 accuracy 0.98 | test loss 0.3794049322605133  accuracy 0.92\n",
            "train loss 0.358345091342926 accuracy 0.98 | test loss 0.37937071919441223  accuracy 0.92\n",
            "train loss 0.35834449529647827 accuracy 0.98 | test loss 0.37938860058784485  accuracy 0.92\n",
            "train loss 0.35834428668022156 accuracy 0.98 | test loss 0.3793545365333557  accuracy 0.92\n",
            "train loss 0.3583451807498932 accuracy 0.99 | test loss 0.379434734582901  accuracy 0.92\n",
            "train loss 0.3583453297615051 accuracy 0.98 | test loss 0.37937912344932556  accuracy 0.92\n",
            "train loss 0.35834380984306335 accuracy 0.98 | test loss 0.3794046640396118  accuracy 0.92\n",
            "train loss 0.35834410786628723 accuracy 0.98 | test loss 0.37937042117118835  accuracy 0.92\n",
            "train loss 0.3583435118198395 accuracy 0.98 | test loss 0.37938830256462097  accuracy 0.92\n",
            "train loss 0.3583432734012604 accuracy 0.98 | test loss 0.3793541491031647  accuracy 0.92\n",
            "train loss 0.35834407806396484 accuracy 0.99 | test loss 0.37943437695503235  accuracy 0.92\n",
            "train loss 0.35834434628486633 accuracy 0.98 | test loss 0.3793787658214569  accuracy 0.92\n",
            "train loss 0.35834258794784546 accuracy 0.98 | test loss 0.3793890178203583  accuracy 0.92\n",
            "train loss 0.35834264755249023 accuracy 0.98 | test loss 0.37935492396354675  accuracy 0.92\n",
            "train loss 0.358343243598938 accuracy 0.99 | test loss 0.37943506240844727  accuracy 0.92\n",
            "train loss 0.3583436608314514 accuracy 0.98 | test loss 0.3793794512748718  accuracy 0.92\n",
            "train loss 0.35834190249443054 accuracy 0.98 | test loss 0.3793695867061615  accuracy 0.92\n",
            "train loss 0.3583422899246216 accuracy 0.98 | test loss 0.37939849495887756  accuracy 0.92\n",
            "train loss 0.35834211111068726 accuracy 0.98 | test loss 0.3793642222881317  accuracy 0.92\n",
            "train loss 0.35834166407585144 accuracy 0.98 | test loss 0.37938207387924194  accuracy 0.92\n",
            "train loss 0.35834136605262756 accuracy 0.98 | test loss 0.3793722093105316  accuracy 0.92\n",
            "train loss 0.358341246843338 accuracy 0.98 | test loss 0.3794010877609253  accuracy 0.92\n",
            "train loss 0.3583415150642395 accuracy 0.98 | test loss 0.3793666660785675  accuracy 0.92\n",
            "train loss 0.3583409786224365 accuracy 0.98 | test loss 0.3793846070766449  accuracy 0.92\n",
            "train loss 0.3583408296108246 accuracy 0.98 | test loss 0.379374623298645  accuracy 0.92\n",
            "train loss 0.35834038257598877 accuracy 0.98 | test loss 0.3793605864048004  accuracy 0.92\n",
            "train loss 0.35834044218063354 accuracy 0.99 | test loss 0.3794254660606384  accuracy 0.92\n",
            "train loss 0.3583414852619171 accuracy 0.98 | test loss 0.3793908953666687  accuracy 0.92\n",
            "train loss 0.358340322971344 accuracy 0.98 | test loss 0.37935671210289  accuracy 0.92\n",
            "train loss 0.35833993554115295 accuracy 0.98 | test loss 0.3793899714946747  accuracy 0.92\n",
            "train loss 0.35833993554115295 accuracy 0.98 | test loss 0.37935569882392883  accuracy 0.92\n",
            "train loss 0.3583396077156067 accuracy 0.98 | test loss 0.37939369678497314  accuracy 0.92\n",
            "train loss 0.35833975672721863 accuracy 0.98 | test loss 0.3793593645095825  accuracy 0.92\n",
            "train loss 0.35833922028541565 accuracy 0.98 | test loss 0.37934961915016174  accuracy 0.92\n",
            "train loss 0.3583395779132843 accuracy 0.99 | test loss 0.37942981719970703  accuracy 0.92\n",
            "train loss 0.35834044218063354 accuracy 0.98 | test loss 0.37937402725219727  accuracy 0.92\n",
            "train loss 0.3583386242389679 accuracy 0.98 | test loss 0.3793640732765198  accuracy 0.92\n",
            "train loss 0.3583386242389679 accuracy 0.98 | test loss 0.3793930113315582  accuracy 0.92\n",
            "train loss 0.35833874344825745 accuracy 0.98 | test loss 0.37935858964920044  accuracy 0.92\n",
            "train loss 0.35833823680877686 accuracy 0.98 | test loss 0.3793487548828125  accuracy 0.92\n",
            "train loss 0.35833847522735596 accuracy 0.99 | test loss 0.3794289231300354  accuracy 0.92\n",
            "train loss 0.35833942890167236 accuracy 0.98 | test loss 0.379373162984848  accuracy 0.92\n",
            "train loss 0.3583376109600067 accuracy 0.98 | test loss 0.37936320900917053  accuracy 0.92\n",
            "train loss 0.3583374619483948 accuracy 0.98 | test loss 0.3793920874595642  accuracy 0.92\n",
            "train loss 0.3583377003669739 accuracy 0.98 | test loss 0.3793577253818512  accuracy 0.92\n",
            "train loss 0.35833725333213806 accuracy 0.98 | test loss 0.37937551736831665  accuracy 0.92\n",
            "train loss 0.35833704471588135 accuracy 0.98 | test loss 0.37936556339263916  accuracy 0.92\n",
            "train loss 0.35833659768104553 accuracy 0.98 | test loss 0.3793756663799286  accuracy 0.92\n",
            "train loss 0.35833659768104553 accuracy 0.98 | test loss 0.3793415129184723  accuracy 0.92\n",
            "train loss 0.3583374619483948 accuracy 0.99 | test loss 0.3794216215610504  accuracy 0.92\n",
            "train loss 0.35833755135536194 accuracy 0.98 | test loss 0.3793868124485016  accuracy 0.92\n",
            "train loss 0.3583363890647888 accuracy 0.98 | test loss 0.3793524205684662  accuracy 0.92\n",
            "train loss 0.3583359718322754 accuracy 0.99 | test loss 0.3794170916080475  accuracy 0.92\n",
            "train loss 0.35833701491355896 accuracy 0.98 | test loss 0.379382461309433  accuracy 0.92\n",
            "train loss 0.3583358824253082 accuracy 0.98 | test loss 0.37934812903404236  accuracy 0.92\n",
            "train loss 0.3583354353904724 accuracy 0.98 | test loss 0.37938132882118225  accuracy 0.92\n",
            "train loss 0.3583354949951172 accuracy 0.98 | test loss 0.37937116622924805  accuracy 0.92\n",
            "train loss 0.3583349883556366 accuracy 0.98 | test loss 0.37933698296546936  accuracy 0.92\n",
            "train loss 0.3583358824253082 accuracy 0.99 | test loss 0.37941718101501465  accuracy 0.92\n",
            "train loss 0.35833603143692017 accuracy 0.98 | test loss 0.37936142086982727  accuracy 0.92\n",
            "train loss 0.35833442211151123 accuracy 0.98 | test loss 0.37937140464782715  accuracy 0.92\n",
            "train loss 0.35833439230918884 accuracy 0.98 | test loss 0.3793371617794037  accuracy 0.92\n",
            "train loss 0.35833507776260376 accuracy 0.99 | test loss 0.3794173300266266  accuracy 0.92\n",
            "train loss 0.35833537578582764 accuracy 0.98 | test loss 0.3793824315071106  accuracy 0.92\n",
            "train loss 0.35833418369293213 accuracy 0.98 | test loss 0.3793480098247528  accuracy 0.92\n",
            "train loss 0.3583337664604187 accuracy 0.98 | test loss 0.37936586141586304  accuracy 0.92\n",
            "train loss 0.3583334982395172 accuracy 0.98 | test loss 0.37935590744018555  accuracy 0.92\n",
            "train loss 0.3583333194255829 accuracy 0.98 | test loss 0.379381388425827  accuracy 0.92\n",
            "train loss 0.35833343863487244 accuracy 0.98 | test loss 0.3793469965457916  accuracy 0.92\n",
            "train loss 0.3583333492279053 accuracy 0.99 | test loss 0.37941160798072815  accuracy 0.92\n",
            "train loss 0.3583340346813202 accuracy 0.98 | test loss 0.3793767988681793  accuracy 0.92\n",
            "train loss 0.35833290219306946 accuracy 0.98 | test loss 0.3793424069881439  accuracy 0.92\n",
            "train loss 0.35833266377449036 accuracy 0.99 | test loss 0.37942248582839966  accuracy 0.92\n",
            "train loss 0.35833412408828735 accuracy 0.98 | test loss 0.3793666362762451  accuracy 0.92\n",
            "train loss 0.35833221673965454 accuracy 0.98 | test loss 0.3793565332889557  accuracy 0.92\n",
            "train loss 0.3583318889141083 accuracy 0.98 | test loss 0.3793577253818512  accuracy 0.92\n",
            "train loss 0.3583318591117859 accuracy 0.98 | test loss 0.37934765219688416  accuracy 0.92\n",
            "train loss 0.3583318293094635 accuracy 0.99 | test loss 0.37941229343414307  accuracy 0.92\n",
            "train loss 0.3583327829837799 accuracy 0.98 | test loss 0.3793773949146271  accuracy 0.92\n",
            "train loss 0.3583315908908844 accuracy 0.98 | test loss 0.3793429434299469  accuracy 0.92\n",
            "train loss 0.35833120346069336 accuracy 0.98 | test loss 0.3793807923793793  accuracy 0.92\n",
            "train loss 0.35833144187927246 accuracy 0.98 | test loss 0.3793463110923767  accuracy 0.92\n",
            "train loss 0.3583306670188904 accuracy 0.98 | test loss 0.379336416721344  accuracy 0.92\n",
            "train loss 0.3583311438560486 accuracy 0.99 | test loss 0.3794165849685669  accuracy 0.92\n",
            "train loss 0.35833194851875305 accuracy 0.98 | test loss 0.3793606460094452  accuracy 0.92\n",
            "train loss 0.35833021998405457 accuracy 0.98 | test loss 0.3793417513370514  accuracy 0.92\n",
            "train loss 0.35833024978637695 accuracy 0.98 | test loss 0.3793794810771942  accuracy 0.92\n",
            "train loss 0.3583303689956665 accuracy 0.98 | test loss 0.3793450593948364  accuracy 0.92\n",
            "train loss 0.3583296835422516 accuracy 0.98 | test loss 0.37936270236968994  accuracy 0.92\n",
            "train loss 0.35832956433296204 accuracy 0.98 | test loss 0.37932831048965454  accuracy 0.92\n",
            "train loss 0.3583301603794098 accuracy 0.99 | test loss 0.37940844893455505  accuracy 0.92\n",
            "train loss 0.3583306074142456 accuracy 0.98 | test loss 0.37937355041503906  accuracy 0.92\n",
            "train loss 0.3583294153213501 accuracy 0.98 | test loss 0.3793391287326813  accuracy 0.92\n",
            "train loss 0.3583289384841919 accuracy 0.98 | test loss 0.3793291449546814  accuracy 0.92\n",
            "train loss 0.3583293557167053 accuracy 0.99 | test loss 0.3794092833995819  accuracy 0.92\n",
            "train loss 0.35832998156547546 accuracy 0.98 | test loss 0.37935346364974976  accuracy 0.92\n",
            "train loss 0.35832831263542175 accuracy 0.98 | test loss 0.37934333086013794  accuracy 0.92\n",
            "train loss 0.3583284020423889 accuracy 0.99 | test loss 0.37939634919166565  accuracy 0.92\n",
            "train loss 0.35832908749580383 accuracy 0.98 | test loss 0.37936145067214966  accuracy 0.92\n",
            "train loss 0.3583279252052307 accuracy 0.98 | test loss 0.37932708859443665  accuracy 0.92\n",
            "train loss 0.35832834243774414 accuracy 0.99 | test loss 0.37940719723701477  accuracy 0.92\n",
            "train loss 0.3583288788795471 accuracy 0.98 | test loss 0.37935125827789307  accuracy 0.92\n",
            "train loss 0.3583272397518158 accuracy 0.98 | test loss 0.37934115529060364  accuracy 0.92\n",
            "train loss 0.35832732915878296 accuracy 0.99 | test loss 0.3793941140174866  accuracy 0.92\n",
            "train loss 0.3583279848098755 accuracy 0.98 | test loss 0.3793591856956482  accuracy 0.92\n",
            "train loss 0.35832685232162476 accuracy 0.98 | test loss 0.3793247938156128  accuracy 0.92\n",
            "train loss 0.3583274781703949 accuracy 0.99 | test loss 0.3793894350528717  accuracy 0.92\n",
            "train loss 0.35832738876342773 accuracy 0.98 | test loss 0.3793546259403229  accuracy 0.92\n",
            "train loss 0.35832637548446655 accuracy 0.98 | test loss 0.3793444037437439  accuracy 0.92\n",
            "train loss 0.3583260178565979 accuracy 0.98 | test loss 0.3793543577194214  accuracy 0.92\n",
            "train loss 0.3583259582519531 accuracy 0.98 | test loss 0.3793199062347412  accuracy 0.92\n",
            "train loss 0.35832691192626953 accuracy 0.99 | test loss 0.3794001042842865  accuracy 0.92\n",
            "train loss 0.35832685232162476 accuracy 0.98 | test loss 0.37936514616012573  accuracy 0.92\n",
            "train loss 0.358325719833374 accuracy 0.98 | test loss 0.37933066487312317  accuracy 0.92\n",
            "train loss 0.35832545161247253 accuracy 0.98 | test loss 0.3793683648109436  accuracy 0.92\n",
            "train loss 0.3583255708217621 accuracy 0.98 | test loss 0.37933388352394104  accuracy 0.92\n",
            "train loss 0.35832488536834717 accuracy 0.98 | test loss 0.3793238699436188  accuracy 0.92\n",
            "train loss 0.358325332403183 accuracy 0.99 | test loss 0.37940382957458496  accuracy 0.92\n",
            "train loss 0.3583260774612427 accuracy 0.98 | test loss 0.3793689012527466  accuracy 0.92\n",
            "train loss 0.35832491517066956 accuracy 0.98 | test loss 0.37933433055877686  accuracy 0.92\n",
            "train loss 0.35832419991493225 accuracy 0.98 | test loss 0.3793242573738098  accuracy 0.92\n",
            "train loss 0.3583245873451233 accuracy 0.99 | test loss 0.37940412759780884  accuracy 0.92\n",
            "train loss 0.35832542181015015 accuracy 0.98 | test loss 0.37934812903404236  accuracy 0.92\n",
            "train loss 0.3583236634731293 accuracy 0.98 | test loss 0.37931373715400696  accuracy 0.92\n",
            "train loss 0.35832464694976807 accuracy 0.99 | test loss 0.3793938457965851  accuracy 0.92\n",
            "train loss 0.35832464694976807 accuracy 0.98 | test loss 0.3793588876724243  accuracy 0.92\n",
            "train loss 0.35832348465919495 accuracy 0.98 | test loss 0.37932437658309937  accuracy 0.92\n",
            "train loss 0.35832324624061584 accuracy 0.98 | test loss 0.3793621361255646  accuracy 0.92\n",
            "train loss 0.35832327604293823 accuracy 0.98 | test loss 0.379327654838562  accuracy 0.92\n",
            "train loss 0.35832273960113525 accuracy 0.98 | test loss 0.37931761145591736  accuracy 0.92\n",
            "train loss 0.3583231270313263 accuracy 0.99 | test loss 0.37939754128456116  accuracy 0.92\n",
            "train loss 0.3583237826824188 accuracy 0.98 | test loss 0.379362553358078  accuracy 0.92\n",
            "train loss 0.3583226203918457 accuracy 0.98 | test loss 0.37932807207107544  accuracy 0.92\n",
            "train loss 0.3583220839500427 accuracy 0.98 | test loss 0.379317969083786  accuracy 0.92\n",
            "train loss 0.35832229256629944 accuracy 0.99 | test loss 0.3793710768222809  accuracy 0.92\n",
            "train loss 0.3583223521709442 accuracy 0.98 | test loss 0.37933626770973206  accuracy 0.92\n",
            "train loss 0.3583216071128845 accuracy 0.98 | test loss 0.3793260157108307  accuracy 0.92\n",
            "train loss 0.35832148790359497 accuracy 0.98 | test loss 0.3793635964393616  accuracy 0.92\n",
            "train loss 0.3583216667175293 accuracy 0.98 | test loss 0.3793289065361023  accuracy 0.92\n",
            "train loss 0.3583209216594696 accuracy 0.98 | test loss 0.3793664872646332  accuracy 0.92\n",
            "train loss 0.3583214581012726 accuracy 0.98 | test loss 0.37933170795440674  accuracy 0.92\n",
            "train loss 0.3583206236362457 accuracy 0.98 | test loss 0.3793215751647949  accuracy 0.92\n",
            "train loss 0.3583206832408905 accuracy 0.99 | test loss 0.37937453389167786  accuracy 0.92\n",
            "train loss 0.3583211898803711 accuracy 0.98 | test loss 0.37933963537216187  accuracy 0.92\n",
            "train loss 0.35832011699676514 accuracy 0.98 | test loss 0.3793294131755829  accuracy 0.92\n",
            "train loss 0.35831981897354126 accuracy 0.98 | test loss 0.3793427050113678  accuracy 0.92\n",
            "train loss 0.35831984877586365 accuracy 0.98 | test loss 0.3793323338031769  accuracy 0.92\n",
            "train loss 0.35831931233406067 accuracy 0.98 | test loss 0.3792979419231415  accuracy 0.92\n",
            "train loss 0.35832104086875916 accuracy 0.99 | test loss 0.379378080368042  accuracy 0.92\n",
            "train loss 0.35832029581069946 accuracy 0.98 | test loss 0.3793431520462036  accuracy 0.92\n",
            "train loss 0.3583191931247711 accuracy 0.98 | test loss 0.3793328106403351  accuracy 0.92\n",
            "train loss 0.3583187162876129 accuracy 0.98 | test loss 0.3792983889579773  accuracy 0.92\n",
            "train loss 0.3583202362060547 accuracy 0.99 | test loss 0.3793782591819763  accuracy 0.92\n",
            "train loss 0.3583196997642517 accuracy 0.98 | test loss 0.37934333086013794  accuracy 0.92\n",
            "train loss 0.3583185374736786 accuracy 0.98 | test loss 0.3793330192565918  accuracy 0.92\n",
            "train loss 0.3583180606365204 accuracy 0.98 | test loss 0.37929853796958923  accuracy 0.92\n",
            "train loss 0.3583194613456726 accuracy 0.99 | test loss 0.3793784976005554  accuracy 0.92\n",
            "train loss 0.3583190143108368 accuracy 0.98 | test loss 0.3793434798717499  accuracy 0.92\n",
            "train loss 0.35831785202026367 accuracy 0.98 | test loss 0.37933316826820374  accuracy 0.92\n",
            "train loss 0.35831740498542786 accuracy 0.98 | test loss 0.37929868698120117  accuracy 0.92\n",
            "train loss 0.3583187162876129 accuracy 0.99 | test loss 0.37937861680984497  accuracy 0.92\n",
            "train loss 0.35831838846206665 accuracy 0.98 | test loss 0.3793225884437561  accuracy 0.92\n",
            "train loss 0.35831695795059204 accuracy 0.98 | test loss 0.3793601095676422  accuracy 0.92\n",
            "train loss 0.3583175241947174 accuracy 0.98 | test loss 0.3793252408504486  accuracy 0.92\n",
            "train loss 0.3583165407180786 accuracy 0.98 | test loss 0.37931501865386963  accuracy 0.92\n",
            "train loss 0.3583168089389801 accuracy 0.99 | test loss 0.37939491868019104  accuracy 0.92\n",
            "train loss 0.3583180904388428 accuracy 0.98 | test loss 0.37933868169784546  accuracy 0.92\n",
            "train loss 0.3583162724971771 accuracy 0.98 | test loss 0.3793041408061981  accuracy 0.92\n",
            "train loss 0.3583168685436249 accuracy 0.99 | test loss 0.37938398122787476  accuracy 0.92\n",
            "train loss 0.35831722617149353 accuracy 0.98 | test loss 0.37934890389442444  accuracy 0.92\n",
            "train loss 0.3583160638809204 accuracy 0.98 | test loss 0.3793140947818756  accuracy 0.92\n",
            "train loss 0.35831549763679504 accuracy 0.98 | test loss 0.3793516457080841  accuracy 0.92\n",
            "train loss 0.3583158552646637 accuracy 0.98 | test loss 0.37931686639785767  accuracy 0.92\n",
            "train loss 0.3583150804042816 accuracy 0.98 | test loss 0.3793066442012787  accuracy 0.92\n",
            "train loss 0.3583154082298279 accuracy 0.99 | test loss 0.37935957312583923  accuracy 0.92\n",
            "train loss 0.3583155870437622 accuracy 0.98 | test loss 0.37932467460632324  accuracy 0.92\n",
            "train loss 0.358314573764801 accuracy 0.98 | test loss 0.3793143332004547  accuracy 0.92\n",
            "train loss 0.35831451416015625 accuracy 0.98 | test loss 0.3793518841266632  accuracy 0.92\n",
            "train loss 0.3583149015903473 accuracy 0.98 | test loss 0.3793170154094696  accuracy 0.92\n",
            "train loss 0.3583138883113861 accuracy 0.99 | test loss 0.379369854927063  accuracy 0.92\n",
            "train loss 0.35831505060195923 accuracy 0.98 | test loss 0.37933477759361267  accuracy 0.92\n",
            "train loss 0.3583138883113861 accuracy 0.98 | test loss 0.37930014729499817  accuracy 0.92\n",
            "train loss 0.3583141565322876 accuracy 0.99 | test loss 0.3793647289276123  accuracy 0.92\n",
            "train loss 0.3583144545555115 accuracy 0.98 | test loss 0.3793298006057739  accuracy 0.92\n",
            "train loss 0.3583134412765503 accuracy 0.98 | test loss 0.3793194591999054  accuracy 0.92\n",
            "train loss 0.3583129048347473 accuracy 0.98 | test loss 0.37930914759635925  accuracy 0.92\n",
            "train loss 0.3583131730556488 accuracy 0.98 | test loss 0.37933778762817383  accuracy 0.92\n",
            "train loss 0.35831302404403687 accuracy 0.98 | test loss 0.379302978515625  accuracy 0.92\n",
            "train loss 0.3583129048347473 accuracy 0.98 | test loss 0.3793472945690155  accuracy 0.92\n",
            "train loss 0.3583129942417145 accuracy 0.98 | test loss 0.3793124258518219  accuracy 0.92\n",
            "train loss 0.35831218957901 accuracy 0.98 | test loss 0.3793175518512726  accuracy 0.92\n",
            "train loss 0.35831186175346375 accuracy 0.98 | test loss 0.37930724024772644  accuracy 0.92\n",
            "train loss 0.35831210017204285 accuracy 0.99 | test loss 0.3793870508670807  accuracy 0.92\n",
            "train loss 0.35831359028816223 accuracy 0.98 | test loss 0.37933069467544556  accuracy 0.92\n",
            "train loss 0.35831165313720703 accuracy 0.98 | test loss 0.3792959451675415  accuracy 0.92\n",
            "train loss 0.3583122193813324 accuracy 0.99 | test loss 0.37937578558921814  accuracy 0.92\n",
            "train loss 0.35831260681152344 accuracy 0.98 | test loss 0.3793405592441559  accuracy 0.92\n",
            "train loss 0.3583114445209503 accuracy 0.98 | test loss 0.37930572032928467  accuracy 0.92\n",
            "train loss 0.3583109676837921 accuracy 0.98 | test loss 0.379343181848526  accuracy 0.92\n",
            "train loss 0.3583112359046936 accuracy 0.98 | test loss 0.3793083429336548  accuracy 0.92\n",
            "train loss 0.35831043124198914 accuracy 0.98 | test loss 0.37929806113243103  accuracy 0.92\n",
            "train loss 0.35831084847450256 accuracy 0.99 | test loss 0.37937793135643005  accuracy 0.92\n",
            "train loss 0.35831183195114136 accuracy 0.98 | test loss 0.3793216943740845  accuracy 0.92\n",
            "train loss 0.35830992460250854 accuracy 0.98 | test loss 0.37928709387779236  accuracy 0.92\n",
            "train loss 0.35831090807914734 accuracy 0.99 | test loss 0.37936699390411377  accuracy 0.92\n",
            "train loss 0.35831090807914734 accuracy 0.98 | test loss 0.3793317377567291  accuracy 0.92\n",
            "train loss 0.3583097755908966 accuracy 0.98 | test loss 0.3792968690395355  accuracy 0.92\n",
            "train loss 0.35830947756767273 accuracy 0.98 | test loss 0.3793344497680664  accuracy 0.92\n",
            "train loss 0.3583095371723175 accuracy 0.98 | test loss 0.3792995810508728  accuracy 0.92\n",
            "train loss 0.35830894112586975 accuracy 0.98 | test loss 0.3792893588542938  accuracy 0.92\n",
            "train loss 0.35830947756767273 accuracy 0.99 | test loss 0.37936922907829285  accuracy 0.92\n",
            "train loss 0.3583100736141205 accuracy 0.98 | test loss 0.3793129622936249  accuracy 0.92\n",
            "train loss 0.3583083152770996 accuracy 0.98 | test loss 0.3793381154537201  accuracy 0.92\n",
            "train loss 0.3583087921142578 accuracy 0.98 | test loss 0.3793031871318817  accuracy 0.92\n",
            "train loss 0.3583081066608429 accuracy 0.98 | test loss 0.37932053208351135  accuracy 0.92\n",
            "train loss 0.35830795764923096 accuracy 0.98 | test loss 0.37928569316864014  accuracy 0.92\n",
            "train loss 0.3583085834980011 accuracy 0.99 | test loss 0.37936556339263916  accuracy 0.92\n",
            "train loss 0.35830894112586975 accuracy 0.98 | test loss 0.3793303668498993  accuracy 0.92\n",
            "train loss 0.35830774903297424 accuracy 0.98 | test loss 0.3792954683303833  accuracy 0.92\n",
            "train loss 0.3583073616027832 accuracy 0.98 | test loss 0.3793329894542694  accuracy 0.92\n",
            "train loss 0.3583075702190399 accuracy 0.98 | test loss 0.3792980909347534  accuracy 0.92\n",
            "train loss 0.35830700397491455 accuracy 0.98 | test loss 0.3792877793312073  accuracy 0.92\n",
            "train loss 0.3583071827888489 accuracy 0.99 | test loss 0.3793676793575287  accuracy 0.92\n",
            "train loss 0.35830816626548767 accuracy 0.98 | test loss 0.3793114125728607  accuracy 0.92\n",
            "train loss 0.358306348323822 accuracy 0.98 | test loss 0.379300981760025  accuracy 0.92\n",
            "train loss 0.358306348323822 accuracy 0.98 | test loss 0.37932947278022766  accuracy 0.92\n",
            "train loss 0.3583064675331116 accuracy 0.98 | test loss 0.37929460406303406  accuracy 0.92\n",
            "train loss 0.358305960893631 accuracy 0.98 | test loss 0.3793118894100189  accuracy 0.92\n",
            "train loss 0.35830581188201904 accuracy 0.98 | test loss 0.379301518201828  accuracy 0.92\n",
            "train loss 0.358305424451828 accuracy 0.98 | test loss 0.37932655215263367  accuracy 0.92\n",
            "train loss 0.3583056628704071 accuracy 0.98 | test loss 0.3792915940284729  accuracy 0.92\n",
            "train loss 0.35830557346343994 accuracy 0.99 | test loss 0.37935587763786316  accuracy 0.92\n",
            "train loss 0.35830625891685486 accuracy 0.98 | test loss 0.3793206810951233  accuracy 0.92\n",
            "train loss 0.35830503702163696 accuracy 0.98 | test loss 0.3792857527732849  accuracy 0.92\n",
            "train loss 0.3583049774169922 accuracy 0.99 | test loss 0.37935012578964233  accuracy 0.92\n",
            "train loss 0.3583056628704071 accuracy 0.98 | test loss 0.37931495904922485  accuracy 0.92\n",
            "train loss 0.358304500579834 accuracy 0.98 | test loss 0.3793044686317444  accuracy 0.92\n",
            "train loss 0.35830408334732056 accuracy 0.98 | test loss 0.37928518652915955  accuracy 0.92\n",
            "train loss 0.35830432176589966 accuracy 0.99 | test loss 0.3793494999408722  accuracy 0.92\n",
            "train loss 0.3583049774169922 accuracy 0.98 | test loss 0.37931427359580994  accuracy 0.92\n",
            "train loss 0.35830381512641907 accuracy 0.98 | test loss 0.37930378317832947  accuracy 0.92\n",
            "train loss 0.35830333828926086 accuracy 0.98 | test loss 0.3793044090270996  accuracy 0.92\n",
            "train loss 0.3583035171031952 accuracy 0.98 | test loss 0.3792939782142639  accuracy 0.92\n",
            "train loss 0.35830309987068176 accuracy 0.98 | test loss 0.37931108474731445  accuracy 0.92\n",
            "train loss 0.3583030104637146 accuracy 0.98 | test loss 0.37927621603012085  accuracy 0.92\n",
            "train loss 0.35830366611480713 accuracy 0.99 | test loss 0.3793560564517975  accuracy 0.92\n",
            "train loss 0.358303964138031 accuracy 0.98 | test loss 0.37929970026016235  accuracy 0.92\n",
            "train loss 0.3583022952079773 accuracy 0.98 | test loss 0.3793093264102936  accuracy 0.92\n",
            "train loss 0.3583023250102997 accuracy 0.98 | test loss 0.37927451729774475  accuracy 0.92\n",
            "train loss 0.3583029806613922 accuracy 0.99 | test loss 0.379354327917099  accuracy 0.92\n",
            "train loss 0.3583032786846161 accuracy 0.98 | test loss 0.3793189823627472  accuracy 0.92\n",
            "train loss 0.35830211639404297 accuracy 0.98 | test loss 0.3792841136455536  accuracy 0.92\n",
            "train loss 0.35830169916152954 accuracy 0.98 | test loss 0.37932148575782776  accuracy 0.92\n",
            "train loss 0.35830190777778625 accuracy 0.98 | test loss 0.3792864978313446  accuracy 0.92\n",
            "train loss 0.3583012819290161 accuracy 0.98 | test loss 0.37927618622779846  accuracy 0.92\n",
            "train loss 0.3583016097545624 accuracy 0.99 | test loss 0.3793559968471527  accuracy 0.92\n",
            "train loss 0.35830244421958923 accuracy 0.98 | test loss 0.3792996108531952  accuracy 0.92\n",
            "train loss 0.3583006262779236 accuracy 0.98 | test loss 0.3792891502380371  accuracy 0.92\n",
            "train loss 0.3583008348941803 accuracy 0.98 | test loss 0.3793177008628845  accuracy 0.92\n",
            "train loss 0.3583007752895355 accuracy 0.98 | test loss 0.379282683134079  accuracy 0.92\n",
            "train loss 0.3583003282546997 accuracy 0.98 | test loss 0.37929999828338623  accuracy 0.92\n",
            "train loss 0.35830000042915344 accuracy 0.98 | test loss 0.3792894780635834  accuracy 0.92\n",
            "train loss 0.3582998514175415 accuracy 0.98 | test loss 0.3793177604675293  accuracy 0.92\n",
            "train loss 0.358300119638443 accuracy 0.98 | test loss 0.3792828321456909  accuracy 0.92\n",
            "train loss 0.3582996428012848 accuracy 0.98 | test loss 0.3793000280857086  accuracy 0.92\n",
            "train loss 0.35829946398735046 accuracy 0.98 | test loss 0.3792893886566162  accuracy 0.92\n",
            "train loss 0.35829901695251465 accuracy 0.98 | test loss 0.37929901480674744  accuracy 0.92\n",
            "train loss 0.35829898715019226 accuracy 0.98 | test loss 0.37926414608955383  accuracy 0.92\n",
            "train loss 0.3583000898361206 accuracy 0.99 | test loss 0.3793439269065857  accuracy 0.92\n",
            "train loss 0.35829994082450867 accuracy 0.98 | test loss 0.37930864095687866  accuracy 0.92\n",
            "train loss 0.35829874873161316 accuracy 0.98 | test loss 0.3792737126350403  accuracy 0.92\n",
            "train loss 0.3582986295223236 accuracy 0.99 | test loss 0.37933799624443054  accuracy 0.92\n",
            "train loss 0.3582993149757385 accuracy 0.98 | test loss 0.3793027102947235  accuracy 0.92\n",
            "train loss 0.3582981824874878 accuracy 0.98 | test loss 0.3792920708656311  accuracy 0.92\n",
            "train loss 0.358297735452652 accuracy 0.98 | test loss 0.3792726397514343  accuracy 0.92\n",
            "train loss 0.3582979738712311 accuracy 0.99 | test loss 0.3793368935585022  accuracy 0.92\n",
            "train loss 0.3582986295223236 accuracy 0.98 | test loss 0.37930163741111755  accuracy 0.92\n",
            "train loss 0.3582974970340729 accuracy 0.98 | test loss 0.37929099798202515  accuracy 0.92\n",
            "train loss 0.3582969903945923 accuracy 0.98 | test loss 0.37925612926483154  accuracy 0.92\n",
            "train loss 0.35829830169677734 accuracy 0.99 | test loss 0.3793359398841858  accuracy 0.92\n",
            "train loss 0.3582979440689087 accuracy 0.98 | test loss 0.37930068373680115  accuracy 0.92\n",
            "train loss 0.35829681158065796 accuracy 0.98 | test loss 0.37929001450538635  accuracy 0.92\n",
            "train loss 0.358296275138855 accuracy 0.98 | test loss 0.379255086183548  accuracy 0.92\n",
            "train loss 0.3582976162433624 accuracy 0.99 | test loss 0.3793349266052246  accuracy 0.92\n",
            "train loss 0.3582972586154938 accuracy 0.98 | test loss 0.3792996108531952  accuracy 0.92\n",
            "train loss 0.35829612612724304 accuracy 0.98 | test loss 0.3792889416217804  accuracy 0.92\n",
            "train loss 0.35829558968544006 accuracy 0.98 | test loss 0.3792540729045868  accuracy 0.92\n",
            "train loss 0.35829687118530273 accuracy 0.99 | test loss 0.37933388352394104  accuracy 0.92\n",
            "train loss 0.35829657316207886 accuracy 0.98 | test loss 0.37929853796958923  accuracy 0.92\n",
            "train loss 0.3582954406738281 accuracy 0.98 | test loss 0.37928786873817444  accuracy 0.92\n",
            "train loss 0.35829490423202515 accuracy 0.98 | test loss 0.37927305698394775  accuracy 0.92\n",
            "train loss 0.35829493403434753 accuracy 0.98 | test loss 0.3792901933193207  accuracy 0.92\n",
            "train loss 0.35829466581344604 accuracy 0.98 | test loss 0.37925535440444946  accuracy 0.92\n",
            "train loss 0.35829558968544006 accuracy 0.99 | test loss 0.37933507561683655  accuracy 0.92\n",
            "train loss 0.358295738697052 accuracy 0.98 | test loss 0.37927865982055664  accuracy 0.92\n",
            "train loss 0.35829412937164307 accuracy 0.98 | test loss 0.37930357456207275  accuracy 0.92\n",
            "train loss 0.35829436779022217 accuracy 0.98 | test loss 0.37926849722862244  accuracy 0.92\n",
            "train loss 0.3582940697669983 accuracy 0.99 | test loss 0.3793327212333679  accuracy 0.92\n",
            "train loss 0.35829493403434753 accuracy 0.98 | test loss 0.3792974054813385  accuracy 0.92\n",
            "train loss 0.3582938015460968 accuracy 0.98 | test loss 0.37928667664527893  accuracy 0.92\n",
            "train loss 0.3582932949066162 accuracy 0.98 | test loss 0.37925177812576294  accuracy 0.92\n",
            "train loss 0.358294278383255 accuracy 0.99 | test loss 0.37933149933815  accuracy 0.92\n",
            "train loss 0.3582942485809326 accuracy 0.98 | test loss 0.3792750835418701  accuracy 0.92\n",
            "train loss 0.3582927882671356 accuracy 0.98 | test loss 0.37929999828338623  accuracy 0.92\n",
            "train loss 0.35829296708106995 accuracy 0.98 | test loss 0.3792647421360016  accuracy 0.92\n",
            "train loss 0.3582928478717804 accuracy 0.99 | test loss 0.37932899594306946  accuracy 0.92\n",
            "train loss 0.3582935333251953 accuracy 0.98 | test loss 0.3792937099933624  accuracy 0.92\n",
            "train loss 0.35829243063926697 accuracy 0.98 | test loss 0.3792828619480133  accuracy 0.92\n",
            "train loss 0.3582918345928192 accuracy 0.98 | test loss 0.3792479634284973  accuracy 0.92\n",
            "train loss 0.35829299688339233 accuracy 0.99 | test loss 0.37932753562927246  accuracy 0.92\n",
            "train loss 0.3582928478717804 accuracy 0.98 | test loss 0.37929221987724304  accuracy 0.92\n",
            "train loss 0.3582916855812073 accuracy 0.98 | test loss 0.3792814314365387  accuracy 0.92\n",
            "train loss 0.3582911491394043 accuracy 0.98 | test loss 0.37924644351005554  accuracy 0.92\n",
            "train loss 0.3582923114299774 accuracy 0.99 | test loss 0.37932607531547546  accuracy 0.92\n",
            "train loss 0.3582921624183655 accuracy 0.98 | test loss 0.37929072976112366  accuracy 0.92\n",
            "train loss 0.35829100012779236 accuracy 0.98 | test loss 0.3792799413204193  accuracy 0.92\n",
            "train loss 0.3582904636859894 accuracy 0.98 | test loss 0.37924498319625854  accuracy 0.92\n",
            "train loss 0.3582916855812073 accuracy 0.99 | test loss 0.3793245553970337  accuracy 0.92\n",
            "train loss 0.3582913875579834 accuracy 0.98 | test loss 0.3792891204357147  accuracy 0.92\n",
            "train loss 0.35829031467437744 accuracy 0.98 | test loss 0.3792783319950104  accuracy 0.92\n",
            "train loss 0.35828977823257446 accuracy 0.98 | test loss 0.3792634606361389  accuracy 0.92\n",
            "train loss 0.3582898676395416 accuracy 0.98 | test loss 0.37928053736686707  accuracy 0.92\n",
            "train loss 0.35828956961631775 accuracy 0.98 | test loss 0.3792456090450287  accuracy 0.92\n",
            "train loss 0.3582904040813446 accuracy 0.99 | test loss 0.37932518124580383  accuracy 0.92\n",
            "train loss 0.35829058289527893 accuracy 0.98 | test loss 0.3792686462402344  accuracy 0.92\n",
            "train loss 0.35828903317451477 accuracy 0.98 | test loss 0.3792782127857208  accuracy 0.92\n",
            "train loss 0.35828879475593567 accuracy 0.98 | test loss 0.37924328446388245  accuracy 0.92\n",
            "train loss 0.35828977823257446 accuracy 0.99 | test loss 0.37932288646698  accuracy 0.92\n",
            "train loss 0.35828977823257446 accuracy 0.98 | test loss 0.37926626205444336  accuracy 0.92\n",
            "train loss 0.35828834772109985 accuracy 0.98 | test loss 0.3792757987976074  accuracy 0.92\n",
            "train loss 0.35828810930252075 accuracy 0.98 | test loss 0.37924087047576904  accuracy 0.92\n",
            "train loss 0.3582891821861267 accuracy 0.99 | test loss 0.3793204426765442  accuracy 0.92\n",
            "train loss 0.35828909277915955 accuracy 0.98 | test loss 0.37928497791290283  accuracy 0.92\n",
            "train loss 0.3582879602909088 accuracy 0.98 | test loss 0.3792741000652313  accuracy 0.92\n",
            "train loss 0.35828742384910583 accuracy 0.98 | test loss 0.37923911213874817  accuracy 0.92\n",
            "train loss 0.3582885265350342 accuracy 0.99 | test loss 0.3793187737464905  accuracy 0.92\n",
            "train loss 0.35828834772109985 accuracy 0.98 | test loss 0.3792831301689148  accuracy 0.92\n",
            "train loss 0.3582872748374939 accuracy 0.98 | test loss 0.37927231192588806  accuracy 0.92\n",
            "train loss 0.35828670859336853 accuracy 0.98 | test loss 0.3792615532875061  accuracy 0.92\n",
            "train loss 0.3582870066165924 accuracy 0.98 | test loss 0.37928977608680725  accuracy 0.92\n",
            "train loss 0.35828688740730286 accuracy 0.98 | test loss 0.3792544901371002  accuracy 0.92\n",
            "train loss 0.358286589384079 accuracy 0.98 | test loss 0.37929168343544006  accuracy 0.92\n",
            "train loss 0.35828664898872375 accuracy 0.98 | test loss 0.3792564570903778  accuracy 0.92\n",
            "train loss 0.35828617215156555 accuracy 0.98 | test loss 0.37927359342575073  accuracy 0.92\n",
            "train loss 0.35828590393066406 accuracy 0.98 | test loss 0.3792627155780792  accuracy 0.92\n",
            "train loss 0.3582855463027954 accuracy 0.99 | test loss 0.3793151378631592  accuracy 0.92\n",
            "train loss 0.35828661918640137 accuracy 0.98 | test loss 0.3792795240879059  accuracy 0.92\n",
            "train loss 0.35828548669815063 accuracy 0.98 | test loss 0.379244327545166  accuracy 0.92\n",
            "train loss 0.35828569531440735 accuracy 0.99 | test loss 0.3793085515499115  accuracy 0.92\n",
            "train loss 0.3582860231399536 accuracy 0.98 | test loss 0.3792731761932373  accuracy 0.92\n",
            "train loss 0.35828495025634766 accuracy 0.98 | test loss 0.37926238775253296  accuracy 0.92\n",
            "train loss 0.3582844138145447 accuracy 0.98 | test loss 0.37928709387779236  accuracy 0.92\n",
            "train loss 0.3582848310470581 accuracy 0.98 | test loss 0.3792518675327301  accuracy 0.92\n",
            "train loss 0.35828444361686707 accuracy 0.99 | test loss 0.3793158233165741  accuracy 0.92\n",
            "train loss 0.35828542709350586 accuracy 0.98 | test loss 0.37925922870635986  accuracy 0.92\n",
            "train loss 0.35828378796577454 accuracy 0.99 | test loss 0.3793117105960846  accuracy 0.92\n",
            "train loss 0.35828498005867004 accuracy 0.98 | test loss 0.3792760670185089  accuracy 0.92\n",
            "train loss 0.35828375816345215 accuracy 0.98 | test loss 0.37924087047576904  accuracy 0.92\n",
            "train loss 0.3582838475704193 accuracy 0.99 | test loss 0.3793050944805145  accuracy 0.92\n",
            "train loss 0.3582843244075775 accuracy 0.98 | test loss 0.37926971912384033  accuracy 0.92\n",
            "train loss 0.35828331112861633 accuracy 0.98 | test loss 0.3792588412761688  accuracy 0.92\n",
            "train loss 0.35828280448913574 accuracy 0.98 | test loss 0.3792634606361389  accuracy 0.92\n",
            "train loss 0.3582826256752014 accuracy 0.98 | test loss 0.37925612926483154  accuracy 0.92\n",
            "train loss 0.3582823872566223 accuracy 0.98 | test loss 0.37929317355155945  accuracy 0.92\n",
            "train loss 0.3582831621170044 accuracy 0.98 | test loss 0.37925782799720764  accuracy 0.92\n",
            "train loss 0.3582821190357208 accuracy 0.98 | test loss 0.37924712896347046  accuracy 0.92\n",
            "train loss 0.3582823574542999 accuracy 0.99 | test loss 0.3792995512485504  accuracy 0.92\n",
            "train loss 0.35828283429145813 accuracy 0.98 | test loss 0.3792639970779419  accuracy 0.92\n",
            "train loss 0.35828161239624023 accuracy 0.98 | test loss 0.379228800535202  accuracy 0.92\n",
            "train loss 0.35828253626823425 accuracy 0.99 | test loss 0.3793083727359772  accuracy 0.92\n",
            "train loss 0.35828277468681335 accuracy 0.98 | test loss 0.37925177812576294  accuracy 0.92\n",
            "train loss 0.35828107595443726 accuracy 0.98 | test loss 0.37926870584487915  accuracy 0.92\n",
            "train loss 0.3582811653614044 accuracy 0.98 | test loss 0.37923353910446167  accuracy 0.92\n",
            "train loss 0.35828161239624023 accuracy 0.99 | test loss 0.37931308150291443  accuracy 0.92\n",
            "train loss 0.3582821190357208 accuracy 0.98 | test loss 0.37927737832069397  accuracy 0.92\n",
            "train loss 0.3582809269428253 accuracy 0.98 | test loss 0.3792421519756317  accuracy 0.92\n",
            "train loss 0.35828039050102234 accuracy 0.98 | test loss 0.3792792856693268  accuracy 0.92\n",
            "train loss 0.35828065872192383 accuracy 0.98 | test loss 0.37924399971961975  accuracy 0.92\n",
            "train loss 0.3582800626754761 accuracy 0.98 | test loss 0.3792487382888794  accuracy 0.92\n",
            "train loss 0.3582797944545746 accuracy 0.98 | test loss 0.3792656362056732  accuracy 0.92\n",
            "train loss 0.3582797646522522 accuracy 0.98 | test loss 0.3792303502559662  accuracy 0.92\n",
            "train loss 0.358280211687088 accuracy 0.99 | test loss 0.37930992245674133  accuracy 0.92\n",
            "train loss 0.35828080773353577 accuracy 0.98 | test loss 0.37925323843955994  accuracy 0.92\n",
            "train loss 0.3582790195941925 accuracy 0.98 | test loss 0.37926244735717773  accuracy 0.92\n",
            "train loss 0.3582790195941925 accuracy 0.98 | test loss 0.37922725081443787  accuracy 0.92\n",
            "train loss 0.35827964544296265 accuracy 0.99 | test loss 0.3793067932128906  accuracy 0.92\n",
            "train loss 0.3582800328731537 accuracy 0.98 | test loss 0.37927111983299255  accuracy 0.92\n",
            "train loss 0.3582788109779358 accuracy 0.98 | test loss 0.3792358338832855  accuracy 0.92\n",
            "train loss 0.35827842354774475 accuracy 0.98 | test loss 0.3792729079723358  accuracy 0.92\n",
            "train loss 0.3582785725593567 accuracy 0.98 | test loss 0.3792375922203064  accuracy 0.92\n",
            "train loss 0.3582780063152313 accuracy 0.98 | test loss 0.379226952791214  accuracy 0.92\n",
            "train loss 0.35827842354774475 accuracy 0.99 | test loss 0.37930646538734436  accuracy 0.92\n",
            "train loss 0.35827913880348206 accuracy 0.98 | test loss 0.3792497217655182  accuracy 0.92\n",
            "train loss 0.3582773804664612 accuracy 0.98 | test loss 0.37925413250923157  accuracy 0.92\n",
            "train loss 0.35827717185020447 accuracy 0.98 | test loss 0.3792189657688141  accuracy 0.92\n",
            "train loss 0.3582783043384552 accuracy 0.99 | test loss 0.37929847836494446  accuracy 0.92\n",
            "train loss 0.3582781255245209 accuracy 0.98 | test loss 0.3792628347873688  accuracy 0.92\n",
            "train loss 0.35827696323394775 accuracy 0.98 | test loss 0.37925174832344055  accuracy 0.92\n",
            "train loss 0.3582764267921448 accuracy 0.98 | test loss 0.37923663854599  accuracy 0.92\n",
            "train loss 0.35827651619911194 accuracy 0.98 | test loss 0.3792736828327179  accuracy 0.92\n",
            "train loss 0.3582767844200134 accuracy 0.98 | test loss 0.3792382776737213  accuracy 0.92\n",
            "train loss 0.3582761287689209 accuracy 0.98 | test loss 0.37925514578819275  accuracy 0.92\n",
            "train loss 0.3582759499549866 accuracy 0.98 | test loss 0.3792199194431305  accuracy 0.92\n",
            "train loss 0.35827651619911194 accuracy 0.99 | test loss 0.37929946184158325  accuracy 0.92\n",
            "train loss 0.35827696323394775 accuracy 0.98 | test loss 0.3792426586151123  accuracy 0.92\n",
            "train loss 0.35827532410621643 accuracy 0.98 | test loss 0.3792317807674408  accuracy 0.92\n",
            "train loss 0.3582756817340851 accuracy 0.99 | test loss 0.37928417325019836  accuracy 0.92\n",
            "train loss 0.35827597975730896 accuracy 0.98 | test loss 0.37924855947494507  accuracy 0.92\n",
            "train loss 0.3582748472690582 accuracy 0.98 | test loss 0.37923750281333923  accuracy 0.92\n",
            "train loss 0.35827475786209106 accuracy 0.99 | test loss 0.379289835691452  accuracy 0.92\n",
            "train loss 0.3582755923271179 accuracy 0.98 | test loss 0.37925422191619873  accuracy 0.92\n",
            "train loss 0.3582743704319 accuracy 0.98 | test loss 0.37921884655952454  accuracy 0.92\n",
            "train loss 0.35827508568763733 accuracy 0.99 | test loss 0.3792828917503357  accuracy 0.92\n",
            "train loss 0.3582749366760254 accuracy 0.98 | test loss 0.37924724817276  accuracy 0.92\n",
            "train loss 0.3582738935947418 accuracy 0.98 | test loss 0.37923628091812134  accuracy 0.92\n",
            "train loss 0.35827362537384033 accuracy 0.99 | test loss 0.37928855419158936  accuracy 0.92\n",
            "train loss 0.3582746088504791 accuracy 0.98 | test loss 0.3792528510093689  accuracy 0.92\n",
            "train loss 0.3582734167575836 accuracy 0.98 | test loss 0.37921759486198425  accuracy 0.92\n",
            "train loss 0.3582739233970642 accuracy 0.99 | test loss 0.37928152084350586  accuracy 0.92\n",
            "train loss 0.3582739531993866 accuracy 0.98 | test loss 0.37924590706825256  accuracy 0.92\n",
            "train loss 0.3582729399204254 accuracy 0.98 | test loss 0.3792348802089691  accuracy 0.92\n",
            "train loss 0.3582724928855896 accuracy 0.99 | test loss 0.3792872130870819  accuracy 0.92\n",
            "train loss 0.3582736551761627 accuracy 0.98 | test loss 0.37925148010253906  accuracy 0.92\n",
            "train loss 0.3582724630832672 accuracy 0.98 | test loss 0.3792162239551544  accuracy 0.92\n",
            "train loss 0.3582727313041687 accuracy 0.99 | test loss 0.379280149936676  accuracy 0.92\n",
            "train loss 0.3582729995250702 accuracy 0.98 | test loss 0.3792445659637451  accuracy 0.92\n",
            "train loss 0.3582720160484314 accuracy 0.98 | test loss 0.3792335093021393  accuracy 0.92\n",
            "train loss 0.3582714796066284 accuracy 0.98 | test loss 0.3792378902435303  accuracy 0.92\n",
            "train loss 0.3582713305950165 accuracy 0.98 | test loss 0.3792504668235779  accuracy 0.92\n",
            "train loss 0.3582714796066284 accuracy 0.98 | test loss 0.37923935055732727  accuracy 0.92\n",
            "train loss 0.35827094316482544 accuracy 0.98 | test loss 0.379204124212265  accuracy 0.92\n",
            "train loss 0.3582723140716553 accuracy 0.99 | test loss 0.3792836368083954  accuracy 0.92\n",
            "train loss 0.35827192664146423 accuracy 0.98 | test loss 0.3792268633842468  accuracy 0.92\n",
            "train loss 0.3582705557346344 accuracy 0.98 | test loss 0.37926381826400757  accuracy 0.92\n",
            "train loss 0.358271062374115 accuracy 0.98 | test loss 0.3792282044887543  accuracy 0.92\n",
            "train loss 0.3582701086997986 accuracy 0.98 | test loss 0.3792325556278229  accuracy 0.92\n",
            "train loss 0.35826995968818665 accuracy 0.98 | test loss 0.37926945090293884  accuracy 0.92\n",
            "train loss 0.35827070474624634 accuracy 0.98 | test loss 0.37923380732536316  accuracy 0.92\n",
            "train loss 0.3582695722579956 accuracy 0.98 | test loss 0.3792227804660797  accuracy 0.92\n",
            "train loss 0.3582698106765747 accuracy 0.99 | test loss 0.379277765750885  accuracy 0.92\n",
            "train loss 0.3582704961299896 accuracy 0.98 | test loss 0.37924209237098694  accuracy 0.92\n",
            "train loss 0.35826945304870605 accuracy 0.98 | test loss 0.37923097610473633  accuracy 0.92\n",
            "train loss 0.3582688868045807 accuracy 0.98 | test loss 0.3792477250099182  accuracy 0.92\n",
            "train loss 0.3582691252231598 accuracy 0.98 | test loss 0.3792124092578888  accuracy 0.92\n",
            "train loss 0.3582693338394165 accuracy 0.99 | test loss 0.37929168343544006  accuracy 0.92\n",
            "train loss 0.35827016830444336 accuracy 0.98 | test loss 0.3792347311973572  accuracy 0.92\n",
            "train loss 0.35826826095581055 accuracy 0.98 | test loss 0.37921950221061707  accuracy 0.92\n",
            "train loss 0.3582681119441986 accuracy 0.98 | test loss 0.3792565166950226  accuracy 0.92\n",
            "train loss 0.3582686185836792 accuracy 0.98 | test loss 0.3792208731174469  accuracy 0.92\n",
            "train loss 0.3582679033279419 accuracy 0.98 | test loss 0.3792252242565155  accuracy 0.92\n",
            "train loss 0.3582676351070404 accuracy 0.98 | test loss 0.3792420029640198  accuracy 0.92\n",
            "train loss 0.3582676649093628 accuracy 0.98 | test loss 0.37920668721199036  accuracy 0.92\n",
            "train loss 0.3582681119441986 accuracy 0.99 | test loss 0.3792859613895416  accuracy 0.92\n",
            "train loss 0.35826873779296875 accuracy 0.98 | test loss 0.37922903895378113  accuracy 0.92\n",
            "train loss 0.35826683044433594 accuracy 0.98 | test loss 0.3792138695716858  accuracy 0.92\n",
            "train loss 0.3582668602466583 accuracy 0.98 | test loss 0.37923067808151245  accuracy 0.92\n",
            "train loss 0.35826659202575684 accuracy 0.98 | test loss 0.3792106509208679  accuracy 0.92\n",
            "train loss 0.3582667410373688 accuracy 0.99 | test loss 0.3792746663093567  accuracy 0.92\n",
            "train loss 0.35826754570007324 accuracy 0.98 | test loss 0.37923893332481384  accuracy 0.92\n",
            "train loss 0.3582664430141449 accuracy 0.98 | test loss 0.37922781705856323  accuracy 0.92\n",
            "train loss 0.35826581716537476 accuracy 0.98 | test loss 0.3792167603969574  accuracy 0.92\n",
            "train loss 0.358266144990921 accuracy 0.98 | test loss 0.37924468517303467  accuracy 0.92\n",
            "train loss 0.3582659959793091 accuracy 0.98 | test loss 0.37920913100242615  accuracy 0.92\n",
            "train loss 0.35826563835144043 accuracy 0.98 | test loss 0.3792528510093689  accuracy 0.92\n",
            "train loss 0.3582659959793091 accuracy 0.98 | test loss 0.379217267036438  accuracy 0.92\n",
            "train loss 0.3582651913166046 accuracy 0.98 | test loss 0.3792417049407959  accuracy 0.92\n",
            "train loss 0.3582652509212494 accuracy 0.98 | test loss 0.3792061507701874  accuracy 0.92\n",
            "train loss 0.35826507210731506 accuracy 0.99 | test loss 0.379270076751709  accuracy 0.92\n",
            "train loss 0.35826581716537476 accuracy 0.98 | test loss 0.37923434376716614  accuracy 0.92\n",
            "train loss 0.3582647740840912 accuracy 0.98 | test loss 0.37922316789627075  accuracy 0.92\n",
            "train loss 0.3582642376422882 accuracy 0.98 | test loss 0.37921205163002014  accuracy 0.92\n",
            "train loss 0.35826438665390015 accuracy 0.99 | test loss 0.3792644143104553  accuracy 0.92\n",
            "train loss 0.3582649528980255 accuracy 0.98 | test loss 0.3792286515235901  accuracy 0.92\n",
            "train loss 0.35826376080513 accuracy 0.98 | test loss 0.37919333577156067  accuracy 0.92\n",
            "train loss 0.35826459527015686 accuracy 0.99 | test loss 0.37927260994911194  accuracy 0.92\n",
            "train loss 0.3582648038864136 accuracy 0.98 | test loss 0.37921565771102905  accuracy 0.92\n",
            "train loss 0.35826313495635986 accuracy 0.98 | test loss 0.3792247772216797  accuracy 0.92\n",
            "train loss 0.3582630157470703 accuracy 0.98 | test loss 0.37918949127197266  accuracy 0.92\n",
            "train loss 0.35826414823532104 accuracy 0.99 | test loss 0.3792687654495239  accuracy 0.92\n",
            "train loss 0.3582639992237091 accuracy 0.98 | test loss 0.37923285365104675  accuracy 0.92\n",
            "train loss 0.3582628071308136 accuracy 0.98 | test loss 0.3792215883731842  accuracy 0.92\n",
            "train loss 0.35826224088668823 accuracy 0.98 | test loss 0.3791862726211548  accuracy 0.92\n",
            "train loss 0.3582635819911957 accuracy 0.99 | test loss 0.37926557660102844  accuracy 0.92\n",
            "train loss 0.35826319456100464 accuracy 0.98 | test loss 0.37922969460487366  accuracy 0.92\n",
            "train loss 0.3582620918750763 accuracy 0.98 | test loss 0.3792184293270111  accuracy 0.92\n",
            "train loss 0.3582615256309509 accuracy 0.98 | test loss 0.3792073726654053  accuracy 0.92\n",
            "train loss 0.3582618534564972 accuracy 0.98 | test loss 0.37923526763916016  accuracy 0.92\n",
            "train loss 0.3582616448402405 accuracy 0.98 | test loss 0.3791996240615845  accuracy 0.92\n",
            "train loss 0.35826170444488525 accuracy 0.99 | test loss 0.3792635202407837  accuracy 0.92\n",
            "train loss 0.35826224088668823 accuracy 0.98 | test loss 0.3792065382003784  accuracy 0.92\n",
            "train loss 0.35826078057289124 accuracy 0.99 | test loss 0.3792588710784912  accuracy 0.92\n",
            "train loss 0.35826173424720764 accuracy 0.98 | test loss 0.3792230188846588  accuracy 0.92\n",
            "train loss 0.35826075077056885 accuracy 0.98 | test loss 0.37921181321144104  accuracy 0.92\n",
            "train loss 0.35826021432876587 accuracy 0.98 | test loss 0.3792284429073334  accuracy 0.92\n",
            "train loss 0.3582603633403778 accuracy 0.98 | test loss 0.3791927993297577  accuracy 0.92\n",
            "train loss 0.35826072096824646 accuracy 0.99 | test loss 0.3792719841003418  accuracy 0.92\n",
            "train loss 0.3582613170146942 accuracy 0.98 | test loss 0.37923601269721985  accuracy 0.92\n",
            "train loss 0.3582600951194763 accuracy 0.98 | test loss 0.37920036911964417  accuracy 0.92\n",
            "train loss 0.3582595884799957 accuracy 0.98 | test loss 0.3792372941970825  accuracy 0.92\n",
            "train loss 0.3582598865032196 accuracy 0.98 | test loss 0.3792015612125397  accuracy 0.92\n",
            "train loss 0.3582591414451599 accuracy 0.98 | test loss 0.379190593957901  accuracy 0.92\n",
            "train loss 0.3582596480846405 accuracy 0.99 | test loss 0.3792698085308075  accuracy 0.92\n",
            "train loss 0.3582603335380554 accuracy 0.98 | test loss 0.37921276688575745  accuracy 0.92\n",
            "train loss 0.35825854539871216 accuracy 0.98 | test loss 0.3792128562927246  accuracy 0.92\n",
            "train loss 0.3582587242126465 accuracy 0.98 | test loss 0.37920165061950684  accuracy 0.92\n",
            "train loss 0.35825836658477783 accuracy 0.98 | test loss 0.37923842668533325  accuracy 0.92\n",
            "train loss 0.3582587242126465 accuracy 0.98 | test loss 0.3792026937007904  accuracy 0.92\n",
            "train loss 0.3582579791545868 accuracy 0.98 | test loss 0.3792194426059723  accuracy 0.92\n",
            "train loss 0.35825788974761963 accuracy 0.98 | test loss 0.37918388843536377  accuracy 0.92\n",
            "train loss 0.35825851559638977 accuracy 0.99 | test loss 0.37926313281059265  accuracy 0.92\n",
            "train loss 0.35825884342193604 accuracy 0.98 | test loss 0.3792271316051483  accuracy 0.92\n",
            "train loss 0.35825762152671814 accuracy 0.98 | test loss 0.37919145822525024  accuracy 0.92\n",
            "train loss 0.3582572042942047 accuracy 0.98 | test loss 0.3792283236980438  accuracy 0.92\n",
            "train loss 0.3582574129104614 accuracy 0.98 | test loss 0.37919268012046814  accuracy 0.92\n",
            "train loss 0.35825687646865845 accuracy 0.98 | test loss 0.3791816234588623  accuracy 0.92\n",
            "train loss 0.3582574129104614 accuracy 0.99 | test loss 0.3792608678340912  accuracy 0.92\n",
            "train loss 0.35825788974761963 accuracy 0.98 | test loss 0.3792038559913635  accuracy 0.92\n",
            "train loss 0.3582562208175659 accuracy 0.98 | test loss 0.3792080581188202  accuracy 0.92\n",
            "train loss 0.35825592279434204 accuracy 0.98 | test loss 0.37917250394821167  accuracy 0.92\n",
            "train loss 0.35825735330581665 accuracy 0.99 | test loss 0.37925174832344055  accuracy 0.92\n",
            "train loss 0.35825687646865845 accuracy 0.98 | test loss 0.3792157769203186  accuracy 0.92\n",
            "train loss 0.3582557737827301 accuracy 0.98 | test loss 0.37920454144477844  accuracy 0.92\n",
            "train loss 0.3582552373409271 accuracy 0.98 | test loss 0.3792411684989929  accuracy 0.92\n",
            "train loss 0.35825610160827637 accuracy 0.98 | test loss 0.37920522689819336  accuracy 0.92\n",
            "train loss 0.35825490951538086 accuracy 0.98 | test loss 0.37919411063194275  accuracy 0.92\n",
            "train loss 0.3582551181316376 accuracy 0.98 | test loss 0.3792218565940857  accuracy 0.92\n",
            "train loss 0.3582550585269928 accuracy 0.98 | test loss 0.37918615341186523  accuracy 0.92\n",
            "train loss 0.35825490951538086 accuracy 0.98 | test loss 0.3792298436164856  accuracy 0.92\n",
            "train loss 0.358254998922348 accuracy 0.98 | test loss 0.37919411063194275  accuracy 0.92\n",
            "train loss 0.35825416445732117 accuracy 0.98 | test loss 0.37920305132865906  accuracy 0.92\n",
            "train loss 0.35825395584106445 accuracy 0.98 | test loss 0.37919187545776367  accuracy 0.92\n",
            "train loss 0.35825401544570923 accuracy 0.99 | test loss 0.37924402952194214  accuracy 0.92\n",
            "train loss 0.35825473070144653 accuracy 0.98 | test loss 0.3792080581188202  accuracy 0.92\n",
            "train loss 0.35825350880622864 accuracy 0.98 | test loss 0.3791724443435669  accuracy 0.92\n",
            "train loss 0.3582543730735779 accuracy 0.99 | test loss 0.3792516887187958  accuracy 0.92\n",
            "train loss 0.3582545816898346 accuracy 0.98 | test loss 0.3791944682598114  accuracy 0.92\n",
            "train loss 0.3582529127597809 accuracy 0.98 | test loss 0.37921103835105896  accuracy 0.92\n",
            "train loss 0.35825297236442566 accuracy 0.98 | test loss 0.3791753351688385  accuracy 0.92\n",
            "train loss 0.358253538608551 accuracy 0.99 | test loss 0.37925460934638977  accuracy 0.92\n",
            "train loss 0.35825392603874207 accuracy 0.98 | test loss 0.37921851873397827  accuracy 0.92\n",
            "train loss 0.35825273394584656 accuracy 0.98 | test loss 0.3791828155517578  accuracy 0.92\n",
            "train loss 0.35825228691101074 accuracy 0.98 | test loss 0.37921959161758423  accuracy 0.92\n",
            "train loss 0.35825246572494507 accuracy 0.98 | test loss 0.37918388843536377  accuracy 0.92\n",
            "train loss 0.35825178027153015 accuracy 0.98 | test loss 0.37917280197143555  accuracy 0.92\n",
            "train loss 0.35825246572494507 accuracy 0.99 | test loss 0.37925201654434204  accuracy 0.92\n",
            "train loss 0.35825294256210327 accuracy 0.98 | test loss 0.37921592593193054  accuracy 0.92\n",
            "train loss 0.3582517206668854 accuracy 0.98 | test loss 0.3791802227497101  accuracy 0.92\n",
            "train loss 0.3582512140274048 accuracy 0.98 | test loss 0.3792169988155365  accuracy 0.92\n",
            "train loss 0.3582514524459839 accuracy 0.98 | test loss 0.37918129563331604  accuracy 0.92\n",
            "train loss 0.3582508862018585 accuracy 0.98 | test loss 0.37918561697006226  accuracy 0.92\n",
            "train loss 0.3582506477832794 accuracy 0.98 | test loss 0.37920209765434265  accuracy 0.92\n",
            "train loss 0.3582504987716675 accuracy 0.98 | test loss 0.37916645407676697  accuracy 0.92\n",
            "train loss 0.35825130343437195 accuracy 0.99 | test loss 0.37924566864967346  accuracy 0.92\n",
            "train loss 0.3582514524459839 accuracy 0.98 | test loss 0.37920957803726196  accuracy 0.92\n",
            "train loss 0.3582502603530884 accuracy 0.98 | test loss 0.3791981339454651  accuracy 0.92\n",
            "train loss 0.358249694108963 accuracy 0.98 | test loss 0.3791625201702118  accuracy 0.92\n",
            "train loss 0.35825079679489136 accuracy 0.99 | test loss 0.3792417347431183  accuracy 0.92\n",
            "train loss 0.3582506477832794 accuracy 0.98 | test loss 0.3792056143283844  accuracy 0.92\n",
            "train loss 0.3582495450973511 accuracy 0.98 | test loss 0.3791942596435547  accuracy 0.92\n",
            "train loss 0.3582489788532257 accuracy 0.98 | test loss 0.37918296456336975  accuracy 0.92\n",
            "train loss 0.35824915766716003 accuracy 0.98 | test loss 0.37921079993247986  accuracy 0.92\n",
            "train loss 0.35824912786483765 accuracy 0.98 | test loss 0.379175066947937  accuracy 0.92\n",
            "train loss 0.3582489788532257 accuracy 0.99 | test loss 0.37923872470855713  accuracy 0.92\n",
            "train loss 0.3582496643066406 accuracy 0.98 | test loss 0.37918147444725037  accuracy 0.92\n",
            "train loss 0.3582482933998108 accuracy 0.98 | test loss 0.3792058229446411  accuracy 0.92\n",
            "train loss 0.3582483232021332 accuracy 0.98 | test loss 0.3791700601577759  accuracy 0.92\n",
            "train loss 0.3582484722137451 accuracy 0.99 | test loss 0.37923377752304077  accuracy 0.92\n",
            "train loss 0.35824885964393616 accuracy 0.98 | test loss 0.3791975677013397  accuracy 0.92\n",
            "train loss 0.3582478165626526 accuracy 0.98 | test loss 0.37918621301651  accuracy 0.92\n",
            "train loss 0.3582472801208496 accuracy 0.98 | test loss 0.37919509410858154  accuracy 0.92\n",
            "train loss 0.35824722051620483 accuracy 0.98 | test loss 0.37915942072868347  accuracy 0.92\n",
            "train loss 0.35824814438819885 accuracy 0.99 | test loss 0.3792386054992676  accuracy 0.92\n",
            "train loss 0.35824817419052124 accuracy 0.98 | test loss 0.37920236587524414  accuracy 0.92\n",
            "train loss 0.35824695229530334 accuracy 0.98 | test loss 0.3791666328907013  accuracy 0.92\n",
            "train loss 0.3582468330860138 accuracy 0.99 | test loss 0.3792303502559662  accuracy 0.92\n",
            "train loss 0.3582475185394287 accuracy 0.98 | test loss 0.3791942596435547  accuracy 0.92\n",
            "train loss 0.3582465350627899 accuracy 0.98 | test loss 0.37918293476104736  accuracy 0.92\n",
            "train loss 0.3582460284233093 accuracy 0.98 | test loss 0.3791869282722473  accuracy 0.92\n",
            "train loss 0.3582456409931183 accuracy 0.98 | test loss 0.37915128469467163  accuracy 0.92\n",
            "train loss 0.35824722051620483 accuracy 0.99 | test loss 0.3792305290699005  accuracy 0.92\n",
            "train loss 0.35824665427207947 accuracy 0.98 | test loss 0.3791942596435547  accuracy 0.92\n",
            "train loss 0.35824546217918396 accuracy 0.98 | test loss 0.3791828453540802  accuracy 0.92\n",
            "train loss 0.35824504494667053 accuracy 0.98 | test loss 0.3792194426059723  accuracy 0.92\n",
            "train loss 0.358245849609375 accuracy 0.98 | test loss 0.37918341159820557  accuracy 0.92\n",
            "train loss 0.3582446575164795 accuracy 0.98 | test loss 0.37917205691337585  accuracy 0.92\n",
            "train loss 0.35824501514434814 accuracy 0.98 | test loss 0.379199743270874  accuracy 0.92\n",
            "train loss 0.35824477672576904 accuracy 0.98 | test loss 0.37916380167007446  accuracy 0.92\n",
            "train loss 0.35824477672576904 accuracy 0.99 | test loss 0.37922748923301697  accuracy 0.92\n",
            "train loss 0.3582453429698944 accuracy 0.98 | test loss 0.37917014956474304  accuracy 0.92\n",
            "train loss 0.3582440912723541 accuracy 0.98 | test loss 0.379194438457489  accuracy 0.92\n",
            "train loss 0.3582439720630646 accuracy 0.98 | test loss 0.37915870547294617  accuracy 0.92\n",
            "train loss 0.35824424028396606 accuracy 0.99 | test loss 0.3792223632335663  accuracy 0.92\n",
            "train loss 0.35824453830718994 accuracy 0.98 | test loss 0.37918615341186523  accuracy 0.92\n",
            "train loss 0.35824352502822876 accuracy 0.98 | test loss 0.37917470932006836  accuracy 0.92\n",
            "train loss 0.35824301838874817 accuracy 0.98 | test loss 0.3791787922382355  accuracy 0.92\n",
            "train loss 0.35824283957481384 accuracy 0.98 | test loss 0.3791910409927368  accuracy 0.92\n",
            "train loss 0.35824301838874817 accuracy 0.98 | test loss 0.37917956709861755  accuracy 0.92\n",
            "train loss 0.3582424223423004 accuracy 0.98 | test loss 0.3791438639163971  accuracy 0.92\n",
            "train loss 0.35824400186538696 accuracy 0.99 | test loss 0.3792230784893036  accuracy 0.92\n",
            "train loss 0.3582434058189392 accuracy 0.98 | test loss 0.37918683886528015  accuracy 0.92\n",
            "train loss 0.3582422435283661 accuracy 0.98 | test loss 0.3791753649711609  accuracy 0.92\n",
            "train loss 0.3582417666912079 accuracy 0.98 | test loss 0.3791917860507965  accuracy 0.92\n",
            "train loss 0.3582419455051422 accuracy 0.98 | test loss 0.3791560232639313  accuracy 0.92\n",
            "train loss 0.3582424521446228 accuracy 0.99 | test loss 0.37923505902290344  accuracy 0.92\n",
            "train loss 0.358242928981781 accuracy 0.98 | test loss 0.3791775107383728  accuracy 0.92\n",
            "train loss 0.35824134945869446 accuracy 0.98 | test loss 0.37917736172676086  accuracy 0.92\n",
            "train loss 0.35824114084243774 accuracy 0.98 | test loss 0.37916576862335205  accuracy 0.92\n",
            "train loss 0.35824111104011536 accuracy 0.99 | test loss 0.37922942638397217  accuracy 0.92\n",
            "train loss 0.3582421541213989 accuracy 0.98 | test loss 0.37919288873672485  accuracy 0.92\n",
            "train loss 0.35824087262153625 accuracy 0.98 | test loss 0.3791569471359253  accuracy 0.92\n",
            "train loss 0.3582407534122467 accuracy 0.99 | test loss 0.3792359530925751  accuracy 0.92\n",
            "train loss 0.35824209451675415 accuracy 0.98 | test loss 0.37917831540107727  accuracy 0.92\n",
            "train loss 0.358240008354187 accuracy 0.98 | test loss 0.37916693091392517  accuracy 0.92\n",
            "train loss 0.35824018716812134 accuracy 0.98 | test loss 0.3791944682598114  accuracy 0.92\n",
            "train loss 0.35824012756347656 accuracy 0.98 | test loss 0.3791583478450775  accuracy 0.92\n",
            "train loss 0.35823971033096313 accuracy 0.98 | test loss 0.3791747987270355  accuracy 0.92\n",
            "train loss 0.3582393527030945 accuracy 0.98 | test loss 0.37916338443756104  accuracy 0.92\n",
            "train loss 0.35823944211006165 accuracy 0.99 | test loss 0.3792153000831604  accuracy 0.92\n",
            "train loss 0.35824012756347656 accuracy 0.98 | test loss 0.3791790306568146  accuracy 0.92\n",
            "train loss 0.35823890566825867 accuracy 0.98 | test loss 0.37914329767227173  accuracy 0.92\n",
            "train loss 0.3582397401332855 accuracy 0.99 | test loss 0.3792223036289215  accuracy 0.92\n",
            "train loss 0.35823991894721985 accuracy 0.98 | test loss 0.3791647255420685  accuracy 0.92\n",
            "train loss 0.3582383394241333 accuracy 0.98 | test loss 0.3791735768318176  accuracy 0.92\n",
            "train loss 0.3582381010055542 accuracy 0.98 | test loss 0.37916210293769836  accuracy 0.92\n",
            "train loss 0.35823822021484375 accuracy 0.98 | test loss 0.37918969988822937  accuracy 0.92\n",
            "train loss 0.35823822021484375 accuracy 0.98 | test loss 0.3791535496711731  accuracy 0.92\n",
            "train loss 0.3582380712032318 accuracy 0.98 | test loss 0.37919679284095764  accuracy 0.92\n",
            "train loss 0.3582381308078766 accuracy 0.98 | test loss 0.379160612821579  accuracy 0.92\n",
            "train loss 0.35823729634284973 accuracy 0.98 | test loss 0.3791694641113281  accuracy 0.92\n",
            "train loss 0.3582371175289154 accuracy 0.98 | test loss 0.3791579604148865  accuracy 0.92\n",
            "train loss 0.35823720693588257 accuracy 0.99 | test loss 0.379209965467453  accuracy 0.92\n",
            "train loss 0.3582378625869751 accuracy 0.98 | test loss 0.37917348742485046  accuracy 0.92\n",
            "train loss 0.3582366406917572 accuracy 0.98 | test loss 0.37913763523101807  accuracy 0.92\n",
            "train loss 0.35823768377304077 accuracy 0.99 | test loss 0.37921661138534546  accuracy 0.92\n",
            "train loss 0.3582376539707184 accuracy 0.98 | test loss 0.37915903329849243  accuracy 0.92\n",
            "train loss 0.3582361042499542 accuracy 0.98 | test loss 0.37919554114341736  accuracy 0.92\n",
            "train loss 0.358236700296402 accuracy 0.98 | test loss 0.3791593015193939  accuracy 0.92\n",
            "train loss 0.3582356870174408 accuracy 0.98 | test loss 0.3791479468345642  accuracy 0.92\n",
            "train loss 0.3582362234592438 accuracy 0.99 | test loss 0.3792268931865692  accuracy 0.92\n",
            "train loss 0.35823705792427063 accuracy 0.98 | test loss 0.3791902959346771  accuracy 0.92\n",
            "train loss 0.35823583602905273 accuracy 0.98 | test loss 0.37915411591529846  accuracy 0.92\n",
            "train loss 0.35823509097099304 accuracy 0.98 | test loss 0.3791906237602234  accuracy 0.92\n",
            "train loss 0.35823556780815125 accuracy 0.98 | test loss 0.3791548013687134  accuracy 0.92\n",
            "train loss 0.35823479294776917 accuracy 0.98 | test loss 0.3791584074497223  accuracy 0.92\n",
            "train loss 0.35823458433151245 accuracy 0.98 | test loss 0.37917467951774597  accuracy 0.92\n",
            "train loss 0.35823455452919006 accuracy 0.98 | test loss 0.3791389465332031  accuracy 0.92\n",
            "train loss 0.35823526978492737 accuracy 0.99 | test loss 0.3792176842689514  accuracy 0.92\n",
            "train loss 0.35823553800582886 accuracy 0.98 | test loss 0.3791811168193817  accuracy 0.92\n",
            "train loss 0.3582342863082886 accuracy 0.98 | test loss 0.3791453540325165  accuracy 0.92\n",
            "train loss 0.35823407769203186 accuracy 0.99 | test loss 0.37920859456062317  accuracy 0.92\n",
            "train loss 0.35823485255241394 accuracy 0.98 | test loss 0.3791723847389221  accuracy 0.92\n",
            "train loss 0.35823363065719604 accuracy 0.98 | test loss 0.37916067242622375  accuracy 0.92\n",
            "train loss 0.358233243227005 accuracy 0.98 | test loss 0.3791603744029999  accuracy 0.92\n",
            "train loss 0.35823333263397217 accuracy 0.98 | test loss 0.3791486620903015  accuracy 0.92\n",
            "train loss 0.3582330644130707 accuracy 0.99 | test loss 0.37921181321144104  accuracy 0.92\n",
            "train loss 0.35823413729667664 accuracy 0.98 | test loss 0.3791753947734833  accuracy 0.92\n",
            "train loss 0.35823288559913635 accuracy 0.98 | test loss 0.3791405260562897  accuracy 0.92\n",
            "train loss 0.3582327961921692 accuracy 0.99 | test loss 0.3792182207107544  accuracy 0.92\n",
            "train loss 0.35823413729667664 accuracy 0.98 | test loss 0.3791612684726715  accuracy 0.92\n",
            "train loss 0.35823214054107666 accuracy 0.98 | test loss 0.3791497051715851  accuracy 0.92\n",
            "train loss 0.35823214054107666 accuracy 0.99 | test loss 0.37920081615448  accuracy 0.92\n",
            "train loss 0.3582327961921692 accuracy 0.98 | test loss 0.37916454672813416  accuracy 0.92\n",
            "train loss 0.3582316040992737 accuracy 0.98 | test loss 0.37915292382240295  accuracy 0.92\n",
            "train loss 0.35823139548301697 accuracy 0.98 | test loss 0.3791802227497101  accuracy 0.92\n",
            "train loss 0.35823172330856323 accuracy 0.98 | test loss 0.3791448473930359  accuracy 0.92\n",
            "train loss 0.3582312762737274 accuracy 0.98 | test loss 0.3791871666908264  accuracy 0.92\n",
            "train loss 0.3582316040992737 accuracy 0.98 | test loss 0.3791520595550537  accuracy 0.92\n",
            "train loss 0.35823073983192444 accuracy 0.98 | test loss 0.3791404664516449  accuracy 0.92\n",
            "train loss 0.35823097825050354 accuracy 0.99 | test loss 0.3791912794113159  accuracy 0.92\n",
            "train loss 0.35823121666908264 accuracy 0.98 | test loss 0.3791554272174835  accuracy 0.92\n",
            "train loss 0.35823020339012146 accuracy 0.98 | test loss 0.3791438341140747  accuracy 0.92\n",
            "train loss 0.35823020339012146 accuracy 0.99 | test loss 0.37922203540802  accuracy 0.92\n",
            "train loss 0.3582318425178528 accuracy 0.98 | test loss 0.37916430830955505  accuracy 0.92\n",
            "train loss 0.35822975635528564 accuracy 0.98 | test loss 0.37912946939468384  accuracy 0.92\n",
            "train loss 0.3582305908203125 accuracy 0.99 | test loss 0.3792071044445038  accuracy 0.92\n",
            "train loss 0.35823073983192444 accuracy 0.98 | test loss 0.37917083501815796  accuracy 0.92\n",
            "train loss 0.35822948813438416 accuracy 0.98 | test loss 0.3791358172893524  accuracy 0.92\n",
            "train loss 0.3582293689250946 accuracy 0.99 | test loss 0.37919801473617554  accuracy 0.92\n",
            "train loss 0.35823002457618713 accuracy 0.98 | test loss 0.3791626989841461  accuracy 0.92\n",
            "train loss 0.3582288920879364 accuracy 0.98 | test loss 0.37915101647377014  accuracy 0.92\n",
            "train loss 0.3582285940647125 accuracy 0.98 | test loss 0.37917372584342957  accuracy 0.92\n",
            "train loss 0.35822874307632446 accuracy 0.98 | test loss 0.3791385889053345  accuracy 0.92\n",
            "train loss 0.3582283556461334 accuracy 0.98 | test loss 0.37917426228523254  accuracy 0.92\n",
            "train loss 0.358228474855423 accuracy 0.98 | test loss 0.37913915514945984  accuracy 0.92\n",
            "train loss 0.3582278788089752 accuracy 0.99 | test loss 0.3791893720626831  accuracy 0.92\n",
            "train loss 0.3582285940647125 accuracy 0.98 | test loss 0.3791540563106537  accuracy 0.92\n",
            "train loss 0.35822775959968567 accuracy 0.98 | test loss 0.37914222478866577  accuracy 0.92\n",
            "train loss 0.35822734236717224 accuracy 0.98 | test loss 0.37917789816856384  accuracy 0.92\n",
            "train loss 0.35822775959968567 accuracy 0.98 | test loss 0.37914255261421204  accuracy 0.92\n",
            "train loss 0.3582269251346588 accuracy 0.98 | test loss 0.37915822863578796  accuracy 0.92\n",
            "train loss 0.3582268953323364 accuracy 0.98 | test loss 0.37912341952323914  accuracy 0.92\n",
            "train loss 0.3582276701927185 accuracy 0.99 | test loss 0.37920019030570984  accuracy 0.92\n",
            "train loss 0.35822784900665283 accuracy 0.98 | test loss 0.3791440427303314  accuracy 0.92\n",
            "train loss 0.35822635889053345 accuracy 0.98 | test loss 0.37916675209999084  accuracy 0.92\n",
            "train loss 0.3582265079021454 accuracy 0.98 | test loss 0.37913161516189575  accuracy 0.92\n",
            "train loss 0.35822638869285583 accuracy 0.99 | test loss 0.3791937530040741  accuracy 0.92\n",
            "train loss 0.3582269847393036 accuracy 0.98 | test loss 0.3791583180427551  accuracy 0.92\n",
            "train loss 0.3582257628440857 accuracy 0.98 | test loss 0.3791465759277344  accuracy 0.92\n",
            "train loss 0.35822534561157227 accuracy 0.98 | test loss 0.3791460692882538  accuracy 0.92\n",
            "train loss 0.3582254648208618 accuracy 0.98 | test loss 0.37913423776626587  accuracy 0.92\n",
            "train loss 0.35822540521621704 accuracy 0.99 | test loss 0.3791963458061218  accuracy 0.92\n",
            "train loss 0.35822629928588867 accuracy 0.98 | test loss 0.37916091084480286  accuracy 0.92\n",
            "train loss 0.358225017786026 accuracy 0.98 | test loss 0.3791259825229645  accuracy 0.92\n",
            "train loss 0.3582250773906708 accuracy 0.99 | test loss 0.3792027235031128  accuracy 0.92\n",
            "train loss 0.3582262694835663 accuracy 0.98 | test loss 0.37914642691612244  accuracy 0.92\n",
            "train loss 0.3582242429256439 accuracy 0.98 | test loss 0.37913474440574646  accuracy 0.92\n",
            "train loss 0.35822439193725586 accuracy 0.99 | test loss 0.3791847825050354  accuracy 0.92\n",
            "train loss 0.35822492837905884 accuracy 0.98 | test loss 0.3791493773460388  accuracy 0.92\n",
            "train loss 0.3582237660884857 accuracy 0.98 | test loss 0.37913745641708374  accuracy 0.92\n",
            "train loss 0.35822364687919617 accuracy 0.98 | test loss 0.37916433811187744  accuracy 0.92\n",
            "train loss 0.3582238554954529 accuracy 0.98 | test loss 0.379129022359848  accuracy 0.92\n",
            "train loss 0.35822364687919617 accuracy 0.98 | test loss 0.37917113304138184  accuracy 0.92\n",
            "train loss 0.35822370648384094 accuracy 0.98 | test loss 0.3791358470916748  accuracy 0.92\n",
            "train loss 0.3582228720188141 accuracy 0.98 | test loss 0.37912416458129883  accuracy 0.92\n",
            "train loss 0.35822340846061707 accuracy 0.99 | test loss 0.37920093536376953  accuracy 0.92\n",
            "train loss 0.35822418332099915 accuracy 0.98 | test loss 0.37916526198387146  accuracy 0.92\n",
            "train loss 0.3582228720188141 accuracy 0.98 | test loss 0.37912994623184204  accuracy 0.92\n",
            "train loss 0.35822227597236633 accuracy 0.99 | test loss 0.379179984331131  accuracy 0.92\n",
            "train loss 0.358223021030426 accuracy 0.98 | test loss 0.3791446089744568  accuracy 0.92\n",
            "train loss 0.3582221567630768 accuracy 0.98 | test loss 0.3791327178478241  accuracy 0.92\n",
            "train loss 0.35822173953056335 accuracy 0.98 | test loss 0.37916824221611023  accuracy 0.92\n",
            "train loss 0.35822218656539917 accuracy 0.98 | test loss 0.37913286685943604  accuracy 0.92\n",
            "train loss 0.3582213222980499 accuracy 0.98 | test loss 0.37912121415138245  accuracy 0.92\n",
            "train loss 0.3582219183444977 accuracy 0.99 | test loss 0.3791978359222412  accuracy 0.92\n",
            "train loss 0.35822272300720215 accuracy 0.98 | test loss 0.3791414797306061  accuracy 0.92\n",
            "train loss 0.35822081565856934 accuracy 0.98 | test loss 0.3791409134864807  accuracy 0.92\n",
            "train loss 0.35822081565856934 accuracy 0.98 | test loss 0.379129022359848  accuracy 0.92\n",
            "train loss 0.3582207262516022 accuracy 0.99 | test loss 0.3791910409927368  accuracy 0.92\n",
            "train loss 0.35822176933288574 accuracy 0.98 | test loss 0.3791554272174835  accuracy 0.92\n",
            "train loss 0.35822051763534546 accuracy 0.98 | test loss 0.37912020087242126  accuracy 0.92\n",
            "train loss 0.3582203984260559 accuracy 0.99 | test loss 0.3791968822479248  accuracy 0.92\n",
            "train loss 0.3582216799259186 accuracy 0.98 | test loss 0.3791405260562897  accuracy 0.92\n",
            "train loss 0.3582196831703186 accuracy 0.98 | test loss 0.37912872433662415  accuracy 0.92\n",
            "train loss 0.358219712972641 accuracy 0.99 | test loss 0.3791787624359131  accuracy 0.92\n",
            "train loss 0.3582203984260559 accuracy 0.98 | test loss 0.37914329767227173  accuracy 0.92\n",
            "train loss 0.3582191467285156 accuracy 0.98 | test loss 0.379108190536499  accuracy 0.92\n",
            "train loss 0.3582201302051544 accuracy 0.99 | test loss 0.37918493151664734  accuracy 0.92\n",
            "train loss 0.3582201302051544 accuracy 0.98 | test loss 0.3791492283344269  accuracy 0.92\n",
            "train loss 0.3582189977169037 accuracy 0.98 | test loss 0.37913718819618225  accuracy 0.92\n",
            "train loss 0.35821837186813354 accuracy 0.98 | test loss 0.37912535667419434  accuracy 0.92\n",
            "train loss 0.35821858048439026 accuracy 0.99 | test loss 0.3791787624359131  accuracy 0.92\n",
            "train loss 0.35821929574012756 accuracy 0.98 | test loss 0.37914329767227173  accuracy 0.92\n",
            "train loss 0.3582182228565216 accuracy 0.98 | test loss 0.3791312277317047  accuracy 0.92\n",
            "train loss 0.35821768641471863 accuracy 0.98 | test loss 0.3791666328907013  accuracy 0.92\n",
            "train loss 0.3582184612751007 accuracy 0.98 | test loss 0.3791312277317047  accuracy 0.92\n",
            "train loss 0.3582172989845276 accuracy 0.98 | test loss 0.3791193962097168  accuracy 0.92\n",
            "train loss 0.3582177758216858 accuracy 0.99 | test loss 0.3791959285736084  accuracy 0.92\n",
            "train loss 0.35821881890296936 accuracy 0.98 | test loss 0.3791395425796509  accuracy 0.92\n",
            "train loss 0.3582170307636261 accuracy 0.98 | test loss 0.3791388273239136  accuracy 0.92\n",
            "train loss 0.35821691155433655 accuracy 0.98 | test loss 0.37912672758102417  accuracy 0.92\n",
            "train loss 0.35821667313575745 accuracy 0.98 | test loss 0.37916216254234314  accuracy 0.92\n",
            "train loss 0.35821714997291565 accuracy 0.98 | test loss 0.37912672758102417  accuracy 0.92\n",
            "train loss 0.35821616649627686 accuracy 0.98 | test loss 0.37916216254234314  accuracy 0.92\n",
            "train loss 0.3582168519496918 accuracy 0.98 | test loss 0.3791266977787018  accuracy 0.92\n",
            "train loss 0.3582157790660858 accuracy 0.98 | test loss 0.37914228439331055  accuracy 0.92\n",
            "train loss 0.35821592807769775 accuracy 0.98 | test loss 0.37910711765289307  accuracy 0.92\n",
            "train loss 0.3582165837287903 accuracy 0.99 | test loss 0.3791837990283966  accuracy 0.92\n",
            "train loss 0.35821688175201416 accuracy 0.98 | test loss 0.379148006439209  accuracy 0.92\n",
            "train loss 0.3582156300544739 accuracy 0.98 | test loss 0.37911269068717957  accuracy 0.92\n",
            "train loss 0.3582153618335724 accuracy 0.99 | test loss 0.37918925285339355  accuracy 0.92\n",
            "train loss 0.3582168519496918 accuracy 0.98 | test loss 0.37913283705711365  accuracy 0.92\n",
            "train loss 0.358214795589447 accuracy 0.98 | test loss 0.37912100553512573  accuracy 0.92\n",
            "train loss 0.35821470618247986 accuracy 0.99 | test loss 0.3791709840297699  accuracy 0.92\n",
            "train loss 0.3582155406475067 accuracy 0.98 | test loss 0.3791353106498718  accuracy 0.92\n",
            "train loss 0.35821425914764404 accuracy 0.98 | test loss 0.37910017371177673  accuracy 0.92\n",
            "train loss 0.3582151234149933 accuracy 0.99 | test loss 0.3791767358779907  accuracy 0.92\n",
            "train loss 0.35821524262428284 accuracy 0.98 | test loss 0.37914106249809265  accuracy 0.92\n",
            "train loss 0.3582141101360321 accuracy 0.98 | test loss 0.37912893295288086  accuracy 0.92\n",
            "train loss 0.35821348428726196 accuracy 0.98 | test loss 0.379116952419281  accuracy 0.92\n",
            "train loss 0.3582136034965515 accuracy 0.99 | test loss 0.37916693091392517  accuracy 0.92\n",
            "train loss 0.35821425914764404 accuracy 0.98 | test loss 0.3791312575340271  accuracy 0.92\n",
            "train loss 0.35821300745010376 accuracy 0.98 | test loss 0.37909603118896484  accuracy 0.92\n",
            "train loss 0.3582141697406769 accuracy 0.99 | test loss 0.37917250394821167  accuracy 0.92\n",
            "train loss 0.35821396112442017 accuracy 0.98 | test loss 0.3791368305683136  accuracy 0.92\n",
            "train loss 0.35821279883384705 accuracy 0.98 | test loss 0.3791246712207794  accuracy 0.92\n",
            "train loss 0.3582122325897217 accuracy 0.98 | test loss 0.37914007902145386  accuracy 0.92\n",
            "train loss 0.3582124710083008 accuracy 0.98 | test loss 0.3791047930717468  accuracy 0.92\n",
            "train loss 0.3582128882408142 accuracy 0.99 | test loss 0.3791813552379608  accuracy 0.92\n",
            "train loss 0.3582134246826172 accuracy 0.98 | test loss 0.3791455328464508  accuracy 0.92\n",
            "train loss 0.35821211338043213 accuracy 0.98 | test loss 0.37911009788513184  accuracy 0.92\n",
            "train loss 0.35821181535720825 accuracy 0.99 | test loss 0.3791722059249878  accuracy 0.92\n",
            "train loss 0.3582126796245575 accuracy 0.98 | test loss 0.37913641333580017  accuracy 0.92\n",
            "train loss 0.3582114279270172 accuracy 0.98 | test loss 0.3791012465953827  accuracy 0.92\n",
            "train loss 0.35821157693862915 accuracy 0.99 | test loss 0.3791777789592743  accuracy 0.92\n",
            "train loss 0.35821259021759033 accuracy 0.98 | test loss 0.3791213929653168  accuracy 0.92\n",
            "train loss 0.3582107424736023 accuracy 0.98 | test loss 0.3791094422340393  accuracy 0.92\n",
            "train loss 0.3582109808921814 accuracy 0.99 | test loss 0.37915942072868347  accuracy 0.92\n",
            "train loss 0.3582112789154053 accuracy 0.98 | test loss 0.379123717546463  accuracy 0.92\n",
            "train loss 0.35821017622947693 accuracy 0.98 | test loss 0.37911176681518555  accuracy 0.92\n",
            "train loss 0.3582102060317993 accuracy 0.99 | test loss 0.37916168570518494  accuracy 0.92\n",
            "train loss 0.35821086168289185 accuracy 0.98 | test loss 0.3791259229183197  accuracy 0.92\n",
            "train loss 0.35820966958999634 accuracy 0.98 | test loss 0.3791137933731079  accuracy 0.92\n",
            "train loss 0.35820960998535156 accuracy 0.98 | test loss 0.3791258633136749  accuracy 0.92\n",
            "train loss 0.35820937156677246 accuracy 0.98 | test loss 0.37911391258239746  accuracy 0.92\n",
            "train loss 0.35820910334587097 accuracy 0.98 | test loss 0.37914058566093445  accuracy 0.92\n",
            "train loss 0.3582094609737396 accuracy 0.98 | test loss 0.3791051506996155  accuracy 0.92\n",
            "train loss 0.35820913314819336 accuracy 0.98 | test loss 0.37914714217185974  accuracy 0.92\n",
            "train loss 0.3582093417644501 accuracy 0.98 | test loss 0.3791116774082184  accuracy 0.92\n",
            "train loss 0.3582085072994232 accuracy 0.98 | test loss 0.3790997862815857  accuracy 0.92\n",
            "train loss 0.35820892453193665 accuracy 0.99 | test loss 0.3791763186454773  accuracy 0.92\n",
            "train loss 0.3582097589969635 accuracy 0.98 | test loss 0.37911972403526306  accuracy 0.92\n",
            "train loss 0.358208030462265 accuracy 0.98 | test loss 0.37911882996559143  accuracy 0.92\n",
            "train loss 0.358208030462265 accuracy 0.98 | test loss 0.379106730222702  accuracy 0.92\n",
            "train loss 0.35820773243904114 accuracy 0.98 | test loss 0.37914201617240906  accuracy 0.92\n",
            "train loss 0.3582080900669098 accuracy 0.98 | test loss 0.3791065514087677  accuracy 0.92\n",
            "train loss 0.3582072854042053 accuracy 0.98 | test loss 0.3791418671607971  accuracy 0.92\n",
            "train loss 0.3582077622413635 accuracy 0.98 | test loss 0.3791063725948334  accuracy 0.92\n",
            "train loss 0.3582068979740143 accuracy 0.98 | test loss 0.3790944516658783  accuracy 0.92\n",
            "train loss 0.3582075536251068 accuracy 0.99 | test loss 0.3791709840297699  accuracy 0.92\n",
            "train loss 0.35820814967155457 accuracy 0.98 | test loss 0.3791351318359375  accuracy 0.92\n",
            "train loss 0.3582068979740143 accuracy 0.98 | test loss 0.3790997266769409  accuracy 0.92\n",
            "train loss 0.3582063913345337 accuracy 0.99 | test loss 0.37917616963386536  accuracy 0.92\n",
            "train loss 0.35820817947387695 accuracy 0.98 | test loss 0.37911951541900635  accuracy 0.92\n",
            "train loss 0.35820600390434265 accuracy 0.98 | test loss 0.3791075348854065  accuracy 0.92\n",
            "train loss 0.3582058548927307 accuracy 0.98 | test loss 0.3791300058364868  accuracy 0.92\n",
            "train loss 0.3582059144973755 accuracy 0.98 | test loss 0.3790944516658783  accuracy 0.92\n",
            "train loss 0.3582060933113098 accuracy 0.99 | test loss 0.37915632128715515  accuracy 0.92\n",
            "train loss 0.3582063913345337 accuracy 0.98 | test loss 0.3791205883026123  accuracy 0.92\n",
            "train loss 0.3582051694393158 accuracy 0.98 | test loss 0.3790853023529053  accuracy 0.92\n",
            "train loss 0.3582059144973755 accuracy 0.99 | test loss 0.37916189432144165  accuracy 0.92\n",
            "train loss 0.3582061231136322 accuracy 0.98 | test loss 0.37912604212760925  accuracy 0.92\n",
            "train loss 0.3582049608230591 accuracy 0.98 | test loss 0.3791137933731079  accuracy 0.92\n",
            "train loss 0.35820433497428894 accuracy 0.98 | test loss 0.37910178303718567  accuracy 0.92\n",
            "train loss 0.3582044839859009 accuracy 0.98 | test loss 0.37912848591804504  accuracy 0.92\n",
            "train loss 0.3582044243812561 accuracy 0.98 | test loss 0.3790930211544037  accuracy 0.92\n",
            "train loss 0.35820427536964417 accuracy 0.99 | test loss 0.37915489077568054  accuracy 0.92\n",
            "train loss 0.3582049608230591 accuracy 0.98 | test loss 0.3791190981864929  accuracy 0.92\n",
            "train loss 0.3582038879394531 accuracy 0.98 | test loss 0.3791068494319916  accuracy 0.92\n",
            "train loss 0.35820332169532776 accuracy 0.98 | test loss 0.37910932302474976  accuracy 0.92\n",
            "train loss 0.35820305347442627 accuracy 0.98 | test loss 0.3791171610355377  accuracy 0.92\n",
            "train loss 0.35820311307907104 accuracy 0.98 | test loss 0.379081666469574  accuracy 0.92\n",
            "train loss 0.35820409655570984 accuracy 0.99 | test loss 0.3791581690311432  accuracy 0.92\n",
            "train loss 0.35820403695106506 accuracy 0.98 | test loss 0.37912237644195557  accuracy 0.92\n",
            "train loss 0.35820281505584717 accuracy 0.98 | test loss 0.3790869116783142  accuracy 0.92\n",
            "train loss 0.35820311307907104 accuracy 0.99 | test loss 0.37914878129959106  accuracy 0.92\n",
            "train loss 0.35820335149765015 accuracy 0.98 | test loss 0.37911298871040344  accuracy 0.92\n",
            "train loss 0.358202189207077 accuracy 0.98 | test loss 0.3791007101535797  accuracy 0.92\n",
            "train loss 0.3582018315792084 accuracy 0.99 | test loss 0.3791504502296448  accuracy 0.92\n",
            "train loss 0.35820284485816956 accuracy 0.98 | test loss 0.37911462783813477  accuracy 0.92\n",
            "train loss 0.35820165276527405 accuracy 0.98 | test loss 0.3791023790836334  accuracy 0.92\n",
            "train loss 0.35820120573043823 accuracy 0.98 | test loss 0.3791143596172333  accuracy 0.92\n",
            "train loss 0.35820135474205017 accuracy 0.98 | test loss 0.37910208106040955  accuracy 0.92\n",
            "train loss 0.3582007586956024 accuracy 0.98 | test loss 0.3790901005268097  accuracy 0.92\n",
            "train loss 0.3582015037536621 accuracy 0.99 | test loss 0.3791433572769165  accuracy 0.92\n",
            "train loss 0.3582017123699188 accuracy 0.98 | test loss 0.37910759449005127  accuracy 0.92\n",
            "train loss 0.3582006096839905 accuracy 0.98 | test loss 0.3790954053401947  accuracy 0.92\n",
            "train loss 0.3582002818584442 accuracy 0.99 | test loss 0.37914514541625977  accuracy 0.92\n",
            "train loss 0.3582012951374054 accuracy 0.98 | test loss 0.37910938262939453  accuracy 0.92\n",
            "train loss 0.3582000732421875 accuracy 0.98 | test loss 0.3790971040725708  accuracy 0.92\n",
            "train loss 0.3581998348236084 accuracy 0.99 | test loss 0.3791588544845581  accuracy 0.92\n",
            "train loss 0.35820120573043823 accuracy 0.98 | test loss 0.37912285327911377  accuracy 0.92\n",
            "train loss 0.35819995403289795 accuracy 0.98 | test loss 0.37908729910850525  accuracy 0.92\n",
            "train loss 0.35819968581199646 accuracy 0.99 | test loss 0.3791637718677521  accuracy 0.92\n",
            "train loss 0.35820120573043823 accuracy 0.98 | test loss 0.3791070580482483  accuracy 0.92\n",
            "train loss 0.35819897055625916 accuracy 0.98 | test loss 0.3790862262248993  accuracy 0.92\n",
            "train loss 0.3581991493701935 accuracy 0.99 | test loss 0.37914809584617615  accuracy 0.92\n",
            "train loss 0.35819995403289795 accuracy 0.98 | test loss 0.37911224365234375  accuracy 0.92\n",
            "train loss 0.35819870233535767 accuracy 0.98 | test loss 0.3791000247001648  accuracy 0.92\n",
            "train loss 0.35819822549819946 accuracy 0.98 | test loss 0.37909919023513794  accuracy 0.92\n",
            "train loss 0.358198344707489 accuracy 0.98 | test loss 0.3790868818759918  accuracy 0.92\n",
            "train loss 0.3581983149051666 accuracy 0.99 | test loss 0.3791486918926239  accuracy 0.92\n",
            "train loss 0.3581991493701935 accuracy 0.98 | test loss 0.3791128396987915  accuracy 0.92\n",
            "train loss 0.3581978380680084 accuracy 0.98 | test loss 0.37907737493515015  accuracy 0.92\n",
            "train loss 0.35819804668426514 accuracy 0.99 | test loss 0.379153847694397  accuracy 0.92\n",
            "train loss 0.3581991493701935 accuracy 0.98 | test loss 0.3790971040725708  accuracy 0.92\n",
            "train loss 0.3581971228122711 accuracy 0.98 | test loss 0.3790850341320038  accuracy 0.92\n",
            "train loss 0.3581973612308502 accuracy 0.99 | test loss 0.37913474440574646  accuracy 0.92\n",
            "train loss 0.35819777846336365 accuracy 0.98 | test loss 0.37909892201423645  accuracy 0.92\n",
            "train loss 0.35819655656814575 accuracy 0.98 | test loss 0.37908679246902466  accuracy 0.92\n",
            "train loss 0.3581966459751129 accuracy 0.99 | test loss 0.37913650274276733  accuracy 0.92\n",
            "train loss 0.35819733142852783 accuracy 0.98 | test loss 0.37910065054893494  accuracy 0.92\n",
            "train loss 0.3581960201263428 accuracy 0.98 | test loss 0.3790651559829712  accuracy 0.92\n",
            "train loss 0.35819733142852783 accuracy 0.99 | test loss 0.3791416883468628  accuracy 0.92\n",
            "train loss 0.35819709300994873 accuracy 0.98 | test loss 0.379084974527359  accuracy 0.92\n",
            "train loss 0.3581957221031189 accuracy 0.99 | test loss 0.3791467845439911  accuracy 0.92\n",
            "train loss 0.35819685459136963 accuracy 0.98 | test loss 0.379110723733902  accuracy 0.92\n",
            "train loss 0.35819557309150696 accuracy 0.98 | test loss 0.3790750503540039  accuracy 0.92\n",
            "train loss 0.35819557309150696 accuracy 0.99 | test loss 0.37915152311325073  accuracy 0.92\n",
            "train loss 0.3581967055797577 accuracy 0.98 | test loss 0.3790947496891022  accuracy 0.92\n",
            "train loss 0.3581947982311249 accuracy 0.98 | test loss 0.37909719347953796  accuracy 0.92\n",
            "train loss 0.358194500207901 accuracy 0.98 | test loss 0.37908488512039185  accuracy 0.92\n",
            "train loss 0.3581947386264801 accuracy 0.98 | test loss 0.37911131978034973  accuracy 0.92\n",
            "train loss 0.3581945598125458 accuracy 0.98 | test loss 0.3790756165981293  accuracy 0.92\n",
            "train loss 0.35819464921951294 accuracy 0.99 | test loss 0.379137247800827  accuracy 0.92\n",
            "train loss 0.35819509625434875 accuracy 0.98 | test loss 0.37910139560699463  accuracy 0.92\n",
            "train loss 0.3581940829753876 accuracy 0.98 | test loss 0.37908899784088135  accuracy 0.92\n",
            "train loss 0.3581935167312622 accuracy 0.98 | test loss 0.37909677624702454  accuracy 0.92\n",
            "train loss 0.3581933379173279 accuracy 0.98 | test loss 0.37906143069267273  accuracy 0.92\n",
            "train loss 0.3581945598125458 accuracy 0.99 | test loss 0.37913787364959717  accuracy 0.92\n",
            "train loss 0.35819435119628906 accuracy 0.98 | test loss 0.37910187244415283  accuracy 0.92\n",
            "train loss 0.35819312930107117 accuracy 0.98 | test loss 0.3790894150733948  accuracy 0.92\n",
            "train loss 0.3581925928592682 accuracy 0.98 | test loss 0.3790971040725708  accuracy 0.92\n",
            "train loss 0.3581925928592682 accuracy 0.98 | test loss 0.37906163930892944  accuracy 0.92\n",
            "train loss 0.35819369554519653 accuracy 0.99 | test loss 0.37913811206817627  accuracy 0.92\n",
            "train loss 0.3581935465335846 accuracy 0.98 | test loss 0.37910202145576477  accuracy 0.92\n",
            "train loss 0.35819223523139954 accuracy 0.98 | test loss 0.3790663182735443  accuracy 0.92\n",
            "train loss 0.3581925630569458 accuracy 0.99 | test loss 0.3791281282901764  accuracy 0.92\n",
            "train loss 0.3581927418708801 accuracy 0.98 | test loss 0.379092276096344  accuracy 0.92\n",
            "train loss 0.35819169878959656 accuracy 0.98 | test loss 0.3790801167488098  accuracy 0.92\n",
            "train loss 0.35819151997566223 accuracy 0.99 | test loss 0.3791297972202301  accuracy 0.92\n",
            "train loss 0.3581923544406891 accuracy 0.98 | test loss 0.3790937662124634  accuracy 0.92\n",
            "train loss 0.3581911325454712 accuracy 0.98 | test loss 0.3790813386440277  accuracy 0.92\n",
            "train loss 0.3581908345222473 accuracy 0.99 | test loss 0.3791309893131256  accuracy 0.92\n",
            "train loss 0.35819190740585327 accuracy 0.98 | test loss 0.3790949583053589  accuracy 0.92\n",
            "train loss 0.3581905961036682 accuracy 0.98 | test loss 0.37905922532081604  accuracy 0.92\n",
            "train loss 0.3581913709640503 accuracy 0.99 | test loss 0.3791210353374481  accuracy 0.92\n",
            "train loss 0.3581911325454712 accuracy 0.98 | test loss 0.3790852129459381  accuracy 0.92\n",
            "train loss 0.35819005966186523 accuracy 0.98 | test loss 0.37907302379608154  accuracy 0.92\n",
            "train loss 0.35819011926651 accuracy 0.99 | test loss 0.37912267446517944  accuracy 0.92\n",
            "train loss 0.3581906855106354 accuracy 0.98 | test loss 0.3790866732597351  accuracy 0.92\n",
            "train loss 0.35818952322006226 accuracy 0.98 | test loss 0.37907424569129944  accuracy 0.92\n",
            "train loss 0.35818949341773987 accuracy 0.99 | test loss 0.37915053963661194  accuracy 0.92\n",
            "train loss 0.3581913411617279 accuracy 0.98 | test loss 0.3790934681892395  accuracy 0.92\n",
            "train loss 0.35818910598754883 accuracy 0.98 | test loss 0.379057914018631  accuracy 0.92\n",
            "train loss 0.35819000005722046 accuracy 0.99 | test loss 0.3791341781616211  accuracy 0.92\n",
            "train loss 0.35819005966186523 accuracy 0.98 | test loss 0.379098117351532  accuracy 0.92\n",
            "train loss 0.35818877816200256 accuracy 0.98 | test loss 0.37906232476234436  accuracy 0.92\n",
            "train loss 0.35818883776664734 accuracy 0.99 | test loss 0.37913867831230164  accuracy 0.92\n",
            "train loss 0.35819000005722046 accuracy 0.98 | test loss 0.3790817856788635  accuracy 0.92\n",
            "train loss 0.3581880033016205 accuracy 0.98 | test loss 0.379069447517395  accuracy 0.92\n",
            "train loss 0.3581882417201996 accuracy 0.99 | test loss 0.3791191279888153  accuracy 0.92\n",
            "train loss 0.3581886291503906 accuracy 0.98 | test loss 0.3790830969810486  accuracy 0.92\n",
            "train loss 0.35818740725517273 accuracy 0.98 | test loss 0.3790706694126129  accuracy 0.92\n",
            "train loss 0.35818755626678467 accuracy 0.99 | test loss 0.37912026047706604  accuracy 0.92\n",
            "train loss 0.3581881523132324 accuracy 0.98 | test loss 0.37908416986465454  accuracy 0.92\n",
            "train loss 0.35818687081336975 accuracy 0.98 | test loss 0.3790484666824341  accuracy 0.92\n",
            "train loss 0.3581882417201996 accuracy 0.99 | test loss 0.3791102468967438  accuracy 0.92\n",
            "train loss 0.35818740725517273 accuracy 0.98 | test loss 0.3790743947029114  accuracy 0.92\n",
            "train loss 0.35818636417388916 accuracy 0.98 | test loss 0.37906214594841003  accuracy 0.92\n",
            "train loss 0.3581869304180145 accuracy 0.99 | test loss 0.37913838028907776  accuracy 0.92\n",
            "train loss 0.35818779468536377 accuracy 0.98 | test loss 0.3791021704673767  accuracy 0.92\n",
            "train loss 0.3581864833831787 accuracy 0.98 | test loss 0.3790663778781891  accuracy 0.92\n",
            "train loss 0.35818591713905334 accuracy 0.98 | test loss 0.3791014850139618  accuracy 0.92\n",
            "train loss 0.35818618535995483 accuracy 0.98 | test loss 0.3790656626224518  accuracy 0.92\n",
            "train loss 0.3581855595111847 accuracy 0.99 | test loss 0.3791152834892273  accuracy 0.92\n",
            "train loss 0.3581863343715668 accuracy 0.98 | test loss 0.3790791928768158  accuracy 0.92\n",
            "train loss 0.358185350894928 accuracy 0.98 | test loss 0.3790667951107025  accuracy 0.92\n",
            "train loss 0.35818496346473694 accuracy 0.98 | test loss 0.37910178303718567  accuracy 0.92\n",
            "train loss 0.35818541049957275 accuracy 0.98 | test loss 0.37906599044799805  accuracy 0.92\n",
            "train loss 0.3581845760345459 accuracy 0.98 | test loss 0.3790957033634186  accuracy 0.92\n",
            "train loss 0.3581848740577698 accuracy 0.98 | test loss 0.37905991077423096  accuracy 0.92\n",
            "train loss 0.35818466544151306 accuracy 0.99 | test loss 0.3791215717792511  accuracy 0.92\n",
            "train loss 0.35818541049957275 accuracy 0.98 | test loss 0.3790854811668396  accuracy 0.92\n",
            "train loss 0.3581841289997101 accuracy 0.98 | test loss 0.3790731430053711  accuracy 0.92\n",
            "train loss 0.35818377137184143 accuracy 0.98 | test loss 0.3790719509124756  accuracy 0.92\n",
            "train loss 0.35818374156951904 accuracy 0.98 | test loss 0.3790595233440399  accuracy 0.92\n",
            "train loss 0.3581838011741638 accuracy 0.99 | test loss 0.37912115454673767  accuracy 0.92\n",
            "train loss 0.3581845760345459 accuracy 0.98 | test loss 0.3790850341320038  accuracy 0.92\n",
            "train loss 0.3581832945346832 accuracy 0.98 | test loss 0.3790494203567505  accuracy 0.92\n",
            "train loss 0.35818371176719666 accuracy 0.99 | test loss 0.379125714302063  accuracy 0.92\n",
            "train loss 0.35818448662757874 accuracy 0.98 | test loss 0.3790687024593353  accuracy 0.92\n",
            "train loss 0.3581825792789459 accuracy 0.98 | test loss 0.3790709972381592  accuracy 0.92\n",
            "train loss 0.35818225145339966 accuracy 0.98 | test loss 0.37905868887901306  accuracy 0.92\n",
            "train loss 0.35818275809288025 accuracy 0.99 | test loss 0.3791348934173584  accuracy 0.92\n",
            "train loss 0.358183890581131 accuracy 0.98 | test loss 0.3790777921676636  accuracy 0.92\n",
            "train loss 0.35818207263946533 accuracy 0.98 | test loss 0.3790620267391205  accuracy 0.92\n",
            "train loss 0.35818174481391907 accuracy 0.98 | test loss 0.37909698486328125  accuracy 0.92\n",
            "train loss 0.35818225145339966 accuracy 0.98 | test loss 0.37906092405319214  accuracy 0.92\n",
            "train loss 0.3581814169883728 accuracy 0.99 | test loss 0.3791104853153229  accuracy 0.92\n",
            "train loss 0.3581823408603668 accuracy 0.98 | test loss 0.379074364900589  accuracy 0.92\n",
            "train loss 0.3581812083721161 accuracy 0.98 | test loss 0.37906181812286377  accuracy 0.92\n",
            "train loss 0.35818085074424744 accuracy 0.98 | test loss 0.37909674644470215  accuracy 0.92\n",
            "train loss 0.3581814467906952 accuracy 0.98 | test loss 0.37906065583229065  accuracy 0.92\n",
            "train loss 0.3581804633140564 accuracy 0.98 | test loss 0.37909042835235596  accuracy 0.92\n",
            "train loss 0.3581809103488922 accuracy 0.98 | test loss 0.37905436754226685  accuracy 0.92\n",
            "train loss 0.35818052291870117 accuracy 0.99 | test loss 0.3791159689426422  accuracy 0.92\n",
            "train loss 0.3581814467906952 accuracy 0.98 | test loss 0.37907981872558594  accuracy 0.92\n",
            "train loss 0.35818010568618774 accuracy 0.98 | test loss 0.37904417514801025  accuracy 0.92\n",
            "train loss 0.3581804633140564 accuracy 0.99 | test loss 0.37912043929100037  accuracy 0.92\n",
            "train loss 0.3581812083721161 accuracy 0.98 | test loss 0.37906336784362793  accuracy 0.92\n",
            "train loss 0.3581794798374176 accuracy 0.98 | test loss 0.37906554341316223  accuracy 0.92\n",
            "train loss 0.3581790328025818 accuracy 0.98 | test loss 0.3790532350540161  accuracy 0.92\n",
            "train loss 0.35817956924438477 accuracy 0.99 | test loss 0.3791061043739319  accuracy 0.92\n",
            "train loss 0.3581799864768982 accuracy 0.98 | test loss 0.3790699541568756  accuracy 0.92\n",
            "train loss 0.35817885398864746 accuracy 0.98 | test loss 0.379057377576828  accuracy 0.92\n",
            "train loss 0.35817858576774597 accuracy 0.98 | test loss 0.379092276096344  accuracy 0.92\n",
            "train loss 0.35817909240722656 accuracy 0.98 | test loss 0.37905624508857727  accuracy 0.92\n",
            "train loss 0.35817816853523254 accuracy 0.99 | test loss 0.3791057765483856  accuracy 0.92\n",
            "train loss 0.35817915201187134 accuracy 0.98 | test loss 0.37906959652900696  accuracy 0.92\n",
            "train loss 0.3581780195236206 accuracy 0.98 | test loss 0.37905699014663696  accuracy 0.92\n",
            "train loss 0.35817766189575195 accuracy 0.99 | test loss 0.37911850214004517  accuracy 0.92\n",
            "train loss 0.35817909240722656 accuracy 0.98 | test loss 0.3790823221206665  accuracy 0.92\n",
            "train loss 0.3581778109073639 accuracy 0.98 | test loss 0.3790464699268341  accuracy 0.92\n",
            "train loss 0.3581775724887848 accuracy 0.99 | test loss 0.3791227340698242  accuracy 0.92\n",
            "train loss 0.3581789433956146 accuracy 0.98 | test loss 0.3790655732154846  accuracy 0.92\n",
            "train loss 0.3581768572330475 accuracy 0.98 | test loss 0.37904441356658936  accuracy 0.92\n",
            "train loss 0.3581770956516266 accuracy 0.99 | test loss 0.3791058659553528  accuracy 0.92\n",
            "train loss 0.3581777811050415 accuracy 0.98 | test loss 0.37906965613365173  accuracy 0.92\n",
            "train loss 0.35817664861679077 accuracy 0.98 | test loss 0.3790570795536041  accuracy 0.92\n",
            "train loss 0.35817623138427734 accuracy 0.98 | test loss 0.379079133272171  accuracy 0.92\n",
            "train loss 0.35817641019821167 accuracy 0.98 | test loss 0.3790431022644043  accuracy 0.92\n",
            "train loss 0.3581762909889221 accuracy 0.99 | test loss 0.3791046440601349  accuracy 0.92\n",
            "train loss 0.35817694664001465 accuracy 0.98 | test loss 0.37906843423843384  accuracy 0.92\n",
            "train loss 0.358175665140152 accuracy 0.98 | test loss 0.37905582785606384  accuracy 0.92\n",
            "train loss 0.3581753075122833 accuracy 0.98 | test loss 0.37905454635620117  accuracy 0.92\n",
            "train loss 0.35817527770996094 accuracy 0.98 | test loss 0.37904199957847595  accuracy 0.92\n",
            "train loss 0.3581755459308624 accuracy 0.99 | test loss 0.3791036009788513  accuracy 0.92\n",
            "train loss 0.3581761121749878 accuracy 0.98 | test loss 0.3790673017501831  accuracy 0.92\n",
            "train loss 0.35817480087280273 accuracy 0.98 | test loss 0.3790316581726074  accuracy 0.92\n",
            "train loss 0.35817545652389526 accuracy 0.99 | test loss 0.37910792231559753  accuracy 0.92\n",
            "train loss 0.3581758439540863 accuracy 0.98 | test loss 0.3790508210659027  accuracy 0.92\n",
            "train loss 0.3581741750240326 accuracy 0.98 | test loss 0.3790529668331146  accuracy 0.92\n",
            "train loss 0.3581739664077759 accuracy 0.98 | test loss 0.3790876269340515  accuracy 0.92\n",
            "train loss 0.3581746220588684 accuracy 0.98 | test loss 0.3790515065193176  accuracy 0.92\n",
            "train loss 0.35817351937294006 accuracy 0.98 | test loss 0.37906646728515625  accuracy 0.92\n",
            "train loss 0.358173668384552 accuracy 0.98 | test loss 0.3790452182292938  accuracy 0.92\n",
            "train loss 0.3581734895706177 accuracy 0.99 | test loss 0.3791067898273468  accuracy 0.92\n",
            "train loss 0.358174592256546 accuracy 0.98 | test loss 0.37907034158706665  accuracy 0.92\n",
            "train loss 0.35817331075668335 accuracy 0.98 | test loss 0.3790343403816223  accuracy 0.92\n",
            "train loss 0.3581733703613281 accuracy 0.99 | test loss 0.37911054491996765  accuracy 0.92\n",
            "train loss 0.3581743538379669 accuracy 0.98 | test loss 0.37905341386795044  accuracy 0.92\n",
            "train loss 0.35817253589630127 accuracy 0.98 | test loss 0.3790555000305176  accuracy 0.92\n",
            "train loss 0.358172208070755 accuracy 0.98 | test loss 0.379062682390213  accuracy 0.92\n",
            "train loss 0.358172208070755 accuracy 0.98 | test loss 0.3790266811847687  accuracy 0.92\n",
            "train loss 0.358173131942749 accuracy 0.99 | test loss 0.3791029155254364  accuracy 0.92\n",
            "train loss 0.3581732213497162 accuracy 0.98 | test loss 0.379066526889801  accuracy 0.92\n",
            "train loss 0.35817188024520874 accuracy 0.98 | test loss 0.37903040647506714  accuracy 0.92\n",
            "train loss 0.35817214846611023 accuracy 0.99 | test loss 0.3790920078754425  accuracy 0.92\n",
            "train loss 0.3581724166870117 accuracy 0.98 | test loss 0.37905585765838623  accuracy 0.92\n",
            "train loss 0.35817137360572815 accuracy 0.98 | test loss 0.3790431618690491  accuracy 0.92\n",
            "train loss 0.3581710755825043 accuracy 0.99 | test loss 0.37909260392189026  accuracy 0.92\n",
            "train loss 0.35817188024520874 accuracy 0.98 | test loss 0.3790563941001892  accuracy 0.92\n",
            "train loss 0.3581707775592804 accuracy 0.98 | test loss 0.3790436089038849  accuracy 0.92\n",
            "train loss 0.35817044973373413 accuracy 0.99 | test loss 0.3790929615497589  accuracy 0.92\n",
            "train loss 0.3581714630126953 accuracy 0.98 | test loss 0.3790566027164459  accuracy 0.92\n",
            "train loss 0.3581702411174774 accuracy 0.98 | test loss 0.3790437877178192  accuracy 0.92\n",
            "train loss 0.3581700026988983 accuracy 0.98 | test loss 0.37907862663269043  accuracy 0.92\n",
            "train loss 0.3581705391407013 accuracy 0.98 | test loss 0.37904247641563416  accuracy 0.92\n",
            "train loss 0.3581695556640625 accuracy 0.98 | test loss 0.379077285528183  accuracy 0.92\n",
            "train loss 0.35817015171051025 accuracy 0.98 | test loss 0.3790411353111267  accuracy 0.92\n",
            "train loss 0.35816919803619385 accuracy 0.99 | test loss 0.3790905177593231  accuracy 0.92\n",
            "train loss 0.3581703007221222 accuracy 0.98 | test loss 0.37905409932136536  accuracy 0.92\n",
            "train loss 0.3581690788269043 accuracy 0.98 | test loss 0.3790413439273834  accuracy 0.92\n",
            "train loss 0.35816872119903564 accuracy 0.99 | test loss 0.3791028559207916  accuracy 0.92\n",
            "train loss 0.3581702411174774 accuracy 0.98 | test loss 0.3790663778781891  accuracy 0.92\n",
            "train loss 0.35816890001296997 accuracy 0.98 | test loss 0.37903037667274475  accuracy 0.92\n",
            "train loss 0.35816866159439087 accuracy 0.99 | test loss 0.3791065216064453  accuracy 0.92\n",
            "train loss 0.3581700325012207 accuracy 0.98 | test loss 0.37904930114746094  accuracy 0.92\n",
            "train loss 0.3581680357456207 accuracy 0.98 | test loss 0.37902799248695374  accuracy 0.92\n",
            "train loss 0.35816818475723267 accuracy 0.99 | test loss 0.3790895342826843  accuracy 0.92\n",
            "train loss 0.3581688106060028 accuracy 0.98 | test loss 0.37905314564704895  accuracy 0.92\n",
            "train loss 0.3581676483154297 accuracy 0.98 | test loss 0.3790404796600342  accuracy 0.92\n",
            "train loss 0.35816729068756104 accuracy 0.98 | test loss 0.37906238436698914  accuracy 0.92\n",
            "train loss 0.35816749930381775 accuracy 0.98 | test loss 0.37902626395225525  accuracy 0.92\n",
            "train loss 0.3581674098968506 accuracy 0.99 | test loss 0.3790878355503082  accuracy 0.92\n",
            "train loss 0.35816797614097595 accuracy 0.98 | test loss 0.37905141711235046  accuracy 0.92\n",
            "train loss 0.3581666946411133 accuracy 0.98 | test loss 0.3790386915206909  accuracy 0.92\n",
            "train loss 0.3581664562225342 accuracy 0.98 | test loss 0.3790648579597473  accuracy 0.92\n",
            "train loss 0.35816681385040283 accuracy 0.98 | test loss 0.37902864813804626  accuracy 0.92\n",
            "train loss 0.35816633701324463 accuracy 0.98 | test loss 0.37907013297080994  accuracy 0.92\n",
            "train loss 0.3581666350364685 accuracy 0.98 | test loss 0.3790339231491089  accuracy 0.92\n",
            "train loss 0.3581659495830536 accuracy 0.98 | test loss 0.379036009311676  accuracy 0.92\n",
            "train loss 0.3581655025482178 accuracy 0.98 | test loss 0.37905097007751465  accuracy 0.92\n",
            "train loss 0.3581655025482178 accuracy 0.98 | test loss 0.3790150284767151  accuracy 0.92\n",
            "train loss 0.358166366815567 accuracy 0.99 | test loss 0.3790911138057709  accuracy 0.92\n",
            "train loss 0.35816648602485657 accuracy 0.98 | test loss 0.37905460596084595  accuracy 0.92\n",
            "train loss 0.3581652045249939 accuracy 0.98 | test loss 0.37901851534843445  accuracy 0.92\n",
            "train loss 0.35816532373428345 accuracy 0.99 | test loss 0.37909460067749023  accuracy 0.92\n",
            "train loss 0.35816630721092224 accuracy 0.98 | test loss 0.3790373206138611  accuracy 0.92\n",
            "train loss 0.3581644296646118 accuracy 0.98 | test loss 0.37902480363845825  accuracy 0.92\n",
            "train loss 0.35816478729248047 accuracy 0.99 | test loss 0.37907421588897705  accuracy 0.92\n",
            "train loss 0.3581649959087372 accuracy 0.98 | test loss 0.3790377974510193  accuracy 0.92\n",
            "train loss 0.35816389322280884 accuracy 0.98 | test loss 0.3790251910686493  accuracy 0.92\n",
            "train loss 0.35816413164138794 accuracy 0.99 | test loss 0.3790746331214905  accuracy 0.92\n",
            "train loss 0.358164519071579 accuracy 0.98 | test loss 0.37903815507888794  accuracy 0.92\n",
            "train loss 0.3581632971763611 accuracy 0.98 | test loss 0.37902534008026123  accuracy 0.92\n",
            "train loss 0.35816359519958496 accuracy 0.99 | test loss 0.37910139560699463  accuracy 0.92\n",
            "train loss 0.3581649363040924 accuracy 0.98 | test loss 0.3790438771247864  accuracy 0.92\n",
            "train loss 0.3581630289554596 accuracy 0.98 | test loss 0.3790278136730194  accuracy 0.92\n",
            "train loss 0.3581627607345581 accuracy 0.98 | test loss 0.3790626525878906  accuracy 0.92\n",
            "train loss 0.3581632077693939 accuracy 0.98 | test loss 0.3790264129638672  accuracy 0.92\n",
            "train loss 0.3581623435020447 accuracy 0.99 | test loss 0.3790757954120636  accuracy 0.92\n",
            "train loss 0.35816332697868347 accuracy 0.98 | test loss 0.37903934717178345  accuracy 0.92\n",
            "train loss 0.3581622540950775 accuracy 0.98 | test loss 0.37902653217315674  accuracy 0.92\n",
            "train loss 0.35816192626953125 accuracy 0.99 | test loss 0.3790879249572754  accuracy 0.92\n",
            "train loss 0.3581632077693939 accuracy 0.98 | test loss 0.3790513575077057  accuracy 0.92\n",
            "train loss 0.35816192626953125 accuracy 0.98 | test loss 0.3790152370929718  accuracy 0.92\n",
            "train loss 0.3581618368625641 accuracy 0.99 | test loss 0.37909117341041565  accuracy 0.92\n",
            "train loss 0.3581629991531372 accuracy 0.98 | test loss 0.37903377413749695  accuracy 0.92\n",
            "train loss 0.3581610918045044 accuracy 0.98 | test loss 0.37903568148612976  accuracy 0.92\n",
            "train loss 0.35816073417663574 accuracy 0.98 | test loss 0.37899959087371826  accuracy 0.92\n",
            "train loss 0.3581623136997223 accuracy 0.99 | test loss 0.3790756165981293  accuracy 0.92\n",
            "train loss 0.35816168785095215 accuracy 0.98 | test loss 0.37903907895088196  accuracy 0.92\n",
            "train loss 0.3581605553627014 accuracy 0.98 | test loss 0.37902626395225525  accuracy 0.92\n",
            "train loss 0.35816019773483276 accuracy 0.98 | test loss 0.37906092405319214  accuracy 0.92\n",
            "train loss 0.35816076397895813 accuracy 0.98 | test loss 0.3790245056152344  accuracy 0.92\n",
            "train loss 0.3581598103046417 accuracy 0.99 | test loss 0.37907376885414124  accuracy 0.92\n",
            "train loss 0.3581608533859253 accuracy 0.98 | test loss 0.3790372312068939  accuracy 0.92\n",
            "train loss 0.3581596314907074 accuracy 0.98 | test loss 0.3790242671966553  accuracy 0.92\n",
            "train loss 0.3581593334674835 accuracy 0.98 | test loss 0.37905895709991455  accuracy 0.92\n",
            "train loss 0.3581599295139313 accuracy 0.98 | test loss 0.3790225386619568  accuracy 0.92\n",
            "train loss 0.3581589162349701 accuracy 0.99 | test loss 0.37907183170318604  accuracy 0.92\n",
            "train loss 0.35816001892089844 accuracy 0.98 | test loss 0.3790353238582611  accuracy 0.92\n",
            "train loss 0.35815882682800293 accuracy 0.98 | test loss 0.3790222704410553  accuracy 0.92\n",
            "train loss 0.35815852880477905 accuracy 0.99 | test loss 0.37908363342285156  accuracy 0.92\n",
            "train loss 0.3581599295139313 accuracy 0.98 | test loss 0.3790470063686371  accuracy 0.92\n",
            "train loss 0.35815858840942383 accuracy 0.98 | test loss 0.379010945558548  accuracy 0.92\n",
            "train loss 0.35815849900245667 accuracy 0.99 | test loss 0.3790869414806366  accuracy 0.92\n",
            "train loss 0.3581596612930298 accuracy 0.98 | test loss 0.3790294826030731  accuracy 0.92\n",
            "train loss 0.3581576347351074 accuracy 0.98 | test loss 0.37900805473327637  accuracy 0.92\n",
            "train loss 0.35815802216529846 accuracy 0.99 | test loss 0.37906935811042786  accuracy 0.92\n",
            "train loss 0.35815852880477905 accuracy 0.98 | test loss 0.3790328800678253  accuracy 0.92\n",
            "train loss 0.35815733671188354 accuracy 0.98 | test loss 0.37902000546455383  accuracy 0.92\n",
            "train loss 0.35815706849098206 accuracy 0.98 | test loss 0.37904173135757446  accuracy 0.92\n",
            "train loss 0.3581571578979492 accuracy 0.98 | test loss 0.3790055513381958  accuracy 0.92\n",
            "train loss 0.35815733671188354 accuracy 0.99 | test loss 0.37906694412231445  accuracy 0.92\n",
            "train loss 0.3581576347351074 accuracy 0.98 | test loss 0.37903037667274475  accuracy 0.92\n",
            "train loss 0.35815638303756714 accuracy 0.98 | test loss 0.3790176808834076  accuracy 0.92\n",
            "train loss 0.3581562638282776 accuracy 0.98 | test loss 0.37904372811317444  accuracy 0.92\n",
            "train loss 0.3581564724445343 accuracy 0.98 | test loss 0.379007488489151  accuracy 0.92\n",
            "train loss 0.35815614461898804 accuracy 0.98 | test loss 0.3790488839149475  accuracy 0.92\n",
            "train loss 0.35815632343292236 accuracy 0.98 | test loss 0.3790125250816345  accuracy 0.92\n",
            "train loss 0.35815563797950745 accuracy 0.98 | test loss 0.3790344297885895  accuracy 0.92\n",
            "train loss 0.35815563797950745 accuracy 0.98 | test loss 0.3790212869644165  accuracy 0.92\n",
            "train loss 0.3581549823284149 accuracy 0.98 | test loss 0.37900862097740173  accuracy 0.92\n",
            "train loss 0.3581555187702179 accuracy 0.99 | test loss 0.3790845274925232  accuracy 0.92\n",
            "train loss 0.35815659165382385 accuracy 0.98 | test loss 0.3790477216243744  accuracy 0.92\n",
            "train loss 0.3581552803516388 accuracy 0.98 | test loss 0.3790113031864166  accuracy 0.92\n",
            "train loss 0.3581545948982239 accuracy 0.99 | test loss 0.3790725767612457  accuracy 0.92\n",
            "train loss 0.3581557273864746 accuracy 0.98 | test loss 0.37903597950935364  accuracy 0.92\n",
            "train loss 0.35815444588661194 accuracy 0.98 | test loss 0.3789999186992645  accuracy 0.92\n",
            "train loss 0.3581545948982239 accuracy 0.99 | test loss 0.3790758550167084  accuracy 0.92\n",
            "train loss 0.35815542936325073 accuracy 0.98 | test loss 0.3790183961391449  accuracy 0.92\n",
            "train loss 0.35815373063087463 accuracy 0.98 | test loss 0.3790401518344879  accuracy 0.92\n",
            "train loss 0.35815390944480896 accuracy 0.98 | test loss 0.37900370359420776  accuracy 0.92\n",
            "train loss 0.3581535518169403 accuracy 0.99 | test loss 0.37906500697135925  accuracy 0.92\n",
            "train loss 0.35815444588661194 accuracy 0.98 | test loss 0.37902843952178955  accuracy 0.92\n",
            "train loss 0.35815322399139404 accuracy 0.98 | test loss 0.37901541590690613  accuracy 0.92\n",
            "train loss 0.358152836561203 accuracy 0.98 | test loss 0.379037082195282  accuracy 0.92\n",
            "train loss 0.3581530749797821 accuracy 0.98 | test loss 0.3790006935596466  accuracy 0.92\n",
            "train loss 0.3581528663635254 accuracy 0.99 | test loss 0.3790620267391205  accuracy 0.92\n",
            "train loss 0.3581535220146179 accuracy 0.98 | test loss 0.379025399684906  accuracy 0.92\n",
            "train loss 0.35815224051475525 accuracy 0.98 | test loss 0.37898921966552734  accuracy 0.92\n",
            "train loss 0.35815298557281494 accuracy 0.99 | test loss 0.3790651857852936  accuracy 0.92\n",
            "train loss 0.3581531345844269 accuracy 0.98 | test loss 0.3790286183357239  accuracy 0.92\n",
            "train loss 0.35815200209617615 accuracy 0.98 | test loss 0.3790155351161957  accuracy 0.92\n",
            "train loss 0.358151376247406 accuracy 0.98 | test loss 0.37901729345321655  accuracy 0.92\n",
            "train loss 0.3581511676311493 accuracy 0.98 | test loss 0.3790085017681122  accuracy 0.92\n",
            "train loss 0.35815107822418213 accuracy 0.98 | test loss 0.37904319167137146  accuracy 0.92\n",
            "train loss 0.3581516444683075 accuracy 0.98 | test loss 0.3790067136287689  accuracy 0.92\n",
            "train loss 0.3581506907939911 accuracy 0.98 | test loss 0.3790084719657898  accuracy 0.92\n",
            "train loss 0.3581506311893463 accuracy 0.98 | test loss 0.37904295325279236  accuracy 0.92\n",
            "train loss 0.3581511676311493 accuracy 0.98 | test loss 0.379006564617157  accuracy 0.92\n",
            "train loss 0.3581501543521881 accuracy 0.98 | test loss 0.37902122735977173  accuracy 0.92\n",
            "train loss 0.3581501543521881 accuracy 0.98 | test loss 0.3789851665496826  accuracy 0.92\n",
            "train loss 0.35815122723579407 accuracy 0.99 | test loss 0.37906113266944885  accuracy 0.92\n",
            "train loss 0.35815107822418213 accuracy 0.98 | test loss 0.3790244162082672  accuracy 0.92\n",
            "train loss 0.35814979672431946 accuracy 0.98 | test loss 0.378988116979599  accuracy 0.92\n",
            "train loss 0.3581502437591553 accuracy 0.99 | test loss 0.37906408309936523  accuracy 0.92\n",
            "train loss 0.3581508696079254 accuracy 0.98 | test loss 0.37900659441947937  accuracy 0.92\n",
            "train loss 0.35814911127090454 accuracy 0.98 | test loss 0.3790282607078552  accuracy 0.92\n",
            "train loss 0.3581492602825165 accuracy 0.98 | test loss 0.37899184226989746  accuracy 0.92\n",
            "train loss 0.35814931988716125 accuracy 0.99 | test loss 0.379052996635437  accuracy 0.92\n",
            "train loss 0.3581497371196747 accuracy 0.98 | test loss 0.3790163993835449  accuracy 0.92\n",
            "train loss 0.3581486940383911 accuracy 0.98 | test loss 0.37900328636169434  accuracy 0.92\n",
            "train loss 0.3581482172012329 accuracy 0.98 | test loss 0.3790249824523926  accuracy 0.92\n",
            "train loss 0.35814833641052246 accuracy 0.98 | test loss 0.3789885640144348  accuracy 0.92\n",
            "train loss 0.35814863443374634 accuracy 0.99 | test loss 0.37904977798461914  accuracy 0.92\n",
            "train loss 0.35814887285232544 accuracy 0.98 | test loss 0.37901321053504944  accuracy 0.92\n",
            "train loss 0.3581477403640747 accuracy 0.98 | test loss 0.37900015711784363  accuracy 0.92\n",
            "train loss 0.3581475019454956 accuracy 0.99 | test loss 0.37904930114746094  accuracy 0.92\n",
            "train loss 0.35814833641052246 accuracy 0.98 | test loss 0.37901267409324646  accuracy 0.92\n",
            "train loss 0.35814711451530457 accuracy 0.98 | test loss 0.3789995610713959  accuracy 0.92\n",
            "train loss 0.3581469655036926 accuracy 0.99 | test loss 0.3790752589702606  accuracy 0.92\n",
            "train loss 0.3581489622592926 accuracy 0.98 | test loss 0.3790174722671509  accuracy 0.92\n",
            "train loss 0.35814669728279114 accuracy 0.98 | test loss 0.37898120284080505  accuracy 0.92\n",
            "train loss 0.3581475615501404 accuracy 0.99 | test loss 0.3790571391582489  accuracy 0.92\n",
            "train loss 0.35814765095710754 accuracy 0.98 | test loss 0.3790203034877777  accuracy 0.92\n",
            "train loss 0.3581463098526001 accuracy 0.98 | test loss 0.37898391485214233  accuracy 0.92\n",
            "train loss 0.3581465780735016 accuracy 0.99 | test loss 0.3790598511695862  accuracy 0.92\n",
            "train loss 0.35814735293388367 accuracy 0.98 | test loss 0.37900230288505554  accuracy 0.92\n",
            "train loss 0.35814550518989563 accuracy 0.98 | test loss 0.37900930643081665  accuracy 0.92\n",
            "train loss 0.3581453561782837 accuracy 0.98 | test loss 0.37899619340896606  accuracy 0.92\n",
            "train loss 0.3581455647945404 accuracy 0.98 | test loss 0.3790220320224762  accuracy 0.92\n",
            "train loss 0.35814544558525085 accuracy 0.98 | test loss 0.3789854645729065  accuracy 0.92\n",
            "train loss 0.3581453561782837 accuracy 0.99 | test loss 0.37904661893844604  accuracy 0.92\n",
            "train loss 0.35814589262008667 accuracy 0.98 | test loss 0.3790099322795868  accuracy 0.92\n",
            "train loss 0.3581448197364807 accuracy 0.98 | test loss 0.37899675965309143  accuracy 0.92\n",
            "train loss 0.3581443727016449 accuracy 0.98 | test loss 0.37901830673217773  accuracy 0.92\n",
            "train loss 0.35814452171325684 accuracy 0.98 | test loss 0.3789818584918976  accuracy 0.92\n",
            "train loss 0.3581446707248688 accuracy 0.99 | test loss 0.3790430724620819  accuracy 0.92\n",
            "train loss 0.3581450283527374 accuracy 0.98 | test loss 0.37900638580322266  accuracy 0.92\n",
            "train loss 0.3581438362598419 accuracy 0.98 | test loss 0.3789932131767273  accuracy 0.92\n",
            "train loss 0.3581436574459076 accuracy 0.99 | test loss 0.37904229760169983  accuracy 0.92\n",
            "train loss 0.35814452171325684 accuracy 0.98 | test loss 0.379005491733551  accuracy 0.92\n",
            "train loss 0.35814327001571655 accuracy 0.98 | test loss 0.37899234890937805  accuracy 0.92\n",
            "train loss 0.35814306139945984 accuracy 0.99 | test loss 0.3790414035320282  accuracy 0.92\n",
            "train loss 0.35814398527145386 accuracy 0.98 | test loss 0.3790045976638794  accuracy 0.92\n",
            "train loss 0.3581427037715912 accuracy 0.98 | test loss 0.37899139523506165  accuracy 0.92\n",
            "train loss 0.35814276337623596 accuracy 0.98 | test loss 0.3790293037891388  accuracy 0.92\n",
            "train loss 0.358143150806427 accuracy 0.98 | test loss 0.3789927065372467  accuracy 0.92\n",
            "train loss 0.3581421673297882 accuracy 0.98 | test loss 0.3789798617362976  accuracy 0.92\n",
            "train loss 0.35814276337623596 accuracy 0.99 | test loss 0.3790556490421295  accuracy 0.92\n",
            "train loss 0.35814347863197327 accuracy 0.98 | test loss 0.3789979815483093  accuracy 0.92\n",
            "train loss 0.35814169049263 accuracy 0.98 | test loss 0.378996342420578  accuracy 0.92\n",
            "train loss 0.35814163088798523 accuracy 0.98 | test loss 0.37898316979408264  accuracy 0.92\n",
            "train loss 0.35814177989959717 accuracy 0.99 | test loss 0.3790443241596222  accuracy 0.92\n",
            "train loss 0.3581424951553345 accuracy 0.98 | test loss 0.3790075480937958  accuracy 0.92\n",
            "train loss 0.358141154050827 accuracy 0.98 | test loss 0.3789710998535156  accuracy 0.92\n",
            "train loss 0.35814177989959717 accuracy 0.99 | test loss 0.3790470063686371  accuracy 0.92\n",
            "train loss 0.3581421673297882 accuracy 0.98 | test loss 0.3790101110935211  accuracy 0.92\n",
            "train loss 0.35814085602760315 accuracy 0.98 | test loss 0.378996878862381  accuracy 0.92\n",
            "train loss 0.3581402003765106 accuracy 0.98 | test loss 0.3789984881877899  accuracy 0.92\n",
            "train loss 0.35814011096954346 accuracy 0.98 | test loss 0.37898948788642883  accuracy 0.92\n",
            "train loss 0.35813993215560913 accuracy 0.98 | test loss 0.3790239691734314  accuracy 0.92\n",
            "train loss 0.35814058780670166 accuracy 0.98 | test loss 0.3789873719215393  accuracy 0.92\n",
            "train loss 0.35813963413238525 accuracy 0.98 | test loss 0.3790165185928345  accuracy 0.92\n",
            "train loss 0.3581400215625763 accuracy 0.98 | test loss 0.37897995114326477  accuracy 0.92\n",
            "train loss 0.35813960433006287 accuracy 0.99 | test loss 0.3790411353111267  accuracy 0.92\n",
            "train loss 0.3581404685974121 accuracy 0.98 | test loss 0.37900426983833313  accuracy 0.92\n",
            "train loss 0.35813918709754944 accuracy 0.98 | test loss 0.3789679706096649  accuracy 0.92\n",
            "train loss 0.3581397235393524 accuracy 0.99 | test loss 0.3790438771247864  accuracy 0.92\n",
            "train loss 0.35814017057418823 accuracy 0.98 | test loss 0.37898626923561096  accuracy 0.92\n",
            "train loss 0.35813865065574646 accuracy 0.98 | test loss 0.37900787591934204  accuracy 0.92\n",
            "train loss 0.35813865065574646 accuracy 0.98 | test loss 0.3789713680744171  accuracy 0.92\n",
            "train loss 0.35813865065574646 accuracy 0.99 | test loss 0.37903258204460144  accuracy 0.92\n",
            "train loss 0.35813915729522705 accuracy 0.98 | test loss 0.37899574637413025  accuracy 0.92\n",
            "train loss 0.3581380844116211 accuracy 0.98 | test loss 0.3789825439453125  accuracy 0.92\n",
            "train loss 0.3581378161907196 accuracy 0.98 | test loss 0.3790040910243988  accuracy 0.92\n",
            "train loss 0.35813772678375244 accuracy 0.98 | test loss 0.3789675831794739  accuracy 0.92\n",
            "train loss 0.3581380248069763 accuracy 0.99 | test loss 0.3790433704853058  accuracy 0.92\n",
            "train loss 0.3581388294696808 accuracy 0.98 | test loss 0.37898552417755127  accuracy 0.92\n",
            "train loss 0.3581368923187256 accuracy 0.98 | test loss 0.3789723813533783  accuracy 0.92\n",
            "train loss 0.3581375181674957 accuracy 0.99 | test loss 0.37904807925224304  accuracy 0.92\n",
            "train loss 0.3581383526325226 accuracy 0.98 | test loss 0.3790110647678375  accuracy 0.92\n",
            "train loss 0.35813698172569275 accuracy 0.98 | test loss 0.3789745271205902  accuracy 0.92\n",
            "train loss 0.35813650488853455 accuracy 0.99 | test loss 0.37902358174324036  accuracy 0.92\n",
            "train loss 0.3581370711326599 accuracy 0.98 | test loss 0.37898677587509155  accuracy 0.92\n",
            "train loss 0.3581361174583435 accuracy 0.98 | test loss 0.3789735436439514  accuracy 0.92\n",
            "train loss 0.35813620686531067 accuracy 0.99 | test loss 0.37903472781181335  accuracy 0.92\n",
            "train loss 0.35813698172569275 accuracy 0.98 | test loss 0.3789978325366974  accuracy 0.92\n",
            "train loss 0.3581356108188629 accuracy 0.98 | test loss 0.37896132469177246  accuracy 0.92\n",
            "train loss 0.35813623666763306 accuracy 0.99 | test loss 0.379037082195282  accuracy 0.92\n",
            "train loss 0.3581365942955017 accuracy 0.98 | test loss 0.37900015711784363  accuracy 0.92\n",
            "train loss 0.3581353425979614 accuracy 0.98 | test loss 0.37898680567741394  accuracy 0.92\n",
            "train loss 0.3581346869468689 accuracy 0.98 | test loss 0.3789738118648529  accuracy 0.92\n",
            "train loss 0.3581351339817047 accuracy 0.99 | test loss 0.3790228068828583  accuracy 0.92\n",
            "train loss 0.3581354320049286 accuracy 0.98 | test loss 0.3789859712123871  accuracy 0.92\n",
            "train loss 0.3581341505050659 accuracy 0.98 | test loss 0.3789496123790741  accuracy 0.92\n",
            "train loss 0.358135849237442 accuracy 0.99 | test loss 0.379025399684906  accuracy 0.92\n",
            "train loss 0.35813507437705994 accuracy 0.98 | test loss 0.378988653421402  accuracy 0.92\n",
            "train loss 0.3581339120864868 accuracy 0.98 | test loss 0.3789753019809723  accuracy 0.92\n",
            "train loss 0.3581337034702301 accuracy 0.98 | test loss 0.3790096938610077  accuracy 0.92\n",
            "train loss 0.35813412070274353 accuracy 0.98 | test loss 0.3789728879928589  accuracy 0.92\n",
            "train loss 0.358133465051651 accuracy 0.99 | test loss 0.3790218234062195  accuracy 0.92\n",
            "train loss 0.3581341505050659 accuracy 0.98 | test loss 0.3789849877357483  accuracy 0.92\n",
            "train loss 0.3581329882144928 accuracy 0.98 | test loss 0.3789716362953186  accuracy 0.92\n",
            "train loss 0.358132928609848 accuracy 0.99 | test loss 0.3790326714515686  accuracy 0.92\n",
            "train loss 0.35813406109809875 accuracy 0.98 | test loss 0.3789956569671631  accuracy 0.92\n",
            "train loss 0.3581326901912689 accuracy 0.98 | test loss 0.3789592683315277  accuracy 0.92\n",
            "train loss 0.35813307762145996 accuracy 0.99 | test loss 0.37903493642807007  accuracy 0.92\n",
            "train loss 0.3581336438655853 accuracy 0.98 | test loss 0.3789979815483093  accuracy 0.92\n",
            "train loss 0.3581323027610779 accuracy 0.98 | test loss 0.3789614140987396  accuracy 0.92\n",
            "train loss 0.35813215374946594 accuracy 0.99 | test loss 0.37903717160224915  accuracy 0.92\n",
            "train loss 0.3581335246562958 accuracy 0.98 | test loss 0.37897926568984985  accuracy 0.92\n",
            "train loss 0.3581315577030182 accuracy 0.98 | test loss 0.37898069620132446  accuracy 0.92\n",
            "train loss 0.3581312596797943 accuracy 0.98 | test loss 0.37896740436553955  accuracy 0.92\n",
            "train loss 0.358131468296051 accuracy 0.99 | test loss 0.3790430426597595  accuracy 0.92\n",
            "train loss 0.3581327795982361 accuracy 0.98 | test loss 0.3790058493614197  accuracy 0.92\n",
            "train loss 0.35813143849372864 accuracy 0.98 | test loss 0.3789689838886261  accuracy 0.92\n",
            "train loss 0.3581307530403137 accuracy 0.98 | test loss 0.3790033757686615  accuracy 0.92\n",
            "train loss 0.3581310510635376 accuracy 0.98 | test loss 0.3789665102958679  accuracy 0.92\n",
            "train loss 0.3581303656101227 accuracy 0.99 | test loss 0.3790155053138733  accuracy 0.92\n",
            "train loss 0.35813114047050476 accuracy 0.98 | test loss 0.37897858023643494  accuracy 0.92\n",
            "train loss 0.3581301271915436 accuracy 0.98 | test loss 0.37896525859832764  accuracy 0.92\n",
            "train loss 0.35812994837760925 accuracy 0.99 | test loss 0.3790261745452881  accuracy 0.92\n",
            "train loss 0.3581309914588928 accuracy 0.98 | test loss 0.37898921966552734  accuracy 0.92\n",
            "train loss 0.3581296503543854 accuracy 0.98 | test loss 0.3789527714252472  accuracy 0.92\n",
            "train loss 0.3581300377845764 accuracy 0.99 | test loss 0.3790285289287567  accuracy 0.92\n",
            "train loss 0.35813063383102417 accuracy 0.98 | test loss 0.3789706230163574  accuracy 0.92\n",
            "train loss 0.35812902450561523 accuracy 0.98 | test loss 0.3789920210838318  accuracy 0.92\n",
            "train loss 0.3581291139125824 accuracy 0.98 | test loss 0.37895527482032776  accuracy 0.92\n",
            "train loss 0.35812908411026 accuracy 0.99 | test loss 0.37901633977890015  accuracy 0.92\n",
            "train loss 0.3581296503543854 accuracy 0.98 | test loss 0.3789794445037842  accuracy 0.92\n",
            "train loss 0.35812845826148987 accuracy 0.98 | test loss 0.3789660632610321  accuracy 0.92\n",
            "train loss 0.35812821984291077 accuracy 0.99 | test loss 0.3790149986743927  accuracy 0.92\n",
            "train loss 0.35812902450561523 accuracy 0.98 | test loss 0.37897810339927673  accuracy 0.92\n",
            "train loss 0.3581278622150421 accuracy 0.98 | test loss 0.37896472215652466  accuracy 0.92\n",
            "train loss 0.3581277132034302 accuracy 0.99 | test loss 0.3790135979652405  accuracy 0.92\n",
            "train loss 0.35812854766845703 accuracy 0.98 | test loss 0.3789766728878021  accuracy 0.92\n",
            "train loss 0.35812726616859436 accuracy 0.98 | test loss 0.3789632320404053  accuracy 0.92\n",
            "train loss 0.3581272065639496 accuracy 0.99 | test loss 0.3790241777896881  accuracy 0.92\n",
            "train loss 0.3581284284591675 accuracy 0.98 | test loss 0.37898707389831543  accuracy 0.92\n",
            "train loss 0.35812705755233765 accuracy 0.98 | test loss 0.37895041704177856  accuracy 0.92\n",
            "train loss 0.3581273555755615 accuracy 0.99 | test loss 0.37902605533599854  accuracy 0.92\n",
            "train loss 0.35812801122665405 accuracy 0.98 | test loss 0.3789888322353363  accuracy 0.92\n",
            "train loss 0.3581266701221466 accuracy 0.98 | test loss 0.3789520263671875  accuracy 0.92\n",
            "train loss 0.3581264317035675 accuracy 0.99 | test loss 0.3790009915828705  accuracy 0.92\n",
            "train loss 0.35812675952911377 accuracy 0.98 | test loss 0.3789641559123993  accuracy 0.92\n",
            "train loss 0.3581259548664093 accuracy 0.98 | test loss 0.378950834274292  accuracy 0.92\n",
            "train loss 0.35812607407569885 accuracy 0.99 | test loss 0.37902647256851196  accuracy 0.92\n",
            "train loss 0.35812726616859436 accuracy 0.98 | test loss 0.3789685070514679  accuracy 0.92\n",
            "train loss 0.35812515020370483 accuracy 0.98 | test loss 0.37895527482032776  accuracy 0.92\n",
            "train loss 0.3581255376338959 accuracy 0.99 | test loss 0.37900421023368835  accuracy 0.92\n",
            "train loss 0.35812586545944214 accuracy 0.98 | test loss 0.3789673149585724  accuracy 0.92\n",
            "train loss 0.35812461376190186 accuracy 0.98 | test loss 0.37898147106170654  accuracy 0.92\n",
            "train loss 0.35812485218048096 accuracy 0.98 | test loss 0.3789447247982025  accuracy 0.92\n",
            "train loss 0.35812535881996155 accuracy 0.99 | test loss 0.37902045249938965  accuracy 0.92\n",
            "train loss 0.3581257462501526 accuracy 0.98 | test loss 0.37898316979408264  accuracy 0.92\n",
            "train loss 0.35812437534332275 accuracy 0.98 | test loss 0.37894636392593384  accuracy 0.92\n",
            "train loss 0.3581244647502899 accuracy 0.99 | test loss 0.3790220618247986  accuracy 0.92\n",
            "train loss 0.3581254482269287 accuracy 0.98 | test loss 0.37896406650543213  accuracy 0.92\n",
            "train loss 0.3581235110759735 accuracy 0.98 | test loss 0.37897083163261414  accuracy 0.92\n",
            "train loss 0.35812339186668396 accuracy 0.98 | test loss 0.378934383392334  accuracy 0.92\n",
            "train loss 0.3581245243549347 accuracy 0.99 | test loss 0.37901008129119873  accuracy 0.92\n",
            "train loss 0.35812434554100037 accuracy 0.98 | test loss 0.37897294759750366  accuracy 0.92\n",
            "train loss 0.35812315344810486 accuracy 0.98 | test loss 0.37895938754081726  accuracy 0.92\n",
            "train loss 0.35812267661094666 accuracy 0.99 | test loss 0.3790081739425659  accuracy 0.92\n",
            "train loss 0.358123779296875 accuracy 0.98 | test loss 0.37897104024887085  accuracy 0.92\n",
            "train loss 0.3581225574016571 accuracy 0.98 | test loss 0.37895750999450684  accuracy 0.92\n",
            "train loss 0.3581222593784332 accuracy 0.98 | test loss 0.3789917528629303  accuracy 0.92\n",
            "train loss 0.3581227660179138 accuracy 0.98 | test loss 0.37895482778549194  accuracy 0.92\n",
            "train loss 0.3581219017505646 accuracy 0.99 | test loss 0.379003643989563  accuracy 0.92\n",
            "train loss 0.358122855424881 accuracy 0.98 | test loss 0.3789665102958679  accuracy 0.92\n",
            "train loss 0.3581216335296631 accuracy 0.98 | test loss 0.3789529800415039  accuracy 0.92\n",
            "train loss 0.35812148451805115 accuracy 0.99 | test loss 0.37901389598846436  accuracy 0.92\n",
            "train loss 0.35812273621559143 accuracy 0.98 | test loss 0.3789766728878021  accuracy 0.92\n",
            "train loss 0.3581213653087616 accuracy 0.98 | test loss 0.3789399564266205  accuracy 0.92\n",
            "train loss 0.3581216037273407 accuracy 0.99 | test loss 0.37901559472084045  accuracy 0.92\n",
            "train loss 0.358122318983078 accuracy 0.98 | test loss 0.3789783716201782  accuracy 0.92\n",
            "train loss 0.35812094807624817 accuracy 0.98 | test loss 0.37894147634506226  accuracy 0.92\n",
            "train loss 0.35812070965766907 accuracy 0.99 | test loss 0.379017174243927  accuracy 0.92\n",
            "train loss 0.3581221401691437 accuracy 0.98 | test loss 0.37895917892456055  accuracy 0.92\n",
            "train loss 0.3581201136112213 accuracy 0.98 | test loss 0.3789604902267456  accuracy 0.92\n",
            "train loss 0.35811981558799744 accuracy 0.98 | test loss 0.378946989774704  accuracy 0.92\n",
            "train loss 0.35812002420425415 accuracy 0.99 | test loss 0.378995805978775  accuracy 0.92\n",
            "train loss 0.35812053084373474 accuracy 0.98 | test loss 0.37895864248275757  accuracy 0.92\n",
            "train loss 0.35811927914619446 accuracy 0.98 | test loss 0.3789726495742798  accuracy 0.92\n",
            "train loss 0.3581194579601288 accuracy 0.98 | test loss 0.3789357542991638  accuracy 0.92\n",
            "train loss 0.35812002420425415 accuracy 0.99 | test loss 0.3790113627910614  accuracy 0.92\n",
            "train loss 0.3581204116344452 accuracy 0.98 | test loss 0.3789741098880768  accuracy 0.92\n",
            "train loss 0.35811904072761536 accuracy 0.98 | test loss 0.378937304019928  accuracy 0.92\n",
            "train loss 0.3581191301345825 accuracy 0.99 | test loss 0.37899819016456604  accuracy 0.92\n",
            "train loss 0.35811948776245117 accuracy 0.98 | test loss 0.3789609372615814  accuracy 0.92\n",
            "train loss 0.3581182360649109 accuracy 0.98 | test loss 0.37894758582115173  accuracy 0.92\n",
            "train loss 0.3581182658672333 accuracy 0.99 | test loss 0.378996342420578  accuracy 0.92\n",
            "train loss 0.35811901092529297 accuracy 0.98 | test loss 0.37895917892456055  accuracy 0.92\n",
            "train loss 0.3581176698207855 accuracy 0.98 | test loss 0.3789456784725189  accuracy 0.92\n",
            "train loss 0.35811781883239746 accuracy 0.98 | test loss 0.378971129655838  accuracy 0.92\n",
            "train loss 0.3581177294254303 accuracy 0.98 | test loss 0.3789343237876892  accuracy 0.92\n",
            "train loss 0.3581177294254303 accuracy 0.99 | test loss 0.3789950907230377  accuracy 0.92\n",
            "train loss 0.3581182062625885 accuracy 0.98 | test loss 0.3789578080177307  accuracy 0.92\n",
            "train loss 0.35811713337898254 accuracy 0.98 | test loss 0.3789443075656891  accuracy 0.92\n",
            "train loss 0.3581167459487915 accuracy 0.99 | test loss 0.37899306416511536  accuracy 0.92\n",
            "train loss 0.3581176698207855 accuracy 0.98 | test loss 0.3789558708667755  accuracy 0.92\n",
            "train loss 0.3581165373325348 accuracy 0.98 | test loss 0.3789423406124115  accuracy 0.92\n",
            "train loss 0.3581162095069885 accuracy 0.99 | test loss 0.37899112701416016  accuracy 0.92\n",
            "train loss 0.35811710357666016 accuracy 0.98 | test loss 0.37895387411117554  accuracy 0.92\n",
            "train loss 0.35811591148376465 accuracy 0.98 | test loss 0.3789403438568115  accuracy 0.92\n",
            "train loss 0.3581160008907318 accuracy 0.99 | test loss 0.3790012300014496  accuracy 0.92\n",
            "train loss 0.3581169545650482 accuracy 0.98 | test loss 0.37896400690078735  accuracy 0.92\n",
            "train loss 0.3581155836582184 accuracy 0.98 | test loss 0.37892723083496094  accuracy 0.92\n",
            "train loss 0.3581160604953766 accuracy 0.99 | test loss 0.3790028691291809  accuracy 0.92\n",
            "train loss 0.3581165671348572 accuracy 0.98 | test loss 0.3789655864238739  accuracy 0.92\n",
            "train loss 0.35811519622802734 accuracy 0.98 | test loss 0.3789287507534027  accuracy 0.92\n",
            "train loss 0.35811513662338257 accuracy 0.99 | test loss 0.37900421023368835  accuracy 0.92\n",
            "train loss 0.35811635851860046 accuracy 0.98 | test loss 0.3789460361003876  accuracy 0.92\n",
            "train loss 0.3581143915653229 accuracy 0.98 | test loss 0.3789326250553131  accuracy 0.92\n",
            "train loss 0.35811465978622437 accuracy 0.99 | test loss 0.37898147106170654  accuracy 0.92\n",
            "train loss 0.3581148684024811 accuracy 0.98 | test loss 0.3789443075656891  accuracy 0.92\n",
            "train loss 0.35811376571655273 accuracy 0.98 | test loss 0.37893083691596985  accuracy 0.92\n",
            "train loss 0.3581142723560333 accuracy 0.99 | test loss 0.3790062963962555  accuracy 0.92\n",
            "train loss 0.35811522603034973 accuracy 0.98 | test loss 0.3789689540863037  accuracy 0.92\n",
            "train loss 0.3581138551235199 accuracy 0.98 | test loss 0.37893202900886536  accuracy 0.92\n",
            "train loss 0.3581134080886841 accuracy 0.99 | test loss 0.3790074586868286  accuracy 0.92\n",
            "train loss 0.35811498761177063 accuracy 0.98 | test loss 0.3789491653442383  accuracy 0.92\n",
            "train loss 0.35811278223991394 accuracy 0.98 | test loss 0.37893572449684143  accuracy 0.92\n",
            "train loss 0.35811302065849304 accuracy 0.99 | test loss 0.3789845108985901  accuracy 0.92\n",
            "train loss 0.3581135869026184 accuracy 0.98 | test loss 0.37894728779792786  accuracy 0.92\n",
            "train loss 0.3581122159957886 accuracy 0.98 | test loss 0.37895357608795166  accuracy 0.92\n",
            "train loss 0.35811224579811096 accuracy 0.98 | test loss 0.3789166808128357  accuracy 0.92\n",
            "train loss 0.35811322927474976 accuracy 0.99 | test loss 0.37899214029312134  accuracy 0.92\n",
            "train loss 0.358113169670105 accuracy 0.98 | test loss 0.37895482778549194  accuracy 0.92\n",
            "train loss 0.3581118583679199 accuracy 0.98 | test loss 0.378941148519516  accuracy 0.92\n",
            "train loss 0.3581114411354065 accuracy 0.98 | test loss 0.37895187735557556  accuracy 0.92\n",
            "train loss 0.35811153054237366 accuracy 0.98 | test loss 0.3789381980895996  accuracy 0.92\n",
            "train loss 0.35811102390289307 accuracy 0.99 | test loss 0.3789869248867035  accuracy 0.92\n",
            "train loss 0.35811224579811096 accuracy 0.98 | test loss 0.3789495825767517  accuracy 0.92\n",
            "train loss 0.3581109046936035 accuracy 0.98 | test loss 0.37893593311309814  accuracy 0.92\n",
            "train loss 0.358110636472702 accuracy 0.98 | test loss 0.37897348403930664  accuracy 0.92\n",
            "train loss 0.3581114113330841 accuracy 0.98 | test loss 0.378936231136322  accuracy 0.92\n",
            "train loss 0.35811033844947815 accuracy 0.98 | test loss 0.37892287969589233  accuracy 0.92\n",
            "train loss 0.3581107258796692 accuracy 0.99 | test loss 0.3789982497692108  accuracy 0.92\n",
            "train loss 0.3581116795539856 accuracy 0.98 | test loss 0.37894001603126526  accuracy 0.92\n",
            "train loss 0.35810989141464233 accuracy 0.98 | test loss 0.37893784046173096  accuracy 0.92\n",
            "train loss 0.35810986161231995 accuracy 0.98 | test loss 0.37892425060272217  accuracy 0.92\n",
            "train loss 0.35810989141464233 accuracy 0.99 | test loss 0.37898507714271545  accuracy 0.92\n",
            "train loss 0.358110636472702 accuracy 0.98 | test loss 0.37894779443740845  accuracy 0.92\n",
            "train loss 0.3581092655658722 accuracy 0.98 | test loss 0.3789108991622925  accuracy 0.92\n",
            "train loss 0.3581100404262543 accuracy 0.99 | test loss 0.37898650765419006  accuracy 0.92\n",
            "train loss 0.3581101894378662 accuracy 0.98 | test loss 0.3789491057395935  accuracy 0.92\n",
            "train loss 0.3581089973449707 accuracy 0.98 | test loss 0.37893545627593994  accuracy 0.92\n",
            "train loss 0.35810843110084534 accuracy 0.98 | test loss 0.3789365291595459  accuracy 0.92\n",
            "train loss 0.35810819268226624 accuracy 0.98 | test loss 0.3789471387863159  accuracy 0.92\n",
            "train loss 0.35810843110084534 accuracy 0.98 | test loss 0.3789333999156952  accuracy 0.92\n",
            "train loss 0.3581077754497528 accuracy 0.98 | test loss 0.37896743416786194  accuracy 0.92\n",
            "train loss 0.35810866951942444 accuracy 0.98 | test loss 0.3789302110671997  accuracy 0.92\n",
            "train loss 0.3581075072288513 accuracy 0.98 | test loss 0.3789313733577728  accuracy 0.92\n",
            "train loss 0.35810741782188416 accuracy 0.98 | test loss 0.3789421021938324  accuracy 0.92\n",
            "train loss 0.3581075072288513 accuracy 0.98 | test loss 0.37892845273017883  accuracy 0.92\n",
            "train loss 0.3581070005893707 accuracy 0.98 | test loss 0.3789624571800232  accuracy 0.92\n",
            "train loss 0.35810771584510803 accuracy 0.98 | test loss 0.37892523407936096  accuracy 0.92\n",
            "train loss 0.3581067621707916 accuracy 0.98 | test loss 0.3789539337158203  accuracy 0.92\n",
            "train loss 0.3581070899963379 accuracy 0.98 | test loss 0.37891680002212524  accuracy 0.92\n",
            "train loss 0.3581070005893707 accuracy 0.99 | test loss 0.3789921998977661  accuracy 0.92\n",
            "train loss 0.35810819268226624 accuracy 0.98 | test loss 0.378933846950531  accuracy 0.92\n",
            "train loss 0.35810598731040955 accuracy 0.98 | test loss 0.37889716029167175  accuracy 0.92\n",
            "train loss 0.35810768604278564 accuracy 0.99 | test loss 0.3789726793766022  accuracy 0.92\n",
            "train loss 0.35810691118240356 accuracy 0.98 | test loss 0.37893539667129517  accuracy 0.92\n",
            "train loss 0.35810577869415283 accuracy 0.98 | test loss 0.3789217174053192  accuracy 0.92\n",
            "train loss 0.3581055700778961 accuracy 0.99 | test loss 0.37897035479545593  accuracy 0.92\n",
            "train loss 0.3581063747406006 accuracy 0.98 | test loss 0.3789331018924713  accuracy 0.92\n",
            "train loss 0.3581051528453827 accuracy 0.98 | test loss 0.3789193630218506  accuracy 0.92\n",
            "train loss 0.35810524225234985 accuracy 0.99 | test loss 0.37899473309516907  accuracy 0.92\n",
            "train loss 0.3581067621707916 accuracy 0.98 | test loss 0.3789362907409668  accuracy 0.92\n",
            "train loss 0.3581046164035797 accuracy 0.98 | test loss 0.3789192736148834  accuracy 0.92\n",
            "train loss 0.35810455679893494 accuracy 0.99 | test loss 0.37897980213165283  accuracy 0.92\n",
            "train loss 0.35810577869415283 accuracy 0.98 | test loss 0.3789424002170563  accuracy 0.92\n",
            "train loss 0.3581043779850006 accuracy 0.98 | test loss 0.3789054751396179  accuracy 0.92\n",
            "train loss 0.35810473561286926 accuracy 0.99 | test loss 0.37898093461990356  accuracy 0.92\n",
            "train loss 0.35810530185699463 accuracy 0.98 | test loss 0.37894344329833984  accuracy 0.92\n",
            "train loss 0.35810407996177673 accuracy 0.98 | test loss 0.37892967462539673  accuracy 0.92\n",
            "train loss 0.358103483915329 accuracy 0.98 | test loss 0.3789306581020355  accuracy 0.92\n",
            "train loss 0.3581031858921051 accuracy 0.98 | test loss 0.37889379262924194  accuracy 0.92\n",
            "train loss 0.35810476541519165 accuracy 0.99 | test loss 0.3789692223072052  accuracy 0.92\n",
            "train loss 0.3581041395664215 accuracy 0.98 | test loss 0.3789319097995758  accuracy 0.92\n",
            "train loss 0.3581029176712036 accuracy 0.98 | test loss 0.3789181411266327  accuracy 0.92\n",
            "train loss 0.3581027090549469 accuracy 0.99 | test loss 0.3789788782596588  accuracy 0.92\n",
            "train loss 0.3581039309501648 accuracy 0.98 | test loss 0.37894129753112793  accuracy 0.92\n",
            "train loss 0.35810258984565735 accuracy 0.98 | test loss 0.3789042532444  accuracy 0.92\n",
            "train loss 0.358102947473526 accuracy 0.99 | test loss 0.3789796829223633  accuracy 0.92\n",
            "train loss 0.35810354351997375 accuracy 0.98 | test loss 0.3789421021938324  accuracy 0.92\n",
            "train loss 0.3581021726131439 accuracy 0.98 | test loss 0.37890490889549255  accuracy 0.92\n",
            "train loss 0.35810205340385437 accuracy 0.99 | test loss 0.3789803087711334  accuracy 0.92\n",
            "train loss 0.3581032156944275 accuracy 0.98 | test loss 0.3789219856262207  accuracy 0.92\n",
            "train loss 0.35810142755508423 accuracy 0.98 | test loss 0.3789229393005371  accuracy 0.92\n",
            "train loss 0.3581010699272156 accuracy 0.98 | test loss 0.3789292573928833  accuracy 0.92\n",
            "train loss 0.358100950717926 accuracy 0.98 | test loss 0.37889233231544495  accuracy 0.92\n",
            "train loss 0.3581021726131439 accuracy 0.99 | test loss 0.3789677023887634  accuracy 0.92\n",
            "train loss 0.35810184478759766 accuracy 0.98 | test loss 0.3789302110671997  accuracy 0.92\n",
            "train loss 0.35810065269470215 accuracy 0.98 | test loss 0.37891632318496704  accuracy 0.92\n",
            "train loss 0.3581003248691559 accuracy 0.98 | test loss 0.378950297832489  accuracy 0.92\n",
            "train loss 0.3581008017063141 accuracy 0.98 | test loss 0.3789129853248596  accuracy 0.92\n",
            "train loss 0.3581000566482544 accuracy 0.99 | test loss 0.37896156311035156  accuracy 0.92\n",
            "train loss 0.35810092091560364 accuracy 0.98 | test loss 0.3789242208003998  accuracy 0.92\n",
            "train loss 0.35809972882270813 accuracy 0.98 | test loss 0.37891045212745667  accuracy 0.92\n",
            "train loss 0.3580995798110962 accuracy 0.99 | test loss 0.37897104024887085  accuracy 0.92\n",
            "train loss 0.3581007421016693 accuracy 0.98 | test loss 0.37893348932266235  accuracy 0.92\n",
            "train loss 0.3580993711948395 accuracy 0.98 | test loss 0.3788963854312897  accuracy 0.92\n",
            "train loss 0.3580998480319977 accuracy 0.99 | test loss 0.37897181510925293  accuracy 0.92\n",
            "train loss 0.3581003248691559 accuracy 0.98 | test loss 0.3789342939853668  accuracy 0.92\n",
            "train loss 0.3580988943576813 accuracy 0.98 | test loss 0.378897100687027  accuracy 0.92\n",
            "train loss 0.35809898376464844 accuracy 0.99 | test loss 0.37897247076034546  accuracy 0.92\n",
            "train loss 0.35809996724128723 accuracy 0.98 | test loss 0.37891408801078796  accuracy 0.92\n",
            "train loss 0.35809820890426636 accuracy 0.98 | test loss 0.37891510128974915  accuracy 0.92\n",
            "train loss 0.3580979108810425 accuracy 0.98 | test loss 0.37892141938209534  accuracy 0.92\n",
            "train loss 0.3580976724624634 accuracy 0.98 | test loss 0.3788842558860779  accuracy 0.92\n",
            "train loss 0.3580991327762604 accuracy 0.99 | test loss 0.37895965576171875  accuracy 0.92\n",
            "train loss 0.3580985963344574 accuracy 0.98 | test loss 0.37892210483551025  accuracy 0.92\n",
            "train loss 0.35809746384620667 accuracy 0.98 | test loss 0.37890827655792236  accuracy 0.92\n",
            "train loss 0.3580971956253052 accuracy 0.98 | test loss 0.3789421617984772  accuracy 0.92\n",
            "train loss 0.3580976128578186 accuracy 0.98 | test loss 0.37890487909317017  accuracy 0.92\n",
            "train loss 0.3580969274044037 accuracy 0.99 | test loss 0.37895339727401733  accuracy 0.92\n",
            "train loss 0.3580976724624634 accuracy 0.98 | test loss 0.3789159059524536  accuracy 0.92\n",
            "train loss 0.35809653997421265 accuracy 0.98 | test loss 0.3789021074771881  accuracy 0.92\n",
            "train loss 0.35809653997421265 accuracy 0.99 | test loss 0.3789774477481842  accuracy 0.92\n",
            "train loss 0.3580980598926544 accuracy 0.98 | test loss 0.37891885638237  accuracy 0.92\n",
            "train loss 0.3580958843231201 accuracy 0.98 | test loss 0.3788817226886749  accuracy 0.92\n",
            "train loss 0.3580973446369171 accuracy 0.99 | test loss 0.3789571225643158  accuracy 0.92\n",
            "train loss 0.3580968379974365 accuracy 0.98 | test loss 0.3789195120334625  accuracy 0.92\n",
            "train loss 0.35809555649757385 accuracy 0.98 | test loss 0.37890568375587463  accuracy 0.92\n",
            "train loss 0.3580953776836395 accuracy 0.99 | test loss 0.378954142332077  accuracy 0.92\n",
            "train loss 0.35809624195098877 accuracy 0.98 | test loss 0.3789166212081909  accuracy 0.92\n",
            "train loss 0.3580949306488037 accuracy 0.98 | test loss 0.37890276312828064  accuracy 0.92\n",
            "train loss 0.3580950200557709 accuracy 0.99 | test loss 0.3789633512496948  accuracy 0.92\n",
            "train loss 0.35809603333473206 accuracy 0.98 | test loss 0.37892571091651917  accuracy 0.92\n",
            "train loss 0.3580946922302246 accuracy 0.98 | test loss 0.37888866662979126  accuracy 0.92\n",
            "train loss 0.3580952286720276 accuracy 0.99 | test loss 0.37896406650543213  accuracy 0.92\n",
            "train loss 0.35809561610221863 accuracy 0.98 | test loss 0.3789263963699341  accuracy 0.92\n",
            "train loss 0.3580942451953888 accuracy 0.98 | test loss 0.3788891136646271  accuracy 0.92\n",
            "train loss 0.35809439420700073 accuracy 0.99 | test loss 0.37896448373794556  accuracy 0.92\n",
            "train loss 0.3580951988697052 accuracy 0.98 | test loss 0.3789268434047699  accuracy 0.92\n",
            "train loss 0.35809385776519775 accuracy 0.98 | test loss 0.3789128363132477  accuracy 0.92\n",
            "train loss 0.35809317231178284 accuracy 0.98 | test loss 0.3788990080356598  accuracy 0.92\n",
            "train loss 0.3580935597419739 accuracy 0.98 | test loss 0.3789242208003998  accuracy 0.92\n",
            "train loss 0.35809326171875 accuracy 0.98 | test loss 0.37891021370887756  accuracy 0.92\n",
            "train loss 0.35809263586997986 accuracy 0.98 | test loss 0.37889304757118225  accuracy 0.92\n",
            "train loss 0.35809287428855896 accuracy 0.99 | test loss 0.37895357608795166  accuracy 0.92\n",
            "train loss 0.3580937087535858 accuracy 0.98 | test loss 0.3789159655570984  accuracy 0.92\n",
            "train loss 0.3580924868583679 accuracy 0.98 | test loss 0.37890204787254333  accuracy 0.92\n",
            "train loss 0.3580920994281769 accuracy 0.98 | test loss 0.3789229393005371  accuracy 0.92\n",
            "train loss 0.3580922484397888 accuracy 0.98 | test loss 0.3788856565952301  accuracy 0.92\n",
            "train loss 0.35809245705604553 accuracy 0.99 | test loss 0.3789610266685486  accuracy 0.92\n",
            "train loss 0.3580932915210724 accuracy 0.98 | test loss 0.3789024353027344  accuracy 0.92\n",
            "train loss 0.35809126496315 accuracy 0.98 | test loss 0.3789161741733551  accuracy 0.92\n",
            "train loss 0.35809141397476196 accuracy 0.98 | test loss 0.3788790702819824  accuracy 0.92\n",
            "train loss 0.3580923080444336 accuracy 0.99 | test loss 0.3789544701576233  accuracy 0.92\n",
            "train loss 0.358092337846756 accuracy 0.98 | test loss 0.37891680002212524  accuracy 0.92\n",
            "train loss 0.35809096693992615 accuracy 0.98 | test loss 0.3788795471191406  accuracy 0.92\n",
            "train loss 0.3580915033817291 accuracy 0.99 | test loss 0.3789549469947815  accuracy 0.92\n",
            "train loss 0.35809189081192017 accuracy 0.98 | test loss 0.37891730666160583  accuracy 0.92\n",
            "train loss 0.35809066891670227 accuracy 0.98 | test loss 0.3789032995700836  accuracy 0.92\n",
            "train loss 0.35808998346328735 accuracy 0.98 | test loss 0.3789094388484955  accuracy 0.92\n",
            "train loss 0.3580899238586426 accuracy 0.98 | test loss 0.37887221574783325  accuracy 0.92\n",
            "train loss 0.3580911159515381 accuracy 0.99 | test loss 0.37894758582115173  accuracy 0.92\n",
            "train loss 0.3580908477306366 accuracy 0.98 | test loss 0.37890997529029846  accuracy 0.92\n",
            "train loss 0.3580895960330963 accuracy 0.98 | test loss 0.3788960576057434  accuracy 0.92\n",
            "train loss 0.35808929800987244 accuracy 0.99 | test loss 0.3789445161819458  accuracy 0.92\n",
            "train loss 0.35809028148651123 accuracy 0.98 | test loss 0.3789069354534149  accuracy 0.92\n",
            "train loss 0.3580889403820038 accuracy 0.98 | test loss 0.3788929581642151  accuracy 0.92\n",
            "train loss 0.35808882117271423 accuracy 0.99 | test loss 0.3789414167404175  accuracy 0.92\n",
            "train loss 0.3580896556377411 accuracy 0.98 | test loss 0.3789038062095642  accuracy 0.92\n",
            "train loss 0.3580883741378784 accuracy 0.98 | test loss 0.3789173662662506  accuracy 0.92\n",
            "train loss 0.3580886125564575 accuracy 0.98 | test loss 0.37888002395629883  accuracy 0.92\n",
            "train loss 0.3580889105796814 accuracy 0.99 | test loss 0.378955215215683  accuracy 0.92\n",
            "train loss 0.35808950662612915 accuracy 0.98 | test loss 0.37891754508018494  accuracy 0.92\n",
            "train loss 0.3580881357192993 accuracy 0.98 | test loss 0.3788801431655884  accuracy 0.92\n",
            "train loss 0.3580881357192993 accuracy 0.99 | test loss 0.37894079089164734  accuracy 0.92\n",
            "train loss 0.3580886125564575 accuracy 0.98 | test loss 0.37890318036079407  accuracy 0.92\n",
            "train loss 0.35808733105659485 accuracy 0.98 | test loss 0.37888938188552856  accuracy 0.92\n",
            "train loss 0.35808730125427246 accuracy 0.99 | test loss 0.37893784046173096  accuracy 0.92\n",
            "train loss 0.3580879867076874 accuracy 0.98 | test loss 0.3789002001285553  accuracy 0.92\n",
            "train loss 0.3580867052078247 accuracy 0.98 | test loss 0.378886342048645  accuracy 0.92\n",
            "train loss 0.35808685421943665 accuracy 0.99 | test loss 0.37893474102020264  accuracy 0.92\n",
            "train loss 0.358087420463562 accuracy 0.98 | test loss 0.37889716029167175  accuracy 0.92\n",
            "train loss 0.35808607935905457 accuracy 0.98 | test loss 0.3789106607437134  accuracy 0.92\n",
            "train loss 0.35808634757995605 accuracy 0.98 | test loss 0.3788734972476959  accuracy 0.92\n",
            "train loss 0.3580869138240814 accuracy 0.99 | test loss 0.3789486587047577  accuracy 0.92\n",
            "train loss 0.3580872714519501 accuracy 0.98 | test loss 0.37891095876693726  accuracy 0.92\n",
            "train loss 0.35808584094047546 accuracy 0.98 | test loss 0.3788736164569855  accuracy 0.92\n",
            "train loss 0.35808610916137695 accuracy 0.99 | test loss 0.37894880771636963  accuracy 0.92\n",
            "train loss 0.3580869138240814 accuracy 0.98 | test loss 0.3788902163505554  accuracy 0.92\n",
            "train loss 0.3580850064754486 accuracy 0.98 | test loss 0.3788963258266449  accuracy 0.92\n",
            "train loss 0.3580847978591919 accuracy 0.98 | test loss 0.3788592517375946  accuracy 0.92\n",
            "train loss 0.35808637738227844 accuracy 0.99 | test loss 0.3789346218109131  accuracy 0.92\n",
            "train loss 0.3580856919288635 accuracy 0.98 | test loss 0.37889692187309265  accuracy 0.92\n",
            "train loss 0.3580845594406128 accuracy 0.98 | test loss 0.3788829743862152  accuracy 0.92\n",
            "train loss 0.35808441042900085 accuracy 0.99 | test loss 0.3789314329624176  accuracy 0.92\n",
            "train loss 0.35808512568473816 accuracy 0.98 | test loss 0.37889379262924194  accuracy 0.92\n",
            "train loss 0.35808393359184265 accuracy 0.98 | test loss 0.3788798451423645  accuracy 0.92\n",
            "train loss 0.3580840528011322 accuracy 0.99 | test loss 0.3789549171924591  accuracy 0.92\n",
            "train loss 0.3580855131149292 accuracy 0.98 | test loss 0.37889620661735535  accuracy 0.92\n",
            "train loss 0.3580833971500397 accuracy 0.98 | test loss 0.37887901067733765  accuracy 0.92\n",
            "train loss 0.3580833375453949 accuracy 0.99 | test loss 0.3789394199848175  accuracy 0.92\n",
            "train loss 0.35808447003364563 accuracy 0.98 | test loss 0.37890177965164185  accuracy 0.92\n",
            "train loss 0.3580830991268158 accuracy 0.98 | test loss 0.37886443734169006  accuracy 0.92\n",
            "train loss 0.3580836057662964 accuracy 0.99 | test loss 0.3789396584033966  accuracy 0.92\n",
            "train loss 0.3580840229988098 accuracy 0.98 | test loss 0.37890195846557617  accuracy 0.92\n",
            "train loss 0.3580828011035919 accuracy 0.98 | test loss 0.3788878619670868  accuracy 0.92\n",
            "train loss 0.35808223485946655 accuracy 0.98 | test loss 0.3788886070251465  accuracy 0.92\n",
            "train loss 0.3580818772315979 accuracy 0.98 | test loss 0.37889882922172546  accuracy 0.92\n",
            "train loss 0.35808220505714417 accuracy 0.98 | test loss 0.3788847327232361  accuracy 0.92\n",
            "train loss 0.358081579208374 accuracy 0.98 | test loss 0.3789054751396179  accuracy 0.92\n",
            "train loss 0.35808196663856506 accuracy 0.98 | test loss 0.3788679540157318  accuracy 0.92\n",
            "train loss 0.3580821454524994 accuracy 0.99 | test loss 0.37892836332321167  accuracy 0.92\n",
            "train loss 0.3580823838710785 accuracy 0.98 | test loss 0.378890722990036  accuracy 0.92\n",
            "train loss 0.3580811321735382 accuracy 0.98 | test loss 0.37887662649154663  accuracy 0.92\n",
            "train loss 0.35808107256889343 accuracy 0.99 | test loss 0.37892499566078186  accuracy 0.92\n",
            "train loss 0.3580818176269531 accuracy 0.98 | test loss 0.3788873553276062  accuracy 0.92\n",
            "train loss 0.3580804765224457 accuracy 0.98 | test loss 0.3788732588291168  accuracy 0.92\n",
            "train loss 0.35808080434799194 accuracy 0.99 | test loss 0.3789483606815338  accuracy 0.92\n",
            "train loss 0.358082115650177 accuracy 0.98 | test loss 0.3788895308971405  accuracy 0.92\n",
            "train loss 0.35808005928993225 accuracy 0.98 | test loss 0.3788723051548004  accuracy 0.92\n",
            "train loss 0.35808005928993225 accuracy 0.99 | test loss 0.378947377204895  accuracy 0.92\n",
            "train loss 0.3580818176269531 accuracy 0.98 | test loss 0.3788886070251465  accuracy 0.92\n",
            "train loss 0.3580795228481293 accuracy 0.98 | test loss 0.3788513243198395  accuracy 0.92\n",
            "train loss 0.3580808937549591 accuracy 0.99 | test loss 0.3789265751838684  accuracy 0.92\n",
            "train loss 0.3580804467201233 accuracy 0.98 | test loss 0.378888875246048  accuracy 0.92\n",
            "train loss 0.3580792248249054 accuracy 0.98 | test loss 0.3788747787475586  accuracy 0.92\n",
            "train loss 0.3580789864063263 accuracy 0.99 | test loss 0.37892305850982666  accuracy 0.92\n",
            "train loss 0.35807982087135315 accuracy 0.98 | test loss 0.37888532876968384  accuracy 0.92\n",
            "train loss 0.35807859897613525 accuracy 0.98 | test loss 0.37887126207351685  accuracy 0.92\n",
            "train loss 0.35807862877845764 accuracy 0.99 | test loss 0.37894633412361145  accuracy 0.92\n",
            "train loss 0.358080118894577 accuracy 0.98 | test loss 0.3788873851299286  accuracy 0.92\n",
            "train loss 0.3580780327320099 accuracy 0.98 | test loss 0.378869891166687  accuracy 0.92\n",
            "train loss 0.35807791352272034 accuracy 0.98 | test loss 0.37890344858169556  accuracy 0.92\n",
            "train loss 0.3580783009529114 accuracy 0.98 | test loss 0.3788658380508423  accuracy 0.92\n",
            "train loss 0.3580777645111084 accuracy 0.99 | test loss 0.37894096970558167  accuracy 0.92\n",
            "train loss 0.35807928442955017 accuracy 0.98 | test loss 0.37888219952583313  accuracy 0.92\n",
            "train loss 0.3580772280693054 accuracy 0.98 | test loss 0.3788827061653137  accuracy 0.92\n",
            "train loss 0.35807695984840393 accuracy 0.98 | test loss 0.37884536385536194  accuracy 0.92\n",
            "train loss 0.3580785393714905 accuracy 0.99 | test loss 0.3789205551147461  accuracy 0.92\n",
            "train loss 0.35807788372039795 accuracy 0.98 | test loss 0.3788827955722809  accuracy 0.92\n",
            "train loss 0.35807666182518005 accuracy 0.98 | test loss 0.37886863946914673  accuracy 0.92\n",
            "train loss 0.3580765426158905 accuracy 0.98 | test loss 0.3789023458957672  accuracy 0.92\n",
            "train loss 0.358076810836792 accuracy 0.98 | test loss 0.37886473536491394  accuracy 0.92\n",
            "train loss 0.3580763041973114 accuracy 0.99 | test loss 0.37893980741500854  accuracy 0.92\n",
            "train loss 0.358077734708786 accuracy 0.98 | test loss 0.37890180945396423  accuracy 0.92\n",
            "train loss 0.3580763638019562 accuracy 0.98 | test loss 0.3788641691207886  accuracy 0.92\n",
            "train loss 0.3580756187438965 accuracy 0.98 | test loss 0.3788977861404419  accuracy 0.92\n",
            "train loss 0.35807594656944275 accuracy 0.98 | test loss 0.37886011600494385  accuracy 0.92\n",
            "train loss 0.35807541012763977 accuracy 0.99 | test loss 0.3789084851741791  accuracy 0.92\n",
            "train loss 0.3580760061740875 accuracy 0.98 | test loss 0.3788708448410034  accuracy 0.92\n",
            "train loss 0.35807517170906067 accuracy 0.98 | test loss 0.37885671854019165  accuracy 0.92\n",
            "train loss 0.35807517170906067 accuracy 0.99 | test loss 0.37893185019493103  accuracy 0.92\n",
            "train loss 0.3580763041973114 accuracy 0.98 | test loss 0.37887299060821533  accuracy 0.92\n",
            "train loss 0.3580743372440338 accuracy 0.98 | test loss 0.37885886430740356  accuracy 0.92\n",
            "train loss 0.35807475447654724 accuracy 0.99 | test loss 0.37893396615982056  accuracy 0.92\n",
            "train loss 0.3580758273601532 accuracy 0.98 | test loss 0.37889593839645386  accuracy 0.92\n",
            "train loss 0.3580743968486786 accuracy 0.98 | test loss 0.378858357667923  accuracy 0.92\n",
            "train loss 0.35807403922080994 accuracy 0.99 | test loss 0.37890663743019104  accuracy 0.92\n",
            "train loss 0.35807448625564575 accuracy 0.98 | test loss 0.3788689374923706  accuracy 0.92\n",
            "train loss 0.35807350277900696 accuracy 0.98 | test loss 0.37885481119155884  accuracy 0.92\n",
            "train loss 0.35807380080223083 accuracy 0.99 | test loss 0.3789299428462982  accuracy 0.92\n",
            "train loss 0.35807475447654724 accuracy 0.98 | test loss 0.37889188528060913  accuracy 0.92\n",
            "train loss 0.358073353767395 accuracy 0.98 | test loss 0.37885427474975586  accuracy 0.92\n",
            "train loss 0.3580731153488159 accuracy 0.99 | test loss 0.37891456484794617  accuracy 0.92\n",
            "train loss 0.35807380080223083 accuracy 0.98 | test loss 0.37887662649154663  accuracy 0.92\n",
            "train loss 0.35807257890701294 accuracy 0.98 | test loss 0.3788624107837677  accuracy 0.92\n",
            "train loss 0.35807234048843384 accuracy 0.99 | test loss 0.3789106011390686  accuracy 0.92\n",
            "train loss 0.3580731749534607 accuracy 0.98 | test loss 0.37887272238731384  accuracy 0.92\n",
            "train loss 0.3580719530582428 accuracy 0.98 | test loss 0.3788585066795349  accuracy 0.92\n",
            "train loss 0.3580719530582428 accuracy 0.99 | test loss 0.3789066970348358  accuracy 0.92\n",
            "train loss 0.35807257890701294 accuracy 0.98 | test loss 0.37886878848075867  accuracy 0.92\n",
            "train loss 0.35807132720947266 accuracy 0.98 | test loss 0.3788546025753021  accuracy 0.92\n",
            "train loss 0.3580717444419861 accuracy 0.99 | test loss 0.37892967462539673  accuracy 0.92\n",
            "train loss 0.3580728769302368 accuracy 0.98 | test loss 0.37889161705970764  accuracy 0.92\n",
            "train loss 0.3580714464187622 accuracy 0.98 | test loss 0.378853976726532  accuracy 0.92\n",
            "train loss 0.35807105898857117 accuracy 0.99 | test loss 0.37891432642936707  accuracy 0.92\n",
            "train loss 0.358071893453598 accuracy 0.98 | test loss 0.3788764178752899  accuracy 0.92\n",
            "train loss 0.3580705225467682 accuracy 0.98 | test loss 0.3788389563560486  accuracy 0.92\n",
            "train loss 0.3580712676048279 accuracy 0.99 | test loss 0.37891408801078796  accuracy 0.92\n",
            "train loss 0.3580714464187622 accuracy 0.98 | test loss 0.37887611985206604  accuracy 0.92\n",
            "train loss 0.3580702245235443 accuracy 0.98 | test loss 0.3788618743419647  accuracy 0.92\n",
            "train loss 0.35806968808174133 accuracy 0.98 | test loss 0.37886250019073486  accuracy 0.92\n",
            "train loss 0.3580695390701294 accuracy 0.98 | test loss 0.378896027803421  accuracy 0.92\n",
            "train loss 0.35807016491889954 accuracy 0.98 | test loss 0.3788582384586334  accuracy 0.92\n",
            "train loss 0.35806915163993835 accuracy 0.99 | test loss 0.3789064586162567  accuracy 0.92\n",
            "train loss 0.3580702543258667 accuracy 0.98 | test loss 0.3788684904575348  accuracy 0.92\n",
            "train loss 0.35806894302368164 accuracy 0.98 | test loss 0.37885424494743347  accuracy 0.92\n",
            "train loss 0.3580690026283264 accuracy 0.99 | test loss 0.37891456484794617  accuracy 0.92\n",
            "train loss 0.3580700159072876 accuracy 0.98 | test loss 0.37887662649154663  accuracy 0.92\n",
            "train loss 0.3580686151981354 accuracy 0.98 | test loss 0.3788391053676605  accuracy 0.92\n",
            "train loss 0.35806921124458313 accuracy 0.99 | test loss 0.3789142668247223  accuracy 0.92\n",
            "train loss 0.3580695688724518 accuracy 0.98 | test loss 0.378876268863678  accuracy 0.92\n",
            "train loss 0.3580681383609772 accuracy 0.98 | test loss 0.3788386583328247  accuracy 0.92\n",
            "train loss 0.35806846618652344 accuracy 0.99 | test loss 0.3789137601852417  accuracy 0.92\n",
            "train loss 0.3580690622329712 accuracy 0.98 | test loss 0.37885481119155884  accuracy 0.92\n",
            "train loss 0.3580673933029175 accuracy 0.98 | test loss 0.37885546684265137  accuracy 0.92\n",
            "train loss 0.35806724429130554 accuracy 0.98 | test loss 0.3788887560367584  accuracy 0.92\n",
            "train loss 0.3580677807331085 accuracy 0.98 | test loss 0.3788510859012604  accuracy 0.92\n",
            "train loss 0.3580668866634369 accuracy 0.99 | test loss 0.3788992464542389  accuracy 0.92\n",
            "train loss 0.3580678105354309 accuracy 0.98 | test loss 0.37886130809783936  accuracy 0.92\n",
            "train loss 0.35806673765182495 accuracy 0.98 | test loss 0.37884706258773804  accuracy 0.92\n",
            "train loss 0.3580666780471802 accuracy 0.99 | test loss 0.3789074718952179  accuracy 0.92\n",
            "train loss 0.3580676317214966 accuracy 0.98 | test loss 0.3788694739341736  accuracy 0.92\n",
            "train loss 0.358066201210022 accuracy 0.98 | test loss 0.3788319230079651  accuracy 0.92\n",
            "train loss 0.35806694626808167 accuracy 0.99 | test loss 0.37890708446502686  accuracy 0.92\n",
            "train loss 0.358067125082016 accuracy 0.98 | test loss 0.37886908650398254  accuracy 0.92\n",
            "train loss 0.3580658733844757 accuracy 0.98 | test loss 0.37885481119155884  accuracy 0.92\n",
            "train loss 0.35806527733802795 accuracy 0.98 | test loss 0.37887537479400635  accuracy 0.92\n",
            "train loss 0.3580656051635742 accuracy 0.98 | test loss 0.3788377344608307  accuracy 0.92\n",
            "train loss 0.35806572437286377 accuracy 0.99 | test loss 0.37889793515205383  accuracy 0.92\n",
            "train loss 0.35806605219841003 accuracy 0.98 | test loss 0.3788599371910095  accuracy 0.92\n",
            "train loss 0.35806477069854736 accuracy 0.98 | test loss 0.3788456618785858  accuracy 0.92\n",
            "train loss 0.35806480050086975 accuracy 0.99 | test loss 0.3788938522338867  accuracy 0.92\n",
            "train loss 0.3580653965473175 accuracy 0.98 | test loss 0.3788558840751648  accuracy 0.92\n",
            "train loss 0.35806411504745483 accuracy 0.98 | test loss 0.3788416087627411  accuracy 0.92\n",
            "train loss 0.35806456208229065 accuracy 0.99 | test loss 0.378916472196579  accuracy 0.92\n",
            "train loss 0.35806572437286377 accuracy 0.98 | test loss 0.37887823581695557  accuracy 0.92\n",
            "train loss 0.35806429386138916 accuracy 0.98 | test loss 0.37884047627449036  accuracy 0.92\n",
            "train loss 0.35806384682655334 accuracy 0.99 | test loss 0.37891536951065063  accuracy 0.92\n",
            "train loss 0.35806527733802795 accuracy 0.98 | test loss 0.3788563013076782  accuracy 0.92\n",
            "train loss 0.35806313157081604 accuracy 0.98 | test loss 0.37881889939308167  accuracy 0.92\n",
            "train loss 0.3580647110939026 accuracy 0.99 | test loss 0.37889397144317627  accuracy 0.92\n",
            "train loss 0.35806402564048767 accuracy 0.98 | test loss 0.37885603308677673  accuracy 0.92\n",
            "train loss 0.35806286334991455 accuracy 0.98 | test loss 0.37884169816970825  accuracy 0.92\n",
            "train loss 0.3580627739429474 accuracy 0.99 | test loss 0.37888988852500916  accuracy 0.92\n",
            "train loss 0.3580634295940399 accuracy 0.98 | test loss 0.37885192036628723  accuracy 0.92\n",
            "train loss 0.358062207698822 accuracy 0.98 | test loss 0.37883761525154114  accuracy 0.92\n",
            "train loss 0.35806259512901306 accuracy 0.99 | test loss 0.3789125084877014  accuracy 0.92\n",
            "train loss 0.3580636978149414 accuracy 0.98 | test loss 0.3788742125034332  accuracy 0.92\n",
            "train loss 0.3580622673034668 accuracy 0.98 | test loss 0.37883636355400085  accuracy 0.92\n",
            "train loss 0.35806190967559814 accuracy 0.99 | test loss 0.3788966238498688  accuracy 0.92\n",
            "train loss 0.358062744140625 accuracy 0.98 | test loss 0.37885868549346924  accuracy 0.92\n",
            "train loss 0.3580613136291504 accuracy 0.98 | test loss 0.3788210153579712  accuracy 0.92\n",
            "train loss 0.358062207698822 accuracy 0.99 | test loss 0.3788960874080658  accuracy 0.92\n",
            "train loss 0.3580622673034668 accuracy 0.98 | test loss 0.3788580894470215  accuracy 0.92\n",
            "train loss 0.3580610454082489 accuracy 0.98 | test loss 0.378843754529953  accuracy 0.92\n",
            "train loss 0.3580605089664459 accuracy 0.98 | test loss 0.3788643181324005  accuracy 0.92\n",
            "train loss 0.35806068778038025 accuracy 0.98 | test loss 0.3788266181945801  accuracy 0.92\n",
            "train loss 0.3580609858036041 accuracy 0.99 | test loss 0.3788869380950928  accuracy 0.92\n",
            "train loss 0.35806116461753845 accuracy 0.98 | test loss 0.37884894013404846  accuracy 0.92\n",
            "train loss 0.35806000232696533 accuracy 0.98 | test loss 0.37883466482162476  accuracy 0.92\n",
            "train loss 0.3580600917339325 accuracy 0.99 | test loss 0.37888282537460327  accuracy 0.92\n",
            "train loss 0.3580605089664459 accuracy 0.98 | test loss 0.37884485721588135  accuracy 0.92\n",
            "train loss 0.3580593466758728 accuracy 0.98 | test loss 0.3788306415081024  accuracy 0.92\n",
            "train loss 0.358059823513031 accuracy 0.99 | test loss 0.37890544533729553  accuracy 0.92\n",
            "train loss 0.3580607771873474 accuracy 0.98 | test loss 0.37886717915534973  accuracy 0.92\n",
            "train loss 0.3580593764781952 accuracy 0.98 | test loss 0.3788292706012726  accuracy 0.92\n",
            "train loss 0.3580591380596161 accuracy 0.99 | test loss 0.37890419363975525  accuracy 0.92\n",
            "train loss 0.35806041955947876 accuracy 0.98 | test loss 0.37884506583213806  accuracy 0.92\n",
            "train loss 0.35805830359458923 accuracy 0.98 | test loss 0.3788309395313263  accuracy 0.92\n",
            "train loss 0.35805878043174744 accuracy 0.99 | test loss 0.3788790702819824  accuracy 0.92\n",
            "train loss 0.35805898904800415 accuracy 0.98 | test loss 0.3788410723209381  accuracy 0.92\n",
            "train loss 0.3580578565597534 accuracy 0.98 | test loss 0.378874272108078  accuracy 0.92\n",
            "train loss 0.35805854201316833 accuracy 0.98 | test loss 0.37883639335632324  accuracy 0.92\n",
            "train loss 0.35805755853652954 accuracy 0.99 | test loss 0.3788844645023346  accuracy 0.92\n",
            "train loss 0.3580585718154907 accuracy 0.98 | test loss 0.3788464665412903  accuracy 0.92\n",
            "train loss 0.3580574095249176 accuracy 0.98 | test loss 0.378832072019577  accuracy 0.92\n",
            "train loss 0.35805729031562805 accuracy 0.99 | test loss 0.37889227271080017  accuracy 0.92\n",
            "train loss 0.3580583930015564 accuracy 0.98 | test loss 0.3788542151451111  accuracy 0.92\n",
            "train loss 0.3580569326877594 accuracy 0.98 | test loss 0.3788166642189026  accuracy 0.92\n",
            "train loss 0.35805758833885193 accuracy 0.99 | test loss 0.3788916766643524  accuracy 0.92\n",
            "train loss 0.3580578565597534 accuracy 0.98 | test loss 0.37885355949401855  accuracy 0.92\n",
            "train loss 0.3580564856529236 accuracy 0.98 | test loss 0.37881582975387573  accuracy 0.92\n",
            "train loss 0.3580568730831146 accuracy 0.99 | test loss 0.3788907825946808  accuracy 0.92\n",
            "train loss 0.3580574095249176 accuracy 0.98 | test loss 0.3788527250289917  accuracy 0.92\n",
            "train loss 0.3580562472343445 accuracy 0.98 | test loss 0.37883827090263367  accuracy 0.92\n",
            "train loss 0.35805556178092957 accuracy 0.98 | test loss 0.3788241147994995  accuracy 0.92\n",
            "train loss 0.3580559492111206 accuracy 0.99 | test loss 0.3788723051548004  accuracy 0.92\n",
            "train loss 0.35805612802505493 accuracy 0.98 | test loss 0.37883424758911133  accuracy 0.92\n",
            "train loss 0.3580550253391266 accuracy 0.98 | test loss 0.378847599029541  accuracy 0.92\n",
            "train loss 0.3580550253391266 accuracy 0.98 | test loss 0.3788246512413025  accuracy 0.92\n",
            "train loss 0.35805511474609375 accuracy 0.99 | test loss 0.3788846433162689  accuracy 0.92\n",
            "train loss 0.3580559194087982 accuracy 0.98 | test loss 0.37884658575057983  accuracy 0.92\n",
            "train loss 0.3580544888973236 accuracy 0.98 | test loss 0.3788088858127594  accuracy 0.92\n",
            "train loss 0.35805538296699524 accuracy 0.99 | test loss 0.37888380885124207  accuracy 0.92\n",
            "train loss 0.3580554127693176 accuracy 0.98 | test loss 0.378845751285553  accuracy 0.92\n",
            "train loss 0.3580542206764221 accuracy 0.98 | test loss 0.37883132696151733  accuracy 0.92\n",
            "train loss 0.35805365443229675 accuracy 0.99 | test loss 0.3788793385028839  accuracy 0.92\n",
            "train loss 0.3580547869205475 accuracy 0.98 | test loss 0.3788412809371948  accuracy 0.92\n",
            "train loss 0.358053594827652 accuracy 0.98 | test loss 0.3788268566131592  accuracy 0.92\n",
            "train loss 0.3580533266067505 accuracy 0.98 | test loss 0.3788602352142334  accuracy 0.92\n",
            "train loss 0.3580537438392639 accuracy 0.98 | test loss 0.3788222670555115  accuracy 0.92\n",
            "train loss 0.3580531179904938 accuracy 0.99 | test loss 0.3788703978061676  accuracy 0.92\n",
            "train loss 0.3580537438392639 accuracy 0.98 | test loss 0.3788323402404785  accuracy 0.92\n",
            "train loss 0.3580525815486908 accuracy 0.98 | test loss 0.37881794571876526  accuracy 0.92\n",
            "train loss 0.35805296897888184 accuracy 0.99 | test loss 0.37889280915260315  accuracy 0.92\n",
            "train loss 0.3580540418624878 accuracy 0.98 | test loss 0.3788335621356964  accuracy 0.92\n",
            "train loss 0.35805198550224304 accuracy 0.98 | test loss 0.37883055210113525  accuracy 0.92\n",
            "train loss 0.3580520451068878 accuracy 0.98 | test loss 0.3788437247276306  accuracy 0.92\n",
            "train loss 0.3580518960952759 accuracy 0.98 | test loss 0.37880584597587585  accuracy 0.92\n",
            "train loss 0.35805264115333557 accuracy 0.99 | test loss 0.37888064980506897  accuracy 0.92\n",
            "train loss 0.3580528199672699 accuracy 0.98 | test loss 0.37884238362312317  accuracy 0.92\n",
            "train loss 0.358051598072052 accuracy 0.98 | test loss 0.378827840089798  accuracy 0.92\n",
            "train loss 0.35805103182792664 accuracy 0.98 | test loss 0.37886106967926025  accuracy 0.92\n",
            "train loss 0.35805171728134155 accuracy 0.98 | test loss 0.37882307171821594  accuracy 0.92\n",
            "train loss 0.358050674200058 accuracy 0.98 | test loss 0.3788564205169678  accuracy 0.92\n",
            "train loss 0.35805124044418335 accuracy 0.98 | test loss 0.37881845235824585  accuracy 0.92\n",
            "train loss 0.35805049538612366 accuracy 0.99 | test loss 0.3788664937019348  accuracy 0.92\n",
            "train loss 0.3580513000488281 accuracy 0.98 | test loss 0.3788284361362457  accuracy 0.92\n",
            "train loss 0.35805022716522217 accuracy 0.98 | test loss 0.3788140118122101  accuracy 0.92\n",
            "train loss 0.35805028676986694 accuracy 0.99 | test loss 0.3788888454437256  accuracy 0.92\n",
            "train loss 0.35805171728134155 accuracy 0.98 | test loss 0.3788294792175293  accuracy 0.92\n",
            "train loss 0.3580494523048401 accuracy 0.98 | test loss 0.3787919282913208  accuracy 0.92\n",
            "train loss 0.35805121064186096 accuracy 0.99 | test loss 0.37886688113212585  accuracy 0.92\n",
            "train loss 0.3580503761768341 accuracy 0.98 | test loss 0.3788287937641144  accuracy 0.92\n",
            "train loss 0.3580491840839386 accuracy 0.98 | test loss 0.37881436944007874  accuracy 0.92\n",
            "train loss 0.3580492436885834 accuracy 0.99 | test loss 0.3788892328739166  accuracy 0.92\n",
            "train loss 0.3580506145954132 accuracy 0.98 | test loss 0.3788508176803589  accuracy 0.92\n",
            "train loss 0.3580491840839386 accuracy 0.98 | test loss 0.3788128197193146  accuracy 0.92\n",
            "train loss 0.35804855823516846 accuracy 0.99 | test loss 0.3788876533508301  accuracy 0.92\n",
            "train loss 0.35805028676986694 accuracy 0.98 | test loss 0.3788283169269562  accuracy 0.92\n",
            "train loss 0.35804811120033264 accuracy 0.98 | test loss 0.3788140118122101  accuracy 0.92\n",
            "train loss 0.35804831981658936 accuracy 0.99 | test loss 0.37886202335357666  accuracy 0.92\n",
            "train loss 0.35804876685142517 accuracy 0.98 | test loss 0.378823846578598  accuracy 0.92\n",
            "train loss 0.3580474853515625 accuracy 0.98 | test loss 0.3788094222545624  accuracy 0.92\n",
            "train loss 0.35804808139801025 accuracy 0.99 | test loss 0.3788842260837555  accuracy 0.92\n",
            "train loss 0.3580490052700043 accuracy 0.98 | test loss 0.37884584069252014  accuracy 0.92\n",
            "train loss 0.35804760456085205 accuracy 0.98 | test loss 0.37880781292915344  accuracy 0.92\n",
            "train loss 0.35804739594459534 accuracy 0.99 | test loss 0.37888267636299133  accuracy 0.92\n",
            "train loss 0.3580484986305237 accuracy 0.98 | test loss 0.378844290971756  accuracy 0.92\n",
            "train loss 0.35804709792137146 accuracy 0.98 | test loss 0.3788062334060669  accuracy 0.92\n",
            "train loss 0.3580467402935028 accuracy 0.99 | test loss 0.3788664638996124  accuracy 0.92\n",
            "train loss 0.3580475449562073 accuracy 0.98 | test loss 0.3788281977176666  accuracy 0.92\n",
            "train loss 0.3580463230609894 accuracy 0.98 | test loss 0.37881362438201904  accuracy 0.92\n",
            "train loss 0.35804617404937744 accuracy 0.98 | test loss 0.37883397936820984  accuracy 0.92\n",
            "train loss 0.3580459654331207 accuracy 0.98 | test loss 0.3787960112094879  accuracy 0.92\n",
            "train loss 0.3580465614795685 accuracy 0.99 | test loss 0.3788708448410034  accuracy 0.92\n",
            "train loss 0.35804691910743713 accuracy 0.98 | test loss 0.37883254885673523  accuracy 0.92\n",
            "train loss 0.3580455780029297 accuracy 0.98 | test loss 0.37881794571876526  accuracy 0.92\n",
            "train loss 0.3580450117588043 accuracy 0.98 | test loss 0.3788512349128723  accuracy 0.92\n",
            "train loss 0.358045756816864 accuracy 0.98 | test loss 0.37881308794021606  accuracy 0.92\n",
            "train loss 0.35804474353790283 accuracy 0.99 | test loss 0.3788610100746155  accuracy 0.92\n",
            "train loss 0.3580457866191864 accuracy 0.98 | test loss 0.3788226544857025  accuracy 0.92\n",
            "train loss 0.3580445647239685 accuracy 0.98 | test loss 0.3788081407546997  accuracy 0.92\n",
            "train loss 0.35804441571235657 accuracy 0.99 | test loss 0.3788682222366333  accuracy 0.92\n",
            "train loss 0.3580455780029297 accuracy 0.98 | test loss 0.37882980704307556  accuracy 0.92\n",
            "train loss 0.3580441176891327 accuracy 0.98 | test loss 0.37879201769828796  accuracy 0.92\n",
            "train loss 0.3580448031425476 accuracy 0.99 | test loss 0.37886688113212585  accuracy 0.92\n",
            "train loss 0.3580450415611267 accuracy 0.98 | test loss 0.3788285255432129  accuracy 0.92\n",
            "train loss 0.35804370045661926 accuracy 0.98 | test loss 0.37881389260292053  accuracy 0.92\n",
            "train loss 0.35804328322410583 accuracy 0.98 | test loss 0.37883415818214417  accuracy 0.92\n",
            "train loss 0.35804352164268494 accuracy 0.98 | test loss 0.37879619002342224  accuracy 0.92\n",
            "train loss 0.3580435812473297 accuracy 0.99 | test loss 0.37887099385261536  accuracy 0.92\n",
            "train loss 0.35804450511932373 accuracy 0.98 | test loss 0.37881162762641907  accuracy 0.92\n",
            "train loss 0.35804250836372375 accuracy 0.98 | test loss 0.3788447082042694  accuracy 0.92\n",
            "train loss 0.35804325342178345 accuracy 0.98 | test loss 0.37880656123161316  accuracy 0.92\n",
            "train loss 0.35804229974746704 accuracy 0.99 | test loss 0.3788544237613678  accuracy 0.92\n",
            "train loss 0.35804328322410583 accuracy 0.98 | test loss 0.37881606817245483  accuracy 0.92\n",
            "train loss 0.3580421507358551 accuracy 0.98 | test loss 0.37880149483680725  accuracy 0.92\n",
            "train loss 0.35804206132888794 accuracy 0.99 | test loss 0.37887632846832275  accuracy 0.92\n",
            "train loss 0.3580435812473297 accuracy 0.98 | test loss 0.3788169026374817  accuracy 0.92\n",
            "train loss 0.358041375875473 accuracy 0.98 | test loss 0.3787789046764374  accuracy 0.92\n",
            "train loss 0.35804298520088196 accuracy 0.99 | test loss 0.3788537383079529  accuracy 0.92\n",
            "train loss 0.35804229974746704 accuracy 0.98 | test loss 0.3788154423236847  accuracy 0.92\n",
            "train loss 0.35804101824760437 accuracy 0.98 | test loss 0.3788008689880371  accuracy 0.92\n",
            "train loss 0.35804107785224915 accuracy 0.99 | test loss 0.37884870171546936  accuracy 0.92\n",
            "train loss 0.3580416738986969 accuracy 0.98 | test loss 0.37881040573120117  accuracy 0.92\n",
            "train loss 0.35804039239883423 accuracy 0.98 | test loss 0.3787958323955536  accuracy 0.92\n",
            "train loss 0.3580409288406372 accuracy 0.99 | test loss 0.3788706064224243  accuracy 0.92\n",
            "train loss 0.358041912317276 accuracy 0.98 | test loss 0.378832072019577  accuracy 0.92\n",
            "train loss 0.358040452003479 accuracy 0.98 | test loss 0.37879401445388794  accuracy 0.92\n",
            "train loss 0.35804030299186707 accuracy 0.99 | test loss 0.37885406613349915  accuracy 0.92\n",
            "train loss 0.3580409288406372 accuracy 0.98 | test loss 0.37881577014923096  accuracy 0.92\n",
            "train loss 0.3580394685268402 accuracy 0.98 | test loss 0.3787779211997986  accuracy 0.92\n",
            "train loss 0.3580406904220581 accuracy 0.99 | test loss 0.3788527548313141  accuracy 0.92\n",
            "train loss 0.35804039239883423 accuracy 0.98 | test loss 0.37881436944007874  accuracy 0.92\n",
            "train loss 0.3580392301082611 accuracy 0.98 | test loss 0.3787997364997864  accuracy 0.92\n",
            "train loss 0.35803893208503723 accuracy 0.99 | test loss 0.3788476586341858  accuracy 0.92\n",
            "train loss 0.3580397665500641 accuracy 0.98 | test loss 0.37880927324295044  accuracy 0.92\n",
            "train loss 0.3580385446548462 accuracy 0.98 | test loss 0.37879469990730286  accuracy 0.92\n",
            "train loss 0.35803863406181335 accuracy 0.99 | test loss 0.3788693845272064  accuracy 0.92\n",
            "train loss 0.3580400049686432 accuracy 0.98 | test loss 0.37883076071739197  accuracy 0.92\n",
            "train loss 0.3580385446548462 accuracy 0.98 | test loss 0.37879255414009094  accuracy 0.92\n",
            "train loss 0.3580380082130432 accuracy 0.99 | test loss 0.37885260581970215  accuracy 0.92\n",
            "train loss 0.3580390214920044 accuracy 0.98 | test loss 0.3788142204284668  accuracy 0.92\n",
            "train loss 0.3580376207828522 accuracy 0.98 | test loss 0.37879955768585205  accuracy 0.92\n",
            "train loss 0.3580375611782074 accuracy 0.98 | test loss 0.3788197934627533  accuracy 0.92\n",
            "train loss 0.35803741216659546 accuracy 0.98 | test loss 0.3787817656993866  accuracy 0.92\n",
            "train loss 0.35803794860839844 accuracy 0.99 | test loss 0.3788565397262573  accuracy 0.92\n",
            "train loss 0.3580383360385895 accuracy 0.98 | test loss 0.3788181245326996  accuracy 0.92\n",
            "train loss 0.35803690552711487 accuracy 0.98 | test loss 0.3788033127784729  accuracy 0.92\n",
            "train loss 0.3580363392829895 accuracy 0.98 | test loss 0.37881308794021606  accuracy 0.92\n",
            "train loss 0.3580365777015686 accuracy 0.98 | test loss 0.37879836559295654  accuracy 0.92\n",
            "train loss 0.3580361008644104 accuracy 0.99 | test loss 0.3788461983203888  accuracy 0.92\n",
            "train loss 0.35803720355033875 accuracy 0.98 | test loss 0.3788078725337982  accuracy 0.92\n",
            "train loss 0.3580359220504761 accuracy 0.98 | test loss 0.3787931501865387  accuracy 0.92\n",
            "train loss 0.3580358028411865 accuracy 0.99 | test loss 0.3788677752017975  accuracy 0.92\n",
            "train loss 0.358037531375885 accuracy 0.98 | test loss 0.37880828976631165  accuracy 0.92\n",
            "train loss 0.35803529620170593 accuracy 0.98 | test loss 0.3787704408168793  accuracy 0.92\n",
            "train loss 0.35803675651550293 accuracy 0.99 | test loss 0.37884521484375  accuracy 0.92\n",
            "train loss 0.35803624987602234 accuracy 0.98 | test loss 0.37880682945251465  accuracy 0.92\n",
            "train loss 0.35803481936454773 accuracy 0.98 | test loss 0.3787921369075775  accuracy 0.92\n",
            "train loss 0.3580349385738373 accuracy 0.98 | test loss 0.3788166642189026  accuracy 0.92\n",
            "train loss 0.3580348789691925 accuracy 0.98 | test loss 0.3788018226623535  accuracy 0.92\n",
            "train loss 0.3580341637134552 accuracy 0.98 | test loss 0.37876376509666443  accuracy 0.92\n",
            "train loss 0.35803595185279846 accuracy 0.99 | test loss 0.37883859872817993  accuracy 0.92\n",
            "train loss 0.3580351173877716 accuracy 0.98 | test loss 0.37880024313926697  accuracy 0.92\n",
            "train loss 0.3580338954925537 accuracy 0.98 | test loss 0.3787855803966522  accuracy 0.92\n",
            "train loss 0.35803404450416565 accuracy 0.99 | test loss 0.378860205411911  accuracy 0.92\n",
            "train loss 0.35803529620170593 accuracy 0.98 | test loss 0.3788215219974518  accuracy 0.92\n",
            "train loss 0.3580338954925537 accuracy 0.98 | test loss 0.3787831664085388  accuracy 0.92\n",
            "train loss 0.35803350806236267 accuracy 0.99 | test loss 0.3788430690765381  accuracy 0.92\n",
            "train loss 0.35803428292274475 accuracy 0.98 | test loss 0.37880459427833557  accuracy 0.92\n",
            "train loss 0.3580329716205597 accuracy 0.98 | test loss 0.3787899315357208  accuracy 0.92\n",
            "train loss 0.35803282260894775 accuracy 0.99 | test loss 0.37883779406547546  accuracy 0.92\n",
            "train loss 0.3580336272716522 accuracy 0.98 | test loss 0.37879934906959534  accuracy 0.92\n",
            "train loss 0.3580322861671448 accuracy 0.98 | test loss 0.3787846565246582  accuracy 0.92\n",
            "train loss 0.3580325245857239 accuracy 0.99 | test loss 0.378859281539917  accuracy 0.92\n",
            "train loss 0.3580338954925537 accuracy 0.98 | test loss 0.37882062792778015  accuracy 0.92\n",
            "train loss 0.3580324351787567 accuracy 0.98 | test loss 0.3787822723388672  accuracy 0.92\n",
            "train loss 0.35803189873695374 accuracy 0.99 | test loss 0.37883010506629944  accuracy 0.92\n",
            "train loss 0.3580324351787567 accuracy 0.98 | test loss 0.3787917196750641  accuracy 0.92\n",
            "train loss 0.35803139209747314 accuracy 0.98 | test loss 0.37880462408065796  accuracy 0.92\n",
            "train loss 0.358031302690506 accuracy 0.98 | test loss 0.3787665367126465  accuracy 0.92\n",
            "train loss 0.3580321669578552 accuracy 0.99 | test loss 0.3788413405418396  accuracy 0.92\n",
            "train loss 0.3580321669578552 accuracy 0.98 | test loss 0.3788028657436371  accuracy 0.92\n",
            "train loss 0.35803091526031494 accuracy 0.98 | test loss 0.378788024187088  accuracy 0.92\n",
            "train loss 0.3580304682254791 accuracy 0.98 | test loss 0.37882113456726074  accuracy 0.92\n",
            "train loss 0.3580310642719269 accuracy 0.98 | test loss 0.3787827491760254  accuracy 0.92\n",
            "train loss 0.3580303192138672 accuracy 0.99 | test loss 0.37883058190345764  accuracy 0.92\n",
            "train loss 0.3580310642719269 accuracy 0.98 | test loss 0.3787921369075775  accuracy 0.92\n",
            "train loss 0.35802993178367615 accuracy 0.98 | test loss 0.378777414560318  accuracy 0.92\n",
            "train loss 0.3580301105976105 accuracy 0.99 | test loss 0.3788520097732544  accuracy 0.92\n",
            "train loss 0.35803133249282837 accuracy 0.98 | test loss 0.3787924349308014  accuracy 0.92\n",
            "train loss 0.358029305934906 accuracy 0.98 | test loss 0.37878915667533875  accuracy 0.92\n",
            "train loss 0.358029305934906 accuracy 0.98 | test loss 0.37877440452575684  accuracy 0.92\n",
            "train loss 0.35802963376045227 accuracy 0.99 | test loss 0.37883421778678894  accuracy 0.92\n",
            "train loss 0.3580300807952881 accuracy 0.98 | test loss 0.3787957727909088  accuracy 0.92\n",
            "train loss 0.35802868008613586 accuracy 0.98 | test loss 0.3787577450275421  accuracy 0.92\n",
            "train loss 0.35802993178367615 accuracy 0.99 | test loss 0.37883248925209045  accuracy 0.92\n",
            "train loss 0.3580295741558075 accuracy 0.98 | test loss 0.37879401445388794  accuracy 0.92\n",
            "train loss 0.3580284118652344 accuracy 0.98 | test loss 0.37877920269966125  accuracy 0.92\n",
            "train loss 0.3580281734466553 accuracy 0.99 | test loss 0.3788270056247711  accuracy 0.92\n",
            "train loss 0.35802894830703735 accuracy 0.98 | test loss 0.378788560628891  accuracy 0.92\n",
            "train loss 0.35802772641181946 accuracy 0.98 | test loss 0.3787737488746643  accuracy 0.92\n",
            "train loss 0.35802799463272095 accuracy 0.99 | test loss 0.3788483440876007  accuracy 0.92\n",
            "train loss 0.35802915692329407 accuracy 0.98 | test loss 0.3788096010684967  accuracy 0.92\n",
            "train loss 0.35802772641181946 accuracy 0.98 | test loss 0.37877124547958374  accuracy 0.92\n",
            "train loss 0.3580273985862732 accuracy 0.99 | test loss 0.37883132696151733  accuracy 0.92\n",
            "train loss 0.3580281436443329 accuracy 0.98 | test loss 0.3787927031517029  accuracy 0.92\n",
            "train loss 0.35802680253982544 accuracy 0.98 | test loss 0.37877798080444336  accuracy 0.92\n",
            "train loss 0.3580267131328583 accuracy 0.99 | test loss 0.3788258135318756  accuracy 0.92\n",
            "train loss 0.35802748799324036 accuracy 0.98 | test loss 0.3787873089313507  accuracy 0.92\n",
            "train loss 0.3580261170864105 accuracy 0.98 | test loss 0.37877264618873596  accuracy 0.92\n",
            "train loss 0.35802650451660156 accuracy 0.99 | test loss 0.3788471817970276  accuracy 0.92\n",
            "train loss 0.35802772641181946 accuracy 0.98 | test loss 0.3788084089756012  accuracy 0.92\n",
            "train loss 0.35802626609802246 accuracy 0.98 | test loss 0.37877002358436584  accuracy 0.92\n",
            "train loss 0.35802584886550903 accuracy 0.99 | test loss 0.37884464859962463  accuracy 0.92\n",
            "train loss 0.35802724957466125 accuracy 0.98 | test loss 0.3787848651409149  accuracy 0.92\n",
            "train loss 0.35802513360977173 accuracy 0.98 | test loss 0.3787814974784851  accuracy 0.92\n",
            "train loss 0.3580252230167389 accuracy 0.98 | test loss 0.3787667751312256  accuracy 0.92\n",
            "train loss 0.3580254316329956 accuracy 0.99 | test loss 0.3788265287876129  accuracy 0.92\n",
            "train loss 0.3580259680747986 accuracy 0.98 | test loss 0.3787878453731537  accuracy 0.92\n",
            "train loss 0.35802459716796875 accuracy 0.98 | test loss 0.3787730038166046  accuracy 0.92\n",
            "train loss 0.3580246567726135 accuracy 0.99 | test loss 0.3788206875324249  accuracy 0.92\n",
            "train loss 0.35802528262138367 accuracy 0.98 | test loss 0.37878212332725525  accuracy 0.92\n",
            "train loss 0.35802391171455383 accuracy 0.98 | test loss 0.3787672817707062  accuracy 0.92\n",
            "train loss 0.3580244481563568 accuracy 0.99 | test loss 0.3788418173789978  accuracy 0.92\n",
            "train loss 0.3580254912376404 accuracy 0.98 | test loss 0.37880298495292664  accuracy 0.92\n",
            "train loss 0.35802406072616577 accuracy 0.98 | test loss 0.3787645995616913  accuracy 0.92\n",
            "train loss 0.35802382230758667 accuracy 0.99 | test loss 0.3788391649723053  accuracy 0.92\n",
            "train loss 0.3580250144004822 accuracy 0.98 | test loss 0.3788004219532013  accuracy 0.92\n",
            "train loss 0.3580235242843628 accuracy 0.98 | test loss 0.37876200675964355  accuracy 0.92\n",
            "train loss 0.3580232858657837 accuracy 0.99 | test loss 0.3788219392299652  accuracy 0.92\n",
            "train loss 0.3580239713191986 accuracy 0.98 | test loss 0.37878334522247314  accuracy 0.92\n",
            "train loss 0.35802268981933594 accuracy 0.98 | test loss 0.3787684440612793  accuracy 0.92\n",
            "train loss 0.35802268981933594 accuracy 0.99 | test loss 0.3788161873817444  accuracy 0.92\n",
            "train loss 0.3580232858657837 accuracy 0.98 | test loss 0.3787776231765747  accuracy 0.92\n",
            "train loss 0.3580220341682434 accuracy 0.98 | test loss 0.37876272201538086  accuracy 0.92\n",
            "train loss 0.3580223619937897 accuracy 0.99 | test loss 0.3788372576236725  accuracy 0.92\n",
            "train loss 0.3580235242843628 accuracy 0.98 | test loss 0.3787985146045685  accuracy 0.92\n",
            "train loss 0.3580220639705658 accuracy 0.98 | test loss 0.37876006960868835  accuracy 0.92\n",
            "train loss 0.3580217659473419 accuracy 0.99 | test loss 0.37883463501930237  accuracy 0.92\n",
            "train loss 0.3580230176448822 accuracy 0.98 | test loss 0.3787749111652374  accuracy 0.92\n",
            "train loss 0.3580210506916046 accuracy 0.98 | test loss 0.3787948787212372  accuracy 0.92\n",
            "train loss 0.3580213189125061 accuracy 0.98 | test loss 0.3787565529346466  accuracy 0.92\n",
            "train loss 0.3580213487148285 accuracy 0.99 | test loss 0.37881627678871155  accuracy 0.92\n",
            "train loss 0.3580217659473419 accuracy 0.98 | test loss 0.37877756357192993  accuracy 0.92\n",
            "train loss 0.35802045464515686 accuracy 0.98 | test loss 0.3787626624107361  accuracy 0.92\n",
            "train loss 0.3580206334590912 accuracy 0.99 | test loss 0.3788103461265564  accuracy 0.92\n",
            "train loss 0.358021080493927 accuracy 0.98 | test loss 0.37877169251441956  accuracy 0.92\n",
            "train loss 0.35801976919174194 accuracy 0.98 | test loss 0.3787567913532257  accuracy 0.92\n",
            "train loss 0.3580204248428345 accuracy 0.99 | test loss 0.3788313865661621  accuracy 0.92\n",
            "train loss 0.35802125930786133 accuracy 0.98 | test loss 0.37879255414009094  accuracy 0.92\n",
            "train loss 0.3580198585987091 accuracy 0.98 | test loss 0.3787541389465332  accuracy 0.92\n",
            "train loss 0.35801976919174194 accuracy 0.99 | test loss 0.37882867455482483  accuracy 0.92\n",
            "train loss 0.3580207824707031 accuracy 0.98 | test loss 0.37878990173339844  accuracy 0.92\n",
            "train loss 0.35801932215690613 accuracy 0.98 | test loss 0.3787514269351959  accuracy 0.92\n",
            "train loss 0.3580192029476166 accuracy 0.99 | test loss 0.37881141901016235  accuracy 0.92\n",
            "train loss 0.35801970958709717 accuracy 0.98 | test loss 0.3787727355957031  accuracy 0.92\n",
            "train loss 0.35801854729652405 accuracy 0.98 | test loss 0.37875792384147644  accuracy 0.92\n",
            "train loss 0.3580187261104584 accuracy 0.99 | test loss 0.37880560755729675  accuracy 0.92\n",
            "train loss 0.35801905393600464 accuracy 0.98 | test loss 0.3787669539451599  accuracy 0.92\n",
            "train loss 0.3580179512500763 accuracy 0.98 | test loss 0.37875205278396606  accuracy 0.92\n",
            "train loss 0.3580183684825897 accuracy 0.99 | test loss 0.3788266181945801  accuracy 0.92\n",
            "train loss 0.35801926255226135 accuracy 0.98 | test loss 0.3787878453731537  accuracy 0.92\n",
            "train loss 0.35801783204078674 accuracy 0.98 | test loss 0.37874943017959595  accuracy 0.92\n",
            "train loss 0.35801777243614197 accuracy 0.99 | test loss 0.3788239657878876  accuracy 0.92\n",
            "train loss 0.35801875591278076 accuracy 0.98 | test loss 0.37876418232917786  accuracy 0.92\n",
            "train loss 0.3580169975757599 accuracy 0.98 | test loss 0.37878409028053284  accuracy 0.92\n",
            "train loss 0.35801708698272705 accuracy 0.98 | test loss 0.3787456750869751  accuracy 0.92\n",
            "train loss 0.3580172657966614 accuracy 0.99 | test loss 0.3788054585456848  accuracy 0.92\n",
            "train loss 0.3580175042152405 accuracy 0.98 | test loss 0.3787667453289032  accuracy 0.92\n",
            "train loss 0.35801634192466736 accuracy 0.98 | test loss 0.3787517845630646  accuracy 0.92\n",
            "train loss 0.35801663994789124 accuracy 0.99 | test loss 0.3787994980812073  accuracy 0.92\n",
            "train loss 0.35801681876182556 accuracy 0.98 | test loss 0.37876081466674805  accuracy 0.92\n",
            "train loss 0.3580157458782196 accuracy 0.98 | test loss 0.3787936270236969  accuracy 0.92\n",
            "train loss 0.35801634192466736 accuracy 0.98 | test loss 0.3787550628185272  accuracy 0.92\n",
            "train loss 0.3580155074596405 accuracy 0.99 | test loss 0.378802627325058  accuracy 0.92\n",
            "train loss 0.35801634192466736 accuracy 0.98 | test loss 0.37876400351524353  accuracy 0.92\n",
            "train loss 0.35801535844802856 accuracy 0.98 | test loss 0.3787490129470825  accuracy 0.92\n",
            "train loss 0.3580152690410614 accuracy 0.99 | test loss 0.37882348895072937  accuracy 0.92\n",
            "train loss 0.35801663994789124 accuracy 0.98 | test loss 0.37876367568969727  accuracy 0.92\n",
            "train loss 0.3580145239830017 accuracy 0.98 | test loss 0.3787488043308258  accuracy 0.92\n",
            "train loss 0.3580150604248047 accuracy 0.99 | test loss 0.37879645824432373  accuracy 0.92\n",
            "train loss 0.35801512002944946 accuracy 0.98 | test loss 0.3787577450275421  accuracy 0.92\n",
            "train loss 0.3580140471458435 accuracy 0.98 | test loss 0.3787904977798462  accuracy 0.92\n",
            "train loss 0.35801467299461365 accuracy 0.98 | test loss 0.3787519037723541  accuracy 0.92\n",
            "train loss 0.35801389813423157 accuracy 0.99 | test loss 0.3787994384765625  accuracy 0.92\n",
            "train loss 0.35801467299461365 accuracy 0.98 | test loss 0.37876075506210327  accuracy 0.92\n",
            "train loss 0.3580135405063629 accuracy 0.98 | test loss 0.37874579429626465  accuracy 0.92\n",
            "train loss 0.358013778924942 accuracy 0.99 | test loss 0.3788203001022339  accuracy 0.92\n",
            "train loss 0.35801491141319275 accuracy 0.98 | test loss 0.3787813186645508  accuracy 0.92\n",
            "train loss 0.35801345109939575 accuracy 0.98 | test loss 0.3787427544593811  accuracy 0.92\n",
            "train loss 0.3580132722854614 accuracy 0.99 | test loss 0.3788025677204132  accuracy 0.92\n",
            "train loss 0.3580138683319092 accuracy 0.98 | test loss 0.3787637948989868  accuracy 0.92\n",
            "train loss 0.35801252722740173 accuracy 0.98 | test loss 0.3787488043308258  accuracy 0.92\n",
            "train loss 0.3580126166343689 accuracy 0.99 | test loss 0.37879636883735657  accuracy 0.92\n",
            "train loss 0.35801318287849426 accuracy 0.98 | test loss 0.37875768542289734  accuracy 0.92\n",
            "train loss 0.3580118417739868 accuracy 0.98 | test loss 0.37874266505241394  accuracy 0.92\n",
            "train loss 0.35801246762275696 accuracy 0.99 | test loss 0.37881720066070557  accuracy 0.92\n",
            "train loss 0.3580133616924286 accuracy 0.98 | test loss 0.37877821922302246  accuracy 0.92\n",
            "train loss 0.358011931180954 accuracy 0.98 | test loss 0.3787396550178528  accuracy 0.92\n",
            "train loss 0.3580118417739868 accuracy 0.99 | test loss 0.37881413102149963  accuracy 0.92\n",
            "train loss 0.3580128252506256 accuracy 0.98 | test loss 0.3787751793861389  accuracy 0.92\n",
            "train loss 0.358011394739151 accuracy 0.98 | test loss 0.378736674785614  accuracy 0.92\n",
            "train loss 0.35801127552986145 accuracy 0.99 | test loss 0.3788112699985504  accuracy 0.92\n",
            "train loss 0.3580124080181122 accuracy 0.98 | test loss 0.37875139713287354  accuracy 0.92\n",
            "train loss 0.358010470867157 accuracy 0.98 | test loss 0.3787364065647125  accuracy 0.92\n",
            "train loss 0.35801103711128235 accuracy 0.99 | test loss 0.37881091237068176  accuracy 0.92\n",
            "train loss 0.35801178216934204 accuracy 0.98 | test loss 0.37877199053764343  accuracy 0.92\n",
            "train loss 0.35801032185554504 accuracy 0.98 | test loss 0.3787335157394409  accuracy 0.92\n",
            "train loss 0.358010470867157 accuracy 0.99 | test loss 0.37880802154541016  accuracy 0.92\n",
            "train loss 0.35801124572753906 accuracy 0.98 | test loss 0.3787692189216614  accuracy 0.92\n",
            "train loss 0.35800987482070923 accuracy 0.98 | test loss 0.37875404953956604  accuracy 0.92\n",
            "train loss 0.3580092489719391 accuracy 0.98 | test loss 0.37877386808395386  accuracy 0.92\n",
            "train loss 0.35800954699516296 accuracy 0.98 | test loss 0.37873518466949463  accuracy 0.92\n",
            "train loss 0.35800960659980774 accuracy 0.99 | test loss 0.3787948191165924  accuracy 0.92\n",
            "train loss 0.35801002383232117 accuracy 0.98 | test loss 0.3787561058998108  accuracy 0.92\n",
            "train loss 0.3580087125301361 accuracy 0.98 | test loss 0.378741055727005  accuracy 0.92\n",
            "train loss 0.35800886154174805 accuracy 0.99 | test loss 0.3787885904312134  accuracy 0.92\n",
            "train loss 0.35800933837890625 accuracy 0.98 | test loss 0.37874987721443176  accuracy 0.92\n",
            "train loss 0.3580080568790436 accuracy 0.98 | test loss 0.3787347972393036  accuracy 0.92\n",
            "train loss 0.3580087125301361 accuracy 0.99 | test loss 0.37880927324295044  accuracy 0.92\n",
            "train loss 0.3580095171928406 accuracy 0.98 | test loss 0.37877020239830017  accuracy 0.92\n",
            "train loss 0.3580080270767212 accuracy 0.98 | test loss 0.37873151898384094  accuracy 0.92\n",
            "train loss 0.35800814628601074 accuracy 0.99 | test loss 0.3788059949874878  accuracy 0.92\n",
            "train loss 0.3580089509487152 accuracy 0.98 | test loss 0.3787669539451599  accuracy 0.92\n",
            "train loss 0.3580074906349182 accuracy 0.98 | test loss 0.37872833013534546  accuracy 0.92\n",
            "train loss 0.3580075800418854 accuracy 0.99 | test loss 0.3788028359413147  accuracy 0.92\n",
            "train loss 0.3580085337162018 accuracy 0.98 | test loss 0.3787429630756378  accuracy 0.92\n",
            "train loss 0.35800668597221375 accuracy 0.98 | test loss 0.37874799966812134  accuracy 0.92\n",
            "train loss 0.35800647735595703 accuracy 0.98 | test loss 0.37873297929763794  accuracy 0.92\n",
            "train loss 0.35800692439079285 accuracy 0.99 | test loss 0.3787805140018463  accuracy 0.92\n",
            "train loss 0.3580070436000824 accuracy 0.98 | test loss 0.3787417411804199  accuracy 0.92\n",
            "train loss 0.3580060601234436 accuracy 0.98 | test loss 0.37877437472343445  accuracy 0.92\n",
            "train loss 0.3580065071582794 accuracy 0.98 | test loss 0.37873566150665283  accuracy 0.92\n",
            "train loss 0.3580058217048645 accuracy 0.99 | test loss 0.3787831664085388  accuracy 0.92\n",
            "train loss 0.3580065071582794 accuracy 0.98 | test loss 0.3787444233894348  accuracy 0.92\n",
            "train loss 0.35800543427467346 accuracy 0.98 | test loss 0.37872934341430664  accuracy 0.92\n",
            "train loss 0.35800573229789734 accuracy 0.99 | test loss 0.37880367040634155  accuracy 0.92\n",
            "train loss 0.35800668597221375 accuracy 0.98 | test loss 0.3787645697593689  accuracy 0.92\n",
            "train loss 0.3580052852630615 accuracy 0.98 | test loss 0.37872588634490967  accuracy 0.92\n",
            "train loss 0.3580052852630615 accuracy 0.99 | test loss 0.37878546118736267  accuracy 0.92\n",
            "train loss 0.35800567269325256 accuracy 0.98 | test loss 0.37874671816825867  accuracy 0.92\n",
            "train loss 0.35800445079803467 accuracy 0.98 | test loss 0.3787318468093872  accuracy 0.92\n",
            "train loss 0.3580045700073242 accuracy 0.99 | test loss 0.3787793219089508  accuracy 0.92\n",
            "train loss 0.35800501704216003 accuracy 0.98 | test loss 0.378740519285202  accuracy 0.92\n",
            "train loss 0.35800379514694214 accuracy 0.98 | test loss 0.37872549891471863  accuracy 0.92\n",
            "train loss 0.3580044209957123 accuracy 0.99 | test loss 0.3787998557090759  accuracy 0.92\n",
            "train loss 0.35800519585609436 accuracy 0.98 | test loss 0.37876075506210327  accuracy 0.92\n",
            "train loss 0.35800376534461975 accuracy 0.98 | test loss 0.37872207164764404  accuracy 0.92\n",
            "train loss 0.3580039143562317 accuracy 0.99 | test loss 0.37879645824432373  accuracy 0.92\n",
            "train loss 0.358004629611969 accuracy 0.98 | test loss 0.37875741720199585  accuracy 0.92\n",
            "train loss 0.3580032289028168 accuracy 0.98 | test loss 0.37874212861061096  accuracy 0.92\n",
            "train loss 0.3580024540424347 accuracy 0.98 | test loss 0.37872710824012756  accuracy 0.92\n",
            "train loss 0.3580031991004944 accuracy 0.99 | test loss 0.3787780702114105  accuracy 0.92\n",
            "train loss 0.3580033779144287 accuracy 0.98 | test loss 0.37873926758766174  accuracy 0.92\n",
            "train loss 0.358002245426178 accuracy 0.98 | test loss 0.3787241280078888  accuracy 0.92\n",
            "train loss 0.35800260305404663 accuracy 0.99 | test loss 0.3787984848022461  accuracy 0.92\n",
            "train loss 0.3580036163330078 accuracy 0.98 | test loss 0.3787592947483063  accuracy 0.92\n",
            "train loss 0.3580021262168884 accuracy 0.98 | test loss 0.3787206709384918  accuracy 0.92\n",
            "train loss 0.35800209641456604 accuracy 0.99 | test loss 0.37879493832588196  accuracy 0.92\n",
            "train loss 0.35800307989120483 accuracy 0.98 | test loss 0.3787350356578827  accuracy 0.92\n",
            "train loss 0.3580012023448944 accuracy 0.98 | test loss 0.37875479459762573  accuracy 0.92\n",
            "train loss 0.35800135135650635 accuracy 0.98 | test loss 0.3787161111831665  accuracy 0.92\n",
            "train loss 0.358001708984375 accuracy 0.99 | test loss 0.3787757158279419  accuracy 0.92\n",
            "train loss 0.3580017685890198 accuracy 0.98 | test loss 0.3787368834018707  accuracy 0.92\n",
            "train loss 0.35800063610076904 accuracy 0.98 | test loss 0.378721684217453  accuracy 0.92\n",
            "train loss 0.3580009341239929 accuracy 0.99 | test loss 0.3787692189216614  accuracy 0.92\n",
            "train loss 0.35800105333328247 accuracy 0.98 | test loss 0.3787304162979126  accuracy 0.92\n",
            "train loss 0.35800009965896606 accuracy 0.98 | test loss 0.3787630498409271  accuracy 0.92\n",
            "train loss 0.3580005466938019 accuracy 0.98 | test loss 0.37872427701950073  accuracy 0.92\n",
            "train loss 0.3579998314380646 accuracy 0.99 | test loss 0.3787717819213867  accuracy 0.92\n",
            "train loss 0.3580005466938019 accuracy 0.98 | test loss 0.37873294949531555  accuracy 0.92\n",
            "train loss 0.3579995930194855 accuracy 0.98 | test loss 0.3787178099155426  accuracy 0.92\n",
            "train loss 0.357999712228775 accuracy 0.99 | test loss 0.3787921071052551  accuracy 0.92\n",
            "train loss 0.35800087451934814 accuracy 0.98 | test loss 0.37873199582099915  accuracy 0.92\n",
            "train loss 0.35799872875213623 accuracy 0.98 | test loss 0.37876462936401367  accuracy 0.92\n",
            "train loss 0.3579995334148407 accuracy 0.98 | test loss 0.37872588634490967  accuracy 0.92\n",
            "train loss 0.3579986095428467 accuracy 0.99 | test loss 0.37877342104911804  accuracy 0.92\n",
            "train loss 0.3579995632171631 accuracy 0.98 | test loss 0.3787344694137573  accuracy 0.92\n",
            "train loss 0.3579983711242676 accuracy 0.98 | test loss 0.3787192404270172  accuracy 0.92\n",
            "train loss 0.35799843072891235 accuracy 0.99 | test loss 0.3787935674190521  accuracy 0.92\n",
            "train loss 0.357999712228775 accuracy 0.98 | test loss 0.3787543475627899  accuracy 0.92\n",
            "train loss 0.3579982817173004 accuracy 0.98 | test loss 0.3787155747413635  accuracy 0.92\n",
            "train loss 0.3579978346824646 accuracy 0.99 | test loss 0.37878990173339844  accuracy 0.92\n",
            "train loss 0.3579992949962616 accuracy 0.98 | test loss 0.37872976064682007  accuracy 0.92\n",
            "train loss 0.35799723863601685 accuracy 0.98 | test loss 0.37871459126472473  accuracy 0.92\n",
            "train loss 0.35799768567085266 accuracy 0.99 | test loss 0.37878885865211487  accuracy 0.92\n",
            "train loss 0.35799863934516907 accuracy 0.98 | test loss 0.37874969840049744  accuracy 0.92\n",
            "train loss 0.3579971492290497 accuracy 0.98 | test loss 0.37871095538139343  accuracy 0.92\n",
            "train loss 0.3579971492290497 accuracy 0.99 | test loss 0.37878525257110596  accuracy 0.92\n",
            "train loss 0.3579980432987213 accuracy 0.98 | test loss 0.3787461519241333  accuracy 0.92\n",
            "train loss 0.3579966723918915 accuracy 0.98 | test loss 0.3787307143211365  accuracy 0.92\n",
            "train loss 0.35799598693847656 accuracy 0.98 | test loss 0.37875044345855713  accuracy 0.92\n",
            "train loss 0.35799640417099 accuracy 0.98 | test loss 0.37871161103248596  accuracy 0.92\n",
            "train loss 0.3579963743686676 accuracy 0.99 | test loss 0.3787710964679718  accuracy 0.92\n",
            "train loss 0.3579968214035034 accuracy 0.98 | test loss 0.3787320554256439  accuracy 0.92\n",
            "train loss 0.35799551010131836 accuracy 0.98 | test loss 0.3787167966365814  accuracy 0.92\n",
            "train loss 0.3579956591129303 accuracy 0.99 | test loss 0.37876421213150024  accuracy 0.92\n",
            "train loss 0.3579961359500885 accuracy 0.98 | test loss 0.3787251114845276  accuracy 0.92\n",
            "train loss 0.35799482464790344 accuracy 0.98 | test loss 0.37873759865760803  accuracy 0.92\n",
            "train loss 0.3579949140548706 accuracy 0.98 | test loss 0.37869903445243835  accuracy 0.92\n",
            "train loss 0.35799598693847656 accuracy 0.99 | test loss 0.3787733316421509  accuracy 0.92\n",
            "train loss 0.35799577832221985 accuracy 0.98 | test loss 0.3787342309951782  accuracy 0.92\n",
            "train loss 0.35799428820610046 accuracy 0.98 | test loss 0.37869560718536377  accuracy 0.92\n",
            "train loss 0.3579954206943512 accuracy 0.99 | test loss 0.37876999378204346  accuracy 0.92\n",
            "train loss 0.3579952120780945 accuracy 0.98 | test loss 0.3787308931350708  accuracy 0.92\n",
            "train loss 0.357994019985199 accuracy 0.98 | test loss 0.3787155747413635  accuracy 0.92\n",
            "train loss 0.35799381136894226 accuracy 0.99 | test loss 0.37876296043395996  accuracy 0.92\n",
            "train loss 0.3579944968223572 accuracy 0.98 | test loss 0.3787238597869873  accuracy 0.92\n",
            "train loss 0.35799330472946167 accuracy 0.98 | test loss 0.3787085711956024  accuracy 0.92\n",
            "train loss 0.3579936623573303 accuracy 0.99 | test loss 0.37878283858299255  accuracy 0.92\n",
            "train loss 0.3579947054386139 accuracy 0.98 | test loss 0.37874361872673035  accuracy 0.92\n",
            "train loss 0.3579932451248169 accuracy 0.98 | test loss 0.37870481610298157  accuracy 0.92\n",
            "train loss 0.35799312591552734 accuracy 0.99 | test loss 0.3787791430950165  accuracy 0.92\n",
            "train loss 0.3579941391944885 accuracy 0.98 | test loss 0.37871894240379333  accuracy 0.92\n",
            "train loss 0.3579922914505005 accuracy 0.98 | test loss 0.3787238299846649  accuracy 0.92\n",
            "train loss 0.357992023229599 accuracy 0.98 | test loss 0.37870848178863525  accuracy 0.92\n",
            "train loss 0.357992559671402 accuracy 0.99 | test loss 0.3787558674812317  accuracy 0.92\n",
            "train loss 0.3579927086830139 accuracy 0.98 | test loss 0.3787167966365814  accuracy 0.92\n",
            "train loss 0.35799163579940796 accuracy 0.98 | test loss 0.3787493109703064  accuracy 0.92\n",
            "train loss 0.3579922020435333 accuracy 0.98 | test loss 0.37871038913726807  accuracy 0.92\n",
            "train loss 0.357991486787796 accuracy 0.99 | test loss 0.37875762581825256  accuracy 0.92\n",
            "train loss 0.35799217224121094 accuracy 0.98 | test loss 0.3787185549736023  accuracy 0.92\n",
            "train loss 0.35799095034599304 accuracy 0.98 | test loss 0.37873098254203796  accuracy 0.92\n",
            "train loss 0.35799098014831543 accuracy 0.98 | test loss 0.37869226932525635  accuracy 0.92\n",
            "train loss 0.3579918444156647 accuracy 0.99 | test loss 0.3787665367126465  accuracy 0.92\n",
            "train loss 0.3579918444156647 accuracy 0.98 | test loss 0.3787272870540619  accuracy 0.92\n",
            "train loss 0.35799047350883484 accuracy 0.98 | test loss 0.3787119686603546  accuracy 0.92\n",
            "train loss 0.35799017548561096 accuracy 0.99 | test loss 0.3787592947483063  accuracy 0.92\n",
            "train loss 0.35799115896224976 accuracy 0.98 | test loss 0.37872016429901123  accuracy 0.92\n",
            "train loss 0.35798975825309753 accuracy 0.98 | test loss 0.37870481610298157  accuracy 0.92\n",
            "train loss 0.35799017548561096 accuracy 0.99 | test loss 0.37877902388572693  accuracy 0.92\n",
            "train loss 0.3579913377761841 accuracy 0.98 | test loss 0.3787396252155304  accuracy 0.92\n",
            "train loss 0.3579898774623871 accuracy 0.98 | test loss 0.3787006735801697  accuracy 0.92\n",
            "train loss 0.357989639043808 accuracy 0.99 | test loss 0.3787602186203003  accuracy 0.92\n",
            "train loss 0.3579902648925781 accuracy 0.98 | test loss 0.3787209987640381  accuracy 0.92\n",
            "train loss 0.35798880457878113 accuracy 0.98 | test loss 0.37869706749916077  accuracy 0.92\n",
            "train loss 0.35798925161361694 accuracy 0.99 | test loss 0.37875643372535706  accuracy 0.92\n",
            "train loss 0.357989639043808 accuracy 0.98 | test loss 0.3787172734737396  accuracy 0.92\n",
            "train loss 0.35798850655555725 accuracy 0.98 | test loss 0.37870192527770996  accuracy 0.92\n",
            "train loss 0.35798853635787964 accuracy 0.99 | test loss 0.37874919176101685  accuracy 0.92\n",
            "train loss 0.35798895359039307 accuracy 0.98 | test loss 0.3787101209163666  accuracy 0.92\n",
            "train loss 0.35798782110214233 accuracy 0.98 | test loss 0.3786948323249817  accuracy 0.92\n",
            "train loss 0.35798850655555725 accuracy 0.99 | test loss 0.37876906991004944  accuracy 0.92\n",
            "train loss 0.3579891622066498 accuracy 0.98 | test loss 0.37872976064682007  accuracy 0.92\n",
            "train loss 0.3579876720905304 accuracy 0.98 | test loss 0.3786909282207489  accuracy 0.92\n",
            "train loss 0.3579879701137543 accuracy 0.99 | test loss 0.37876516580581665  accuracy 0.92\n",
            "train loss 0.357988566160202 accuracy 0.98 | test loss 0.3787260353565216  accuracy 0.92\n",
            "train loss 0.3579871952533722 accuracy 0.98 | test loss 0.3787105083465576  accuracy 0.92\n",
            "train loss 0.3579865097999573 accuracy 0.98 | test loss 0.3787153959274292  accuracy 0.92\n",
            "train loss 0.3579863905906677 accuracy 0.98 | test loss 0.3786768317222595  accuracy 0.92\n",
            "train loss 0.3579881191253662 accuracy 0.99 | test loss 0.37875109910964966  accuracy 0.92\n",
            "train loss 0.35798728466033936 accuracy 0.98 | test loss 0.37871190905570984  accuracy 0.92\n",
            "train loss 0.3579860329627991 accuracy 0.98 | test loss 0.37869659066200256  accuracy 0.92\n",
            "train loss 0.35798636078834534 accuracy 0.99 | test loss 0.3787708282470703  accuracy 0.92\n",
            "train loss 0.35798752307891846 accuracy 0.98 | test loss 0.378731369972229  accuracy 0.92\n",
            "train loss 0.3579860329627991 accuracy 0.98 | test loss 0.37869247794151306  accuracy 0.92\n",
            "train loss 0.35798588395118713 accuracy 0.99 | test loss 0.3787666857242584  accuracy 0.92\n",
            "train loss 0.3579869270324707 accuracy 0.98 | test loss 0.3787063658237457  accuracy 0.92\n",
            "train loss 0.3579849898815155 accuracy 0.98 | test loss 0.3787260055541992  accuracy 0.92\n",
            "train loss 0.3579852283000946 accuracy 0.98 | test loss 0.37868696451187134  accuracy 0.92\n",
            "train loss 0.35798555612564087 accuracy 0.99 | test loss 0.37874630093574524  accuracy 0.92\n",
            "train loss 0.35798561573028564 accuracy 0.98 | test loss 0.3787071108818054  accuracy 0.92\n",
            "train loss 0.35798439383506775 accuracy 0.98 | test loss 0.37869173288345337  accuracy 0.92\n",
            "train loss 0.3579847514629364 accuracy 0.99 | test loss 0.3787659704685211  accuracy 0.92\n",
            "train loss 0.35798579454421997 accuracy 0.98 | test loss 0.3787265419960022  accuracy 0.92\n",
            "train loss 0.3579843044281006 accuracy 0.98 | test loss 0.37868762016296387  accuracy 0.92\n",
            "train loss 0.3579842746257782 accuracy 0.99 | test loss 0.378761887550354  accuracy 0.92\n",
            "train loss 0.3579852283000946 accuracy 0.98 | test loss 0.37872251868247986  accuracy 0.92\n",
            "train loss 0.3579837679862976 accuracy 0.98 | test loss 0.37870699167251587  accuracy 0.92\n",
            "train loss 0.3579830825328827 accuracy 0.98 | test loss 0.3787117600440979  accuracy 0.92\n",
            "train loss 0.3579830527305603 accuracy 0.98 | test loss 0.3786730170249939  accuracy 0.92\n",
            "train loss 0.3579844534397125 accuracy 0.99 | test loss 0.37874725461006165  accuracy 0.92\n",
            "train loss 0.35798391699790955 accuracy 0.98 | test loss 0.37870803475379944  accuracy 0.92\n",
            "train loss 0.3579825758934021 accuracy 0.98 | test loss 0.378692626953125  accuracy 0.92\n",
            "train loss 0.3579827845096588 accuracy 0.99 | test loss 0.3787399232387543  accuracy 0.92\n",
            "train loss 0.35798323154449463 accuracy 0.98 | test loss 0.37870070338249207  accuracy 0.92\n",
            "train loss 0.35798197984695435 accuracy 0.98 | test loss 0.378712922334671  accuracy 0.92\n",
            "train loss 0.35798195004463196 accuracy 0.98 | test loss 0.37867429852485657  accuracy 0.92\n",
            "train loss 0.35798317193984985 accuracy 0.99 | test loss 0.3787485361099243  accuracy 0.92\n",
            "train loss 0.3579828441143036 accuracy 0.98 | test loss 0.37870925664901733  accuracy 0.92\n",
            "train loss 0.357981413602829 accuracy 0.98 | test loss 0.37867048382759094  accuracy 0.92\n",
            "train loss 0.3579826354980469 accuracy 0.99 | test loss 0.3787447214126587  accuracy 0.92\n",
            "train loss 0.3579823076725006 accuracy 0.98 | test loss 0.3787055015563965  accuracy 0.92\n",
            "train loss 0.3579810559749603 accuracy 0.98 | test loss 0.3786901533603668  accuracy 0.92\n",
            "train loss 0.35798102617263794 accuracy 0.99 | test loss 0.3787373900413513  accuracy 0.92\n",
            "train loss 0.3579815626144409 accuracy 0.98 | test loss 0.3786981999874115  accuracy 0.92\n",
            "train loss 0.3579804003238678 accuracy 0.98 | test loss 0.37871038913726807  accuracy 0.92\n",
            "train loss 0.357980340719223 accuracy 0.98 | test loss 0.3786714971065521  accuracy 0.92\n",
            "train loss 0.357981413602829 accuracy 0.99 | test loss 0.3787456750869751  accuracy 0.92\n",
            "train loss 0.35798126459121704 accuracy 0.98 | test loss 0.3787064254283905  accuracy 0.92\n",
            "train loss 0.3579798936843872 accuracy 0.98 | test loss 0.3786908984184265  accuracy 0.92\n",
            "train loss 0.35797983407974243 accuracy 0.99 | test loss 0.37873807549476624  accuracy 0.92\n",
            "train loss 0.35798048973083496 accuracy 0.98 | test loss 0.3786989450454712  accuracy 0.92\n",
            "train loss 0.3579792082309723 accuracy 0.98 | test loss 0.378683477640152  accuracy 0.92\n",
            "train loss 0.3579797148704529 accuracy 0.99 | test loss 0.378757506608963  accuracy 0.92\n",
            "train loss 0.3579806387424469 accuracy 0.98 | test loss 0.3787180185317993  accuracy 0.92\n",
            "train loss 0.3579792082309723 accuracy 0.98 | test loss 0.37867894768714905  accuracy 0.92\n",
            "train loss 0.3579792380332947 accuracy 0.99 | test loss 0.37875300645828247  accuracy 0.92\n",
            "train loss 0.35798007249832153 accuracy 0.98 | test loss 0.37871354818344116  accuracy 0.92\n",
            "train loss 0.35797858238220215 accuracy 0.98 | test loss 0.3786745071411133  accuracy 0.92\n",
            "train loss 0.3579787611961365 accuracy 0.99 | test loss 0.37873390316963196  accuracy 0.92\n",
            "train loss 0.3579789996147156 accuracy 0.98 | test loss 0.3786947429180145  accuracy 0.92\n",
            "train loss 0.35797789692878723 accuracy 0.98 | test loss 0.378679484128952  accuracy 0.92\n",
            "train loss 0.3579781949520111 accuracy 0.99 | test loss 0.3787267208099365  accuracy 0.92\n",
            "train loss 0.35797828435897827 accuracy 0.98 | test loss 0.3786875009536743  accuracy 0.92\n",
            "train loss 0.3579773008823395 accuracy 0.98 | test loss 0.37872007489204407  accuracy 0.92\n",
            "train loss 0.3579777479171753 accuracy 0.98 | test loss 0.378680944442749  accuracy 0.92\n",
            "train loss 0.3579771816730499 accuracy 0.99 | test loss 0.3787282109260559  accuracy 0.92\n",
            "train loss 0.3579777479171753 accuracy 0.98 | test loss 0.3786889612674713  accuracy 0.92\n",
            "train loss 0.3579768240451813 accuracy 0.98 | test loss 0.37867358326911926  accuracy 0.92\n",
            "train loss 0.3579770624637604 accuracy 0.99 | test loss 0.37874773144721985  accuracy 0.92\n",
            "train loss 0.3579779863357544 accuracy 0.98 | test loss 0.37868738174438477  accuracy 0.92\n",
            "train loss 0.35797613859176636 accuracy 0.98 | test loss 0.37870681285858154  accuracy 0.92\n",
            "train loss 0.3579762279987335 accuracy 0.98 | test loss 0.3786677420139313  accuracy 0.92\n",
            "train loss 0.3579767048358917 accuracy 0.99 | test loss 0.3787270188331604  accuracy 0.92\n",
            "train loss 0.3579765856266022 accuracy 0.98 | test loss 0.3786877989768982  accuracy 0.92\n",
            "train loss 0.35797545313835144 accuracy 0.98 | test loss 0.37867245078086853  accuracy 0.92\n",
            "train loss 0.3579760193824768 accuracy 0.99 | test loss 0.37874647974967957  accuracy 0.92\n",
            "train loss 0.3579767942428589 accuracy 0.98 | test loss 0.37870705127716064  accuracy 0.92\n",
            "train loss 0.3579753041267395 accuracy 0.98 | test loss 0.378667950630188  accuracy 0.92\n",
            "train loss 0.357975572347641 accuracy 0.99 | test loss 0.3787422180175781  accuracy 0.92\n",
            "train loss 0.3579762279987335 accuracy 0.98 | test loss 0.37870270013809204  accuracy 0.92\n",
            "train loss 0.3579748570919037 accuracy 0.98 | test loss 0.3786870539188385  accuracy 0.92\n",
            "train loss 0.35797426104545593 accuracy 0.98 | test loss 0.3787064254283905  accuracy 0.92\n",
            "train loss 0.35797449946403503 accuracy 0.98 | test loss 0.37866729497909546  accuracy 0.92\n",
            "train loss 0.3579747676849365 accuracy 0.99 | test loss 0.3787265419960022  accuracy 0.92\n",
            "train loss 0.3579748868942261 accuracy 0.98 | test loss 0.3786872327327728  accuracy 0.92\n",
            "train loss 0.3579736351966858 accuracy 0.98 | test loss 0.37867170572280884  accuracy 0.92\n",
            "train loss 0.3579740822315216 accuracy 0.99 | test loss 0.37874576449394226  accuracy 0.92\n",
            "train loss 0.357975035905838 accuracy 0.98 | test loss 0.3787062466144562  accuracy 0.92\n",
            "train loss 0.35797354578971863 accuracy 0.98 | test loss 0.37866708636283875  accuracy 0.92\n",
            "train loss 0.3579736351966858 accuracy 0.99 | test loss 0.37874120473861694  accuracy 0.92\n",
            "train loss 0.35797446966171265 accuracy 0.98 | test loss 0.378701776266098  accuracy 0.92\n",
            "train loss 0.35797300934791565 accuracy 0.98 | test loss 0.3786860704421997  accuracy 0.92\n",
            "train loss 0.3579724431037903 accuracy 0.98 | test loss 0.3787054419517517  accuracy 0.92\n",
            "train loss 0.35797274112701416 accuracy 0.98 | test loss 0.3786662518978119  accuracy 0.92\n",
            "train loss 0.3579728603363037 accuracy 0.99 | test loss 0.378725528717041  accuracy 0.92\n",
            "train loss 0.3579731285572052 accuracy 0.98 | test loss 0.3786861300468445  accuracy 0.92\n",
            "train loss 0.35797178745269775 accuracy 0.98 | test loss 0.3786706030368805  accuracy 0.92\n",
            "train loss 0.35797226428985596 accuracy 0.99 | test loss 0.378717839717865  accuracy 0.92\n",
            "train loss 0.3579724133014679 accuracy 0.98 | test loss 0.37867847084999084  accuracy 0.92\n",
            "train loss 0.35797134041786194 accuracy 0.98 | test loss 0.37871092557907104  accuracy 0.92\n",
            "train loss 0.3579718768596649 accuracy 0.98 | test loss 0.37867167592048645  accuracy 0.92\n",
            "train loss 0.35797119140625 accuracy 0.99 | test loss 0.37871885299682617  accuracy 0.92\n",
            "train loss 0.3579718768596649 accuracy 0.98 | test loss 0.37867945432662964  accuracy 0.92\n",
            "train loss 0.3579707145690918 accuracy 0.98 | test loss 0.3786916732788086  accuracy 0.92\n",
            "train loss 0.35797062516212463 accuracy 0.98 | test loss 0.37865251302719116  accuracy 0.92\n",
            "train loss 0.3579716384410858 accuracy 0.99 | test loss 0.37872663140296936  accuracy 0.92\n",
            "train loss 0.3579714894294739 accuracy 0.98 | test loss 0.37868720293045044  accuracy 0.92\n",
            "train loss 0.3579701781272888 accuracy 0.98 | test loss 0.3786715567111969  accuracy 0.92\n",
            "train loss 0.3579700291156769 accuracy 0.99 | test loss 0.37871870398521423  accuracy 0.92\n",
            "train loss 0.35797080397605896 accuracy 0.98 | test loss 0.3786793053150177  accuracy 0.92\n",
            "train loss 0.3579694628715515 accuracy 0.98 | test loss 0.37866365909576416  accuracy 0.92\n",
            "train loss 0.3579700291156769 accuracy 0.99 | test loss 0.3787376582622528  accuracy 0.92\n",
            "train loss 0.3579709529876709 accuracy 0.98 | test loss 0.37867704033851624  accuracy 0.92\n",
            "train loss 0.35796913504600525 accuracy 0.98 | test loss 0.37870073318481445  accuracy 0.92\n",
            "train loss 0.35796940326690674 accuracy 0.98 | test loss 0.37866154313087463  accuracy 0.92\n",
            "train loss 0.35796916484832764 accuracy 0.99 | test loss 0.378720760345459  accuracy 0.92\n",
            "train loss 0.35796982049942017 accuracy 0.98 | test loss 0.37868133187294006  accuracy 0.92\n",
            "train loss 0.35796865820884705 accuracy 0.98 | test loss 0.3786656856536865  accuracy 0.92\n",
            "train loss 0.35796844959259033 accuracy 0.99 | test loss 0.378712922334671  accuracy 0.92\n",
            "train loss 0.3579690456390381 accuracy 0.98 | test loss 0.3786734640598297  accuracy 0.92\n",
            "train loss 0.35796794295310974 accuracy 0.98 | test loss 0.37865790724754333  accuracy 0.92\n",
            "train loss 0.35796844959259033 accuracy 0.99 | test loss 0.378731906414032  accuracy 0.92\n",
            "train loss 0.35796919465065 accuracy 0.98 | test loss 0.3786923885345459  accuracy 0.92\n",
            "train loss 0.3579677641391754 accuracy 0.98 | test loss 0.3786531686782837  accuracy 0.92\n",
            "train loss 0.35796797275543213 accuracy 0.99 | test loss 0.37872716784477234  accuracy 0.92\n",
            "train loss 0.35796865820884705 accuracy 0.98 | test loss 0.3786666691303253  accuracy 0.92\n",
            "train loss 0.35796698927879333 accuracy 0.99 | test loss 0.37871378660202026  accuracy 0.92\n",
            "train loss 0.3579678237438202 accuracy 0.98 | test loss 0.37867429852485657  accuracy 0.92\n",
            "train loss 0.35796675086021423 accuracy 0.98 | test loss 0.3786586821079254  accuracy 0.92\n",
            "train loss 0.3579668402671814 accuracy 0.99 | test loss 0.3787326216697693  accuracy 0.92\n",
            "train loss 0.35796797275543213 accuracy 0.98 | test loss 0.3786720335483551  accuracy 0.92\n",
            "train loss 0.35796600580215454 accuracy 0.98 | test loss 0.37869131565093994  accuracy 0.92\n",
            "train loss 0.35796621441841125 accuracy 0.98 | test loss 0.37865206599235535  accuracy 0.92\n",
            "train loss 0.3579666018486023 accuracy 0.99 | test loss 0.3787112832069397  accuracy 0.92\n",
            "train loss 0.3579666316509247 accuracy 0.98 | test loss 0.378671795129776  accuracy 0.92\n",
            "train loss 0.3579653799533844 accuracy 0.98 | test loss 0.37865614891052246  accuracy 0.92\n",
            "train loss 0.3579659163951874 accuracy 0.99 | test loss 0.3787301182746887  accuracy 0.92\n",
            "train loss 0.357966810464859 accuracy 0.98 | test loss 0.37869060039520264  accuracy 0.92\n",
            "train loss 0.3579653203487396 accuracy 0.98 | test loss 0.37865135073661804  accuracy 0.92\n",
            "train loss 0.35796546936035156 accuracy 0.99 | test loss 0.3787253499031067  accuracy 0.92\n",
            "train loss 0.35796618461608887 accuracy 0.98 | test loss 0.37868574261665344  accuracy 0.92\n",
            "train loss 0.35796478390693665 accuracy 0.98 | test loss 0.37866994738578796  accuracy 0.92\n",
            "train loss 0.3579641580581665 accuracy 0.98 | test loss 0.3786892592906952  accuracy 0.92\n",
            "train loss 0.3579644560813904 accuracy 0.98 | test loss 0.37864989042282104  accuracy 0.92\n",
            "train loss 0.35796478390693665 accuracy 0.99 | test loss 0.3787090480327606  accuracy 0.92\n",
            "train loss 0.3579648435115814 accuracy 0.98 | test loss 0.3786695897579193  accuracy 0.92\n",
            "train loss 0.35796356201171875 accuracy 0.98 | test loss 0.3786538541316986  accuracy 0.92\n",
            "train loss 0.35796409845352173 accuracy 0.99 | test loss 0.37872785329818726  accuracy 0.92\n",
            "train loss 0.35796499252319336 accuracy 0.98 | test loss 0.37868815660476685  accuracy 0.92\n",
            "train loss 0.35796356201171875 accuracy 0.98 | test loss 0.37864890694618225  accuracy 0.92\n",
            "train loss 0.3579636216163635 accuracy 0.99 | test loss 0.3787229061126709  accuracy 0.92\n",
            "train loss 0.3579643964767456 accuracy 0.98 | test loss 0.3786833584308624  accuracy 0.92\n",
            "train loss 0.3579629063606262 accuracy 0.98 | test loss 0.3786441385746002  accuracy 0.92\n",
            "train loss 0.3579631745815277 accuracy 0.99 | test loss 0.37871813774108887  accuracy 0.92\n",
            "train loss 0.35796377062797546 accuracy 0.98 | test loss 0.3786786198616028  accuracy 0.92\n",
            "train loss 0.35796260833740234 accuracy 0.98 | test loss 0.37866273522377014  accuracy 0.92\n",
            "train loss 0.3579619228839874 accuracy 0.98 | test loss 0.3786672055721283  accuracy 0.92\n",
            "train loss 0.3579616844654083 accuracy 0.98 | test loss 0.37865149974823  accuracy 0.92\n",
            "train loss 0.3579622507095337 accuracy 0.99 | test loss 0.3786984980106354  accuracy 0.92\n",
            "train loss 0.35796234011650085 accuracy 0.98 | test loss 0.37865903973579407  accuracy 0.92\n",
            "train loss 0.3579613268375397 accuracy 0.98 | test loss 0.3786911964416504  accuracy 0.92\n",
            "train loss 0.3579618036746979 accuracy 0.98 | test loss 0.3786517381668091  accuracy 0.92\n",
            "train loss 0.3579612970352173 accuracy 0.99 | test loss 0.37872573733329773  accuracy 0.92\n",
            "train loss 0.3579627275466919 accuracy 0.98 | test loss 0.378665030002594  accuracy 0.92\n",
            "train loss 0.35796061158180237 accuracy 0.98 | test loss 0.37866079807281494  accuracy 0.92\n",
            "train loss 0.35796064138412476 accuracy 0.98 | test loss 0.3786727786064148  accuracy 0.92\n",
            "train loss 0.35796043276786804 accuracy 0.98 | test loss 0.3786569833755493  accuracy 0.92\n",
            "train loss 0.3579602837562561 accuracy 0.98 | test loss 0.3786805272102356  accuracy 0.92\n",
            "train loss 0.35796043276786804 accuracy 0.98 | test loss 0.37866461277008057  accuracy 0.92\n",
            "train loss 0.3579597473144531 accuracy 0.98 | test loss 0.37867647409439087  accuracy 0.92\n",
            "train loss 0.35795989632606506 accuracy 0.98 | test loss 0.3786371648311615  accuracy 0.92\n",
            "train loss 0.35796070098876953 accuracy 0.99 | test loss 0.37871116399765015  accuracy 0.92\n",
            "train loss 0.3579607605934143 accuracy 0.98 | test loss 0.3786715269088745  accuracy 0.92\n",
            "train loss 0.35795924067497253 accuracy 0.98 | test loss 0.3786323368549347  accuracy 0.92\n",
            "train loss 0.3579602837562561 accuracy 0.99 | test loss 0.3787063658237457  accuracy 0.92\n",
            "train loss 0.35796016454696655 accuracy 0.98 | test loss 0.3786667585372925  accuracy 0.92\n",
            "train loss 0.3579588532447815 accuracy 0.98 | test loss 0.3786509931087494  accuracy 0.92\n",
            "train loss 0.35795867443084717 accuracy 0.99 | test loss 0.37869793176651  accuracy 0.92\n",
            "train loss 0.3579593896865845 accuracy 0.98 | test loss 0.3786584436893463  accuracy 0.92\n",
            "train loss 0.3579581379890442 accuracy 0.98 | test loss 0.378670334815979  accuracy 0.92\n",
            "train loss 0.3579581379890442 accuracy 0.98 | test loss 0.3786310851573944  accuracy 0.92\n",
            "train loss 0.35795918107032776 accuracy 0.99 | test loss 0.37870508432388306  accuracy 0.92\n",
            "train loss 0.3579590618610382 accuracy 0.98 | test loss 0.3786655068397522  accuracy 0.92\n",
            "train loss 0.3579576015472412 accuracy 0.98 | test loss 0.3786497116088867  accuracy 0.92\n",
            "train loss 0.3579576015472412 accuracy 0.99 | test loss 0.37869662046432495  accuracy 0.92\n",
            "train loss 0.35795825719833374 accuracy 0.98 | test loss 0.37865710258483887  accuracy 0.92\n",
            "train loss 0.3579569160938263 accuracy 0.98 | test loss 0.37866896390914917  accuracy 0.92\n",
            "train loss 0.35795700550079346 accuracy 0.98 | test loss 0.3786298334598541  accuracy 0.92\n",
            "train loss 0.35795801877975464 accuracy 0.99 | test loss 0.3787038028240204  accuracy 0.92\n",
            "train loss 0.3579578995704651 accuracy 0.98 | test loss 0.3786640763282776  accuracy 0.92\n",
            "train loss 0.3579563796520233 accuracy 0.98 | test loss 0.37862494587898254  accuracy 0.92\n",
            "train loss 0.3579576015472412 accuracy 0.99 | test loss 0.3786989152431488  accuracy 0.92\n",
            "train loss 0.35795730352401733 accuracy 0.98 | test loss 0.37865936756134033  accuracy 0.92\n",
            "train loss 0.35795608162879944 accuracy 0.98 | test loss 0.37864357233047485  accuracy 0.92\n",
            "train loss 0.3579559922218323 accuracy 0.99 | test loss 0.3786904811859131  accuracy 0.92\n",
            "train loss 0.35795649886131287 accuracy 0.98 | test loss 0.378650963306427  accuracy 0.92\n",
            "train loss 0.35795530676841736 accuracy 0.98 | test loss 0.3786351978778839  accuracy 0.92\n",
            "train loss 0.35795605182647705 accuracy 0.99 | test loss 0.37870916724205017  accuracy 0.92\n",
            "train loss 0.3579566776752472 accuracy 0.98 | test loss 0.3786693513393402  accuracy 0.92\n",
            "train loss 0.3579551577568054 accuracy 0.98 | test loss 0.3786298930644989  accuracy 0.92\n",
            "train loss 0.35795560479164124 accuracy 0.99 | test loss 0.37870392203330994  accuracy 0.92\n",
            "train loss 0.35795608162879944 accuracy 0.98 | test loss 0.3786640763282776  accuracy 0.92\n",
            "train loss 0.3579547107219696 accuracy 0.98 | test loss 0.37864813208580017  accuracy 0.92\n",
            "train loss 0.3579542934894562 accuracy 0.98 | test loss 0.37868034839630127  accuracy 0.92\n",
            "train loss 0.3579547703266144 accuracy 0.98 | test loss 0.3786408007144928  accuracy 0.92\n",
            "train loss 0.35795408487319946 accuracy 0.99 | test loss 0.3786877393722534  accuracy 0.92\n",
            "train loss 0.357954740524292 accuracy 0.98 | test loss 0.37864822149276733  accuracy 0.92\n",
            "train loss 0.35795360803604126 accuracy 0.98 | test loss 0.37863245606422424  accuracy 0.92\n",
            "train loss 0.3579541742801666 accuracy 0.99 | test loss 0.3787063658237457  accuracy 0.92\n",
            "train loss 0.35795485973358154 accuracy 0.98 | test loss 0.3786665201187134  accuracy 0.92\n",
            "train loss 0.35795339941978455 accuracy 0.98 | test loss 0.37862712144851685  accuracy 0.92\n",
            "train loss 0.3579537570476532 accuracy 0.99 | test loss 0.3787010908126831  accuracy 0.92\n",
            "train loss 0.35795432329177856 accuracy 0.98 | test loss 0.378640353679657  accuracy 0.92\n",
            "train loss 0.35795271396636963 accuracy 0.98 | test loss 0.3786724805831909  accuracy 0.92\n",
            "train loss 0.3579529821872711 accuracy 0.98 | test loss 0.37863296270370483  accuracy 0.92\n",
            "train loss 0.3579525947570801 accuracy 0.99 | test loss 0.37867990136146545  accuracy 0.92\n",
            "train loss 0.35795295238494873 accuracy 0.98 | test loss 0.37864044308662415  accuracy 0.92\n",
            "train loss 0.35795196890830994 accuracy 0.98 | test loss 0.37862467765808105  accuracy 0.92\n",
            "train loss 0.35795271396636963 accuracy 0.99 | test loss 0.37869855761528015  accuracy 0.92\n",
            "train loss 0.35795310139656067 accuracy 0.98 | test loss 0.37865883111953735  accuracy 0.92\n",
            "train loss 0.35795164108276367 accuracy 0.98 | test loss 0.3786427080631256  accuracy 0.92\n",
            "train loss 0.35795122385025024 accuracy 0.99 | test loss 0.3786896765232086  accuracy 0.92\n",
            "train loss 0.3579523265361786 accuracy 0.98 | test loss 0.37864992022514343  accuracy 0.92\n",
            "train loss 0.35795092582702637 accuracy 0.98 | test loss 0.37863394618034363  accuracy 0.92\n",
            "train loss 0.35795122385025024 accuracy 0.99 | test loss 0.37870773673057556  accuracy 0.92\n",
            "train loss 0.35795244574546814 accuracy 0.98 | test loss 0.37866783142089844  accuracy 0.92\n",
            "train loss 0.35795095562934875 accuracy 0.98 | test loss 0.37862831354141235  accuracy 0.92\n",
            "train loss 0.3579508364200592 accuracy 0.99 | test loss 0.37868744134902954  accuracy 0.92\n",
            "train loss 0.3579513430595398 accuracy 0.98 | test loss 0.37864774465560913  accuracy 0.92\n",
            "train loss 0.3579499423503876 accuracy 0.98 | test loss 0.37864670157432556  accuracy 0.92\n",
            "train loss 0.35794970393180847 accuracy 0.98 | test loss 0.37862738966941833  accuracy 0.92\n",
            "train loss 0.3579501509666443 accuracy 0.99 | test loss 0.3786863684654236  accuracy 0.92\n",
            "train loss 0.35795074701309204 accuracy 0.98 | test loss 0.37864670157432556  accuracy 0.92\n",
            "train loss 0.3579493761062622 accuracy 0.98 | test loss 0.37863075733184814  accuracy 0.92\n",
            "train loss 0.35794952511787415 accuracy 0.99 | test loss 0.37867769598960876  accuracy 0.92\n",
            "train loss 0.3579499423503876 accuracy 0.98 | test loss 0.37863805890083313  accuracy 0.92\n",
            "train loss 0.3579486906528473 accuracy 0.98 | test loss 0.3786422908306122  accuracy 0.92\n",
            "train loss 0.3579484522342682 accuracy 0.98 | test loss 0.37862634658813477  accuracy 0.92\n",
            "train loss 0.35794925689697266 accuracy 0.99 | test loss 0.3787001073360443  accuracy 0.92\n",
            "train loss 0.3579500615596771 accuracy 0.98 | test loss 0.3786602020263672  accuracy 0.92\n",
            "train loss 0.35794851183891296 accuracy 0.98 | test loss 0.3786206841468811  accuracy 0.92\n",
            "train loss 0.35794883966445923 accuracy 0.99 | test loss 0.3786945343017578  accuracy 0.92\n",
            "train loss 0.357949435710907 accuracy 0.98 | test loss 0.3786546587944031  accuracy 0.92\n",
            "train loss 0.3579479157924652 accuracy 0.98 | test loss 0.378615140914917  accuracy 0.92\n",
            "train loss 0.3579484522342682 accuracy 0.99 | test loss 0.37868908047676086  accuracy 0.92\n",
            "train loss 0.35794883966445923 accuracy 0.98 | test loss 0.37862831354141235  accuracy 0.92\n",
            "train loss 0.35794734954833984 accuracy 0.99 | test loss 0.3786752223968506  accuracy 0.92\n",
            "train loss 0.35794803500175476 accuracy 0.98 | test loss 0.37863555550575256  accuracy 0.92\n",
            "train loss 0.3579469323158264 accuracy 0.98 | test loss 0.37861961126327515  accuracy 0.92\n",
            "train loss 0.35794737935066223 accuracy 0.99 | test loss 0.37869346141815186  accuracy 0.92\n",
            "train loss 0.3579481542110443 accuracy 0.98 | test loss 0.37865352630615234  accuracy 0.92\n",
            "train loss 0.3579466640949249 accuracy 0.98 | test loss 0.37861403822898865  accuracy 0.92\n",
            "train loss 0.3579469919204712 accuracy 0.99 | test loss 0.3786877691745758  accuracy 0.92\n",
            "train loss 0.35794752836227417 accuracy 0.98 | test loss 0.37862685322761536  accuracy 0.92\n",
            "train loss 0.35794591903686523 accuracy 0.99 | test loss 0.37867361307144165  accuracy 0.92\n",
            "train loss 0.3579467833042145 accuracy 0.98 | test loss 0.3786338269710541  accuracy 0.92\n",
            "train loss 0.3579457104206085 accuracy 0.98 | test loss 0.3786178529262543  accuracy 0.92\n",
            "train loss 0.35794597864151 accuracy 0.99 | test loss 0.3786916136741638  accuracy 0.92\n",
            "train loss 0.35794684290885925 accuracy 0.98 | test loss 0.37865179777145386  accuracy 0.92\n",
            "train loss 0.35794538259506226 accuracy 0.98 | test loss 0.3786356747150421  accuracy 0.92\n",
            "train loss 0.3579447865486145 accuracy 0.98 | test loss 0.378639817237854  accuracy 0.92\n",
            "train loss 0.35794463753700256 accuracy 0.98 | test loss 0.378620445728302  accuracy 0.92\n",
            "train loss 0.35794487595558167 accuracy 0.99 | test loss 0.37867942452430725  accuracy 0.92\n",
            "train loss 0.3579457402229309 accuracy 0.98 | test loss 0.3786395490169525  accuracy 0.92\n",
            "train loss 0.3579442501068115 accuracy 0.98 | test loss 0.37863829731941223  accuracy 0.92\n",
            "train loss 0.35794395208358765 accuracy 0.98 | test loss 0.37859877943992615  accuracy 0.92\n",
            "train loss 0.35794559121131897 accuracy 0.99 | test loss 0.3786727786064148  accuracy 0.92\n",
            "train loss 0.35794487595558167 accuracy 0.98 | test loss 0.37863296270370483  accuracy 0.92\n",
            "train loss 0.357943594455719 accuracy 0.98 | test loss 0.37861692905426025  accuracy 0.92\n",
            "train loss 0.35794398188591003 accuracy 0.99 | test loss 0.37869060039520264  accuracy 0.92\n",
            "train loss 0.3579450249671936 accuracy 0.98 | test loss 0.3786506652832031  accuracy 0.92\n",
            "train loss 0.35794347524642944 accuracy 0.98 | test loss 0.37861114740371704  accuracy 0.92\n",
            "train loss 0.3579435646533966 accuracy 0.99 | test loss 0.3786849081516266  accuracy 0.92\n",
            "train loss 0.3579443395137787 accuracy 0.98 | test loss 0.37862396240234375  accuracy 0.92\n",
            "train loss 0.3579425811767578 accuracy 0.99 | test loss 0.3786706030368805  accuracy 0.92\n",
            "train loss 0.3579435646533966 accuracy 0.98 | test loss 0.37863075733184814  accuracy 0.92\n",
            "train loss 0.3579423725605011 accuracy 0.98 | test loss 0.37861472368240356  accuracy 0.92\n",
            "train loss 0.3579425811767578 accuracy 0.99 | test loss 0.3786884546279907  accuracy 0.92\n",
            "train loss 0.35794365406036377 accuracy 0.98 | test loss 0.3786485195159912  accuracy 0.92\n",
            "train loss 0.3579421639442444 accuracy 0.98 | test loss 0.37860891222953796  accuracy 0.92\n",
            "train loss 0.35794225335121155 accuracy 0.99 | test loss 0.3786678612232208  accuracy 0.92\n",
            "train loss 0.35794252157211304 accuracy 0.98 | test loss 0.3786279857158661  accuracy 0.92\n",
            "train loss 0.35794129967689514 accuracy 0.98 | test loss 0.3786267340183258  accuracy 0.92\n",
            "train loss 0.35794106125831604 accuracy 0.98 | test loss 0.37865859270095825  accuracy 0.92\n",
            "train loss 0.35794174671173096 accuracy 0.98 | test loss 0.37861883640289307  accuracy 0.92\n",
            "train loss 0.35794082283973694 accuracy 0.99 | test loss 0.3786656856536865  accuracy 0.92\n",
            "train loss 0.3579416871070862 accuracy 0.98 | test loss 0.37862586975097656  accuracy 0.92\n",
            "train loss 0.35794055461883545 accuracy 0.98 | test loss 0.3786098062992096  accuracy 0.92\n",
            "train loss 0.3579408824443817 accuracy 0.99 | test loss 0.37868350744247437  accuracy 0.92\n",
            "train loss 0.3579418361186981 accuracy 0.98 | test loss 0.3786434829235077  accuracy 0.92\n",
            "train loss 0.35794028639793396 accuracy 0.98 | test loss 0.3786039650440216  accuracy 0.92\n",
            "train loss 0.35794052481651306 accuracy 0.99 | test loss 0.3786628544330597  accuracy 0.92\n",
            "train loss 0.357940673828125 accuracy 0.98 | test loss 0.37862303853034973  accuracy 0.92\n",
            "train loss 0.3579395115375519 accuracy 0.98 | test loss 0.3786218464374542  accuracy 0.92\n",
            "train loss 0.357939213514328 accuracy 0.98 | test loss 0.37865370512008667  accuracy 0.92\n",
            "train loss 0.3579398989677429 accuracy 0.98 | test loss 0.3786139488220215  accuracy 0.92\n",
            "train loss 0.35793906450271606 accuracy 0.99 | test loss 0.37866073846817017  accuracy 0.92\n",
            "train loss 0.35793983936309814 accuracy 0.98 | test loss 0.3786208927631378  accuracy 0.92\n",
            "train loss 0.3579387664794922 accuracy 0.98 | test loss 0.37860482931137085  accuracy 0.92\n",
            "train loss 0.3579391539096832 accuracy 0.99 | test loss 0.37867850065231323  accuracy 0.92\n",
            "train loss 0.3579399883747101 accuracy 0.98 | test loss 0.37863853573799133  accuracy 0.92\n",
            "train loss 0.3579384386539459 accuracy 0.98 | test loss 0.3785989284515381  accuracy 0.92\n",
            "train loss 0.3579387962818146 accuracy 0.99 | test loss 0.37867265939712524  accuracy 0.92\n",
            "train loss 0.35793936252593994 accuracy 0.98 | test loss 0.37861159443855286  accuracy 0.92\n",
            "train loss 0.357937753200531 accuracy 0.98 | test loss 0.37864360213279724  accuracy 0.92\n",
            "train loss 0.3579379916191101 accuracy 0.98 | test loss 0.37860387563705444  accuracy 0.92\n",
            "train loss 0.35793769359588623 accuracy 0.99 | test loss 0.3786775767803192  accuracy 0.92\n",
            "train loss 0.35793888568878174 accuracy 0.98 | test loss 0.3786376416683197  accuracy 0.92\n",
            "train loss 0.3579375445842743 accuracy 0.98 | test loss 0.37862148880958557  accuracy 0.92\n",
            "train loss 0.3579367995262146 accuracy 0.98 | test loss 0.37862029671669006  accuracy 0.92\n",
            "train loss 0.3579365313053131 accuracy 0.98 | test loss 0.3786521553993225  accuracy 0.92\n",
            "train loss 0.3579373359680176 accuracy 0.98 | test loss 0.3786122798919678  accuracy 0.92\n",
            "train loss 0.35793638229370117 accuracy 0.99 | test loss 0.3786589205265045  accuracy 0.92\n",
            "train loss 0.3579373061656952 accuracy 0.98 | test loss 0.37861907482147217  accuracy 0.92\n",
            "train loss 0.3579360544681549 accuracy 0.98 | test loss 0.3786029815673828  accuracy 0.92\n",
            "train loss 0.35793647170066833 accuracy 0.99 | test loss 0.3786766231060028  accuracy 0.92\n",
            "train loss 0.35793742537498474 accuracy 0.98 | test loss 0.3786364197731018  accuracy 0.92\n",
            "train loss 0.35793590545654297 accuracy 0.98 | test loss 0.37859678268432617  accuracy 0.92\n",
            "train loss 0.3579360842704773 accuracy 0.99 | test loss 0.37867048382759094  accuracy 0.92\n",
            "train loss 0.3579367697238922 accuracy 0.98 | test loss 0.3786303997039795  accuracy 0.92\n",
            "train loss 0.3579353988170624 accuracy 0.98 | test loss 0.3786141872406006  accuracy 0.92\n",
            "train loss 0.3579348027706146 accuracy 0.98 | test loss 0.37864604592323303  accuracy 0.92\n",
            "train loss 0.35793542861938477 accuracy 0.98 | test loss 0.3786061704158783  accuracy 0.92\n",
            "train loss 0.3579346239566803 accuracy 0.99 | test loss 0.37865278124809265  accuracy 0.92\n",
            "train loss 0.3579353988170624 accuracy 0.98 | test loss 0.3786129653453827  accuracy 0.92\n",
            "train loss 0.35793426632881165 accuracy 0.98 | test loss 0.37859684228897095  accuracy 0.92\n",
            "train loss 0.3579348027706146 accuracy 0.99 | test loss 0.3786705434322357  accuracy 0.92\n",
            "train loss 0.3579355478286743 accuracy 0.98 | test loss 0.3786303699016571  accuracy 0.92\n",
            "train loss 0.35793402791023254 accuracy 0.98 | test loss 0.3785907030105591  accuracy 0.92\n",
            "train loss 0.35793444514274597 accuracy 0.99 | test loss 0.37866440415382385  accuracy 0.92\n",
            "train loss 0.3579348623752594 accuracy 0.98 | test loss 0.3786243498325348  accuracy 0.92\n",
            "train loss 0.35793358087539673 accuracy 0.98 | test loss 0.3786080777645111  accuracy 0.92\n",
            "train loss 0.35793304443359375 accuracy 0.98 | test loss 0.37863990664482117  accuracy 0.92\n",
            "train loss 0.35793358087539673 accuracy 0.98 | test loss 0.3786000609397888  accuracy 0.92\n",
            "train loss 0.357932984828949 accuracy 0.99 | test loss 0.3786737620830536  accuracy 0.92\n",
            "train loss 0.35793453454971313 accuracy 0.98 | test loss 0.3786126375198364  accuracy 0.92\n",
            "train loss 0.35793235898017883 accuracy 0.98 | test loss 0.3786315321922302  accuracy 0.92\n",
            "train loss 0.3579326868057251 accuracy 0.98 | test loss 0.37859174609184265  accuracy 0.92\n",
            "train loss 0.35793280601501465 accuracy 0.99 | test loss 0.3786505162715912  accuracy 0.92\n",
            "train loss 0.35793304443359375 accuracy 0.98 | test loss 0.37861061096191406  accuracy 0.92\n",
            "train loss 0.3579317331314087 accuracy 0.98 | test loss 0.37860918045043945  accuracy 0.92\n",
            "train loss 0.3579314649105072 accuracy 0.98 | test loss 0.37864091992378235  accuracy 0.92\n",
            "train loss 0.3579322397708893 accuracy 0.98 | test loss 0.3786010146141052  accuracy 0.92\n",
            "train loss 0.3579312860965729 accuracy 0.99 | test loss 0.3786746859550476  accuracy 0.92\n",
            "train loss 0.3579331934452057 accuracy 0.98 | test loss 0.3786133825778961  accuracy 0.92\n",
            "train loss 0.3579308092594147 accuracy 0.98 | test loss 0.37858846783638  accuracy 0.92\n",
            "train loss 0.35793158411979675 accuracy 0.99 | test loss 0.37864723801612854  accuracy 0.92\n",
            "train loss 0.3579317033290863 accuracy 0.98 | test loss 0.3786073625087738  accuracy 0.92\n",
            "train loss 0.357930451631546 accuracy 0.98 | test loss 0.3785912096500397  accuracy 0.92\n",
            "train loss 0.357930988073349 accuracy 0.99 | test loss 0.37866485118865967  accuracy 0.92\n",
            "train loss 0.35793182253837585 accuracy 0.98 | test loss 0.37862467765808105  accuracy 0.92\n",
            "train loss 0.3579303026199341 accuracy 0.98 | test loss 0.3785848617553711  accuracy 0.92\n",
            "train loss 0.35793060064315796 accuracy 0.99 | test loss 0.37865856289863586  accuracy 0.92\n",
            "train loss 0.35793113708496094 accuracy 0.98 | test loss 0.378618448972702  accuracy 0.92\n",
            "train loss 0.3579297959804535 accuracy 0.98 | test loss 0.37860220670700073  accuracy 0.92\n",
            "train loss 0.35792937874794006 accuracy 0.98 | test loss 0.3786211311817169  accuracy 0.92\n",
            "train loss 0.35792937874794006 accuracy 0.98 | test loss 0.37858131527900696  accuracy 0.92\n",
            "train loss 0.3579299747943878 accuracy 0.99 | test loss 0.3786548674106598  accuracy 0.92\n",
            "train loss 0.3579302430152893 accuracy 0.98 | test loss 0.3786146342754364  accuracy 0.92\n",
            "train loss 0.35792890191078186 accuracy 0.98 | test loss 0.3785983920097351  accuracy 0.92\n",
            "train loss 0.357928603887558 accuracy 0.98 | test loss 0.378630131483078  accuracy 0.92\n",
            "train loss 0.35792890191078186 accuracy 0.98 | test loss 0.3785902261734009  accuracy 0.92\n",
            "train loss 0.3579285442829132 accuracy 0.99 | test loss 0.37866389751434326  accuracy 0.92\n",
            "train loss 0.3579297661781311 accuracy 0.98 | test loss 0.37862372398376465  accuracy 0.92\n",
            "train loss 0.3579282760620117 accuracy 0.98 | test loss 0.3785839080810547  accuracy 0.92\n",
            "train loss 0.35792818665504456 accuracy 0.99 | test loss 0.3786575198173523  accuracy 0.92\n",
            "train loss 0.35792914032936096 accuracy 0.98 | test loss 0.3786173164844513  accuracy 0.92\n",
            "train loss 0.3579278588294983 accuracy 0.98 | test loss 0.37860098481178284  accuracy 0.92\n",
            "train loss 0.3579270839691162 accuracy 0.98 | test loss 0.3786048889160156  accuracy 0.92\n",
            "train loss 0.3579268455505371 accuracy 0.98 | test loss 0.37858861684799194  accuracy 0.92\n",
            "train loss 0.35792747139930725 accuracy 0.99 | test loss 0.3786621689796448  accuracy 0.92\n",
            "train loss 0.35792845487594604 accuracy 0.98 | test loss 0.3786219358444214  accuracy 0.92\n",
            "train loss 0.3579269349575043 accuracy 0.98 | test loss 0.37858206033706665  accuracy 0.92\n",
            "train loss 0.3579271137714386 accuracy 0.99 | test loss 0.3786557614803314  accuracy 0.92\n",
            "train loss 0.3579277992248535 accuracy 0.98 | test loss 0.37861552834510803  accuracy 0.92\n",
            "train loss 0.35792624950408936 accuracy 0.98 | test loss 0.37857571244239807  accuracy 0.92\n",
            "train loss 0.35792678594589233 accuracy 0.99 | test loss 0.37864938378334045  accuracy 0.92\n",
            "train loss 0.3579271733760834 accuracy 0.98 | test loss 0.37860918045043945  accuracy 0.92\n",
            "train loss 0.3579258620738983 accuracy 0.98 | test loss 0.3785927891731262  accuracy 0.92\n",
            "train loss 0.3579254150390625 accuracy 0.99 | test loss 0.3786394000053406  accuracy 0.92\n",
            "train loss 0.35792630910873413 accuracy 0.98 | test loss 0.3785993158817291  accuracy 0.92\n",
            "train loss 0.35792508721351624 accuracy 0.98 | test loss 0.3785831332206726  accuracy 0.92\n",
            "train loss 0.3579254448413849 accuracy 0.99 | test loss 0.37865668535232544  accuracy 0.92\n",
            "train loss 0.35792648792266846 accuracy 0.98 | test loss 0.3786163926124573  accuracy 0.92\n",
            "train loss 0.3579249382019043 accuracy 0.98 | test loss 0.3785765767097473  accuracy 0.92\n",
            "train loss 0.357925146818161 accuracy 0.99 | test loss 0.3786352574825287  accuracy 0.92\n",
            "train loss 0.35792526602745056 accuracy 0.98 | test loss 0.378595232963562  accuracy 0.92\n",
            "train loss 0.35792404413223267 accuracy 0.98 | test loss 0.3785938620567322  accuracy 0.92\n",
            "train loss 0.3579239249229431 accuracy 0.98 | test loss 0.3786254823207855  accuracy 0.92\n",
            "train loss 0.3579244613647461 accuracy 0.98 | test loss 0.37858548760414124  accuracy 0.92\n",
            "train loss 0.3579237163066864 accuracy 0.99 | test loss 0.378632128238678  accuracy 0.92\n",
            "train loss 0.3579244017601013 accuracy 0.98 | test loss 0.3785920739173889  accuracy 0.92\n",
            "train loss 0.3579232692718506 accuracy 0.98 | test loss 0.3786035478115082  accuracy 0.92\n",
            "train loss 0.35792312026023865 accuracy 0.98 | test loss 0.3785637617111206  accuracy 0.92\n",
            "train loss 0.35792434215545654 accuracy 0.99 | test loss 0.3786374628543854  accuracy 0.92\n",
            "train loss 0.3579239845275879 accuracy 0.98 | test loss 0.3785972595214844  accuracy 0.92\n",
            "train loss 0.3579227030277252 accuracy 0.98 | test loss 0.3785809874534607  accuracy 0.92\n",
            "train loss 0.35792282223701477 accuracy 0.99 | test loss 0.3786545395851135  accuracy 0.92\n",
            "train loss 0.35792410373687744 accuracy 0.98 | test loss 0.37861430644989014  accuracy 0.92\n",
            "train loss 0.3579225540161133 accuracy 0.98 | test loss 0.3785743713378906  accuracy 0.92\n",
            "train loss 0.3579224944114685 accuracy 0.99 | test loss 0.3786480128765106  accuracy 0.92\n",
            "train loss 0.3579234182834625 accuracy 0.98 | test loss 0.37860777974128723  accuracy 0.92\n",
            "train loss 0.3579220473766327 accuracy 0.98 | test loss 0.3785914182662964  accuracy 0.92\n",
            "train loss 0.3579213619232178 accuracy 0.98 | test loss 0.37859538197517395  accuracy 0.92\n",
            "train loss 0.35792112350463867 accuracy 0.98 | test loss 0.3785759210586548  accuracy 0.92\n",
            "train loss 0.3579213619232178 accuracy 0.99 | test loss 0.37864935398101807  accuracy 0.92\n",
            "train loss 0.35792288184165955 accuracy 0.98 | test loss 0.3785880208015442  accuracy 0.92\n",
            "train loss 0.35792076587677 accuracy 0.98 | test loss 0.37858644127845764  accuracy 0.92\n",
            "train loss 0.35792067646980286 accuracy 0.98 | test loss 0.3786180913448334  accuracy 0.92\n",
            "train loss 0.35792112350463867 accuracy 0.98 | test loss 0.37857818603515625  accuracy 0.92\n",
            "train loss 0.35792049765586853 accuracy 0.99 | test loss 0.37865155935287476  accuracy 0.92\n",
            "train loss 0.3579220473766327 accuracy 0.98 | test loss 0.3785901665687561  accuracy 0.92\n",
            "train loss 0.357919842004776 accuracy 0.98 | test loss 0.378608763217926  accuracy 0.92\n",
            "train loss 0.35792022943496704 accuracy 0.98 | test loss 0.3785688281059265  accuracy 0.92\n",
            "train loss 0.35792043805122375 accuracy 0.99 | test loss 0.3786275386810303  accuracy 0.92\n",
            "train loss 0.3579205870628357 accuracy 0.98 | test loss 0.3785873353481293  accuracy 0.92\n",
            "train loss 0.35791921615600586 accuracy 0.98 | test loss 0.378571093082428  accuracy 0.92\n",
            "train loss 0.3579198718070984 accuracy 0.99 | test loss 0.3786446154117584  accuracy 0.92\n",
            "train loss 0.35792067646980286 accuracy 0.98 | test loss 0.37860435247421265  accuracy 0.92\n",
            "train loss 0.3579191565513611 accuracy 0.98 | test loss 0.37856441736221313  accuracy 0.92\n",
            "train loss 0.3579195737838745 accuracy 0.99 | test loss 0.37863799929618835  accuracy 0.92\n",
            "train loss 0.35791999101638794 accuracy 0.98 | test loss 0.3785977065563202  accuracy 0.92\n",
            "train loss 0.35791853070259094 accuracy 0.98 | test loss 0.3785812556743622  accuracy 0.92\n",
            "train loss 0.35791826248168945 accuracy 0.99 | test loss 0.3786278963088989  accuracy 0.92\n",
            "train loss 0.3579191565513611 accuracy 0.98 | test loss 0.37858763337135315  accuracy 0.92\n",
            "train loss 0.35791778564453125 accuracy 0.98 | test loss 0.3785712718963623  accuracy 0.92\n",
            "train loss 0.35791823267936707 accuracy 0.99 | test loss 0.3786447048187256  accuracy 0.92\n",
            "train loss 0.357919305562973 accuracy 0.98 | test loss 0.37860438227653503  accuracy 0.92\n",
            "train loss 0.35791778564453125 accuracy 0.98 | test loss 0.3785645067691803  accuracy 0.92\n",
            "train loss 0.3579179346561432 accuracy 0.99 | test loss 0.37863799929618835  accuracy 0.92\n",
            "train loss 0.3579186201095581 accuracy 0.98 | test loss 0.3785977363586426  accuracy 0.92\n",
            "train loss 0.3579171299934387 accuracy 0.98 | test loss 0.37858131527900696  accuracy 0.92\n",
            "train loss 0.35791662335395813 accuracy 0.98 | test loss 0.37861305475234985  accuracy 0.92\n",
            "train loss 0.35791730880737305 accuracy 0.98 | test loss 0.3785730004310608  accuracy 0.92\n",
            "train loss 0.35791662335395813 accuracy 0.99 | test loss 0.37861958146095276  accuracy 0.92\n",
            "train loss 0.35791724920272827 accuracy 0.98 | test loss 0.37857934832572937  accuracy 0.92\n",
            "train loss 0.3579159379005432 accuracy 0.98 | test loss 0.37859079241752625  accuracy 0.92\n",
            "train loss 0.3579159379005432 accuracy 0.98 | test loss 0.3785657286643982  accuracy 0.92\n",
            "train loss 0.3579162657260895 accuracy 0.99 | test loss 0.37862440943717957  accuracy 0.92\n",
            "train loss 0.35791677236557007 accuracy 0.98 | test loss 0.3785841763019562  accuracy 0.92\n",
            "train loss 0.35791537165641785 accuracy 0.98 | test loss 0.37856775522232056  accuracy 0.92\n",
            "train loss 0.3579157292842865 accuracy 0.99 | test loss 0.3786143362522125  accuracy 0.92\n",
            "train loss 0.3579159379005432 accuracy 0.98 | test loss 0.3785741329193115  accuracy 0.92\n",
            "train loss 0.35791486501693726 accuracy 0.98 | test loss 0.3786057233810425  accuracy 0.92\n",
            "train loss 0.35791540145874023 accuracy 0.98 | test loss 0.3785656690597534  accuracy 0.92\n",
            "train loss 0.35791486501693726 accuracy 0.99 | test loss 0.3786391317844391  accuracy 0.92\n",
            "train loss 0.3579162657260895 accuracy 0.98 | test loss 0.378598690032959  accuracy 0.92\n",
            "train loss 0.3579147160053253 accuracy 0.98 | test loss 0.3785587251186371  accuracy 0.92\n",
            "train loss 0.3579145669937134 accuracy 0.99 | test loss 0.3786323070526123  accuracy 0.92\n",
            "train loss 0.3579155504703522 accuracy 0.98 | test loss 0.3785708546638489  accuracy 0.92\n",
            "train loss 0.35791388154029846 accuracy 0.98 | test loss 0.37858957052230835  accuracy 0.92\n",
            "train loss 0.35791391134262085 accuracy 0.98 | test loss 0.37857306003570557  accuracy 0.92\n",
            "train loss 0.3579133450984955 accuracy 0.98 | test loss 0.3786046802997589  accuracy 0.92\n",
            "train loss 0.3579139709472656 accuracy 0.98 | test loss 0.3785645067691803  accuracy 0.92\n",
            "train loss 0.3579133450984955 accuracy 0.99 | test loss 0.3786379396915436  accuracy 0.92\n",
            "train loss 0.35791483521461487 accuracy 0.98 | test loss 0.3785974681377411  accuracy 0.92\n",
            "train loss 0.3579132854938507 accuracy 0.98 | test loss 0.378557413816452  accuracy 0.92\n",
            "train loss 0.3579130470752716 accuracy 0.99 | test loss 0.37863075733184814  accuracy 0.92\n",
            "train loss 0.35791411995887756 accuracy 0.98 | test loss 0.3785904347896576  accuracy 0.92\n",
            "train loss 0.3579128086566925 accuracy 0.98 | test loss 0.3785738945007324  accuracy 0.92\n",
            "train loss 0.3579120635986328 accuracy 0.98 | test loss 0.378557413816452  accuracy 0.92\n",
            "train loss 0.35791274905204773 accuracy 0.99 | test loss 0.3786309063434601  accuracy 0.92\n",
            "train loss 0.35791346430778503 accuracy 0.98 | test loss 0.37859046459198  accuracy 0.92\n",
            "train loss 0.3579119145870209 accuracy 0.98 | test loss 0.3785504698753357  accuracy 0.92\n",
            "train loss 0.35791245102882385 accuracy 0.99 | test loss 0.37862396240234375  accuracy 0.92\n",
            "train loss 0.3579127788543701 accuracy 0.98 | test loss 0.3785836696624756  accuracy 0.92\n",
            "train loss 0.3579113781452179 accuracy 0.98 | test loss 0.3785671591758728  accuracy 0.92\n",
            "train loss 0.3579111397266388 accuracy 0.99 | test loss 0.37861353158950806  accuracy 0.92\n",
            "train loss 0.35791197419166565 accuracy 0.98 | test loss 0.3785732686519623  accuracy 0.92\n",
            "train loss 0.35791054368019104 accuracy 0.98 | test loss 0.3785568177700043  accuracy 0.92\n",
            "train loss 0.3579111397266388 accuracy 0.99 | test loss 0.37863025069236755  accuracy 0.92\n",
            "train loss 0.3579120635986328 accuracy 0.98 | test loss 0.3785896897315979  accuracy 0.92\n",
            "train loss 0.35791048407554626 accuracy 0.98 | test loss 0.37854960560798645  accuracy 0.92\n",
            "train loss 0.3579108715057373 accuracy 0.99 | test loss 0.3786230683326721  accuracy 0.92\n",
            "train loss 0.3579113781452179 accuracy 0.98 | test loss 0.378582626581192  accuracy 0.92\n",
            "train loss 0.35790982842445374 accuracy 0.98 | test loss 0.37856605648994446  accuracy 0.92\n",
            "train loss 0.35790953040122986 accuracy 0.99 | test loss 0.3786123991012573  accuracy 0.92\n",
            "train loss 0.35791054368019104 accuracy 0.98 | test loss 0.3785720765590668  accuracy 0.92\n",
            "train loss 0.35790911316871643 accuracy 0.98 | test loss 0.37855568528175354  accuracy 0.92\n",
            "train loss 0.357909619808197 accuracy 0.99 | test loss 0.37862899899482727  accuracy 0.92\n",
            "train loss 0.3579106032848358 accuracy 0.98 | test loss 0.37858846783638  accuracy 0.92\n",
            "train loss 0.35790908336639404 accuracy 0.98 | test loss 0.378548264503479  accuracy 0.92\n",
            "train loss 0.35790932178497314 accuracy 0.99 | test loss 0.3786216676235199  accuracy 0.92\n",
            "train loss 0.3579099178314209 accuracy 0.98 | test loss 0.37858110666275024  accuracy 0.92\n",
            "train loss 0.3579083979129791 accuracy 0.98 | test loss 0.3785644769668579  accuracy 0.92\n",
            "train loss 0.35790809988975525 accuracy 0.98 | test loss 0.3785960376262665  accuracy 0.92\n",
            "train loss 0.35790857672691345 accuracy 0.98 | test loss 0.3785557150840759  accuracy 0.92\n",
            "train loss 0.3579079806804657 accuracy 0.99 | test loss 0.37860214710235596  accuracy 0.92\n",
            "train loss 0.35790854692459106 accuracy 0.98 | test loss 0.3785618543624878  accuracy 0.92\n",
            "train loss 0.35790741443634033 accuracy 0.98 | test loss 0.3785933554172516  accuracy 0.92\n",
            "train loss 0.3579079210758209 accuracy 0.98 | test loss 0.3785531520843506  accuracy 0.92\n",
            "train loss 0.3579072058200836 accuracy 0.99 | test loss 0.37862640619277954  accuracy 0.92\n",
            "train loss 0.35790884494781494 accuracy 0.98 | test loss 0.37856483459472656  accuracy 0.92\n",
            "train loss 0.35790663957595825 accuracy 0.98 | test loss 0.378583163022995  accuracy 0.92\n",
            "train loss 0.35790693759918213 accuracy 0.98 | test loss 0.378542959690094  accuracy 0.92\n",
            "train loss 0.3579072058200836 accuracy 0.99 | test loss 0.3786015510559082  accuracy 0.92\n",
            "train loss 0.35790732502937317 accuracy 0.98 | test loss 0.3785612881183624  accuracy 0.92\n",
            "train loss 0.3579060137271881 accuracy 0.98 | test loss 0.37854480743408203  accuracy 0.92\n",
            "train loss 0.3579067289829254 accuracy 0.99 | test loss 0.3786182701587677  accuracy 0.92\n",
            "train loss 0.35790741443634033 accuracy 0.98 | test loss 0.37857767939567566  accuracy 0.92\n",
            "train loss 0.35790586471557617 accuracy 0.98 | test loss 0.3785375952720642  accuracy 0.92\n",
            "train loss 0.35790640115737915 accuracy 0.99 | test loss 0.3786110579967499  accuracy 0.92\n",
            "train loss 0.3579067289829254 accuracy 0.98 | test loss 0.3785706162452698  accuracy 0.92\n",
            "train loss 0.3579053282737732 accuracy 0.98 | test loss 0.3785540759563446  accuracy 0.92\n",
            "train loss 0.3579050600528717 accuracy 0.99 | test loss 0.37860041856765747  accuracy 0.92\n",
            "train loss 0.35790586471557617 accuracy 0.98 | test loss 0.3785600960254669  accuracy 0.92\n",
            "train loss 0.3579045832157135 accuracy 0.98 | test loss 0.3785436153411865  accuracy 0.92\n",
            "train loss 0.35790517926216125 accuracy 0.99 | test loss 0.3786170184612274  accuracy 0.92\n",
            "train loss 0.35790595412254333 accuracy 0.98 | test loss 0.3785764276981354  accuracy 0.92\n",
            "train loss 0.35790443420410156 accuracy 0.98 | test loss 0.37853628396987915  accuracy 0.92\n",
            "train loss 0.3579048812389374 accuracy 0.99 | test loss 0.37860968708992004  accuracy 0.92\n",
            "train loss 0.3579052686691284 accuracy 0.98 | test loss 0.3785691261291504  accuracy 0.92\n",
            "train loss 0.3579038977622986 accuracy 0.98 | test loss 0.37855246663093567  accuracy 0.92\n",
            "train loss 0.35790351033210754 accuracy 0.99 | test loss 0.37859877943992615  accuracy 0.92\n",
            "train loss 0.35790443420410156 accuracy 0.98 | test loss 0.3785584270954132  accuracy 0.92\n",
            "train loss 0.3579031229019165 accuracy 0.98 | test loss 0.3785417973995209  accuracy 0.92\n",
            "train loss 0.3579036593437195 accuracy 0.99 | test loss 0.378615140914917  accuracy 0.92\n",
            "train loss 0.35790449380874634 accuracy 0.98 | test loss 0.37857455015182495  accuracy 0.92\n",
            "train loss 0.3579029440879822 accuracy 0.98 | test loss 0.37853434681892395  accuracy 0.92\n",
            "train loss 0.357903391122818 accuracy 0.99 | test loss 0.37860769033432007  accuracy 0.92\n",
            "train loss 0.3579038083553314 accuracy 0.98 | test loss 0.3785671889781952  accuracy 0.92\n",
            "train loss 0.3579023778438568 accuracy 0.98 | test loss 0.3785504102706909  accuracy 0.92\n",
            "train loss 0.3579021394252777 accuracy 0.98 | test loss 0.37858185172080994  accuracy 0.92\n",
            "train loss 0.3579024374485016 accuracy 0.98 | test loss 0.37854161858558655  accuracy 0.92\n",
            "train loss 0.3579021096229553 accuracy 0.99 | test loss 0.37861496210098267  accuracy 0.92\n",
            "train loss 0.35790327191352844 accuracy 0.98 | test loss 0.37857431173324585  accuracy 0.92\n",
            "train loss 0.35790175199508667 accuracy 0.98 | test loss 0.37853410840034485  accuracy 0.92\n",
            "train loss 0.35790184140205383 accuracy 0.99 | test loss 0.37860751152038574  accuracy 0.92\n",
            "train loss 0.3579025864601135 accuracy 0.98 | test loss 0.3785669207572937  accuracy 0.92\n",
            "train loss 0.3579012453556061 accuracy 0.98 | test loss 0.3785501718521118  accuracy 0.92\n",
            "train loss 0.35790061950683594 accuracy 0.98 | test loss 0.3785537779331207  accuracy 0.92\n",
            "train loss 0.35790035128593445 accuracy 0.98 | test loss 0.37855732440948486  accuracy 0.92\n",
            "train loss 0.3579002320766449 accuracy 0.98 | test loss 0.3785172700881958  accuracy 0.92\n",
            "train loss 0.35790205001831055 accuracy 0.99 | test loss 0.3785907030105591  accuracy 0.92\n",
            "train loss 0.35790109634399414 accuracy 0.98 | test loss 0.378550261259079  accuracy 0.92\n",
            "train loss 0.3578997850418091 accuracy 0.98 | test loss 0.3785336911678314  accuracy 0.92\n",
            "train loss 0.35790055990219116 accuracy 0.99 | test loss 0.3786070942878723  accuracy 0.92\n",
            "train loss 0.3579012155532837 accuracy 0.98 | test loss 0.3785665035247803  accuracy 0.92\n",
            "train loss 0.35789960622787476 accuracy 0.98 | test loss 0.3785262703895569  accuracy 0.92\n",
            "train loss 0.3579002916812897 accuracy 0.99 | test loss 0.378599613904953  accuracy 0.92\n",
            "train loss 0.3579005300998688 accuracy 0.98 | test loss 0.37855905294418335  accuracy 0.92\n",
            "train loss 0.3578990399837494 accuracy 0.98 | test loss 0.37854233384132385  accuracy 0.92\n",
            "train loss 0.35789892077445984 accuracy 0.99 | test loss 0.37858858704566956  accuracy 0.92\n",
            "train loss 0.35789960622787476 accuracy 0.98 | test loss 0.37854814529418945  accuracy 0.92\n",
            "train loss 0.3578982949256897 accuracy 0.98 | test loss 0.37855926156044006  accuracy 0.92\n",
            "train loss 0.3578983247280121 accuracy 0.98 | test loss 0.378519207239151  accuracy 0.92\n",
            "train loss 0.35789957642555237 accuracy 0.99 | test loss 0.3785926401615143  accuracy 0.92\n",
            "train loss 0.35789915919303894 accuracy 0.98 | test loss 0.37855207920074463  accuracy 0.92\n",
            "train loss 0.35789766907691956 accuracy 0.98 | test loss 0.3785353899002075  accuracy 0.92\n",
            "train loss 0.357898086309433 accuracy 0.99 | test loss 0.378608763217926  accuracy 0.92\n",
            "train loss 0.3578992486000061 accuracy 0.98 | test loss 0.3785681128501892  accuracy 0.92\n",
            "train loss 0.35789769887924194 accuracy 0.98 | test loss 0.37852782011032104  accuracy 0.92\n",
            "train loss 0.3578978180885315 accuracy 0.99 | test loss 0.37860122323036194  accuracy 0.92\n",
            "train loss 0.3578985631465912 accuracy 0.98 | test loss 0.3785606026649475  accuracy 0.92\n",
            "train loss 0.35789698362350464 accuracy 0.98 | test loss 0.37852033972740173  accuracy 0.92\n",
            "train loss 0.35789754986763 accuracy 0.99 | test loss 0.3785938322544098  accuracy 0.92\n",
            "train loss 0.35789787769317627 accuracy 0.98 | test loss 0.37855324149131775  accuracy 0.92\n",
            "train loss 0.3578966557979584 accuracy 0.98 | test loss 0.3785364329814911  accuracy 0.92\n",
            "train loss 0.35789626836776733 accuracy 0.99 | test loss 0.37858274579048157  accuracy 0.92\n",
            "train loss 0.35789698362350464 accuracy 0.98 | test loss 0.3785422444343567  accuracy 0.92\n",
            "train loss 0.3578958511352539 accuracy 0.98 | test loss 0.3785255253314972  accuracy 0.92\n",
            "train loss 0.3578964173793793 accuracy 0.99 | test loss 0.3785988390445709  accuracy 0.92\n",
            "train loss 0.3578970730304718 accuracy 0.98 | test loss 0.3785582184791565  accuracy 0.92\n",
            "train loss 0.35789549350738525 accuracy 0.98 | test loss 0.3785179853439331  accuracy 0.92\n",
            "train loss 0.3578961491584778 accuracy 0.99 | test loss 0.378591388463974  accuracy 0.92\n",
            "train loss 0.3578963279724121 accuracy 0.98 | test loss 0.37855079770088196  accuracy 0.92\n",
            "train loss 0.3578951060771942 accuracy 0.98 | test loss 0.3785339891910553  accuracy 0.92\n",
            "train loss 0.35789480805397034 accuracy 0.98 | test loss 0.3785652816295624  accuracy 0.92\n",
            "train loss 0.3578949570655823 accuracy 0.98 | test loss 0.378525048494339  accuracy 0.92\n",
            "train loss 0.35789480805397034 accuracy 0.99 | test loss 0.3785983622074127  accuracy 0.92\n",
            "train loss 0.3578958511352539 accuracy 0.98 | test loss 0.3785577416419983  accuracy 0.92\n",
            "train loss 0.3578943610191345 accuracy 0.98 | test loss 0.37854093313217163  accuracy 0.92\n",
            "train loss 0.35789382457733154 accuracy 0.98 | test loss 0.37855926156044006  accuracy 0.92\n",
            "train loss 0.35789400339126587 accuracy 0.98 | test loss 0.3785189986228943  accuracy 0.92\n",
            "train loss 0.3578943908214569 accuracy 0.99 | test loss 0.37857744097709656  accuracy 0.92\n",
            "train loss 0.3578943610191345 accuracy 0.98 | test loss 0.3785369098186493  accuracy 0.92\n",
            "train loss 0.3578931391239166 accuracy 0.98 | test loss 0.3785553276538849  accuracy 0.92\n",
            "train loss 0.35789328813552856 accuracy 0.98 | test loss 0.37851500511169434  accuracy 0.92\n",
            "train loss 0.35789382457733154 accuracy 0.99 | test loss 0.3785734474658966  accuracy 0.92\n",
            "train loss 0.35789361596107483 accuracy 0.98 | test loss 0.3785329759120941  accuracy 0.92\n",
            "train loss 0.3578924536705017 accuracy 0.98 | test loss 0.3785511553287506  accuracy 0.92\n",
            "train loss 0.35789263248443604 accuracy 0.98 | test loss 0.37853437662124634  accuracy 0.92\n",
            "train loss 0.3578922152519226 accuracy 0.98 | test loss 0.37856563925743103  accuracy 0.92\n",
            "train loss 0.3578927516937256 accuracy 0.98 | test loss 0.3785252273082733  accuracy 0.92\n",
            "train loss 0.3578921854496002 accuracy 0.99 | test loss 0.3785983622074127  accuracy 0.92\n",
            "train loss 0.3578937351703644 accuracy 0.98 | test loss 0.37853652238845825  accuracy 0.92\n",
            "train loss 0.35789138078689575 accuracy 0.98 | test loss 0.3785591125488281  accuracy 0.92\n",
            "train loss 0.3578919768333435 accuracy 0.98 | test loss 0.37854212522506714  accuracy 0.92\n",
            "train loss 0.3578912317752838 accuracy 0.98 | test loss 0.37852537631988525  accuracy 0.92\n",
            "train loss 0.35789141058921814 accuracy 0.99 | test loss 0.37859848141670227  accuracy 0.92\n",
            "train loss 0.357892781496048 accuracy 0.98 | test loss 0.37855765223503113  accuracy 0.92\n",
            "train loss 0.3578912317752838 accuracy 0.98 | test loss 0.378517210483551  accuracy 0.92\n",
            "train loss 0.35789114236831665 accuracy 0.99 | test loss 0.37859046459198  accuracy 0.92\n",
            "train loss 0.35789209604263306 accuracy 0.98 | test loss 0.3785497844219208  accuracy 0.92\n",
            "train loss 0.3578905165195465 accuracy 0.98 | test loss 0.378509521484375  accuracy 0.92\n",
            "train loss 0.3578909635543823 accuracy 0.99 | test loss 0.3785827159881592  accuracy 0.92\n",
            "train loss 0.35789138078689575 accuracy 0.98 | test loss 0.3785209655761719  accuracy 0.92\n",
            "train loss 0.35788992047309875 accuracy 0.99 | test loss 0.37856703996658325  accuracy 0.92\n",
            "train loss 0.3578905463218689 accuracy 0.98 | test loss 0.3785264492034912  accuracy 0.92\n",
            "train loss 0.3578895628452301 accuracy 0.98 | test loss 0.3785375952720642  accuracy 0.92\n",
            "train loss 0.357889324426651 accuracy 0.98 | test loss 0.3785208463668823  accuracy 0.92\n",
            "train loss 0.3578895032405853 accuracy 0.99 | test loss 0.37856701016426086  accuracy 0.92\n",
            "train loss 0.357889860868454 accuracy 0.98 | test loss 0.3785264492034912  accuracy 0.92\n",
            "train loss 0.357888787984848 accuracy 0.98 | test loss 0.3785577416419983  accuracy 0.92\n",
            "train loss 0.35788923501968384 accuracy 0.98 | test loss 0.3785172998905182  accuracy 0.92\n",
            "train loss 0.357888787984848 accuracy 0.99 | test loss 0.3785903751850128  accuracy 0.92\n",
            "train loss 0.3578900694847107 accuracy 0.98 | test loss 0.37854957580566406  accuracy 0.92\n",
            "train loss 0.35788851976394653 accuracy 0.98 | test loss 0.3785092830657959  accuracy 0.92\n",
            "train loss 0.3578885495662689 accuracy 0.99 | test loss 0.37858253717422485  accuracy 0.92\n",
            "train loss 0.35788944363594055 accuracy 0.98 | test loss 0.3785206973552704  accuracy 0.92\n",
            "train loss 0.35788771510124207 accuracy 0.98 | test loss 0.37853896617889404  accuracy 0.92\n",
            "train loss 0.35788774490356445 accuracy 0.98 | test loss 0.378522127866745  accuracy 0.92\n",
            "train loss 0.3578873872756958 accuracy 0.98 | test loss 0.3785533905029297  accuracy 0.92\n",
            "train loss 0.35788771510124207 accuracy 0.98 | test loss 0.3785129189491272  accuracy 0.92\n",
            "train loss 0.3578874468803406 accuracy 0.99 | test loss 0.3785860240459442  accuracy 0.92\n",
            "train loss 0.3578885495662689 accuracy 0.98 | test loss 0.37854522466659546  accuracy 0.92\n",
            "train loss 0.35788702964782715 accuracy 0.98 | test loss 0.37850481271743774  accuracy 0.92\n",
            "train loss 0.35788726806640625 accuracy 0.99 | test loss 0.3785780668258667  accuracy 0.92\n",
            "train loss 0.357887864112854 accuracy 0.98 | test loss 0.3785373568534851  accuracy 0.92\n",
            "train loss 0.35788658261299133 accuracy 0.98 | test loss 0.37852048873901367  accuracy 0.92\n",
            "train loss 0.3578859269618988 accuracy 0.99 | test loss 0.3785665035247803  accuracy 0.92\n",
            "train loss 0.35788694024086 accuracy 0.98 | test loss 0.37852585315704346  accuracy 0.92\n",
            "train loss 0.35788577795028687 accuracy 0.98 | test loss 0.3785091042518616  accuracy 0.92\n",
            "train loss 0.35788610577583313 accuracy 0.99 | test loss 0.3785821795463562  accuracy 0.92\n",
            "train loss 0.35788702964782715 accuracy 0.98 | test loss 0.37854140996932983  accuracy 0.92\n",
            "train loss 0.3578855097293854 accuracy 0.98 | test loss 0.37850093841552734  accuracy 0.92\n",
            "train loss 0.3578858971595764 accuracy 0.99 | test loss 0.378574013710022  accuracy 0.92\n",
            "train loss 0.35788631439208984 accuracy 0.98 | test loss 0.378533273935318  accuracy 0.92\n",
            "train loss 0.3578850328922272 accuracy 0.98 | test loss 0.3785165250301361  accuracy 0.92\n",
            "train loss 0.35788458585739136 accuracy 0.98 | test loss 0.378547728061676  accuracy 0.92\n",
            "train loss 0.35788494348526 accuracy 0.98 | test loss 0.378507137298584  accuracy 0.92\n",
            "train loss 0.3578846752643585 accuracy 0.99 | test loss 0.3785803020000458  accuracy 0.92\n",
            "train loss 0.35788580775260925 accuracy 0.98 | test loss 0.378539502620697  accuracy 0.92\n",
            "train loss 0.3578842580318451 accuracy 0.98 | test loss 0.37852248549461365  accuracy 0.92\n",
            "train loss 0.35788360238075256 accuracy 0.98 | test loss 0.3785407245159149  accuracy 0.92\n",
            "train loss 0.35788390040397644 accuracy 0.98 | test loss 0.3785001337528229  accuracy 0.92\n",
            "train loss 0.3578842878341675 accuracy 0.99 | test loss 0.378558486700058  accuracy 0.92\n",
            "train loss 0.3578842580318451 accuracy 0.98 | test loss 0.37851783633232117  accuracy 0.92\n",
            "train loss 0.35788291692733765 accuracy 0.98 | test loss 0.3785362243652344  accuracy 0.92\n",
            "train loss 0.35788318514823914 accuracy 0.98 | test loss 0.37849563360214233  accuracy 0.92\n",
            "train loss 0.3578837513923645 accuracy 0.99 | test loss 0.37855395674705505  accuracy 0.92\n",
            "train loss 0.3578835129737854 accuracy 0.98 | test loss 0.378513365983963  accuracy 0.92\n",
            "train loss 0.35788238048553467 accuracy 0.98 | test loss 0.37853914499282837  accuracy 0.92\n",
            "train loss 0.35788267850875854 accuracy 0.98 | test loss 0.3784986138343811  accuracy 0.92\n",
            "train loss 0.3578827977180481 accuracy 0.99 | test loss 0.3785717785358429  accuracy 0.92\n",
            "train loss 0.3578835129737854 accuracy 0.98 | test loss 0.37853094935417175  accuracy 0.92\n",
            "train loss 0.35788214206695557 accuracy 0.98 | test loss 0.37851396203041077  accuracy 0.92\n",
            "train loss 0.3578815460205078 accuracy 0.98 | test loss 0.3785451352596283  accuracy 0.92\n",
            "train loss 0.3578821122646332 accuracy 0.98 | test loss 0.37850454449653625  accuracy 0.92\n",
            "train loss 0.3578815758228302 accuracy 0.99 | test loss 0.37857764959335327  accuracy 0.92\n",
            "train loss 0.3578829765319824 accuracy 0.98 | test loss 0.37851566076278687  accuracy 0.92\n",
            "train loss 0.35788100957870483 accuracy 0.98 | test loss 0.37853384017944336  accuracy 0.92\n",
            "train loss 0.3578811287879944 accuracy 0.98 | test loss 0.3784933388233185  accuracy 0.92\n",
            "train loss 0.3578815460205078 accuracy 0.99 | test loss 0.3785664141178131  accuracy 0.92\n",
            "train loss 0.35788199305534363 accuracy 0.98 | test loss 0.37852567434310913  accuracy 0.92\n",
            "train loss 0.3578805923461914 accuracy 0.98 | test loss 0.37850868701934814  accuracy 0.92\n",
            "train loss 0.357880175113678 accuracy 0.98 | test loss 0.3785398006439209  accuracy 0.92\n",
            "train loss 0.35788053274154663 accuracy 0.98 | test loss 0.37849920988082886  accuracy 0.92\n",
            "train loss 0.3578803241252899 accuracy 0.99 | test loss 0.37857234477996826  accuracy 0.92\n",
            "train loss 0.3578813970088959 accuracy 0.98 | test loss 0.37853139638900757  accuracy 0.92\n",
            "train loss 0.3578798174858093 accuracy 0.98 | test loss 0.37849098443984985  accuracy 0.92\n",
            "train loss 0.3578801155090332 accuracy 0.99 | test loss 0.3785640597343445  accuracy 0.92\n",
            "train loss 0.3578806519508362 accuracy 0.98 | test loss 0.3785233199596405  accuracy 0.92\n",
            "train loss 0.3578794002532959 accuracy 0.98 | test loss 0.37850630283355713  accuracy 0.92\n",
            "train loss 0.35787883400917053 accuracy 0.99 | test loss 0.3785523474216461  accuracy 0.92\n",
            "train loss 0.35787978768348694 accuracy 0.98 | test loss 0.3785116374492645  accuracy 0.92\n",
            "train loss 0.3578786253929138 accuracy 0.98 | test loss 0.3784947991371155  accuracy 0.92\n",
            "train loss 0.35787901282310486 accuracy 0.99 | test loss 0.3785679042339325  accuracy 0.92\n",
            "train loss 0.3578798472881317 accuracy 0.98 | test loss 0.3785269856452942  accuracy 0.92\n",
            "train loss 0.35787829756736755 accuracy 0.98 | test loss 0.37848642468452454  accuracy 0.92\n",
            "train loss 0.35787880420684814 accuracy 0.99 | test loss 0.37855952978134155  accuracy 0.92\n",
            "train loss 0.357879102230072 accuracy 0.98 | test loss 0.3785187304019928  accuracy 0.92\n",
            "train loss 0.3578778803348541 accuracy 0.98 | test loss 0.3785017728805542  accuracy 0.92\n",
            "train loss 0.3578774034976959 accuracy 0.99 | test loss 0.37854766845703125  accuracy 0.92\n",
            "train loss 0.35787826776504517 accuracy 0.98 | test loss 0.3785068392753601  accuracy 0.92\n",
            "train loss 0.35787710547447205 accuracy 0.98 | test loss 0.3785177171230316  accuracy 0.92\n",
            "train loss 0.35787689685821533 accuracy 0.98 | test loss 0.3784772455692291  accuracy 0.92\n",
            "train loss 0.35787826776504517 accuracy 0.99 | test loss 0.37855038046836853  accuracy 0.92\n",
            "train loss 0.3578777313232422 accuracy 0.98 | test loss 0.37850967049598694  accuracy 0.92\n",
            "train loss 0.3578764498233795 accuracy 0.98 | test loss 0.3784927725791931  accuracy 0.92\n",
            "train loss 0.35787680745124817 accuracy 0.99 | test loss 0.37856584787368774  accuracy 0.92\n",
            "train loss 0.3578777611255646 accuracy 0.98 | test loss 0.3785248398780823  accuracy 0.92\n",
            "train loss 0.3578762114048004 accuracy 0.98 | test loss 0.37848424911499023  accuracy 0.92\n",
            "train loss 0.35787665843963623 accuracy 0.99 | test loss 0.378557413816452  accuracy 0.92\n",
            "train loss 0.35787704586982727 accuracy 0.98 | test loss 0.3785164952278137  accuracy 0.92\n",
            "train loss 0.3578757047653198 accuracy 0.98 | test loss 0.37849950790405273  accuracy 0.92\n",
            "train loss 0.35787534713745117 accuracy 0.99 | test loss 0.37854552268981934  accuracy 0.92\n",
            "train loss 0.35787615180015564 accuracy 0.98 | test loss 0.3785046935081482  accuracy 0.92\n",
            "train loss 0.35787492990493774 accuracy 0.98 | test loss 0.3784877359867096  accuracy 0.92\n",
            "train loss 0.3578755855560303 accuracy 0.99 | test loss 0.378560870885849  accuracy 0.92\n",
            "train loss 0.3578762412071228 accuracy 0.98 | test loss 0.37851986289024353  accuracy 0.92\n",
            "train loss 0.35787466168403625 accuracy 0.98 | test loss 0.37847933173179626  accuracy 0.92\n",
            "train loss 0.35787534713745117 accuracy 0.99 | test loss 0.37855246663093567  accuracy 0.92\n",
            "train loss 0.3578754961490631 accuracy 0.98 | test loss 0.3785114884376526  accuracy 0.92\n",
            "train loss 0.35787421464920044 accuracy 0.98 | test loss 0.37849441170692444  accuracy 0.92\n",
            "train loss 0.35787397623062134 accuracy 0.98 | test loss 0.3785257339477539  accuracy 0.92\n",
            "train loss 0.3578740954399109 accuracy 0.98 | test loss 0.37848514318466187  accuracy 0.92\n",
            "train loss 0.3578741252422333 accuracy 0.99 | test loss 0.3785582184791565  accuracy 0.92\n",
            "train loss 0.3578749895095825 accuracy 0.98 | test loss 0.3785172700881958  accuracy 0.92\n",
            "train loss 0.35787340998649597 accuracy 0.98 | test loss 0.3785001337528229  accuracy 0.92\n",
            "train loss 0.35787299275398254 accuracy 0.99 | test loss 0.3785460591316223  accuracy 0.92\n",
            "train loss 0.3578740656375885 accuracy 0.98 | test loss 0.3785051703453064  accuracy 0.92\n",
            "train loss 0.3578725755214691 accuracy 0.98 | test loss 0.3784881830215454  accuracy 0.92\n",
            "train loss 0.3578731119632721 accuracy 0.99 | test loss 0.37856122851371765  accuracy 0.92\n",
            "train loss 0.3578741252422333 accuracy 0.98 | test loss 0.3785201907157898  accuracy 0.92\n",
            "train loss 0.35787254571914673 accuracy 0.98 | test loss 0.37847959995269775  accuracy 0.92\n",
            "train loss 0.3578729033470154 accuracy 0.99 | test loss 0.37855270504951477  accuracy 0.92\n",
            "train loss 0.3578733801841736 accuracy 0.98 | test loss 0.3785116970539093  accuracy 0.92\n",
            "train loss 0.35787180066108704 accuracy 0.98 | test loss 0.37849465012550354  accuracy 0.92\n",
            "train loss 0.3578716218471527 accuracy 0.99 | test loss 0.378540575504303  accuracy 0.92\n",
            "train loss 0.35787245631217957 accuracy 0.98 | test loss 0.3784996569156647  accuracy 0.92\n",
            "train loss 0.3578711152076721 accuracy 0.98 | test loss 0.37853071093559265  accuracy 0.92\n",
            "train loss 0.3578718602657318 accuracy 0.98 | test loss 0.37848982214927673  accuracy 0.92\n",
            "train loss 0.3578709065914154 accuracy 0.99 | test loss 0.3785479962825775  accuracy 0.92\n",
            "train loss 0.3578721880912781 accuracy 0.98 | test loss 0.37850698828697205  accuracy 0.92\n",
            "train loss 0.3578706383705139 accuracy 0.98 | test loss 0.378481388092041  accuracy 0.92\n",
            "train loss 0.3578707277774811 accuracy 0.99 | test loss 0.3785395622253418  accuracy 0.92\n",
            "train loss 0.35787147283554077 accuracy 0.98 | test loss 0.37849876284599304  accuracy 0.92\n",
            "train loss 0.3578702509403229 accuracy 0.98 | test loss 0.3784964680671692  accuracy 0.92\n",
            "train loss 0.35786986351013184 accuracy 0.98 | test loss 0.3784794509410858  accuracy 0.92\n",
            "train loss 0.357870489358902 accuracy 0.99 | test loss 0.37855255603790283  accuracy 0.92\n",
            "train loss 0.3578712046146393 accuracy 0.98 | test loss 0.3785114884376526  accuracy 0.92\n",
            "train loss 0.35786962509155273 accuracy 0.98 | test loss 0.37847089767456055  accuracy 0.92\n",
            "train loss 0.35787028074264526 accuracy 0.99 | test loss 0.37854400277137756  accuracy 0.92\n",
            "train loss 0.357870489358902 accuracy 0.98 | test loss 0.3785029947757721  accuracy 0.92\n",
            "train loss 0.35786908864974976 accuracy 0.98 | test loss 0.37848588824272156  accuracy 0.92\n",
            "train loss 0.3578689992427826 accuracy 0.99 | test loss 0.37853187322616577  accuracy 0.92\n",
            "train loss 0.35786956548690796 accuracy 0.98 | test loss 0.37849098443984985  accuracy 0.92\n",
            "train loss 0.35786840319633484 accuracy 0.98 | test loss 0.37852203845977783  accuracy 0.92\n",
            "train loss 0.3578689396381378 accuracy 0.98 | test loss 0.3784812092781067  accuracy 0.92\n",
            "train loss 0.3578682541847229 accuracy 0.99 | test loss 0.3785542845726013  accuracy 0.92\n",
            "train loss 0.357869952917099 accuracy 0.98 | test loss 0.3784920275211334  accuracy 0.92\n",
            "train loss 0.3578677177429199 accuracy 0.98 | test loss 0.3785099685192108  accuracy 0.92\n",
            "train loss 0.357867956161499 accuracy 0.98 | test loss 0.3784693479537964  accuracy 0.92\n",
            "train loss 0.35786837339401245 accuracy 0.99 | test loss 0.3785274922847748  accuracy 0.92\n",
            "train loss 0.3578682541847229 accuracy 0.98 | test loss 0.37848663330078125  accuracy 0.92\n",
            "train loss 0.35786712169647217 accuracy 0.98 | test loss 0.37850460410118103  accuracy 0.92\n",
            "train loss 0.3578672707080841 accuracy 0.98 | test loss 0.37848737835884094  accuracy 0.92\n",
            "train loss 0.3578668236732483 accuracy 0.98 | test loss 0.37851840257644653  accuracy 0.92\n",
            "train loss 0.3578673005104065 accuracy 0.98 | test loss 0.37847763299942017  accuracy 0.92\n",
            "train loss 0.3578668534755707 accuracy 0.99 | test loss 0.37855055928230286  accuracy 0.92\n",
            "train loss 0.35786813497543335 accuracy 0.98 | test loss 0.37848833203315735  accuracy 0.92\n",
            "train loss 0.3578660786151886 accuracy 0.98 | test loss 0.3785063922405243  accuracy 0.92\n",
            "train loss 0.3578662872314453 accuracy 0.98 | test loss 0.3784657120704651  accuracy 0.92\n",
            "train loss 0.35786688327789307 accuracy 0.99 | test loss 0.37853866815567017  accuracy 0.92\n",
            "train loss 0.35786712169647217 accuracy 0.98 | test loss 0.37849757075309753  accuracy 0.92\n",
            "train loss 0.35786566138267517 accuracy 0.98 | test loss 0.37848037481307983  accuracy 0.92\n",
            "train loss 0.3578656017780304 accuracy 0.99 | test loss 0.37853845953941345  accuracy 0.92\n",
            "train loss 0.3578666150569916 accuracy 0.98 | test loss 0.378497451543808  accuracy 0.92\n",
            "train loss 0.3578650653362274 accuracy 0.98 | test loss 0.37845680117607117  accuracy 0.92\n",
            "train loss 0.3578663468360901 accuracy 0.99 | test loss 0.37852996587753296  accuracy 0.92\n",
            "train loss 0.3578658998012543 accuracy 0.98 | test loss 0.3784889578819275  accuracy 0.92\n",
            "train loss 0.35786452889442444 accuracy 0.98 | test loss 0.37847182154655457  accuracy 0.92\n",
            "train loss 0.35786497592926025 accuracy 0.99 | test loss 0.3785448372364044  accuracy 0.92\n",
            "train loss 0.35786595940589905 accuracy 0.98 | test loss 0.3785036504268646  accuracy 0.92\n",
            "train loss 0.3578643798828125 accuracy 0.98 | test loss 0.3784629702568054  accuracy 0.92\n",
            "train loss 0.3578647971153259 accuracy 0.99 | test loss 0.37853607535362244  accuracy 0.92\n",
            "train loss 0.35786521434783936 accuracy 0.98 | test loss 0.3784949481487274  accuracy 0.92\n",
            "train loss 0.35786375403404236 accuracy 0.98 | test loss 0.3784778118133545  accuracy 0.92\n",
            "train loss 0.3578636050224304 accuracy 0.99 | test loss 0.37852373719215393  accuracy 0.92\n",
            "train loss 0.35786429047584534 accuracy 0.98 | test loss 0.37848272919654846  accuracy 0.92\n",
            "train loss 0.3578629493713379 accuracy 0.98 | test loss 0.37848588824272156  accuracy 0.92\n",
            "train loss 0.3578626811504364 accuracy 0.98 | test loss 0.378468781709671  accuracy 0.92\n",
            "train loss 0.3578634560108185 accuracy 0.99 | test loss 0.3785417079925537  accuracy 0.92\n",
            "train loss 0.35786429047584534 accuracy 0.98 | test loss 0.3785005211830139  accuracy 0.92\n",
            "train loss 0.3578626811504364 accuracy 0.98 | test loss 0.37845978140830994  accuracy 0.92\n",
            "train loss 0.35786333680152893 accuracy 0.99 | test loss 0.37853285670280457  accuracy 0.92\n",
            "train loss 0.35786354541778564 accuracy 0.98 | test loss 0.37849172949790955  accuracy 0.92\n",
            "train loss 0.3578619956970215 accuracy 0.98 | test loss 0.37847450375556946  accuracy 0.92\n",
            "train loss 0.3578619956970215 accuracy 0.99 | test loss 0.3785204291343689  accuracy 0.92\n",
            "train loss 0.357862651348114 accuracy 0.98 | test loss 0.3784794509410858  accuracy 0.92\n",
            "train loss 0.35786136984825134 accuracy 0.98 | test loss 0.37851038575172424  accuracy 0.92\n",
            "train loss 0.3578619956970215 accuracy 0.98 | test loss 0.37846946716308594  accuracy 0.92\n",
            "train loss 0.35786136984825134 accuracy 0.99 | test loss 0.37854233384132385  accuracy 0.92\n",
            "train loss 0.3578628897666931 accuracy 0.98 | test loss 0.3784799873828888  accuracy 0.92\n",
            "train loss 0.3578607141971588 accuracy 0.98 | test loss 0.378497838973999  accuracy 0.92\n",
            "train loss 0.3578609824180603 accuracy 0.98 | test loss 0.37845706939697266  accuracy 0.92\n",
            "train loss 0.35786139965057373 accuracy 0.99 | test loss 0.3785298764705658  accuracy 0.92\n",
            "train loss 0.35786178708076477 accuracy 0.98 | test loss 0.37848860025405884  accuracy 0.92\n",
            "train loss 0.3578603267669678 accuracy 0.98 | test loss 0.37847140431404114  accuracy 0.92\n",
            "train loss 0.35786008834838867 accuracy 0.99 | test loss 0.37852942943573  accuracy 0.92\n",
            "train loss 0.35786131024360657 accuracy 0.98 | test loss 0.3784882128238678  accuracy 0.92\n",
            "train loss 0.35785973072052 accuracy 0.98 | test loss 0.3784622848033905  accuracy 0.92\n",
            "train loss 0.3578599989414215 accuracy 0.99 | test loss 0.37852033972740173  accuracy 0.92\n",
            "train loss 0.3578605651855469 accuracy 0.98 | test loss 0.3784793019294739  accuracy 0.92\n",
            "train loss 0.35785913467407227 accuracy 0.98 | test loss 0.3784768581390381  accuracy 0.92\n",
            "train loss 0.3578588664531708 accuracy 0.98 | test loss 0.3785077631473541  accuracy 0.92\n",
            "train loss 0.35785964131355286 accuracy 0.98 | test loss 0.37846675515174866  accuracy 0.92\n",
            "train loss 0.3578588366508484 accuracy 0.99 | test loss 0.3785126805305481  accuracy 0.92\n",
            "train loss 0.3578595221042633 accuracy 0.98 | test loss 0.3784716725349426  accuracy 0.92\n",
            "train loss 0.3578583896160126 accuracy 0.98 | test loss 0.3784824311733246  accuracy 0.92\n",
            "train loss 0.35785815119743347 accuracy 0.98 | test loss 0.3784417510032654  accuracy 0.92\n",
            "train loss 0.35785964131355286 accuracy 0.99 | test loss 0.3785148561000824  accuracy 0.92\n",
            "train loss 0.35785895586013794 accuracy 0.98 | test loss 0.37847375869750977  accuracy 0.92\n",
            "train loss 0.3578576445579529 accuracy 0.98 | test loss 0.37845659255981445  accuracy 0.92\n",
            "train loss 0.357858270406723 accuracy 0.99 | test loss 0.37852948904037476  accuracy 0.92\n",
            "train loss 0.3578590452671051 accuracy 0.98 | test loss 0.3784882128238678  accuracy 0.92\n",
            "train loss 0.35785743594169617 accuracy 0.98 | test loss 0.3784474730491638  accuracy 0.92\n",
            "train loss 0.35785815119743347 accuracy 0.99 | test loss 0.3785204291343689  accuracy 0.92\n",
            "train loss 0.357858270406723 accuracy 0.98 | test loss 0.3784792721271515  accuracy 0.92\n",
            "train loss 0.3578568994998932 accuracy 0.98 | test loss 0.3784619867801666  accuracy 0.92\n",
            "train loss 0.3578568696975708 accuracy 0.99 | test loss 0.37850791215896606  accuracy 0.92\n",
            "train loss 0.357857346534729 accuracy 0.98 | test loss 0.3784668743610382  accuracy 0.92\n",
            "train loss 0.35785621404647827 accuracy 0.98 | test loss 0.37849774956703186  accuracy 0.92\n",
            "train loss 0.35785675048828125 accuracy 0.98 | test loss 0.37845680117607117  accuracy 0.92\n",
            "train loss 0.35785621404647827 accuracy 0.99 | test loss 0.37852969765663147  accuracy 0.92\n",
            "train loss 0.3578575849533081 accuracy 0.98 | test loss 0.37846723198890686  accuracy 0.92\n",
            "train loss 0.35785558819770813 accuracy 0.98 | test loss 0.3784851133823395  accuracy 0.92\n",
            "train loss 0.3578556776046753 accuracy 0.98 | test loss 0.3784441649913788  accuracy 0.92\n",
            "train loss 0.35785627365112305 accuracy 0.99 | test loss 0.3785170018672943  accuracy 0.92\n",
            "train loss 0.35785648226737976 accuracy 0.98 | test loss 0.37847578525543213  accuracy 0.92\n",
            "train loss 0.35785526037216187 accuracy 0.98 | test loss 0.37845849990844727  accuracy 0.92\n",
            "train loss 0.357854962348938 accuracy 0.99 | test loss 0.37851637601852417  accuracy 0.92\n",
            "train loss 0.35785597562789917 accuracy 0.98 | test loss 0.3784751296043396  accuracy 0.92\n",
            "train loss 0.3578544855117798 accuracy 0.98 | test loss 0.37847253680229187  accuracy 0.92\n",
            "train loss 0.3578541576862335 accuracy 0.98 | test loss 0.3784521520137787  accuracy 0.92\n",
            "train loss 0.3578545153141022 accuracy 0.99 | test loss 0.37851008772850037  accuracy 0.92\n",
            "train loss 0.3578552305698395 accuracy 0.98 | test loss 0.37846899032592773  accuracy 0.92\n",
            "train loss 0.35785382986068726 accuracy 0.98 | test loss 0.3784664571285248  accuracy 0.92\n",
            "train loss 0.357853502035141 accuracy 0.98 | test loss 0.3784770369529724  accuracy 0.92\n",
            "train loss 0.3578535318374634 accuracy 0.98 | test loss 0.3784511983394623  accuracy 0.92\n",
            "train loss 0.3578539192676544 accuracy 0.99 | test loss 0.3785090148448944  accuracy 0.92\n",
            "train loss 0.35785430669784546 accuracy 0.98 | test loss 0.378467857837677  accuracy 0.92\n",
            "train loss 0.35785284638404846 accuracy 0.98 | test loss 0.37848567962646484  accuracy 0.92\n",
            "train loss 0.3578532338142395 accuracy 0.98 | test loss 0.37844473123550415  accuracy 0.92\n",
            "train loss 0.357853502035141 accuracy 0.99 | test loss 0.378502756357193  accuracy 0.92\n",
            "train loss 0.3578535318374634 accuracy 0.98 | test loss 0.37846171855926514  accuracy 0.92\n",
            "train loss 0.3578522503376007 accuracy 0.98 | test loss 0.37845924496650696  accuracy 0.92\n",
            "train loss 0.3578522503376007 accuracy 0.98 | test loss 0.3784900903701782  accuracy 0.92\n",
            "train loss 0.35785260796546936 accuracy 0.98 | test loss 0.37844908237457275  accuracy 0.92\n",
            "train loss 0.3578523099422455 accuracy 0.99 | test loss 0.37852194905281067  accuracy 0.92\n",
            "train loss 0.3578534722328186 accuracy 0.98 | test loss 0.3784806430339813  accuracy 0.92\n",
            "train loss 0.35785186290740967 accuracy 0.98 | test loss 0.37843969464302063  accuracy 0.92\n",
            "train loss 0.35785216093063354 accuracy 0.99 | test loss 0.3785126805305481  accuracy 0.92\n",
            "train loss 0.3578526973724365 accuracy 0.98 | test loss 0.37847137451171875  accuracy 0.92\n",
            "train loss 0.35785141587257385 accuracy 0.98 | test loss 0.3784539997577667  accuracy 0.92\n",
            "train loss 0.35785090923309326 accuracy 0.98 | test loss 0.37848490476608276  accuracy 0.92\n",
            "train loss 0.3578512370586395 accuracy 0.98 | test loss 0.3784438967704773  accuracy 0.92\n",
            "train loss 0.3578510880470276 accuracy 0.99 | test loss 0.37851682305336  accuracy 0.92\n",
            "train loss 0.35785210132598877 accuracy 0.98 | test loss 0.37847548723220825  accuracy 0.92\n",
            "train loss 0.3578505516052246 accuracy 0.98 | test loss 0.37845808267593384  accuracy 0.92\n",
            "train loss 0.35785001516342163 accuracy 0.98 | test loss 0.37847593426704407  accuracy 0.92\n",
            "train loss 0.35785019397735596 accuracy 0.98 | test loss 0.3784349858760834  accuracy 0.92\n",
            "train loss 0.3578508198261261 accuracy 0.99 | test loss 0.37850791215896606  accuracy 0.92\n",
            "train loss 0.3578510284423828 accuracy 0.98 | test loss 0.3784666061401367  accuracy 0.92\n",
            "train loss 0.3578495681285858 accuracy 0.98 | test loss 0.3784492313861847  accuracy 0.92\n",
            "train loss 0.35784950852394104 accuracy 0.99 | test loss 0.3785070776939392  accuracy 0.92\n",
            "train loss 0.35785049200057983 accuracy 0.98 | test loss 0.37846580147743225  accuracy 0.92\n",
            "train loss 0.35784897208213806 accuracy 0.98 | test loss 0.37843990325927734  accuracy 0.92\n",
            "train loss 0.3578493893146515 accuracy 0.99 | test loss 0.37849780917167664  accuracy 0.92\n",
            "train loss 0.35784971714019775 accuracy 0.98 | test loss 0.3784566819667816  accuracy 0.92\n",
            "train loss 0.3578484356403351 accuracy 0.98 | test loss 0.3784540593624115  accuracy 0.92\n",
            "train loss 0.35784828662872314 accuracy 0.98 | test loss 0.37848490476608276  accuracy 0.92\n",
            "train loss 0.35784879326820374 accuracy 0.98 | test loss 0.3784438669681549  accuracy 0.92\n",
            "train loss 0.35784828662872314 accuracy 0.99 | test loss 0.37851667404174805  accuracy 0.92\n",
            "train loss 0.357849657535553 accuracy 0.98 | test loss 0.3784753084182739  accuracy 0.92\n",
            "train loss 0.35784804821014404 accuracy 0.98 | test loss 0.37843433022499084  accuracy 0.92\n",
            "train loss 0.357848197221756 accuracy 0.99 | test loss 0.37850722670555115  accuracy 0.92\n",
            "train loss 0.3578488826751709 accuracy 0.98 | test loss 0.37846583127975464  accuracy 0.92\n",
            "train loss 0.35784751176834106 accuracy 0.98 | test loss 0.37844839692115784  accuracy 0.92\n",
            "train loss 0.3578470051288605 accuracy 0.99 | test loss 0.37849411368370056  accuracy 0.92\n",
            "train loss 0.3578479290008545 accuracy 0.98 | test loss 0.37845298647880554  accuracy 0.92\n",
            "train loss 0.3578467071056366 accuracy 0.98 | test loss 0.37843558192253113  accuracy 0.92\n",
            "train loss 0.35784727334976196 accuracy 0.99 | test loss 0.37850844860076904  accuracy 0.92\n",
            "train loss 0.3578479588031769 accuracy 0.98 | test loss 0.37846705317497253  accuracy 0.92\n",
            "train loss 0.35784637928009033 accuracy 0.98 | test loss 0.37842607498168945  accuracy 0.92\n",
            "train loss 0.35784712433815 accuracy 0.99 | test loss 0.37849903106689453  accuracy 0.92\n",
            "train loss 0.3578472137451172 accuracy 0.98 | test loss 0.3784576654434204  accuracy 0.92\n",
            "train loss 0.35784590244293213 accuracy 0.98 | test loss 0.3784402310848236  accuracy 0.92\n",
            "train loss 0.35784584283828735 accuracy 0.99 | test loss 0.37851306796073914  accuracy 0.92\n",
            "train loss 0.3578472137451172 accuracy 0.98 | test loss 0.37847164273262024  accuracy 0.92\n",
            "train loss 0.35784560441970825 accuracy 0.98 | test loss 0.37843063473701477  accuracy 0.92\n",
            "train loss 0.3578456938266754 accuracy 0.99 | test loss 0.37850332260131836  accuracy 0.92\n",
            "train loss 0.3578464388847351 accuracy 0.98 | test loss 0.37846189737319946  accuracy 0.92\n",
            "train loss 0.35784509778022766 accuracy 0.98 | test loss 0.3784444332122803  accuracy 0.92\n",
            "train loss 0.3578445613384247 accuracy 0.98 | test loss 0.37847524881362915  accuracy 0.92\n",
            "train loss 0.3578449785709381 accuracy 0.98 | test loss 0.3784342110157013  accuracy 0.92\n",
            "train loss 0.35784465074539185 accuracy 0.99 | test loss 0.3785070776939392  accuracy 0.92\n",
            "train loss 0.35784584283828735 accuracy 0.98 | test loss 0.3784656524658203  accuracy 0.92\n",
            "train loss 0.3578442335128784 accuracy 0.98 | test loss 0.37844815850257874  accuracy 0.92\n",
            "train loss 0.35784369707107544 accuracy 0.98 | test loss 0.378465861082077  accuracy 0.92\n",
            "train loss 0.35784387588500977 accuracy 0.98 | test loss 0.37842485308647156  accuracy 0.92\n",
            "train loss 0.3578444719314575 accuracy 0.99 | test loss 0.37849754095077515  accuracy 0.92\n",
            "train loss 0.357844740152359 accuracy 0.98 | test loss 0.37845611572265625  accuracy 0.92\n",
            "train loss 0.3578432500362396 accuracy 0.98 | test loss 0.3784385919570923  accuracy 0.92\n",
            "train loss 0.35784316062927246 accuracy 0.99 | test loss 0.3784964680671692  accuracy 0.92\n",
            "train loss 0.3578442335128784 accuracy 0.98 | test loss 0.3784550726413727  accuracy 0.92\n",
            "train loss 0.3578426241874695 accuracy 0.98 | test loss 0.37842902541160583  accuracy 0.92\n",
            "train loss 0.3578430414199829 accuracy 0.99 | test loss 0.37848684191703796  accuracy 0.92\n",
            "train loss 0.35784342885017395 accuracy 0.98 | test loss 0.3784455358982086  accuracy 0.92\n",
            "train loss 0.3578420579433441 accuracy 0.98 | test loss 0.3784429132938385  accuracy 0.92\n",
            "train loss 0.35784196853637695 accuracy 0.98 | test loss 0.3784736096858978  accuracy 0.92\n",
            "train loss 0.35784247517585754 accuracy 0.98 | test loss 0.3784324824810028  accuracy 0.92\n",
            "train loss 0.35784196853637695 accuracy 0.99 | test loss 0.37850522994995117  accuracy 0.92\n",
            "train loss 0.3578433096408844 accuracy 0.98 | test loss 0.3784637451171875  accuracy 0.92\n",
            "train loss 0.35784170031547546 accuracy 0.98 | test loss 0.37842267751693726  accuracy 0.92\n",
            "train loss 0.3578418791294098 accuracy 0.99 | test loss 0.37849554419517517  accuracy 0.92\n",
            "train loss 0.3578425645828247 accuracy 0.98 | test loss 0.3784541189670563  accuracy 0.92\n",
            "train loss 0.3578411638736725 accuracy 0.98 | test loss 0.3784366250038147  accuracy 0.92\n",
            "train loss 0.35784074664115906 accuracy 0.99 | test loss 0.3784823417663574  accuracy 0.92\n",
            "train loss 0.3578416109085083 accuracy 0.98 | test loss 0.3784410059452057  accuracy 0.92\n",
            "train loss 0.35784032940864563 accuracy 0.98 | test loss 0.37845146656036377  accuracy 0.92\n",
            "train loss 0.3578401803970337 accuracy 0.98 | test loss 0.3784103989601135  accuracy 0.92\n",
            "train loss 0.3578415513038635 accuracy 0.99 | test loss 0.37848329544067383  accuracy 0.92\n",
            "train loss 0.35784101486206055 accuracy 0.98 | test loss 0.3784419298171997  accuracy 0.92\n",
            "train loss 0.3578396439552307 accuracy 0.98 | test loss 0.3784245252609253  accuracy 0.92\n",
            "train loss 0.3578402101993561 accuracy 0.99 | test loss 0.37849730253219604  accuracy 0.92\n",
            "train loss 0.35784101486206055 accuracy 0.98 | test loss 0.37845578789711  accuracy 0.92\n",
            "train loss 0.357839435338974 accuracy 0.98 | test loss 0.37841475009918213  accuracy 0.92\n",
            "train loss 0.3578401207923889 accuracy 0.99 | test loss 0.37848764657974243  accuracy 0.92\n",
            "train loss 0.35784026980400085 accuracy 0.98 | test loss 0.37844622135162354  accuracy 0.92\n",
            "train loss 0.357838898897171 accuracy 0.98 | test loss 0.37842872738838196  accuracy 0.92\n",
            "train loss 0.357838898897171 accuracy 0.99 | test loss 0.3784744441509247  accuracy 0.92\n",
            "train loss 0.35783934593200684 accuracy 0.98 | test loss 0.37843310832977295  accuracy 0.92\n",
            "train loss 0.3578382730484009 accuracy 0.98 | test loss 0.37846386432647705  accuracy 0.92\n",
            "train loss 0.3578386604785919 accuracy 0.98 | test loss 0.3784226179122925  accuracy 0.92\n",
            "train loss 0.35783830285072327 accuracy 0.99 | test loss 0.3784954845905304  accuracy 0.92\n",
            "train loss 0.35783958435058594 accuracy 0.98 | test loss 0.37843284010887146  accuracy 0.92\n",
            "train loss 0.3578376770019531 accuracy 0.98 | test loss 0.37845057249069214  accuracy 0.92\n",
            "train loss 0.35783758759498596 accuracy 0.98 | test loss 0.3784095048904419  accuracy 0.92\n",
            "train loss 0.35783839225769043 accuracy 0.99 | test loss 0.3784821927547455  accuracy 0.92\n",
            "train loss 0.3578384220600128 accuracy 0.98 | test loss 0.378440797328949  accuracy 0.92\n",
            "train loss 0.3578372001647949 accuracy 0.98 | test loss 0.3784233033657074  accuracy 0.92\n",
            "train loss 0.35783711075782776 accuracy 0.99 | test loss 0.3784959018230438  accuracy 0.92\n",
            "train loss 0.3578384220600128 accuracy 0.98 | test loss 0.3784543573856354  accuracy 0.92\n",
            "train loss 0.35783684253692627 accuracy 0.98 | test loss 0.3784131407737732  accuracy 0.92\n",
            "train loss 0.357837051153183 accuracy 0.99 | test loss 0.37848585844039917  accuracy 0.92\n",
            "train loss 0.35783761739730835 accuracy 0.98 | test loss 0.3784444332122803  accuracy 0.92\n",
            "train loss 0.3578363358974457 accuracy 0.98 | test loss 0.37842684984207153  accuracy 0.92\n",
            "train loss 0.35783591866493225 accuracy 0.98 | test loss 0.37845751643180847  accuracy 0.92\n",
            "train loss 0.35783615708351135 accuracy 0.98 | test loss 0.37841635942459106  accuracy 0.92\n",
            "train loss 0.3578360378742218 accuracy 0.99 | test loss 0.3784891664981842  accuracy 0.92\n",
            "train loss 0.3578369915485382 accuracy 0.98 | test loss 0.37844765186309814  accuracy 0.92\n",
            "train loss 0.35783544182777405 accuracy 0.98 | test loss 0.37842997908592224  accuracy 0.92\n",
            "train loss 0.35783499479293823 accuracy 0.99 | test loss 0.3784756660461426  accuracy 0.92\n",
            "train loss 0.3578360676765442 accuracy 0.98 | test loss 0.3784342408180237  accuracy 0.92\n",
            "train loss 0.3578346073627472 accuracy 0.98 | test loss 0.37841668725013733  accuracy 0.92\n",
            "train loss 0.35783514380455017 accuracy 0.99 | test loss 0.3784894347190857  accuracy 0.92\n",
            "train loss 0.3578360676765442 accuracy 0.98 | test loss 0.37844786047935486  accuracy 0.92\n",
            "train loss 0.35783445835113525 accuracy 0.98 | test loss 0.37840670347213745  accuracy 0.92\n",
            "train loss 0.3578350841999054 accuracy 0.99 | test loss 0.37847957015037537  accuracy 0.92\n",
            "train loss 0.3578352928161621 accuracy 0.98 | test loss 0.3784380257129669  accuracy 0.92\n",
            "train loss 0.3578338027000427 accuracy 0.98 | test loss 0.3784204423427582  accuracy 0.92\n",
            "train loss 0.3578338027000427 accuracy 0.99 | test loss 0.37846606969833374  accuracy 0.92\n",
            "train loss 0.3578343093395233 accuracy 0.98 | test loss 0.3784247040748596  accuracy 0.92\n",
            "train loss 0.35783329606056213 accuracy 0.98 | test loss 0.37845537066459656  accuracy 0.92\n",
            "train loss 0.3578336536884308 accuracy 0.98 | test loss 0.3784140646457672  accuracy 0.92\n",
            "train loss 0.35783329606056213 accuracy 0.99 | test loss 0.3784867823123932  accuracy 0.92\n",
            "train loss 0.3578345477581024 accuracy 0.98 | test loss 0.37842413783073425  accuracy 0.92\n",
            "train loss 0.35783255100250244 accuracy 0.99 | test loss 0.37846964597702026  accuracy 0.92\n",
            "train loss 0.35783353447914124 accuracy 0.98 | test loss 0.378428190946579  accuracy 0.92\n",
            "train loss 0.35783225297927856 accuracy 0.98 | test loss 0.378410667181015  accuracy 0.92\n",
            "train loss 0.35783278942108154 accuracy 0.99 | test loss 0.3784833550453186  accuracy 0.92\n",
            "train loss 0.357833594083786 accuracy 0.98 | test loss 0.3784416913986206  accuracy 0.92\n",
            "train loss 0.3578319549560547 accuracy 0.98 | test loss 0.3784005641937256  accuracy 0.92\n",
            "train loss 0.357832670211792 accuracy 0.99 | test loss 0.3784734010696411  accuracy 0.92\n",
            "train loss 0.35783278942108154 accuracy 0.98 | test loss 0.37843188643455505  accuracy 0.92\n",
            "train loss 0.3578314483165741 accuracy 0.98 | test loss 0.37841421365737915  accuracy 0.92\n",
            "train loss 0.3578314185142517 accuracy 0.99 | test loss 0.3784599304199219  accuracy 0.92\n",
            "train loss 0.3578318655490875 accuracy 0.98 | test loss 0.37841853499412537  accuracy 0.92\n",
            "train loss 0.35783088207244873 accuracy 0.98 | test loss 0.3784492313861847  accuracy 0.92\n",
            "train loss 0.3578311800956726 accuracy 0.98 | test loss 0.3784078061580658  accuracy 0.92\n",
            "train loss 0.35783088207244873 accuracy 0.99 | test loss 0.3784804940223694  accuracy 0.92\n",
            "train loss 0.35783201456069946 accuracy 0.98 | test loss 0.378438800573349  accuracy 0.92\n",
            "train loss 0.3578304946422577 accuracy 0.98 | test loss 0.37842103838920593  accuracy 0.92\n",
            "train loss 0.35782983899116516 accuracy 0.98 | test loss 0.3784516751766205  accuracy 0.92\n",
            "train loss 0.3578305244445801 accuracy 0.98 | test loss 0.37841033935546875  accuracy 0.92\n",
            "train loss 0.3578299582004547 accuracy 0.99 | test loss 0.3784560263156891  accuracy 0.92\n",
            "train loss 0.35783037543296814 accuracy 0.98 | test loss 0.3784146010875702  accuracy 0.92\n",
            "train loss 0.3578292727470398 accuracy 0.98 | test loss 0.37842509150505066  accuracy 0.92\n",
            "train loss 0.3578290343284607 accuracy 0.98 | test loss 0.3783988952636719  accuracy 0.92\n",
            "train loss 0.35782983899116516 accuracy 0.99 | test loss 0.3784715235233307  accuracy 0.92\n",
            "train loss 0.35783034563064575 accuracy 0.98 | test loss 0.37842994928359985  accuracy 0.92\n",
            "train loss 0.3578290045261383 accuracy 0.98 | test loss 0.37841224670410156  accuracy 0.92\n",
            "train loss 0.35782867670059204 accuracy 0.99 | test loss 0.378469854593277  accuracy 0.92\n",
            "train loss 0.3578298091888428 accuracy 0.98 | test loss 0.3784283399581909  accuracy 0.92\n",
            "train loss 0.35782819986343384 accuracy 0.98 | test loss 0.37840214371681213  accuracy 0.92\n",
            "train loss 0.3578285872936249 accuracy 0.99 | test loss 0.37845996022224426  accuracy 0.92\n",
            "train loss 0.3578290343284607 accuracy 0.98 | test loss 0.37841853499412537  accuracy 0.92\n",
            "train loss 0.357827752828598 accuracy 0.98 | test loss 0.37841567397117615  accuracy 0.92\n",
            "train loss 0.3578275144100189 accuracy 0.98 | test loss 0.37844622135162354  accuracy 0.92\n",
            "train loss 0.3578280508518219 accuracy 0.98 | test loss 0.3784048855304718  accuracy 0.92\n",
            "train loss 0.3578275740146637 accuracy 0.99 | test loss 0.3784775137901306  accuracy 0.92\n",
            "train loss 0.35782888531684875 accuracy 0.98 | test loss 0.3784146308898926  accuracy 0.92\n",
            "train loss 0.35782697796821594 accuracy 0.98 | test loss 0.3784323036670685  accuracy 0.92\n",
            "train loss 0.35782694816589355 accuracy 0.98 | test loss 0.37839099764823914  accuracy 0.92\n",
            "train loss 0.35782766342163086 accuracy 0.99 | test loss 0.37846359610557556  accuracy 0.92\n",
            "train loss 0.3578277826309204 accuracy 0.98 | test loss 0.37842199206352234  accuracy 0.92\n",
            "train loss 0.35782644152641296 accuracy 0.98 | test loss 0.37840428948402405  accuracy 0.92\n",
            "train loss 0.35782644152641296 accuracy 0.99 | test loss 0.3784767687320709  accuracy 0.92\n",
            "train loss 0.3578277826309204 accuracy 0.98 | test loss 0.37843501567840576  accuracy 0.92\n",
            "train loss 0.3578261435031891 accuracy 0.98 | test loss 0.3783937096595764  accuracy 0.92\n",
            "train loss 0.3578263819217682 accuracy 0.99 | test loss 0.3784661889076233  accuracy 0.92\n",
            "train loss 0.35782697796821594 accuracy 0.98 | test loss 0.3784245252609253  accuracy 0.92\n",
            "train loss 0.3578256070613861 accuracy 0.98 | test loss 0.378406822681427  accuracy 0.92\n",
            "train loss 0.35782521963119507 accuracy 0.98 | test loss 0.3784373700618744  accuracy 0.92\n",
            "train loss 0.35782545804977417 accuracy 0.98 | test loss 0.3783959746360779  accuracy 0.92\n",
            "train loss 0.35782545804977417 accuracy 0.99 | test loss 0.3784686326980591  accuracy 0.92\n",
            "train loss 0.357826292514801 accuracy 0.98 | test loss 0.3784269392490387  accuracy 0.92\n",
            "train loss 0.35782474279403687 accuracy 0.98 | test loss 0.37840911746025085  accuracy 0.92\n",
            "train loss 0.3578243553638458 accuracy 0.99 | test loss 0.37845462560653687  accuracy 0.92\n",
            "train loss 0.3578253388404846 accuracy 0.98 | test loss 0.37841299176216125  accuracy 0.92\n",
            "train loss 0.35782384872436523 accuracy 0.98 | test loss 0.3784155547618866  accuracy 0.92\n",
            "train loss 0.3578236401081085 accuracy 0.98 | test loss 0.3783978819847107  accuracy 0.92\n",
            "train loss 0.3578243851661682 accuracy 0.99 | test loss 0.3784705400466919  accuracy 0.92\n",
            "train loss 0.35782521963119507 accuracy 0.98 | test loss 0.37842878699302673  accuracy 0.92\n",
            "train loss 0.3578236401081085 accuracy 0.98 | test loss 0.37838736176490784  accuracy 0.92\n",
            "train loss 0.35782432556152344 accuracy 0.99 | test loss 0.37845999002456665  accuracy 0.92\n",
            "train loss 0.3578244745731354 accuracy 0.98 | test loss 0.37841835618019104  accuracy 0.92\n",
            "train loss 0.35782283544540405 accuracy 0.98 | test loss 0.3783770203590393  accuracy 0.92\n",
            "train loss 0.35782432556152344 accuracy 0.99 | test loss 0.37844976782798767  accuracy 0.92\n",
            "train loss 0.3578236699104309 accuracy 0.98 | test loss 0.37840819358825684  accuracy 0.92\n",
            "train loss 0.3578224182128906 accuracy 0.98 | test loss 0.3783905804157257  accuracy 0.92\n",
            "train loss 0.3578230142593384 accuracy 0.99 | test loss 0.3784632384777069  accuracy 0.92\n",
            "train loss 0.3578236401081085 accuracy 0.98 | test loss 0.37842145562171936  accuracy 0.92\n",
            "train loss 0.3578220307826996 accuracy 0.98 | test loss 0.3783801198005676  accuracy 0.92\n",
            "train loss 0.3578229546546936 accuracy 0.99 | test loss 0.3784528970718384  accuracy 0.92\n",
            "train loss 0.35782286524772644 accuracy 0.98 | test loss 0.3784111738204956  accuracy 0.92\n",
            "train loss 0.35782158374786377 accuracy 0.98 | test loss 0.3783934712409973  accuracy 0.92\n",
            "train loss 0.35782167315483093 accuracy 0.99 | test loss 0.37846606969833374  accuracy 0.92\n",
            "train loss 0.35782286524772644 accuracy 0.98 | test loss 0.3784242868423462  accuracy 0.92\n",
            "train loss 0.3578212261199951 accuracy 0.98 | test loss 0.37838295102119446  accuracy 0.92\n",
            "train loss 0.35782161355018616 accuracy 0.99 | test loss 0.37845557928085327  accuracy 0.92\n",
            "train loss 0.357822060585022 accuracy 0.98 | test loss 0.3784139156341553  accuracy 0.92\n",
            "train loss 0.3578207790851593 accuracy 0.98 | test loss 0.37839606404304504  accuracy 0.92\n",
            "train loss 0.3578205108642578 accuracy 0.99 | test loss 0.37844139337539673  accuracy 0.92\n",
            "train loss 0.3578210771083832 accuracy 0.98 | test loss 0.3783997893333435  accuracy 0.92\n",
            "train loss 0.3578200042247772 accuracy 0.98 | test loss 0.3784303069114685  accuracy 0.92\n",
            "train loss 0.35782039165496826 accuracy 0.98 | test loss 0.3783889412879944  accuracy 0.92\n",
            "train loss 0.35781997442245483 accuracy 0.99 | test loss 0.37846145033836365  accuracy 0.92\n",
            "train loss 0.3578213155269623 accuracy 0.98 | test loss 0.3783985376358032  accuracy 0.92\n",
            "train loss 0.35781940817832947 accuracy 0.98 | test loss 0.3784158527851105  accuracy 0.92\n",
            "train loss 0.35781943798065186 accuracy 0.98 | test loss 0.37839797139167786  accuracy 0.92\n",
            "train loss 0.3578190505504608 accuracy 0.98 | test loss 0.37842848896980286  accuracy 0.92\n",
            "train loss 0.35781943798065186 accuracy 0.98 | test loss 0.3783869743347168  accuracy 0.92\n",
            "train loss 0.3578192889690399 accuracy 0.99 | test loss 0.3784596025943756  accuracy 0.92\n",
            "train loss 0.3578202724456787 accuracy 0.98 | test loss 0.3784177303314209  accuracy 0.92\n",
            "train loss 0.357818603515625 accuracy 0.98 | test loss 0.37837642431259155  accuracy 0.92\n",
            "train loss 0.35781919956207275 accuracy 0.99 | test loss 0.37844905257225037  accuracy 0.92\n",
            "train loss 0.35781943798065186 accuracy 0.98 | test loss 0.3784072697162628  accuracy 0.92\n",
            "train loss 0.3578180968761444 accuracy 0.98 | test loss 0.37838947772979736  accuracy 0.92\n",
            "train loss 0.35781797766685486 accuracy 0.99 | test loss 0.3784620463848114  accuracy 0.92\n",
            "train loss 0.35781943798065186 accuracy 0.98 | test loss 0.37842026352882385  accuracy 0.92\n",
            "train loss 0.35781779885292053 accuracy 0.98 | test loss 0.3783787786960602  accuracy 0.92\n",
            "train loss 0.3578179180622101 accuracy 0.99 | test loss 0.37845128774642944  accuracy 0.92\n",
            "train loss 0.357818603515625 accuracy 0.98 | test loss 0.3784095048904419  accuracy 0.92\n",
            "train loss 0.35781726241111755 accuracy 0.98 | test loss 0.37839165329933167  accuracy 0.92\n",
            "train loss 0.3578168451786041 accuracy 0.99 | test loss 0.37843698263168335  accuracy 0.92\n",
            "train loss 0.3578175902366638 accuracy 0.98 | test loss 0.37839528918266296  accuracy 0.92\n",
            "train loss 0.3578163683414459 accuracy 0.98 | test loss 0.3783775866031647  accuracy 0.92\n",
            "train loss 0.35781723260879517 accuracy 0.99 | test loss 0.3784501552581787  accuracy 0.92\n",
            "train loss 0.3578175902366638 accuracy 0.98 | test loss 0.3784083425998688  accuracy 0.92\n",
            "train loss 0.35781601071357727 accuracy 0.98 | test loss 0.37836694717407227  accuracy 0.92\n",
            "train loss 0.357817143201828 accuracy 0.99 | test loss 0.37843963503837585  accuracy 0.92\n",
            "train loss 0.3578168451786041 accuracy 0.98 | test loss 0.3783978819847107  accuracy 0.92\n",
            "train loss 0.35781553387641907 accuracy 0.98 | test loss 0.37838003039360046  accuracy 0.92\n",
            "train loss 0.3578159213066101 accuracy 0.99 | test loss 0.37845268845558167  accuracy 0.92\n",
            "train loss 0.35781681537628174 accuracy 0.98 | test loss 0.37841087579727173  accuracy 0.92\n",
            "train loss 0.3578151762485504 accuracy 0.98 | test loss 0.3783694803714752  accuracy 0.92\n",
            "train loss 0.3578158915042877 accuracy 0.99 | test loss 0.37844210863113403  accuracy 0.92\n",
            "train loss 0.35781601071357727 accuracy 0.98 | test loss 0.3784003257751465  accuracy 0.92\n",
            "train loss 0.3578146994113922 accuracy 0.98 | test loss 0.37838247418403625  accuracy 0.92\n",
            "train loss 0.3578146696090698 accuracy 0.99 | test loss 0.37842780351638794  accuracy 0.92\n",
            "train loss 0.3578149974346161 accuracy 0.98 | test loss 0.37838611006736755  accuracy 0.92\n",
            "train loss 0.35781416296958923 accuracy 0.98 | test loss 0.3784165382385254  accuracy 0.92\n",
            "train loss 0.35781431198120117 accuracy 0.98 | test loss 0.37837496399879456  accuracy 0.92\n",
            "train loss 0.3578142523765564 accuracy 0.99 | test loss 0.37844741344451904  accuracy 0.92\n",
            "train loss 0.3578151762485504 accuracy 0.98 | test loss 0.3784056305885315  accuracy 0.92\n",
            "train loss 0.3578137457370758 accuracy 0.98 | test loss 0.3783877193927765  accuracy 0.92\n",
            "train loss 0.35781317949295044 accuracy 0.98 | test loss 0.3784181475639343  accuracy 0.92\n",
            "train loss 0.35781362652778625 accuracy 0.98 | test loss 0.37837663292884827  accuracy 0.92\n",
            "train loss 0.3578133285045624 accuracy 0.99 | test loss 0.3784492015838623  accuracy 0.92\n",
            "train loss 0.3578144311904907 accuracy 0.98 | test loss 0.3784072697162628  accuracy 0.92\n",
            "train loss 0.35781288146972656 accuracy 0.98 | test loss 0.3783894181251526  accuracy 0.92\n",
            "train loss 0.3578124940395355 accuracy 0.98 | test loss 0.378406822681427  accuracy 0.92\n",
            "train loss 0.3578124940395355 accuracy 0.98 | test loss 0.37836524844169617  accuracy 0.92\n",
            "train loss 0.3578132092952728 accuracy 0.99 | test loss 0.378437876701355  accuracy 0.92\n",
            "train loss 0.35781329870224 accuracy 0.98 | test loss 0.3783961534500122  accuracy 0.92\n",
            "train loss 0.357811838388443 accuracy 0.98 | test loss 0.3783782124519348  accuracy 0.92\n",
            "train loss 0.35781198740005493 accuracy 0.99 | test loss 0.3784506916999817  accuracy 0.92\n",
            "train loss 0.3578132688999176 accuracy 0.98 | test loss 0.3784087300300598  accuracy 0.92\n",
            "train loss 0.3578115999698639 accuracy 0.98 | test loss 0.378367155790329  accuracy 0.92\n",
            "train loss 0.35781195759773254 accuracy 0.99 | test loss 0.37843963503837585  accuracy 0.92\n",
            "train loss 0.35781240463256836 accuracy 0.98 | test loss 0.37839773297309875  accuracy 0.92\n",
            "train loss 0.35781097412109375 accuracy 0.98 | test loss 0.37837982177734375  accuracy 0.92\n",
            "train loss 0.35781076550483704 accuracy 0.99 | test loss 0.37842512130737305  accuracy 0.92\n",
            "train loss 0.35781145095825195 accuracy 0.98 | test loss 0.3783832788467407  accuracy 0.92\n",
            "train loss 0.3578103482723236 accuracy 0.98 | test loss 0.37841376662254333  accuracy 0.92\n",
            "train loss 0.35781076550483704 accuracy 0.98 | test loss 0.37837204337120056  accuracy 0.92\n",
            "train loss 0.3578103482723236 accuracy 0.99 | test loss 0.37844452261924744  accuracy 0.92\n",
            "train loss 0.35781165957450867 accuracy 0.98 | test loss 0.3783814609050751  accuracy 0.92\n",
            "train loss 0.3578096330165863 accuracy 0.99 | test loss 0.3784266710281372  accuracy 0.92\n",
            "train loss 0.3578106462955475 accuracy 0.98 | test loss 0.37838491797447205  accuracy 0.92\n",
            "train loss 0.3578093349933624 accuracy 0.98 | test loss 0.37836703658103943  accuracy 0.92\n",
            "train loss 0.35780996084213257 accuracy 0.99 | test loss 0.37843963503837585  accuracy 0.92\n",
            "train loss 0.3578106164932251 accuracy 0.98 | test loss 0.37839773297309875  accuracy 0.92\n",
            "train loss 0.3578089773654938 accuracy 0.98 | test loss 0.3783562481403351  accuracy 0.92\n",
            "train loss 0.3578099310398102 accuracy 0.99 | test loss 0.37842878699302673  accuracy 0.92\n",
            "train loss 0.35780981183052063 accuracy 0.98 | test loss 0.3783869743347168  accuracy 0.92\n",
            "train loss 0.35780850052833557 accuracy 0.98 | test loss 0.37836912274360657  accuracy 0.92\n",
            "train loss 0.3578087091445923 accuracy 0.99 | test loss 0.37844160199165344  accuracy 0.92\n",
            "train loss 0.35780978202819824 accuracy 0.98 | test loss 0.37839964032173157  accuracy 0.92\n",
            "train loss 0.3578081429004669 accuracy 0.98 | test loss 0.37835806608200073  accuracy 0.92\n",
            "train loss 0.3578087091445923 accuracy 0.99 | test loss 0.3784305453300476  accuracy 0.92\n",
            "train loss 0.3578089475631714 accuracy 0.98 | test loss 0.3783886730670929  accuracy 0.92\n",
            "train loss 0.35780763626098633 accuracy 0.98 | test loss 0.3783707618713379  accuracy 0.92\n",
            "train loss 0.35780754685401917 accuracy 0.99 | test loss 0.37841612100601196  accuracy 0.92\n",
            "train loss 0.3578079640865326 accuracy 0.98 | test loss 0.378374308347702  accuracy 0.92\n",
            "train loss 0.3578070104122162 accuracy 0.98 | test loss 0.37840473651885986  accuracy 0.92\n",
            "train loss 0.35780730843544006 accuracy 0.98 | test loss 0.3783630430698395  accuracy 0.92\n",
            "train loss 0.35780707001686096 accuracy 0.99 | test loss 0.3784354329109192  accuracy 0.92\n",
            "train loss 0.35780811309814453 accuracy 0.98 | test loss 0.3783935010433197  accuracy 0.92\n",
            "train loss 0.3578066825866699 accuracy 0.98 | test loss 0.3783755302429199  accuracy 0.92\n",
            "train loss 0.35780608654022217 accuracy 0.98 | test loss 0.378405898809433  accuracy 0.92\n",
            "train loss 0.357806533575058 accuracy 0.98 | test loss 0.3783641755580902  accuracy 0.92\n",
            "train loss 0.3578062355518341 accuracy 0.99 | test loss 0.3784366548061371  accuracy 0.92\n",
            "train loss 0.35780736804008484 accuracy 0.98 | test loss 0.3783947229385376  accuracy 0.92\n",
            "train loss 0.3578057885169983 accuracy 0.98 | test loss 0.3783767521381378  accuracy 0.92\n",
            "train loss 0.35780540108680725 accuracy 0.98 | test loss 0.37839415669441223  accuracy 0.92\n",
            "train loss 0.35780537128448486 accuracy 0.98 | test loss 0.37835246324539185  accuracy 0.92\n",
            "train loss 0.35780614614486694 accuracy 0.99 | test loss 0.37842506170272827  accuracy 0.92\n",
            "train loss 0.3578062355518341 accuracy 0.98 | test loss 0.37838315963745117  accuracy 0.92\n",
            "train loss 0.3578047454357147 accuracy 0.98 | test loss 0.378365159034729  accuracy 0.92\n",
            "train loss 0.35780492424964905 accuracy 0.99 | test loss 0.3784375786781311  accuracy 0.92\n",
            "train loss 0.35780614614486694 accuracy 0.98 | test loss 0.3783954679965973  accuracy 0.92\n",
            "train loss 0.3578045070171356 accuracy 0.98 | test loss 0.3783538043498993  accuracy 0.92\n",
            "train loss 0.35780492424964905 accuracy 0.99 | test loss 0.3784261643886566  accuracy 0.92\n",
            "train loss 0.3578053116798401 accuracy 0.98 | test loss 0.37838423252105713  accuracy 0.92\n",
            "train loss 0.3578038811683655 accuracy 0.98 | test loss 0.3783663213253021  accuracy 0.92\n",
            "train loss 0.35780373215675354 accuracy 0.99 | test loss 0.37843844294548035  accuracy 0.92\n",
            "train loss 0.3578053116798401 accuracy 0.98 | test loss 0.37839633226394653  accuracy 0.92\n",
            "train loss 0.3578036427497864 accuracy 0.98 | test loss 0.37835463881492615  accuracy 0.92\n",
            "train loss 0.3578037619590759 accuracy 0.99 | test loss 0.3784269690513611  accuracy 0.92\n",
            "train loss 0.35780447721481323 accuracy 0.98 | test loss 0.37838491797447205  accuracy 0.92\n",
            "train loss 0.35780298709869385 accuracy 0.98 | test loss 0.3783668875694275  accuracy 0.92\n",
            "train loss 0.3578026592731476 accuracy 0.99 | test loss 0.378412127494812  accuracy 0.92\n",
            "train loss 0.35780346393585205 accuracy 0.98 | test loss 0.3783701956272125  accuracy 0.92\n",
            "train loss 0.35780227184295654 accuracy 0.98 | test loss 0.37840041518211365  accuracy 0.92\n",
            "train loss 0.35780277848243713 accuracy 0.98 | test loss 0.3783586919307709  accuracy 0.92\n",
            "train loss 0.3578021824359894 accuracy 0.99 | test loss 0.37843093276023865  accuracy 0.92\n",
            "train loss 0.3578036427497864 accuracy 0.98 | test loss 0.3783676326274872  accuracy 0.92\n",
            "train loss 0.3578016459941864 accuracy 0.98 | test loss 0.3783847689628601  accuracy 0.92\n",
            "train loss 0.3578015863895416 accuracy 0.98 | test loss 0.3783666789531708  accuracy 0.92\n",
            "train loss 0.3578013777732849 accuracy 0.99 | test loss 0.3784239590167999  accuracy 0.92\n",
            "train loss 0.3578026592731476 accuracy 0.98 | test loss 0.3783818781375885  accuracy 0.92\n",
            "train loss 0.35780104994773865 accuracy 0.98 | test loss 0.3783753216266632  accuracy 0.92\n",
            "train loss 0.3578009307384491 accuracy 0.98 | test loss 0.37835726141929626  accuracy 0.92\n",
            "train loss 0.3578011095523834 accuracy 0.99 | test loss 0.37841469049453735  accuracy 0.92\n",
            "train loss 0.35780173540115356 accuracy 0.98 | test loss 0.37837278842926025  accuracy 0.92\n",
            "train loss 0.3578002154827118 accuracy 0.98 | test loss 0.37836647033691406  accuracy 0.92\n",
            "train loss 0.35780027508735657 accuracy 0.98 | test loss 0.37837645411491394  accuracy 0.92\n",
            "train loss 0.3578000068664551 accuracy 0.98 | test loss 0.3783583343029022  accuracy 0.92\n",
            "train loss 0.3578002154827118 accuracy 0.99 | test loss 0.37843069434165955  accuracy 0.92\n",
            "train loss 0.3578015863895416 accuracy 0.98 | test loss 0.37838858366012573  accuracy 0.92\n",
            "train loss 0.3577999472618103 accuracy 0.98 | test loss 0.3783467710018158  accuracy 0.92\n",
            "train loss 0.3578002154827118 accuracy 0.99 | test loss 0.37841930985450745  accuracy 0.92\n",
            "train loss 0.35780075192451477 accuracy 0.98 | test loss 0.378377228975296  accuracy 0.92\n",
            "train loss 0.3577991724014282 accuracy 0.98 | test loss 0.37835901975631714  accuracy 0.92\n",
            "train loss 0.35779905319213867 accuracy 0.99 | test loss 0.3784042298793793  accuracy 0.92\n",
            "train loss 0.3577997386455536 accuracy 0.98 | test loss 0.3783622682094574  accuracy 0.92\n",
            "train loss 0.3577984869480133 accuracy 0.98 | test loss 0.3783925175666809  accuracy 0.92\n",
            "train loss 0.35779905319213867 accuracy 0.98 | test loss 0.37835073471069336  accuracy 0.92\n",
            "train loss 0.35779863595962524 accuracy 0.99 | test loss 0.37842312455177307  accuracy 0.92\n",
            "train loss 0.35779985785484314 accuracy 0.98 | test loss 0.3783809542655945  accuracy 0.92\n",
            "train loss 0.3577982187271118 accuracy 0.98 | test loss 0.3783392608165741  accuracy 0.92\n",
            "train loss 0.35779869556427 accuracy 0.99 | test loss 0.37841159105300903  accuracy 0.92\n",
            "train loss 0.3577990233898163 accuracy 0.98 | test loss 0.3783695101737976  accuracy 0.92\n",
            "train loss 0.3577977418899536 accuracy 0.98 | test loss 0.37835150957107544  accuracy 0.92\n",
            "train loss 0.3577974736690521 accuracy 0.99 | test loss 0.37842369079589844  accuracy 0.92\n",
            "train loss 0.3577989935874939 accuracy 0.98 | test loss 0.3783815801143646  accuracy 0.92\n",
            "train loss 0.3577972948551178 accuracy 0.98 | test loss 0.3783397972583771  accuracy 0.92\n",
            "train loss 0.3577975332736969 accuracy 0.99 | test loss 0.3784121572971344  accuracy 0.92\n",
            "train loss 0.35779809951782227 accuracy 0.98 | test loss 0.3783700466156006  accuracy 0.92\n",
            "train loss 0.357796847820282 accuracy 0.98 | test loss 0.3783518373966217  accuracy 0.92\n",
            "train loss 0.35779640078544617 accuracy 0.99 | test loss 0.37839704751968384  accuracy 0.92\n",
            "train loss 0.3577970862388611 accuracy 0.98 | test loss 0.3783551752567291  accuracy 0.92\n",
            "train loss 0.3577960133552551 accuracy 0.98 | test loss 0.378365159034729  accuracy 0.92\n",
            "train loss 0.35779574513435364 accuracy 0.98 | test loss 0.3783470690250397  accuracy 0.92\n",
            "train loss 0.35779625177383423 accuracy 0.99 | test loss 0.3784193992614746  accuracy 0.92\n",
            "train loss 0.357797235250473 accuracy 0.98 | test loss 0.3783772587776184  accuracy 0.92\n",
            "train loss 0.3577956259250641 accuracy 0.98 | test loss 0.37833553552627563  accuracy 0.92\n",
            "train loss 0.357796311378479 accuracy 0.99 | test loss 0.37840795516967773  accuracy 0.92\n",
            "train loss 0.35779643058776855 accuracy 0.98 | test loss 0.3783659040927887  accuracy 0.92\n",
            "train loss 0.3577948808670044 accuracy 0.98 | test loss 0.3783477246761322  accuracy 0.92\n",
            "train loss 0.35779517889022827 accuracy 0.99 | test loss 0.37839293479919434  accuracy 0.92\n",
            "train loss 0.357795387506485 accuracy 0.98 | test loss 0.37835097312927246  accuracy 0.92\n",
            "train loss 0.3577944040298462 accuracy 0.99 | test loss 0.3783959150314331  accuracy 0.92\n",
            "train loss 0.35779523849487305 accuracy 0.98 | test loss 0.37835386395454407  accuracy 0.92\n",
            "train loss 0.35779398679733276 accuracy 0.98 | test loss 0.3783840835094452  accuracy 0.92\n",
            "train loss 0.35779455304145813 accuracy 0.98 | test loss 0.3783422112464905  accuracy 0.92\n",
            "train loss 0.3577940762042999 accuracy 0.99 | test loss 0.37841442227363586  accuracy 0.92\n",
            "train loss 0.357795387506485 accuracy 0.98 | test loss 0.37835097312927246  accuracy 0.92\n",
            "train loss 0.3577934205532074 accuracy 0.98 | test loss 0.3783680200576782  accuracy 0.92\n",
            "train loss 0.3577934205532074 accuracy 0.98 | test loss 0.37834975123405457  accuracy 0.92\n",
            "train loss 0.35779324173927307 accuracy 0.99 | test loss 0.3784070611000061  accuracy 0.92\n",
            "train loss 0.3577944040298462 accuracy 0.98 | test loss 0.3783649504184723  accuracy 0.92\n",
            "train loss 0.35779279470443726 accuracy 0.98 | test loss 0.37833815813064575  accuracy 0.92\n",
            "train loss 0.35779324173927307 accuracy 0.99 | test loss 0.3783954083919525  accuracy 0.92\n",
            "train loss 0.35779356956481934 accuracy 0.98 | test loss 0.3783533275127411  accuracy 0.92\n",
            "train loss 0.3577922284603119 accuracy 0.98 | test loss 0.37837034463882446  accuracy 0.92\n",
            "train loss 0.3577924370765686 accuracy 0.98 | test loss 0.3783285915851593  accuracy 0.92\n",
            "train loss 0.35779303312301636 accuracy 0.99 | test loss 0.3784008026123047  accuracy 0.92\n",
            "train loss 0.3577931821346283 accuracy 0.98 | test loss 0.3783586919307709  accuracy 0.92\n",
            "train loss 0.35779184103012085 accuracy 0.98 | test loss 0.3783404529094696  accuracy 0.92\n",
            "train loss 0.3577919006347656 accuracy 0.99 | test loss 0.3783978223800659  accuracy 0.92\n",
            "train loss 0.3577926456928253 accuracy 0.98 | test loss 0.37835562229156494  accuracy 0.92\n",
            "train loss 0.35779109597206116 accuracy 0.98 | test loss 0.37835246324539185  accuracy 0.92\n",
            "train loss 0.35779088735580444 accuracy 0.98 | test loss 0.3783590495586395  accuracy 0.92\n",
            "train loss 0.3577909767627716 accuracy 0.98 | test loss 0.37834084033966064  accuracy 0.92\n",
            "train loss 0.35779106616973877 accuracy 0.99 | test loss 0.37841305136680603  accuracy 0.92\n",
            "train loss 0.3577924370765686 accuracy 0.98 | test loss 0.3783707618713379  accuracy 0.92\n",
            "train loss 0.3577907979488373 accuracy 0.98 | test loss 0.37832894921302795  accuracy 0.92\n",
            "train loss 0.35779106616973877 accuracy 0.99 | test loss 0.3784012794494629  accuracy 0.92\n",
            "train loss 0.35779157280921936 accuracy 0.98 | test loss 0.3783591687679291  accuracy 0.92\n",
            "train loss 0.3577900528907776 accuracy 0.98 | test loss 0.3783408999443054  accuracy 0.92\n",
            "train loss 0.35778990387916565 accuracy 0.99 | test loss 0.3784131407737732  accuracy 0.92\n",
            "train loss 0.3577915132045746 accuracy 0.98 | test loss 0.37837088108062744  accuracy 0.92\n",
            "train loss 0.35778987407684326 accuracy 0.98 | test loss 0.37832900881767273  accuracy 0.92\n",
            "train loss 0.35778993368148804 accuracy 0.99 | test loss 0.37840133905410767  accuracy 0.92\n",
            "train loss 0.35779067873954773 accuracy 0.98 | test loss 0.3783591389656067  accuracy 0.92\n",
            "train loss 0.35778915882110596 accuracy 0.98 | test loss 0.3783408999443054  accuracy 0.92\n",
            "train loss 0.35778889060020447 accuracy 0.99 | test loss 0.3783859610557556  accuracy 0.92\n",
            "train loss 0.35778963565826416 accuracy 0.98 | test loss 0.3783438801765442  accuracy 0.92\n",
            "train loss 0.3577882945537567 accuracy 0.98 | test loss 0.3783739507198334  accuracy 0.92\n",
            "train loss 0.35778895020484924 accuracy 0.98 | test loss 0.3783319294452667  accuracy 0.92\n",
            "train loss 0.35778847336769104 accuracy 0.99 | test loss 0.37840408086776733  accuracy 0.92\n",
            "train loss 0.3577897548675537 accuracy 0.98 | test loss 0.3783618211746216  accuracy 0.92\n",
            "train loss 0.3577881455421448 accuracy 0.98 | test loss 0.3783435821533203  accuracy 0.92\n",
            "train loss 0.3577875792980194 accuracy 0.98 | test loss 0.37836065888404846  accuracy 0.92\n",
            "train loss 0.35778769850730896 accuracy 0.98 | test loss 0.37831878662109375  accuracy 0.92\n",
            "train loss 0.3577885031700134 accuracy 0.99 | test loss 0.37839093804359436  accuracy 0.92\n",
            "train loss 0.3577885031700134 accuracy 0.98 | test loss 0.37834876775741577  accuracy 0.92\n",
            "train loss 0.3577870726585388 accuracy 0.98 | test loss 0.37833061814308167  accuracy 0.92\n",
            "train loss 0.3577873408794403 accuracy 0.99 | test loss 0.3784027099609375  accuracy 0.92\n",
            "train loss 0.35778847336769104 accuracy 0.98 | test loss 0.3783603608608246  accuracy 0.92\n",
            "train loss 0.35778677463531494 accuracy 0.98 | test loss 0.3783184587955475  accuracy 0.92\n",
            "train loss 0.3577874004840851 accuracy 0.99 | test loss 0.3783906400203705  accuracy 0.92\n",
            "train loss 0.3577875792980194 accuracy 0.98 | test loss 0.3783484697341919  accuracy 0.92\n",
            "train loss 0.3577862083911896 accuracy 0.98 | test loss 0.3783302307128906  accuracy 0.92\n",
            "train loss 0.35778623819351196 accuracy 0.99 | test loss 0.37840232253074646  accuracy 0.92\n",
            "train loss 0.357787549495697 accuracy 0.98 | test loss 0.37835997343063354  accuracy 0.92\n",
            "train loss 0.3577858507633209 accuracy 0.98 | test loss 0.37831804156303406  accuracy 0.92\n",
            "train loss 0.3577863276004791 accuracy 0.99 | test loss 0.37839019298553467  accuracy 0.92\n",
            "train loss 0.3577866554260254 accuracy 0.98 | test loss 0.37834808230400085  accuracy 0.92\n",
            "train loss 0.35778528451919556 accuracy 0.98 | test loss 0.3783298134803772  accuracy 0.92\n",
            "train loss 0.357785165309906 accuracy 0.99 | test loss 0.3784020245075226  accuracy 0.92\n",
            "train loss 0.3577865958213806 accuracy 0.98 | test loss 0.37835967540740967  accuracy 0.92\n",
            "train loss 0.3577849566936493 accuracy 0.98 | test loss 0.3783177435398102  accuracy 0.92\n",
            "train loss 0.3577852249145508 accuracy 0.99 | test loss 0.3783898949623108  accuracy 0.92\n",
            "train loss 0.357785701751709 accuracy 0.98 | test loss 0.37834757566452026  accuracy 0.92\n",
            "train loss 0.3577844202518463 accuracy 0.98 | test loss 0.3783293068408966  accuracy 0.92\n",
            "train loss 0.35778412222862244 accuracy 0.99 | test loss 0.3783743679523468  accuracy 0.92\n",
            "train loss 0.3577847182750702 accuracy 0.98 | test loss 0.3783322870731354  accuracy 0.92\n",
            "train loss 0.3577837347984314 accuracy 0.99 | test loss 0.3783894181251526  accuracy 0.92\n",
            "train loss 0.3577849566936493 accuracy 0.98 | test loss 0.37834712862968445  accuracy 0.92\n",
            "train loss 0.3577834367752075 accuracy 0.98 | test loss 0.3783288598060608  accuracy 0.92\n",
            "train loss 0.3577834367752075 accuracy 0.99 | test loss 0.3783739507198334  accuracy 0.92\n",
            "train loss 0.3577839434146881 accuracy 0.98 | test loss 0.3783318102359772  accuracy 0.92\n",
            "train loss 0.3577827513217926 accuracy 0.98 | test loss 0.3783618211746216  accuracy 0.92\n",
            "train loss 0.3577832281589508 accuracy 0.98 | test loss 0.3783198595046997  accuracy 0.92\n",
            "train loss 0.3577829897403717 accuracy 0.99 | test loss 0.3783921003341675  accuracy 0.92\n",
            "train loss 0.3577840328216553 accuracy 0.98 | test loss 0.37834978103637695  accuracy 0.92\n",
            "train loss 0.35778242349624634 accuracy 0.98 | test loss 0.3783314526081085  accuracy 0.92\n",
            "train loss 0.3577820360660553 accuracy 0.98 | test loss 0.37834852933883667  accuracy 0.92\n",
            "train loss 0.3577819764614105 accuracy 0.98 | test loss 0.3783065676689148  accuracy 0.92\n",
            "train loss 0.3577830493450165 accuracy 0.99 | test loss 0.37837880849838257  accuracy 0.92\n",
            "train loss 0.3577828109264374 accuracy 0.98 | test loss 0.3783365786075592  accuracy 0.92\n",
            "train loss 0.3577813506126404 accuracy 0.98 | test loss 0.3783183693885803  accuracy 0.92\n",
            "train loss 0.35778188705444336 accuracy 0.99 | test loss 0.37839046120643616  accuracy 0.92\n",
            "train loss 0.3577827513217926 accuracy 0.98 | test loss 0.3783479928970337  accuracy 0.92\n",
            "train loss 0.3577810525894165 accuracy 0.98 | test loss 0.3783060610294342  accuracy 0.92\n",
            "train loss 0.35778194665908813 accuracy 0.99 | test loss 0.378378301858902  accuracy 0.92\n",
            "train loss 0.35778185725212097 accuracy 0.98 | test loss 0.378336101770401  accuracy 0.92\n",
            "train loss 0.35778045654296875 accuracy 0.98 | test loss 0.37831783294677734  accuracy 0.92\n",
            "train loss 0.357780784368515 accuracy 0.99 | test loss 0.3783899247646332  accuracy 0.92\n",
            "train loss 0.3577818274497986 accuracy 0.98 | test loss 0.3783475160598755  accuracy 0.92\n",
            "train loss 0.3577801287174225 accuracy 0.98 | test loss 0.37830549478530884  accuracy 0.92\n",
            "train loss 0.3577808439731598 accuracy 0.99 | test loss 0.37837767601013184  accuracy 0.92\n",
            "train loss 0.35778093338012695 accuracy 0.98 | test loss 0.3783353269100189  accuracy 0.92\n",
            "train loss 0.35777953267097473 accuracy 0.98 | test loss 0.3783170282840729  accuracy 0.92\n",
            "train loss 0.35777971148490906 accuracy 0.99 | test loss 0.3783891499042511  accuracy 0.92\n",
            "train loss 0.3577808737754822 accuracy 0.98 | test loss 0.378346711397171  accuracy 0.92\n",
            "train loss 0.35777923464775085 accuracy 0.98 | test loss 0.37830469012260437  accuracy 0.92\n",
            "train loss 0.3577798008918762 accuracy 0.99 | test loss 0.378376841545105  accuracy 0.92\n",
            "train loss 0.3577800393104553 accuracy 0.98 | test loss 0.37833449244499207  accuracy 0.92\n",
            "train loss 0.3577786684036255 accuracy 0.98 | test loss 0.3783162236213684  accuracy 0.92\n",
            "train loss 0.3577786982059479 accuracy 0.99 | test loss 0.37838828563690186  accuracy 0.92\n",
            "train loss 0.35777994990348816 accuracy 0.98 | test loss 0.37834587693214417  accuracy 0.92\n",
            "train loss 0.35777831077575684 accuracy 0.98 | test loss 0.37830379605293274  accuracy 0.92\n",
            "train loss 0.35777872800827026 accuracy 0.99 | test loss 0.3783758878707886  accuracy 0.92\n",
            "train loss 0.3577790856361389 accuracy 0.98 | test loss 0.37833356857299805  accuracy 0.92\n",
            "train loss 0.35777774453163147 accuracy 0.98 | test loss 0.3783152401447296  accuracy 0.92\n",
            "train loss 0.3577776551246643 accuracy 0.99 | test loss 0.3783602714538574  accuracy 0.92\n",
            "train loss 0.35777804255485535 accuracy 0.98 | test loss 0.37831810116767883  accuracy 0.92\n",
            "train loss 0.3577772080898285 accuracy 0.98 | test loss 0.37834808230400085  accuracy 0.92\n",
            "train loss 0.35777732729911804 accuracy 0.98 | test loss 0.37830597162246704  accuracy 0.92\n",
            "train loss 0.35777732729911804 accuracy 0.99 | test loss 0.3783780634403229  accuracy 0.92\n",
            "train loss 0.3577781617641449 accuracy 0.98 | test loss 0.37833571434020996  accuracy 0.92\n",
            "train loss 0.3577767014503479 accuracy 0.98 | test loss 0.37831732630729675  accuracy 0.92\n",
            "train loss 0.35777631402015686 accuracy 0.99 | test loss 0.37836217880249023  accuracy 0.92\n",
            "train loss 0.35777708888053894 accuracy 0.98 | test loss 0.3783199191093445  accuracy 0.92\n",
            "train loss 0.35777589678764343 accuracy 0.98 | test loss 0.3783499300479889  accuracy 0.92\n",
            "train loss 0.35777637362480164 accuracy 0.98 | test loss 0.3783078193664551  accuracy 0.92\n",
            "train loss 0.3577759563922882 accuracy 0.99 | test loss 0.37837982177734375  accuracy 0.92\n",
            "train loss 0.3577772378921509 accuracy 0.98 | test loss 0.378316193819046  accuracy 0.92\n",
            "train loss 0.35777536034584045 accuracy 0.98 | test loss 0.37833303213119507  accuracy 0.92\n",
            "train loss 0.3577752709388733 accuracy 0.98 | test loss 0.3783145844936371  accuracy 0.92\n",
            "train loss 0.35777512192726135 accuracy 0.99 | test loss 0.3783716857433319  accuracy 0.92\n",
            "train loss 0.3577761650085449 accuracy 0.98 | test loss 0.37832939624786377  accuracy 0.92\n",
            "train loss 0.3577747344970703 accuracy 0.98 | test loss 0.3783226013183594  accuracy 0.92\n",
            "train loss 0.3577745854854584 accuracy 0.98 | test loss 0.37830427289009094  accuracy 0.92\n",
            "train loss 0.357774943113327 accuracy 0.99 | test loss 0.37837618589401245  accuracy 0.92\n",
            "train loss 0.35777580738067627 accuracy 0.98 | test loss 0.37833371758461  accuracy 0.92\n",
            "train loss 0.35777410864830017 accuracy 0.98 | test loss 0.3783152401447296  accuracy 0.92\n",
            "train loss 0.35777390003204346 accuracy 0.99 | test loss 0.378359854221344  accuracy 0.92\n",
            "train loss 0.3577747344970703 accuracy 0.98 | test loss 0.3783175051212311  accuracy 0.92\n",
            "train loss 0.3577735126018524 accuracy 0.99 | test loss 0.37837454676628113  accuracy 0.92\n",
            "train loss 0.357774943113327 accuracy 0.98 | test loss 0.3783320486545563  accuracy 0.92\n",
            "train loss 0.3577733039855957 accuracy 0.98 | test loss 0.37828996777534485  accuracy 0.92\n",
            "train loss 0.3577743470668793 accuracy 0.99 | test loss 0.37836217880249023  accuracy 0.92\n",
            "train loss 0.35777410864830017 accuracy 0.98 | test loss 0.3783198595046997  accuracy 0.92\n",
            "train loss 0.35777270793914795 accuracy 0.98 | test loss 0.3783015310764313  accuracy 0.92\n",
            "train loss 0.35777321457862854 accuracy 0.99 | test loss 0.3783736228942871  accuracy 0.92\n",
            "train loss 0.3577740490436554 accuracy 0.98 | test loss 0.37833112478256226  accuracy 0.92\n",
            "train loss 0.3577723503112793 accuracy 0.98 | test loss 0.3782890737056732  accuracy 0.92\n",
            "train loss 0.3577732741832733 accuracy 0.99 | test loss 0.3783612847328186  accuracy 0.92\n",
            "train loss 0.35777315497398376 accuracy 0.98 | test loss 0.3783189356327057  accuracy 0.92\n",
            "train loss 0.35777175426483154 accuracy 0.98 | test loss 0.37830057740211487  accuracy 0.92\n",
            "train loss 0.35777217149734497 accuracy 0.99 | test loss 0.3783727288246155  accuracy 0.92\n",
            "train loss 0.357773095369339 accuracy 0.98 | test loss 0.37833017110824585  accuracy 0.92\n",
            "train loss 0.3577713966369629 accuracy 0.98 | test loss 0.3782881200313568  accuracy 0.92\n",
            "train loss 0.3577722907066345 accuracy 0.99 | test loss 0.3783603608608246  accuracy 0.92\n",
            "train loss 0.35777226090431213 accuracy 0.98 | test loss 0.3783179819583893  accuracy 0.92\n",
            "train loss 0.3577708601951599 accuracy 0.98 | test loss 0.3782995939254761  accuracy 0.92\n",
            "train loss 0.3577711284160614 accuracy 0.99 | test loss 0.37834465503692627  accuracy 0.92\n",
            "train loss 0.3577711880207062 accuracy 0.98 | test loss 0.37830236554145813  accuracy 0.92\n",
            "train loss 0.3577704429626465 accuracy 0.99 | test loss 0.37834715843200684  accuracy 0.92\n",
            "train loss 0.35777097940444946 accuracy 0.98 | test loss 0.3783048093318939  accuracy 0.92\n",
            "train loss 0.35777008533477783 accuracy 0.99 | test loss 0.3783618211746216  accuracy 0.92\n",
            "train loss 0.35777121782302856 accuracy 0.98 | test loss 0.3783193528652191  accuracy 0.92\n",
            "train loss 0.35776984691619873 accuracy 0.98 | test loss 0.37830087542533875  accuracy 0.92\n",
            "train loss 0.35776981711387634 accuracy 0.99 | test loss 0.378345787525177  accuracy 0.92\n",
            "train loss 0.357770174741745 accuracy 0.98 | test loss 0.3783034384250641  accuracy 0.92\n",
            "train loss 0.3577691614627838 accuracy 0.99 | test loss 0.37834814190864563  accuracy 0.92\n",
            "train loss 0.35776999592781067 accuracy 0.98 | test loss 0.3783058226108551  accuracy 0.92\n",
            "train loss 0.3577688932418823 accuracy 0.98 | test loss 0.378315269947052  accuracy 0.92\n",
            "train loss 0.35776862502098083 accuracy 0.98 | test loss 0.37829676270484924  accuracy 0.92\n",
            "train loss 0.3577691614627838 accuracy 0.99 | test loss 0.3783687651157379  accuracy 0.92\n",
            "train loss 0.35777008533477783 accuracy 0.98 | test loss 0.3783261775970459  accuracy 0.92\n",
            "train loss 0.35776838660240173 accuracy 0.98 | test loss 0.3782840669155121  accuracy 0.92\n",
            "train loss 0.3577692210674286 accuracy 0.99 | test loss 0.3783561587333679  accuracy 0.92\n",
            "train loss 0.3577692210674286 accuracy 0.98 | test loss 0.37831375002861023  accuracy 0.92\n",
            "train loss 0.3577677011489868 accuracy 0.98 | test loss 0.3782952129840851  accuracy 0.92\n",
            "train loss 0.357768177986145 accuracy 0.99 | test loss 0.37836721539497375  accuracy 0.92\n",
            "train loss 0.3577691614627838 accuracy 0.98 | test loss 0.37832462787628174  accuracy 0.92\n",
            "train loss 0.3577674329280853 accuracy 0.98 | test loss 0.37828245759010315  accuracy 0.92\n",
            "train loss 0.3577682375907898 accuracy 0.99 | test loss 0.37835463881492615  accuracy 0.92\n",
            "train loss 0.3577682375907898 accuracy 0.98 | test loss 0.37831205129623413  accuracy 0.92\n",
            "train loss 0.3577667772769928 accuracy 0.98 | test loss 0.378293514251709  accuracy 0.92\n",
            "train loss 0.35776713490486145 accuracy 0.99 | test loss 0.3783654570579529  accuracy 0.92\n",
            "train loss 0.357768177986145 accuracy 0.98 | test loss 0.37832289934158325  accuracy 0.92\n",
            "train loss 0.3577664792537689 accuracy 0.98 | test loss 0.37828078866004944  accuracy 0.92\n",
            "train loss 0.357767254114151 accuracy 0.99 | test loss 0.37835291028022766  accuracy 0.92\n",
            "train loss 0.3577673137187958 accuracy 0.98 | test loss 0.3783104717731476  accuracy 0.92\n",
            "train loss 0.35776588320732117 accuracy 0.98 | test loss 0.3782918155193329  accuracy 0.92\n",
            "train loss 0.35776618123054504 accuracy 0.99 | test loss 0.378336638212204  accuracy 0.92\n",
            "train loss 0.35776621103286743 accuracy 0.98 | test loss 0.37829428911209106  accuracy 0.92\n",
            "train loss 0.3577654957771301 accuracy 0.99 | test loss 0.37833893299102783  accuracy 0.92\n",
            "train loss 0.3577660322189331 accuracy 0.98 | test loss 0.37829649448394775  accuracy 0.92\n",
            "train loss 0.3577651083469391 accuracy 0.99 | test loss 0.37835344672203064  accuracy 0.92\n",
            "train loss 0.3577662706375122 accuracy 0.98 | test loss 0.37831100821495056  accuracy 0.92\n",
            "train loss 0.3577648103237152 accuracy 0.98 | test loss 0.37829235196113586  accuracy 0.92\n",
            "train loss 0.35776486992836 accuracy 0.99 | test loss 0.37833717465400696  accuracy 0.92\n",
            "train loss 0.35776522755622864 accuracy 0.98 | test loss 0.37829479575157166  accuracy 0.92\n",
            "train loss 0.35776418447494507 accuracy 0.99 | test loss 0.3783394396305084  accuracy 0.92\n",
            "train loss 0.3577650487422943 accuracy 0.98 | test loss 0.37829700112342834  accuracy 0.92\n",
            "train loss 0.3577638268470764 accuracy 0.98 | test loss 0.3782784044742584  accuracy 0.92\n",
            "train loss 0.3577648103237152 accuracy 0.99 | test loss 0.3783504366874695  accuracy 0.92\n",
            "train loss 0.35776495933532715 accuracy 0.98 | test loss 0.37830793857574463  accuracy 0.92\n",
            "train loss 0.3577633500099182 accuracy 0.98 | test loss 0.37828928232192993  accuracy 0.92\n",
            "train loss 0.35776370763778687 accuracy 0.99 | test loss 0.3783612847328186  accuracy 0.92\n",
            "train loss 0.35776486992836 accuracy 0.98 | test loss 0.37831854820251465  accuracy 0.92\n",
            "train loss 0.3577632009983063 accuracy 0.98 | test loss 0.3782762885093689  accuracy 0.92\n",
            "train loss 0.3577638268470764 accuracy 0.99 | test loss 0.37834829092025757  accuracy 0.92\n",
            "train loss 0.35776397585868835 accuracy 0.98 | test loss 0.3783058226108551  accuracy 0.92\n",
            "train loss 0.3577624559402466 accuracy 0.98 | test loss 0.3782871663570404  accuracy 0.92\n",
            "train loss 0.35776275396347046 accuracy 0.99 | test loss 0.3783591389656067  accuracy 0.92\n",
            "train loss 0.3577638864517212 accuracy 0.98 | test loss 0.37831640243530273  accuracy 0.92\n",
            "train loss 0.3577622175216675 accuracy 0.98 | test loss 0.378274142742157  accuracy 0.92\n",
            "train loss 0.35776287317276 accuracy 0.99 | test loss 0.37834617495536804  accuracy 0.92\n",
            "train loss 0.3577629625797272 accuracy 0.98 | test loss 0.378303587436676  accuracy 0.92\n",
            "train loss 0.35776153206825256 accuracy 0.98 | test loss 0.37828493118286133  accuracy 0.92\n",
            "train loss 0.35776177048683167 accuracy 0.99 | test loss 0.3783569633960724  accuracy 0.92\n",
            "train loss 0.3577629327774048 accuracy 0.98 | test loss 0.37831422686576843  accuracy 0.92\n",
            "train loss 0.3577612340450287 accuracy 0.98 | test loss 0.3782719373703003  accuracy 0.92\n",
            "train loss 0.3577619194984436 accuracy 0.99 | test loss 0.37834399938583374  accuracy 0.92\n",
            "train loss 0.35776200890541077 accuracy 0.98 | test loss 0.37830138206481934  accuracy 0.92\n",
            "train loss 0.35776060819625854 accuracy 0.98 | test loss 0.378282755613327  accuracy 0.92\n",
            "train loss 0.35776081681251526 accuracy 0.99 | test loss 0.37832754850387573  accuracy 0.92\n",
            "train loss 0.3577609658241272 accuracy 0.98 | test loss 0.37828508019447327  accuracy 0.92\n",
            "train loss 0.3577602803707123 accuracy 0.99 | test loss 0.37834206223487854  accuracy 0.92\n",
            "train loss 0.3577612340450287 accuracy 0.98 | test loss 0.3782995045185089  accuracy 0.92\n",
            "train loss 0.3577597439289093 accuracy 0.98 | test loss 0.3783160448074341  accuracy 0.92\n",
            "train loss 0.357759952545166 accuracy 0.98 | test loss 0.37827369570732117  accuracy 0.92\n",
            "train loss 0.35776007175445557 accuracy 0.99 | test loss 0.3783307671546936  accuracy 0.92\n",
            "train loss 0.3577602207660675 accuracy 0.98 | test loss 0.3782881796360016  accuracy 0.92\n",
            "train loss 0.3577592074871063 accuracy 0.98 | test loss 0.37830477952957153  accuracy 0.92\n",
            "train loss 0.3577590882778168 accuracy 0.98 | test loss 0.37828612327575684  accuracy 0.92\n",
            "train loss 0.3577588200569153 accuracy 0.98 | test loss 0.37831583619117737  accuracy 0.92\n",
            "train loss 0.3577590584754944 accuracy 0.98 | test loss 0.37827348709106445  accuracy 0.92\n",
            "train loss 0.3577592074871063 accuracy 0.99 | test loss 0.3783455193042755  accuracy 0.92\n",
            "train loss 0.35775986313819885 accuracy 0.98 | test loss 0.37830275297164917  accuracy 0.92\n",
            "train loss 0.35775816440582275 accuracy 0.98 | test loss 0.3782605528831482  accuracy 0.92\n",
            "train loss 0.3577593266963959 accuracy 0.99 | test loss 0.3783325254917145  accuracy 0.92\n",
            "train loss 0.35775893926620483 accuracy 0.98 | test loss 0.3782900273799896  accuracy 0.92\n",
            "train loss 0.35775768756866455 accuracy 0.98 | test loss 0.3782714009284973  accuracy 0.92\n",
            "train loss 0.3577582538127899 accuracy 0.99 | test loss 0.3783434331417084  accuracy 0.92\n",
            "train loss 0.35775884985923767 accuracy 0.98 | test loss 0.3783006966114044  accuracy 0.92\n",
            "train loss 0.35775721073150635 accuracy 0.98 | test loss 0.3782820403575897  accuracy 0.92\n",
            "train loss 0.35775724053382874 accuracy 0.99 | test loss 0.37832680344581604  accuracy 0.92\n",
            "train loss 0.3577577769756317 accuracy 0.98 | test loss 0.3782842457294464  accuracy 0.92\n",
            "train loss 0.3577566146850586 accuracy 0.98 | test loss 0.37831395864486694  accuracy 0.92\n",
            "train loss 0.3577570617198944 accuracy 0.98 | test loss 0.37827157974243164  accuracy 0.92\n",
            "train loss 0.35775694251060486 accuracy 0.99 | test loss 0.3783435821533203  accuracy 0.92\n",
            "train loss 0.3577578663825989 accuracy 0.98 | test loss 0.37830084562301636  accuracy 0.92\n",
            "train loss 0.3577561378479004 accuracy 0.98 | test loss 0.3782821297645569  accuracy 0.92\n",
            "train loss 0.3577560484409332 accuracy 0.99 | test loss 0.3783268630504608  accuracy 0.92\n",
            "train loss 0.35775676369667053 accuracy 0.98 | test loss 0.3782843351364136  accuracy 0.92\n",
            "train loss 0.3577553331851959 accuracy 0.98 | test loss 0.3783140480518341  accuracy 0.92\n",
            "train loss 0.3577560484409332 accuracy 0.98 | test loss 0.37827152013778687  accuracy 0.92\n",
            "train loss 0.3577556610107422 accuracy 0.99 | test loss 0.3783433437347412  accuracy 0.92\n",
            "train loss 0.3577567934989929 accuracy 0.98 | test loss 0.37830060720443726  accuracy 0.92\n",
            "train loss 0.3577551245689392 accuracy 0.98 | test loss 0.3782583177089691  accuracy 0.92\n",
            "train loss 0.3577558100223541 accuracy 0.99 | test loss 0.3783303499221802  accuracy 0.92\n",
            "train loss 0.3577558696269989 accuracy 0.98 | test loss 0.3782876431941986  accuracy 0.92\n",
            "train loss 0.3577546179294586 accuracy 0.98 | test loss 0.3782690465450287  accuracy 0.92\n",
            "train loss 0.35775473713874817 accuracy 0.99 | test loss 0.3783409893512726  accuracy 0.92\n",
            "train loss 0.3577558100223541 accuracy 0.98 | test loss 0.378298282623291  accuracy 0.92\n",
            "train loss 0.3577541708946228 accuracy 0.98 | test loss 0.3782794773578644  accuracy 0.92\n",
            "train loss 0.3577538728713989 accuracy 0.98 | test loss 0.3782961964607239  accuracy 0.92\n",
            "train loss 0.3577536940574646 accuracy 0.98 | test loss 0.37825384736061096  accuracy 0.92\n",
            "train loss 0.3577548861503601 accuracy 0.99 | test loss 0.3783257305622101  accuracy 0.92\n",
            "train loss 0.35775449872016907 accuracy 0.98 | test loss 0.3782830834388733  accuracy 0.92\n",
            "train loss 0.35775306820869446 accuracy 0.98 | test loss 0.3782643675804138  accuracy 0.92\n",
            "train loss 0.35775381326675415 accuracy 0.99 | test loss 0.3783361315727234  accuracy 0.92\n",
            "train loss 0.35775434970855713 accuracy 0.98 | test loss 0.37829336524009705  accuracy 0.92\n",
            "train loss 0.3577526807785034 accuracy 0.98 | test loss 0.37825101613998413  accuracy 0.92\n",
            "train loss 0.3577539622783661 accuracy 0.99 | test loss 0.3783228099346161  accuracy 0.92\n",
            "train loss 0.3577534854412079 accuracy 0.98 | test loss 0.37828025221824646  accuracy 0.92\n",
            "train loss 0.35775211453437805 accuracy 0.98 | test loss 0.3782615661621094  accuracy 0.92\n",
            "train loss 0.3577529191970825 accuracy 0.99 | test loss 0.37833350896835327  accuracy 0.92\n",
            "train loss 0.3577533960342407 accuracy 0.98 | test loss 0.37829065322875977  accuracy 0.92\n",
            "train loss 0.3577516973018646 accuracy 0.98 | test loss 0.37824833393096924  accuracy 0.92\n",
            "train loss 0.35775306820869446 accuracy 0.99 | test loss 0.3783203661441803  accuracy 0.92\n",
            "train loss 0.3577524721622467 accuracy 0.98 | test loss 0.3782776892185211  accuracy 0.92\n",
            "train loss 0.35775119066238403 accuracy 0.98 | test loss 0.37827929854393005  accuracy 0.92\n",
            "train loss 0.35775092244148254 accuracy 0.98 | test loss 0.37826061248779297  accuracy 0.92\n",
            "train loss 0.3577517569065094 accuracy 0.99 | test loss 0.3783325254917145  accuracy 0.92\n",
            "train loss 0.3577522933483124 accuracy 0.98 | test loss 0.37828966975212097  accuracy 0.92\n",
            "train loss 0.35775062441825867 accuracy 0.98 | test loss 0.37824732065200806  accuracy 0.92\n",
            "train loss 0.35775190591812134 accuracy 0.99 | test loss 0.37831932306289673  accuracy 0.92\n",
            "train loss 0.35775136947631836 accuracy 0.98 | test loss 0.37827661633491516  accuracy 0.92\n",
            "train loss 0.3577499985694885 accuracy 0.98 | test loss 0.3782782554626465  accuracy 0.92\n",
            "train loss 0.35774973034858704 accuracy 0.98 | test loss 0.3782595694065094  accuracy 0.92\n",
            "train loss 0.35775065422058105 accuracy 0.99 | test loss 0.37833139300346375  accuracy 0.92\n",
            "train loss 0.3577512204647064 accuracy 0.98 | test loss 0.3782885670661926  accuracy 0.92\n",
            "train loss 0.3577495217323303 accuracy 0.98 | test loss 0.37824615836143494  accuracy 0.92\n",
            "train loss 0.3577507734298706 accuracy 0.99 | test loss 0.3783181607723236  accuracy 0.92\n",
            "train loss 0.3577503263950348 accuracy 0.98 | test loss 0.37827545404434204  accuracy 0.92\n",
            "train loss 0.3577488362789154 accuracy 0.98 | test loss 0.3782770335674286  accuracy 0.92\n",
            "train loss 0.3577485680580139 accuracy 0.98 | test loss 0.3782583177089691  accuracy 0.92\n",
            "train loss 0.3577495515346527 accuracy 0.99 | test loss 0.37833014130592346  accuracy 0.92\n",
            "train loss 0.3577501177787781 accuracy 0.98 | test loss 0.37828731536865234  accuracy 0.92\n",
            "train loss 0.357748419046402 accuracy 0.98 | test loss 0.3782448470592499  accuracy 0.92\n",
            "train loss 0.35774967074394226 accuracy 0.99 | test loss 0.3783167898654938  accuracy 0.92\n",
            "train loss 0.35774919390678406 accuracy 0.98 | test loss 0.3782741129398346  accuracy 0.92\n",
            "train loss 0.3577476441860199 accuracy 0.98 | test loss 0.3782905638217926  accuracy 0.92\n",
            "train loss 0.35774797201156616 accuracy 0.98 | test loss 0.37824809551239014  accuracy 0.92\n",
            "train loss 0.3577485680580139 accuracy 0.99 | test loss 0.37830495834350586  accuracy 0.92\n",
            "train loss 0.35774821043014526 accuracy 0.98 | test loss 0.3782622814178467  accuracy 0.92\n",
            "train loss 0.35774728655815125 accuracy 0.99 | test loss 0.3783068358898163  accuracy 0.92\n",
            "train loss 0.35774797201156616 accuracy 0.98 | test loss 0.3782641887664795  accuracy 0.92\n",
            "train loss 0.357746958732605 accuracy 0.98 | test loss 0.37830066680908203  accuracy 0.92\n",
            "train loss 0.35774746537208557 accuracy 0.98 | test loss 0.3782581388950348  accuracy 0.92\n",
            "train loss 0.357746958732605 accuracy 0.99 | test loss 0.3783026933670044  accuracy 0.92\n",
            "train loss 0.35774725675582886 accuracy 0.98 | test loss 0.3782599866390228  accuracy 0.92\n",
            "train loss 0.35774630308151245 accuracy 0.99 | test loss 0.3783046007156372  accuracy 0.92\n",
            "train loss 0.35774701833724976 accuracy 0.98 | test loss 0.37826186418533325  accuracy 0.92\n",
            "train loss 0.35774603486061096 accuracy 0.98 | test loss 0.37827131152153015  accuracy 0.92\n",
            "train loss 0.3577457368373871 accuracy 0.98 | test loss 0.3782673180103302  accuracy 0.92\n",
            "train loss 0.357745498418808 accuracy 0.98 | test loss 0.3782968819141388  accuracy 0.92\n",
            "train loss 0.3577461242675781 accuracy 0.98 | test loss 0.378254234790802  accuracy 0.92\n",
            "train loss 0.3577457368373871 accuracy 0.99 | test loss 0.3783259391784668  accuracy 0.92\n",
            "train loss 0.357746958732605 accuracy 0.98 | test loss 0.3782617747783661  accuracy 0.92\n",
            "train loss 0.35774505138397217 accuracy 0.99 | test loss 0.37830623984336853  accuracy 0.92\n",
            "train loss 0.35774585604667664 accuracy 0.98 | test loss 0.3782635033130646  accuracy 0.92\n",
            "train loss 0.3577445149421692 accuracy 0.98 | test loss 0.37829315662384033  accuracy 0.92\n",
            "train loss 0.35774508118629456 accuracy 0.98 | test loss 0.3782505691051483  accuracy 0.92\n",
            "train loss 0.35774481296539307 accuracy 0.99 | test loss 0.37832221388816833  accuracy 0.92\n",
            "train loss 0.357745885848999 accuracy 0.98 | test loss 0.37825807929039  accuracy 0.92\n",
            "train loss 0.35774415731430054 accuracy 0.98 | test loss 0.378274530172348  accuracy 0.92\n",
            "train loss 0.35774385929107666 accuracy 0.98 | test loss 0.37825560569763184  accuracy 0.92\n",
            "train loss 0.35774409770965576 accuracy 0.99 | test loss 0.37832725048065186  accuracy 0.92\n",
            "train loss 0.35774537920951843 accuracy 0.98 | test loss 0.37828418612480164  accuracy 0.92\n",
            "train loss 0.3577437102794647 accuracy 0.98 | test loss 0.3782416880130768  accuracy 0.92\n",
            "train loss 0.3577442765235901 accuracy 0.99 | test loss 0.3783133327960968  accuracy 0.92\n",
            "train loss 0.3577444851398468 accuracy 0.98 | test loss 0.3782704472541809  accuracy 0.92\n",
            "train loss 0.35774287581443787 accuracy 0.98 | test loss 0.3782515525817871  accuracy 0.92\n",
            "train loss 0.3577432930469513 accuracy 0.99 | test loss 0.3783230781555176  accuracy 0.92\n",
            "train loss 0.35774433612823486 accuracy 0.98 | test loss 0.3782801032066345  accuracy 0.92\n",
            "train loss 0.3577426075935364 accuracy 0.98 | test loss 0.3782375752925873  accuracy 0.92\n",
            "train loss 0.35774344205856323 accuracy 0.99 | test loss 0.378309428691864  accuracy 0.92\n",
            "train loss 0.35774344205856323 accuracy 0.98 | test loss 0.37826651334762573  accuracy 0.92\n",
            "train loss 0.35774192214012146 accuracy 0.98 | test loss 0.37824758887290955  accuracy 0.92\n",
            "train loss 0.35774245858192444 accuracy 0.99 | test loss 0.3783193528652191  accuracy 0.92\n",
            "train loss 0.3577432930469513 accuracy 0.98 | test loss 0.37827640771865845  accuracy 0.92\n",
            "train loss 0.3577416241168976 accuracy 0.98 | test loss 0.3782338500022888  accuracy 0.92\n",
            "train loss 0.357742577791214 accuracy 0.99 | test loss 0.37830573320388794  accuracy 0.92\n",
            "train loss 0.3577423691749573 accuracy 0.98 | test loss 0.37826284766197205  accuracy 0.92\n",
            "train loss 0.35774093866348267 accuracy 0.98 | test loss 0.37824389338493347  accuracy 0.92\n",
            "train loss 0.3577415347099304 accuracy 0.99 | test loss 0.3783157169818878  accuracy 0.92\n",
            "train loss 0.3577422499656677 accuracy 0.98 | test loss 0.37827277183532715  accuracy 0.92\n",
            "train loss 0.3577405512332916 accuracy 0.98 | test loss 0.3782302737236023  accuracy 0.92\n",
            "train loss 0.35774168372154236 accuracy 0.99 | test loss 0.3783021569252014  accuracy 0.92\n",
            "train loss 0.3577413856983185 accuracy 0.98 | test loss 0.3782592713832855  accuracy 0.92\n",
            "train loss 0.35774001479148865 accuracy 0.98 | test loss 0.37824034690856934  accuracy 0.92\n",
            "train loss 0.3577406704425812 accuracy 0.99 | test loss 0.3783121407032013  accuracy 0.92\n",
            "train loss 0.35774123668670654 accuracy 0.98 | test loss 0.3782692551612854  accuracy 0.92\n",
            "train loss 0.35773956775665283 accuracy 0.98 | test loss 0.3782501816749573  accuracy 0.92\n",
            "train loss 0.35773977637290955 accuracy 0.99 | test loss 0.3782947361469269  accuracy 0.92\n",
            "train loss 0.3577400743961334 accuracy 0.98 | test loss 0.3782518804073334  accuracy 0.92\n",
            "train loss 0.3577391803264618 accuracy 0.99 | test loss 0.37829622626304626  accuracy 0.92\n",
            "train loss 0.3577399253845215 accuracy 0.98 | test loss 0.37825337052345276  accuracy 0.92\n",
            "train loss 0.3577387034893036 accuracy 0.98 | test loss 0.37828293442726135  accuracy 0.92\n",
            "train loss 0.3577391803264618 accuracy 0.98 | test loss 0.3782402276992798  accuracy 0.92\n",
            "train loss 0.3577389121055603 accuracy 0.99 | test loss 0.3783118426799774  accuracy 0.92\n",
            "train loss 0.3577399253845215 accuracy 0.98 | test loss 0.3782688081264496  accuracy 0.92\n",
            "train loss 0.35773834586143494 accuracy 0.98 | test loss 0.37824973464012146  accuracy 0.92\n",
            "train loss 0.3577379882335663 accuracy 0.99 | test loss 0.37829405069351196  accuracy 0.92\n",
            "train loss 0.35773882269859314 accuracy 0.98 | test loss 0.37825119495391846  accuracy 0.92\n",
            "train loss 0.35773754119873047 accuracy 0.98 | test loss 0.3782806694507599  accuracy 0.92\n",
            "train loss 0.35773801803588867 accuracy 0.98 | test loss 0.3782379925251007  accuracy 0.92\n",
            "train loss 0.35773780941963196 accuracy 0.99 | test loss 0.37830954790115356  accuracy 0.92\n",
            "train loss 0.35773882269859314 accuracy 0.98 | test loss 0.37826645374298096  accuracy 0.92\n",
            "train loss 0.357737272977829 accuracy 0.98 | test loss 0.3782474398612976  accuracy 0.92\n",
            "train loss 0.35773685574531555 accuracy 0.99 | test loss 0.3782918155193329  accuracy 0.92\n",
            "train loss 0.3577377200126648 accuracy 0.98 | test loss 0.378248929977417  accuracy 0.92\n",
            "train loss 0.35773634910583496 accuracy 0.99 | test loss 0.378305584192276  accuracy 0.92\n",
            "train loss 0.35773786902427673 accuracy 0.98 | test loss 0.37826254963874817  accuracy 0.92\n",
            "train loss 0.3577362596988678 accuracy 0.98 | test loss 0.3782583773136139  accuracy 0.92\n",
            "train loss 0.35773584246635437 accuracy 0.98 | test loss 0.37821584939956665  accuracy 0.92\n",
            "train loss 0.3577376902103424 accuracy 0.99 | test loss 0.37828773260116577  accuracy 0.92\n",
            "train loss 0.35773664712905884 accuracy 0.98 | test loss 0.37824487686157227  accuracy 0.92\n",
            "train loss 0.35773542523384094 accuracy 0.98 | test loss 0.37827444076538086  accuracy 0.92\n",
            "train loss 0.35773590207099915 accuracy 0.98 | test loss 0.37823179364204407  accuracy 0.93\n",
            "train loss 0.357735812664032 accuracy 0.99 | test loss 0.37830328941345215  accuracy 0.92\n",
            "train loss 0.35773664712905884 accuracy 0.98 | test loss 0.3782602548599243  accuracy 0.92\n",
            "train loss 0.35773521661758423 accuracy 0.98 | test loss 0.3782411813735962  accuracy 0.92\n",
            "train loss 0.3577348589897156 accuracy 0.99 | test loss 0.37828555703163147  accuracy 0.92\n",
            "train loss 0.3577355444431305 accuracy 0.98 | test loss 0.3782426714897156  accuracy 0.92\n",
            "train loss 0.3577342927455902 accuracy 0.99 | test loss 0.3782993257045746  accuracy 0.92\n",
            "train loss 0.3577357530593872 accuracy 0.98 | test loss 0.3782563805580139  accuracy 0.93\n",
            "train loss 0.3577342927455902 accuracy 0.98 | test loss 0.37825217843055725  accuracy 0.92\n",
            "train loss 0.35773375630378723 accuracy 0.98 | test loss 0.3782331645488739  accuracy 0.92\n",
            "train loss 0.3577345609664917 accuracy 0.99 | test loss 0.3783048987388611  accuracy 0.92\n",
            "train loss 0.357735276222229 accuracy 0.98 | test loss 0.3782617747783661  accuracy 0.92\n",
            "train loss 0.3577335774898529 accuracy 0.98 | test loss 0.3782193958759308  accuracy 0.93\n",
            "train loss 0.357734739780426 accuracy 0.99 | test loss 0.37829092144966125  accuracy 0.92\n",
            "train loss 0.357734352350235 accuracy 0.98 | test loss 0.378248006105423  accuracy 0.92\n",
            "train loss 0.3577328324317932 accuracy 0.98 | test loss 0.3782641887664795  accuracy 0.92\n",
            "train loss 0.3577331006526947 accuracy 0.98 | test loss 0.3782215416431427  accuracy 0.92\n",
            "train loss 0.35773372650146484 accuracy 0.99 | test loss 0.3782782256603241  accuracy 0.92\n",
            "train loss 0.3577333092689514 accuracy 0.98 | test loss 0.3782356083393097  accuracy 0.93\n",
            "train loss 0.3577324450016022 accuracy 0.99 | test loss 0.37830692529678345  accuracy 0.92\n",
            "train loss 0.35773417353630066 accuracy 0.98 | test loss 0.37824270129203796  accuracy 0.93\n",
            "train loss 0.3577321171760559 accuracy 0.98 | test loss 0.37825873494148254  accuracy 0.92\n",
            "train loss 0.35773199796676636 accuracy 0.98 | test loss 0.3782164752483368  accuracy 0.93\n",
            "train loss 0.35773298144340515 accuracy 0.99 | test loss 0.37828758358955383  accuracy 0.92\n",
            "train loss 0.35773277282714844 accuracy 0.98 | test loss 0.3782446086406708  accuracy 0.92\n",
            "train loss 0.3577314615249634 accuracy 0.98 | test loss 0.3782256543636322  accuracy 0.93\n",
            "train loss 0.35773196816444397 accuracy 0.99 | test loss 0.3782970607280731  accuracy 0.92\n",
            "train loss 0.3577326536178589 accuracy 0.98 | test loss 0.3782539367675781  accuracy 0.92\n",
            "train loss 0.3577309846878052 accuracy 0.98 | test loss 0.3782348930835724  accuracy 0.92\n",
            "train loss 0.35773101449012756 accuracy 0.99 | test loss 0.37830644845962524  accuracy 0.92\n",
            "train loss 0.35773250460624695 accuracy 0.98 | test loss 0.3782631456851959  accuracy 0.92\n",
            "train loss 0.35773077607154846 accuracy 0.98 | test loss 0.37822088599205017  accuracy 0.93\n",
            "train loss 0.3577311933040619 accuracy 0.99 | test loss 0.37829187512397766  accuracy 0.92\n",
            "train loss 0.35773155093193054 accuracy 0.98 | test loss 0.37824878096580505  accuracy 0.92\n",
            "train loss 0.357729971408844 accuracy 0.98 | test loss 0.3782299757003784  accuracy 0.93\n",
            "train loss 0.3577302396297455 accuracy 0.99 | test loss 0.37830138206481934  accuracy 0.92\n",
            "train loss 0.357731431722641 accuracy 0.98 | test loss 0.3782581388950348  accuracy 0.92\n",
            "train loss 0.3577297031879425 accuracy 0.98 | test loss 0.378216415643692  accuracy 0.93\n",
            "train loss 0.3577303886413574 accuracy 0.99 | test loss 0.37828710675239563  accuracy 0.92\n",
            "train loss 0.3577304780483246 accuracy 0.98 | test loss 0.37824442982673645  accuracy 0.93\n",
            "train loss 0.3577289879322052 accuracy 0.98 | test loss 0.378225713968277  accuracy 0.93\n",
            "train loss 0.35772940516471863 accuracy 0.99 | test loss 0.37829673290252686  accuracy 0.92\n",
            "train loss 0.35773035883903503 accuracy 0.98 | test loss 0.3782535493373871  accuracy 0.93\n",
            "train loss 0.35772860050201416 accuracy 0.98 | test loss 0.3782121539115906  accuracy 0.93\n",
            "train loss 0.35772964358329773 accuracy 0.99 | test loss 0.37828245759010315  accuracy 0.92\n",
            "train loss 0.35772940516471863 accuracy 0.98 | test loss 0.3782402276992798  accuracy 0.93\n",
            "train loss 0.35772812366485596 accuracy 0.98 | test loss 0.3782414197921753  accuracy 0.93\n",
            "train loss 0.3577277958393097 accuracy 0.98 | test loss 0.3782426416873932  accuracy 0.93\n",
            "train loss 0.3577274978160858 accuracy 0.98 | test loss 0.37822386622428894  accuracy 0.93\n",
            "train loss 0.3577283024787903 accuracy 0.99 | test loss 0.37829458713531494  accuracy 0.92\n",
            "train loss 0.35772910714149475 accuracy 0.98 | test loss 0.37825170159339905  accuracy 0.93\n",
            "train loss 0.3577273488044739 accuracy 0.98 | test loss 0.37821027636528015  accuracy 0.93\n",
            "train loss 0.3577284812927246 accuracy 0.99 | test loss 0.37828031182289124  accuracy 0.92\n",
            "train loss 0.35772812366485596 accuracy 0.98 | test loss 0.3782382905483246  accuracy 0.93\n",
            "train loss 0.35772666335105896 accuracy 0.98 | test loss 0.37825340032577515  accuracy 0.92\n",
            "train loss 0.35772690176963806 accuracy 0.98 | test loss 0.3782118558883667  accuracy 0.93\n",
            "train loss 0.3577274978160858 accuracy 0.99 | test loss 0.37828218936920166  accuracy 0.92\n",
            "train loss 0.35772764682769775 accuracy 0.98 | test loss 0.3782396614551544  accuracy 0.93\n",
            "train loss 0.35772624611854553 accuracy 0.98 | test loss 0.37822094559669495  accuracy 0.93\n",
            "train loss 0.357726514339447 accuracy 0.99 | test loss 0.37829139828681946  accuracy 0.92\n",
            "train loss 0.3577274978160858 accuracy 0.98 | test loss 0.3782484829425812  accuracy 0.93\n",
            "train loss 0.35772576928138733 accuracy 0.98 | test loss 0.3782069981098175  accuracy 0.93\n",
            "train loss 0.35772672295570374 accuracy 0.99 | test loss 0.37827688455581665  accuracy 0.92\n",
            "train loss 0.3577265739440918 accuracy 0.98 | test loss 0.37823486328125  accuracy 0.93\n",
            "train loss 0.35772520303726196 accuracy 0.98 | test loss 0.37821608781814575  accuracy 0.93\n",
            "train loss 0.35772573947906494 accuracy 0.99 | test loss 0.378286212682724  accuracy 0.92\n",
            "train loss 0.35772642493247986 accuracy 0.98 | test loss 0.3782437741756439  accuracy 0.93\n",
            "train loss 0.35772475600242615 accuracy 0.98 | test loss 0.37822484970092773  accuracy 0.93\n",
            "train loss 0.3577248156070709 accuracy 0.99 | test loss 0.3782680034637451  accuracy 0.92\n",
            "train loss 0.35772526264190674 accuracy 0.98 | test loss 0.3782258629798889  accuracy 0.93\n",
            "train loss 0.3577243983745575 accuracy 0.99 | test loss 0.37828153371810913  accuracy 0.93\n",
            "train loss 0.35772547125816345 accuracy 0.98 | test loss 0.3782396614551544  accuracy 0.93\n",
            "train loss 0.35772377252578735 accuracy 0.98 | test loss 0.3782181441783905  accuracy 0.93\n",
            "train loss 0.35772398114204407 accuracy 0.99 | test loss 0.37828779220581055  accuracy 0.93\n",
            "train loss 0.3577253520488739 accuracy 0.98 | test loss 0.37822505831718445  accuracy 0.93\n",
            "train loss 0.35772353410720825 accuracy 0.98 | test loss 0.378240168094635  accuracy 0.93\n",
            "train loss 0.3577233850955963 accuracy 0.98 | test loss 0.3782212436199188  accuracy 0.93\n",
            "train loss 0.3577233850955963 accuracy 0.99 | test loss 0.37829118967056274  accuracy 0.92\n",
            "train loss 0.35772478580474854 accuracy 0.98 | test loss 0.37824875116348267  accuracy 0.93\n",
            "train loss 0.35772308707237244 accuracy 0.98 | test loss 0.3782072067260742  accuracy 0.93\n",
            "train loss 0.3577236235141754 accuracy 0.99 | test loss 0.3782768249511719  accuracy 0.93\n",
            "train loss 0.35772383213043213 accuracy 0.98 | test loss 0.3782348930835724  accuracy 0.93\n",
            "train loss 0.3577224016189575 accuracy 0.98 | test loss 0.37821611762046814  accuracy 0.93\n",
            "train loss 0.35772261023521423 accuracy 0.99 | test loss 0.37828561663627625  accuracy 0.92\n",
            "train loss 0.3577236831188202 accuracy 0.98 | test loss 0.378243625164032  accuracy 0.93\n",
            "train loss 0.3577219545841217 accuracy 0.98 | test loss 0.3782021105289459  accuracy 0.93\n",
            "train loss 0.35772284865379333 accuracy 0.99 | test loss 0.3782716989517212  accuracy 0.93\n",
            "train loss 0.35772275924682617 accuracy 0.98 | test loss 0.3782297670841217  accuracy 0.93\n",
            "train loss 0.35772138833999634 accuracy 0.98 | test loss 0.37821105122566223  accuracy 0.93\n",
            "train loss 0.35772189497947693 accuracy 0.99 | test loss 0.3782806396484375  accuracy 0.93\n",
            "train loss 0.35772261023521423 accuracy 0.98 | test loss 0.37823861837387085  accuracy 0.93\n",
            "train loss 0.35772085189819336 accuracy 0.98 | test loss 0.37821975350379944  accuracy 0.93\n",
            "train loss 0.3577210605144501 accuracy 0.99 | test loss 0.378262460231781  accuracy 0.93\n",
            "train loss 0.3577214777469635 accuracy 0.98 | test loss 0.3782206177711487  accuracy 0.93\n",
            "train loss 0.3577205240726471 accuracy 0.98 | test loss 0.37824949622154236  accuracy 0.93\n",
            "train loss 0.35772067308425903 accuracy 0.98 | test loss 0.3782079219818115  accuracy 0.93\n",
            "train loss 0.35772085189819336 accuracy 0.99 | test loss 0.37827757000923157  accuracy 0.93\n",
            "train loss 0.3577214777469635 accuracy 0.98 | test loss 0.3782355785369873  accuracy 0.93\n",
            "train loss 0.3577197194099426 accuracy 0.98 | test loss 0.3782166540622711  accuracy 0.93\n",
            "train loss 0.3577199876308441 accuracy 0.99 | test loss 0.37825945019721985  accuracy 0.93\n",
            "train loss 0.3577203154563904 accuracy 0.98 | test loss 0.3782176971435547  accuracy 0.93\n",
            "train loss 0.3577193319797516 accuracy 0.99 | test loss 0.37826019525527954  accuracy 0.93\n",
            "train loss 0.3577200472354889 accuracy 0.98 | test loss 0.37821832299232483  accuracy 0.93\n",
            "train loss 0.3577190339565277 accuracy 0.99 | test loss 0.3782738745212555  accuracy 0.93\n",
            "train loss 0.3577202558517456 accuracy 0.98 | test loss 0.3782319128513336  accuracy 0.93\n",
            "train loss 0.35771864652633667 accuracy 0.98 | test loss 0.37821295857429504  accuracy 0.93\n",
            "train loss 0.35771888494491577 accuracy 0.99 | test loss 0.3782558739185333  accuracy 0.93\n",
            "train loss 0.35771915316581726 accuracy 0.98 | test loss 0.3782140612602234  accuracy 0.93\n",
            "train loss 0.3577183485031128 accuracy 0.99 | test loss 0.37828344106674194  accuracy 0.93\n",
            "train loss 0.35771989822387695 accuracy 0.98 | test loss 0.37824133038520813  accuracy 0.93\n",
            "train loss 0.35771819949150085 accuracy 0.98 | test loss 0.3781996965408325  accuracy 0.93\n",
            "train loss 0.3577185869216919 accuracy 0.99 | test loss 0.3782692551612854  accuracy 0.93\n",
            "train loss 0.35771894454956055 accuracy 0.98 | test loss 0.37822726368904114  accuracy 0.93\n",
            "train loss 0.35771751403808594 accuracy 0.98 | test loss 0.37820830941200256  accuracy 0.93\n",
            "train loss 0.3577176332473755 accuracy 0.99 | test loss 0.3782777786254883  accuracy 0.93\n",
            "train loss 0.3577187657356262 accuracy 0.98 | test loss 0.37823569774627686  accuracy 0.93\n",
            "train loss 0.35771703720092773 accuracy 0.98 | test loss 0.37819406390190125  accuracy 0.93\n",
            "train loss 0.3577178418636322 accuracy 0.99 | test loss 0.3782636523246765  accuracy 0.93\n",
            "train loss 0.3577178120613098 accuracy 0.98 | test loss 0.378221720457077  accuracy 0.93\n",
            "train loss 0.35771650075912476 accuracy 0.98 | test loss 0.3782028257846832  accuracy 0.93\n",
            "train loss 0.3577168881893158 accuracy 0.99 | test loss 0.3782724440097809  accuracy 0.93\n",
            "train loss 0.3577176630496979 accuracy 0.98 | test loss 0.37823042273521423  accuracy 0.93\n",
            "train loss 0.35771599411964417 accuracy 0.98 | test loss 0.37821143865585327  accuracy 0.93\n",
            "train loss 0.35771605372428894 accuracy 0.99 | test loss 0.37825411558151245  accuracy 0.93\n",
            "train loss 0.35771650075912476 accuracy 0.98 | test loss 0.37821224331855774  accuracy 0.93\n",
            "train loss 0.35771551728248596 accuracy 0.98 | test loss 0.37824103236198425  accuracy 0.93\n",
            "train loss 0.35771575570106506 accuracy 0.98 | test loss 0.3781992495059967  accuracy 0.93\n",
            "train loss 0.357715904712677 accuracy 0.99 | test loss 0.37826886773109436  accuracy 0.93\n",
            "train loss 0.35771647095680237 accuracy 0.98 | test loss 0.3782268762588501  accuracy 0.93\n",
            "train loss 0.35771486163139343 accuracy 0.98 | test loss 0.37820789217948914  accuracy 0.93\n",
            "train loss 0.357714980840683 accuracy 0.99 | test loss 0.37825068831443787  accuracy 0.93\n",
            "train loss 0.357715368270874 accuracy 0.98 | test loss 0.3782087564468384  accuracy 0.93\n",
            "train loss 0.35771438479423523 accuracy 0.99 | test loss 0.3782512843608856  accuracy 0.93\n",
            "train loss 0.35771510004997253 accuracy 0.98 | test loss 0.3782094120979309  accuracy 0.93\n",
            "train loss 0.35771411657333374 accuracy 0.99 | test loss 0.3782648742198944  accuracy 0.93\n",
            "train loss 0.35771527886390686 accuracy 0.98 | test loss 0.37822291254997253  accuracy 0.93\n",
            "train loss 0.3577137589454651 accuracy 0.98 | test loss 0.3782038688659668  accuracy 0.93\n",
            "train loss 0.3577139675617218 accuracy 0.99 | test loss 0.37827348709106445  accuracy 0.93\n",
            "train loss 0.3577151894569397 accuracy 0.98 | test loss 0.3782314360141754  accuracy 0.93\n",
            "train loss 0.3577134609222412 accuracy 0.98 | test loss 0.37818968296051025  accuracy 0.93\n",
            "train loss 0.3577142357826233 accuracy 0.99 | test loss 0.3782593011856079  accuracy 0.93\n",
            "train loss 0.3577141761779785 accuracy 0.98 | test loss 0.3782173693180084  accuracy 0.93\n",
            "train loss 0.3577127456665039 accuracy 0.98 | test loss 0.37821224331855774  accuracy 0.93\n",
            "train loss 0.3577125072479248 accuracy 0.98 | test loss 0.3782409727573395  accuracy 0.93\n",
            "train loss 0.3577130436897278 accuracy 0.98 | test loss 0.3781990706920624  accuracy 0.93\n",
            "train loss 0.35771268606185913 accuracy 0.99 | test loss 0.37826845049858093  accuracy 0.93\n",
            "train loss 0.3577137589454651 accuracy 0.98 | test loss 0.3782263994216919  accuracy 0.93\n",
            "train loss 0.35771217942237854 accuracy 0.98 | test loss 0.37820732593536377  accuracy 0.93\n",
            "train loss 0.35771191120147705 accuracy 0.99 | test loss 0.378249853849411  accuracy 0.93\n",
            "train loss 0.35771262645721436 accuracy 0.98 | test loss 0.3782079219818115  accuracy 0.93\n",
            "train loss 0.35771140456199646 accuracy 0.98 | test loss 0.37823665142059326  accuracy 0.93\n",
            "train loss 0.3577118515968323 accuracy 0.98 | test loss 0.3781948685646057  accuracy 0.93\n",
            "train loss 0.3577117919921875 accuracy 0.99 | test loss 0.37826433777809143  accuracy 0.93\n",
            "train loss 0.35771262645721436 accuracy 0.98 | test loss 0.37822225689888  accuracy 0.93\n",
            "train loss 0.35771098732948303 accuracy 0.98 | test loss 0.3782031536102295  accuracy 0.93\n",
            "train loss 0.3577108681201935 accuracy 0.99 | test loss 0.37824589014053345  accuracy 0.93\n",
            "train loss 0.35771143436431885 accuracy 0.98 | test loss 0.3782039284706116  accuracy 0.93\n",
            "train loss 0.3577102720737457 accuracy 0.99 | test loss 0.3782733082771301  accuracy 0.93\n",
            "train loss 0.3577122688293457 accuracy 0.98 | test loss 0.3782103657722473  accuracy 0.93\n",
            "train loss 0.3577099144458771 accuracy 0.98 | test loss 0.37822508811950684  accuracy 0.93\n",
            "train loss 0.3577100932598114 accuracy 0.98 | test loss 0.3781833052635193  accuracy 0.93\n",
            "train loss 0.35771089792251587 accuracy 0.99 | test loss 0.37825271487236023  accuracy 0.93\n",
            "train loss 0.3577108383178711 accuracy 0.98 | test loss 0.3782106339931488  accuracy 0.93\n",
            "train loss 0.3577094078063965 accuracy 0.98 | test loss 0.37819159030914307  accuracy 0.93\n",
            "train loss 0.35770994424819946 accuracy 0.99 | test loss 0.37826094031333923  accuracy 0.93\n",
            "train loss 0.35771068930625916 accuracy 0.98 | test loss 0.3782188296318054  accuracy 0.93\n",
            "train loss 0.3577089309692383 accuracy 0.98 | test loss 0.37817707657814026  accuracy 0.93\n",
            "train loss 0.35771021246910095 accuracy 0.99 | test loss 0.37824657559394836  accuracy 0.93\n",
            "train loss 0.357709676027298 accuracy 0.98 | test loss 0.3782046139240265  accuracy 0.93\n",
            "train loss 0.3577083945274353 accuracy 0.98 | test loss 0.3782133162021637  accuracy 0.93\n",
            "train loss 0.3577081263065338 accuracy 0.98 | test loss 0.37821418046951294  accuracy 0.93\n",
            "train loss 0.3577079772949219 accuracy 0.98 | test loss 0.3781723976135254  accuracy 0.93\n",
            "train loss 0.35770976543426514 accuracy 0.99 | test loss 0.37824201583862305  accuracy 0.93\n",
            "train loss 0.35770872235298157 accuracy 0.98 | test loss 0.37820014357566833  accuracy 0.93\n",
            "train loss 0.35770758986473083 accuracy 0.99 | test loss 0.3782426118850708  accuracy 0.93\n",
            "train loss 0.35770851373672485 accuracy 0.98 | test loss 0.3782006502151489  accuracy 0.93\n",
            "train loss 0.35770729184150696 accuracy 0.98 | test loss 0.3782093822956085  accuracy 0.93\n",
            "train loss 0.3577069640159607 accuracy 0.98 | test loss 0.37822410464286804  accuracy 0.93\n",
            "train loss 0.35770735144615173 accuracy 0.98 | test loss 0.37818217277526855  accuracy 0.93\n",
            "train loss 0.35770776867866516 accuracy 0.99 | test loss 0.37823763489723206  accuracy 0.93\n",
            "train loss 0.35770756006240845 accuracy 0.98 | test loss 0.37819570302963257  accuracy 0.93\n",
            "train loss 0.35770660638809204 accuracy 0.99 | test loss 0.37826505303382874  accuracy 0.93\n",
            "train loss 0.35770830512046814 accuracy 0.98 | test loss 0.378222793340683  accuracy 0.93\n",
            "train loss 0.35770654678344727 accuracy 0.98 | test loss 0.3781810402870178  accuracy 0.93\n",
            "train loss 0.35770687460899353 accuracy 0.99 | test loss 0.37825050950050354  accuracy 0.93\n",
            "train loss 0.35770732164382935 accuracy 0.98 | test loss 0.37820836901664734  accuracy 0.93\n",
            "train loss 0.3577060103416443 accuracy 0.98 | test loss 0.3781892955303192  accuracy 0.93\n",
            "train loss 0.3577059209346771 accuracy 0.99 | test loss 0.3782586455345154  accuracy 0.93\n",
            "train loss 0.357707142829895 accuracy 0.98 | test loss 0.37821653485298157  accuracy 0.93\n",
            "train loss 0.3577055037021637 accuracy 0.98 | test loss 0.37819746136665344  accuracy 0.93\n",
            "train loss 0.35770517587661743 accuracy 0.99 | test loss 0.37824007868766785  accuracy 0.93\n",
            "train loss 0.3577059805393219 accuracy 0.98 | test loss 0.3781980872154236  accuracy 0.93\n",
            "train loss 0.35770460963249207 accuracy 0.98 | test loss 0.3782128095626831  accuracy 0.93\n",
            "train loss 0.357704758644104 accuracy 0.98 | test loss 0.37819358706474304  accuracy 0.93\n",
            "train loss 0.3577047288417816 accuracy 0.99 | test loss 0.37824901938438416  accuracy 0.93\n",
            "train loss 0.3577057421207428 accuracy 0.98 | test loss 0.37820687890052795  accuracy 0.93\n",
            "train loss 0.3577040731906891 accuracy 0.98 | test loss 0.37819892168045044  accuracy 0.93\n",
            "train loss 0.3577040731906891 accuracy 0.98 | test loss 0.378234326839447  accuracy 0.93\n",
            "train loss 0.357704758644104 accuracy 0.98 | test loss 0.37819236516952515  accuracy 0.93\n",
            "train loss 0.35770368576049805 accuracy 0.99 | test loss 0.37823486328125  accuracy 0.93\n",
            "train loss 0.3577044606208801 accuracy 0.98 | test loss 0.3781927525997162  accuracy 0.93\n",
            "train loss 0.3577033281326294 accuracy 0.99 | test loss 0.3782482147216797  accuracy 0.93\n",
            "train loss 0.35770463943481445 accuracy 0.98 | test loss 0.3782060444355011  accuracy 0.93\n",
            "train loss 0.3577031195163727 accuracy 0.98 | test loss 0.3782006800174713  accuracy 0.93\n",
            "train loss 0.3577026426792145 accuracy 0.98 | test loss 0.3781816065311432  accuracy 0.93\n",
            "train loss 0.35770362615585327 accuracy 0.99 | test loss 0.3782510757446289  accuracy 0.93\n",
            "train loss 0.3577041029930115 accuracy 0.98 | test loss 0.37820884585380554  accuracy 0.93\n",
            "train loss 0.3577024042606354 accuracy 0.98 | test loss 0.3781670331954956  accuracy 0.93\n",
            "train loss 0.35770383477211 accuracy 0.99 | test loss 0.3782365322113037  accuracy 0.93\n",
            "train loss 0.35770314931869507 accuracy 0.98 | test loss 0.3781944215297699  accuracy 0.93\n",
            "train loss 0.35770174860954285 accuracy 0.99 | test loss 0.37823691964149475  accuracy 0.93\n",
            "train loss 0.3577028810977936 accuracy 0.98 | test loss 0.37819480895996094  accuracy 0.93\n",
            "train loss 0.35770151019096375 accuracy 0.98 | test loss 0.37817567586898804  accuracy 0.93\n",
            "train loss 0.3577024042606354 accuracy 0.99 | test loss 0.37824514508247375  accuracy 0.93\n",
            "train loss 0.35770273208618164 accuracy 0.98 | test loss 0.37820297479629517  accuracy 0.93\n",
            "train loss 0.35770103335380554 accuracy 0.98 | test loss 0.37818384170532227  accuracy 0.93\n",
            "train loss 0.35770148038864136 accuracy 0.99 | test loss 0.37825316190719604  accuracy 0.93\n",
            "train loss 0.3577025532722473 accuracy 0.98 | test loss 0.3782108724117279  accuracy 0.93\n",
            "train loss 0.35770082473754883 accuracy 0.98 | test loss 0.3781689405441284  accuracy 0.93\n",
            "train loss 0.35770177841186523 accuracy 0.99 | test loss 0.3782384395599365  accuracy 0.93\n",
            "train loss 0.3577015697956085 accuracy 0.98 | test loss 0.3781962990760803  accuracy 0.93\n",
            "train loss 0.35770002007484436 accuracy 0.98 | test loss 0.37819716334342957  accuracy 0.93\n",
            "train loss 0.3576997220516205 accuracy 0.98 | test loss 0.3781979978084564  accuracy 0.93\n",
            "train loss 0.35769960284233093 accuracy 0.98 | test loss 0.378176212310791  accuracy 0.93\n",
            "train loss 0.35770025849342346 accuracy 0.99 | test loss 0.3782455325126648  accuracy 0.93\n",
            "train loss 0.3577011823654175 accuracy 0.98 | test loss 0.37820327281951904  accuracy 0.93\n",
            "train loss 0.35769954323768616 accuracy 0.98 | test loss 0.37818393111228943  accuracy 0.93\n",
            "train loss 0.3576994240283966 accuracy 0.99 | test loss 0.37825319170951843  accuracy 0.93\n",
            "train loss 0.35770103335380554 accuracy 0.98 | test loss 0.37821081280708313  accuracy 0.93\n",
            "train loss 0.3576992452144623 accuracy 0.98 | test loss 0.3781689405441284  accuracy 0.93\n",
            "train loss 0.3576996624469757 accuracy 0.99 | test loss 0.3782382905483246  accuracy 0.93\n",
            "train loss 0.3576999604701996 accuracy 0.98 | test loss 0.3781960904598236  accuracy 0.93\n",
            "train loss 0.3576985001564026 accuracy 0.98 | test loss 0.3781769871711731  accuracy 0.93\n",
            "train loss 0.35769882798194885 accuracy 0.99 | test loss 0.3782463073730469  accuracy 0.93\n",
            "train loss 0.35769981145858765 accuracy 0.98 | test loss 0.37820395827293396  accuracy 0.93\n",
            "train loss 0.3576980531215668 accuracy 0.98 | test loss 0.37816205620765686  accuracy 0.93\n",
            "train loss 0.35769903659820557 accuracy 0.99 | test loss 0.37823158502578735  accuracy 0.93\n",
            "train loss 0.35769882798194885 accuracy 0.98 | test loss 0.37818941473960876  accuracy 0.93\n",
            "train loss 0.35769742727279663 accuracy 0.98 | test loss 0.37817031145095825  accuracy 0.93\n",
            "train loss 0.35769811272621155 accuracy 0.99 | test loss 0.37823981046676636  accuracy 0.93\n",
            "train loss 0.3576986491680145 accuracy 0.98 | test loss 0.3781975209712982  accuracy 0.93\n",
            "train loss 0.3576969802379608 accuracy 0.98 | test loss 0.3781782388687134  accuracy 0.93\n",
            "train loss 0.3576972484588623 accuracy 0.99 | test loss 0.3782476782798767  accuracy 0.93\n",
            "train loss 0.3576984703540802 accuracy 0.98 | test loss 0.3782053291797638  accuracy 0.93\n",
            "train loss 0.3576967418193817 accuracy 0.98 | test loss 0.3781633973121643  accuracy 0.93\n",
            "train loss 0.3576975166797638 accuracy 0.99 | test loss 0.37823286652565  accuracy 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_decision_boundary(model_1, X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "RsW1mUo3g8qD",
        "outputId": "2b65f343-ad5f-4bfa-c85a-5fe9b21cdc04"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "reVYoxcfinvI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}